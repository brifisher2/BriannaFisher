<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Here is some of my work in R Studio!</title>

<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>









<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark the anchor link active (and if it's in a dropdown, also mark that active)
  var dropdown = menuAnchor.closest('li.dropdown');
  if (window.bootstrap) { // Bootstrap 4+
    menuAnchor.addClass('active');
    dropdown.find('> .dropdown-toggle').addClass('active');
  } else { // Bootstrap 3
    menuAnchor.parent().addClass('active');
    dropdown.addClass('active');
  }

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Brianna Fisher</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="About.html">About</a>
</li>
<li>
  <a href="CV.html">CV / Published Work</a>
</li>
<li>
  <a href="portfolio2.html">Portfolio</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">Here is some of my work in R Studio!</h1>

</div>


<div id="portfolio" class="section level1 tabset">
<h1>Portfolio</h1>
<div id="introduction-to-data-science" class="section level2">
<h2>Introduction to Data Science</h2>
<h2>
Introduction to Data Science
</h2>
<div id="problem-set-1" class="section level3">
<h3>Problem Set 1</h3>
<p><strong>Question 1a</strong></p>
<pre class="r"><code>state &lt;- c(1, 2, 3, 4, 5)
pop &lt;- c(12.80, 19.45, 3.56, 0.97, 8.88)
cases &lt;- c(139623, 439238, 52095, 17857, 196337)</code></pre>
<p>The first vector, state, is created using the concatenate function to combine the five states within the data set (state 1, 2, 3, 4, and 5). The second vector, pop, is created using the concatenate function to combine the populations for those five states (12.80, 19.45, 3.56, 0.97, 8.88). The third vector, cases, is created using the concatenate function to combine the numbers of cases for the five states within the data set (139623, 439238, 52095, 17857, 196337). Now, these three vectors store all of the data on COVID-19 for five northeastern states as provided within the data table.</p>
<p><strong>Question 1b</strong></p>
<pre class="r"><code>ne.covid &lt;- cbind(state, pop, cases)
ne.covid</code></pre>
<pre><code>##      state   pop  cases
## [1,]     1 12.80 139623
## [2,]     2 19.45 439238
## [3,]     3  3.56  52095
## [4,]     4  0.97  17857
## [5,]     5  8.88 196337</code></pre>
<p>The object ne.covid was created by combining the three columns (state, population, cases) from the data set into a matrix. The function cbind was implemented and assigned to ne.covid. Once created, running ne.covid displays the same data table but in R.</p>
<p><strong>Question 1c</strong></p>
<pre class="r"><code>mean(ne.covid[,2])</code></pre>
<pre><code>## [1] 9.132</code></pre>
<pre class="r"><code>median(ne.covid[,2])</code></pre>
<pre><code>## [1] 8.88</code></pre>
<pre class="r"><code>max(ne.covid[,2])</code></pre>
<pre><code>## [1] 19.45</code></pre>
<pre class="r"><code>min(ne.covid[,2])</code></pre>
<pre><code>## [1] 0.97</code></pre>
<p>The mean of the second column of ne.covid is 9.132, the median is 8.88, the maximum is 19.45, and the minimum is 0.97.</p>
<p><strong>Question 1d</strong></p>
<pre class="r"><code>mean(ne.covid[,3])</code></pre>
<pre><code>## [1] 169030</code></pre>
<pre class="r"><code>median(ne.covid[,3])</code></pre>
<pre><code>## [1] 139623</code></pre>
<pre class="r"><code>max(ne.covid[,3])</code></pre>
<pre><code>## [1] 439238</code></pre>
<pre class="r"><code>min(ne.covid[,3])</code></pre>
<pre><code>## [1] 17857</code></pre>
<p>The mean of the third column of ne.covid is 169030, the median is 139623, the maximum is 439238, and the minimum is 17857.</p>
<p><strong>Question 1e</strong></p>
<pre class="r"><code>#creating a vector for state population in thousands
pop.in.1000s &lt;- pop*1000

#creating a vector for covid-19 cases per 1000 residenrs
cases.per.1000 &lt;- cases /pop.in.1000s</code></pre>
<p>The vector cases.per.1000 is created by assigning the result of the cases divided by 1000 to the vector. This vector represents the number of COVID-19 cases in each state per 1000 residents.</p>
<p><strong>Question 1f</strong></p>
<pre class="r"><code>state_chr &lt;- c(&quot;PA&quot;, &quot;NY&quot;, &quot;CT&quot;, &quot;DE&quot;, &quot;NJ&quot;)

plot(y=cases.per.1000, x=pop, xlab = &quot;Population in Millions&quot;, ylab = &quot;Cases per 1000 Residents&quot;, main = &quot;COVID-19 in the Northeast&quot;, type = &quot;n&quot;)</code></pre>
<p><img src="portfolio2_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<pre class="r"><code>plot(y=cases.per.1000, x=pop, xlab = &quot;Population in Millions&quot;, ylab = &quot;Cases per 1000 Residents&quot;, main = &quot;COVID-19 in the Northeast&quot;, text(x = pop, y = cases.per.1000, labels = state_chr))</code></pre>
<p><img src="portfolio2_files/figure-html/unnamed-chunk-6-2.png" width="672" /> The scatterplot “COVID-19 in the Northeast” was created by using the plot function. Within the plot, y is designated as cases.per.1000, x is designated as population in millisons, the x-axis is labeled population with the xlab function, and the y-axis is labeled Cases per 1000 Residents with the ylab function. The title is created with the main function, and is labeled COVID-19 in the Northeast. The states are assigned to their corresponding dot on the scatterplot with the text function.</p>
<p><strong>Question 1g</strong></p>
<pre class="r"><code>#adding cases.per.1000 and state_chr as columns to the ne.covid matrix
ne.covid &lt;- cbind(ne.covid, cases.per.1000, state_chr)

#subsetting to identify the state most affected by COVID 19
ne.covid[ne.covid[, &quot;cases.per.1000&quot;] == max(cases.per.1000), c(&quot;state_chr&quot;, &quot;cases.per.1000&quot;)]</code></pre>
<pre><code>##          state_chr     cases.per.1000 
##               &quot;NY&quot; &quot;22.5829305912596&quot;</code></pre>
<pre class="r"><code>#subsetting to identify the state least affected by COVID 19
ne.covid[ne.covid[, &quot;cases.per.1000&quot;] == min(cases.per.1000), c(&quot;state_chr&quot;, &quot;cases.per.1000&quot;)]</code></pre>
<pre><code>##      state_chr cases.per.1000 
##           &quot;PA&quot; &quot;10.908046875&quot;</code></pre>
<p>New York has been the most affected by COVID-19, with around 22.58 cases per 1000 residents. Pennsylvania has been the least affceted by COVID-19, with about 10.91 cases per 1000 residents.</p>
<p><strong>Question 1h</strong> If I could get one more piece of information about COVID-19 to describe how affected each of these states are, it would be the death rates. The death rates would signify the level of impact COVID-19 had on the states, as some people within the cases category may be asymptomatic or have mild symptoms and are okay now.</p>
<p><strong>Question 2a</strong></p>
<pre class="r"><code>load(&quot;/Users/briannafisher/Dropbox/Github/BriannaFisher/data/2019MLBTeamsData.Rdata&quot;)
bb$avgattpergame &lt;- as.numeric(bb$home.attendance/bb$games.played)
median(bb$avgattpergame)</code></pre>
<pre><code>## [1] 14055.35</code></pre>
<pre class="r"><code>max(bb$avgattpergame)</code></pre>
<pre><code>## [1] 24532.77</code></pre>
<pre class="r"><code>min(bb$avgattpergame)</code></pre>
<pre><code>## [1] 5008.037</code></pre>
<p>Because there are an even number of teams, no singular team had the median average attendance of 14055.35 but the two in the middle were the Washington Nationals (with a median average attendance of 13949.27) and the Minnesota Twins (with a median average attendance of 14161.43). The team with the maximum average attendance per game was the Los Angeles Dodgers, with a maximum of 24532.77. The team with the minimum average attendance per game was the Miami Marlins, with a minimum of 5008.037.</p>
<p><strong>Question 2b</strong></p>
<pre class="r"><code>bb$teambattavg &lt;- as.numeric(bb$hits/bb$at.bats)
median(bb$teambattavg)</code></pre>
<pre><code>## [1] 0.2492307</code></pre>
<pre class="r"><code>max(bb$teambattavg)</code></pre>
<pre><code>## [1] 0.2740068</code></pre>
<pre class="r"><code>min(bb$teambattavg)</code></pre>
<pre><code>## [1] 0.2364828</code></pre>
<p>Because there are an even number of teams, no singular team had the median team batting average of 0.2492307 but the two in the middle were the Oakland Athletics (with a median team batting average of 0.2488761) and the Cleveland Indians (with a median team batting average of 0.2495853). The team with the maximum batting average is the Houston Astros with a maximum of 0.2740068. The team with the minimum batting average is the Toronto Blue Jays with a minimum of 0.2364828.</p>
<p><strong>Question 2c</strong></p>
<pre class="r"><code>plot(y=bb$avgattpergame, x=bb$teambattavg, xlab = &quot;Team Batting Average&quot;, 
     ylab = &quot;Average Attendance Per Game&quot;, main = &quot;MLB 2019 Data&quot;)</code></pre>
<p><img src="portfolio2_files/figure-html/unnamed-chunk-10-1.png" width="672" /> The graph looks very spread out, with the dots in seemingly randomly places. It is fairly nonlinear with no clear direction or association. The graph tells you that there is no relationship between team skill and attendance.</p>
<p><strong>Question 2d</strong></p>
<pre class="r"><code>bb$runs.pitch &lt;- as.numeric(bb$opponent.runs/bb$outs.pitched)
plot(y=bb$avgattpergame, x=bb$runs.pitch, xlab = &quot;Opponent Runs per Outs Pitched&quot;, 
     ylab = &quot;Average Attendance Per Game&quot;, main = &quot;MLB 2019 Data 2&quot;)</code></pre>
<p><img src="portfolio2_files/figure-html/unnamed-chunk-11-1.png" width="672" /> The graph looks like the lower the opponent runs per outs pitched, the higher the average attendance per game. The same is for the opposite, the lower the average attendance per game, the higher the opponent runs per outs pitched. There are some outliers, though, that do not fit the pattern. This tells you that while there is not a linear relationship between team skill and attendance, there is an association between the two.</p>
<p><strong>Question 2e</strong></p>
<pre class="r"><code>bb$teamwinper &lt;- as.numeric(bb$wins/bb$games.played)
plot(y=bb$teamwinper, x=bb$teambattavg, xlab = &quot;Team Batting Average&quot;, 
     ylab = &quot;Team Winning Percentage&quot;, main = &quot;MLB 2019 Data 3&quot;)</code></pre>
<p><img src="portfolio2_files/figure-html/unnamed-chunk-12-1.png" width="672" /> The graph looks more linear than the other two, with team winning percentage increasing as team batting average increases. This tells you that there is a positive relationship between team batting average and team winning percentage.</p>
<p><strong>Question 2 Bonus</strong></p>
<pre class="r"><code>prediction &lt;- lm(formula = teamwinper ~ teambattavg, data = bb)
plot(bb$teamwinper ~ bb$teambattavg, xlab = &quot;Team Batting Average&quot;, 
     ylab = &quot;Team Winning Percentage&quot;, main = &quot;MLB 2019 Data 3&quot;)
abline(prediction)</code></pre>
<p><img src="portfolio2_files/figure-html/unnamed-chunk-13-1.png" width="672" /> To make a better prediction of a team’s winning percentage, the least squares regression line can be calculated and plotted in order to show where the predicted values would lie. This line is used to predict the value of y, or team winning percentage, for any value of x, or team batting average.</p>
<p><strong>Question 3a</strong></p>
<pre class="r"><code>recentgrads &lt;- read.csv(&quot;/Users/briannafisher/Dropbox/Github/BriannaFisher/data/recentgrads.csv&quot;, header = TRUE, na=&quot;NA&quot;)
ncol(recentgrads)</code></pre>
<pre><code>## [1] 15</code></pre>
<pre class="r"><code>nrow(recentgrads)</code></pre>
<pre><code>## [1] 173</code></pre>
<p>There are 15 columns and 173 rows in the “recentgrads” data set. The unit of analysis of the data is major, as the data focuses on the jobs college graduates received depending on their major.</p>
<p><strong>Question 3b</strong></p>
<pre class="r"><code>table(recentgrads$Major_category)</code></pre>
<pre><code>## 
##     Agriculture &amp; Natural Resources                                Arts 
##                                  10                                   8 
##              Biology &amp; Life Science                            Business 
##                                  14                                  13 
##         Communications &amp; Journalism             Computers &amp; Mathematics 
##                                   4                                  11 
##                           Education                         Engineering 
##                                  16                                  29 
##                              Health           Humanities &amp; Liberal Arts 
##                                  12                                  15 
## Industrial Arts &amp; Consumer Services                   Interdisciplinary 
##                                   7                                   1 
##                 Law &amp; Public Policy                   Physical Sciences 
##                                   5                                  10 
##            Psychology &amp; Social Work                      Social Science 
##                                   9                                   9</code></pre>
<p>There are 16 different major categories that the data are divided into. The engineering category has the most majors, with 29 different majors.</p>
<p><strong>Question 3c</strong></p>
<pre class="r"><code>sum(recentgrads$Women, na.rm = T)</code></pre>
<pre><code>## [1] 3895228</code></pre>
<pre class="r"><code>percentwomen &lt;- sum(recentgrads$Women, na.rm = T)/sum(recentgrads$Total, na.rm = T)
percentwomen * 100</code></pre>
<pre><code>## [1] 57.52255</code></pre>
<p>There are 3,895,228 women included in the dataset. 57.52% of the people in the dataset are women.</p>
<p><strong>Question 3d</strong></p>
<pre class="r"><code>recentgrads$womengrads &lt;- as.numeric(recentgrads$Women/recentgrads$Total)
order(recentgrads$womengrads, na.last = T)</code></pre>
<pre><code>##   [1]  74  67  27   2   4   9   1 107 112  12   6   3  51  53  82  15  29  10
##  [19]  11  66  21  26  76  20  46  39  32  18  43  54  25  44  72  23  85 113
##  [37]  14  16 111  64  34  28  24 144  36   5  31  17  19  37 106 108  73  80
##  [55] 159  33 136  65 142  63  70  38  48  58  13   7 148  42 115  59  86  77
##  [73]  95  90  79 103 140  75 147 118  83  68  41  47  84 126   8  69 123  30
##  [91]  98  55 122 133  81  93 161  60  91  62 134 124 143  78 102 168  61  57
## [109] 169 109 131  71 128 121 117 167 150  94  88  97 145 137 141  50 166  96
## [127] 158 138  92 163  49 125 100 160 127 120 162 116 130 154  87  40 153  45
## [145]  99 132 105 110 135 146 119 172 156 171 155 114 170 149  56 104 129 173
## [163]  89  35 152 157 101 151 139  52 164 165  22</code></pre>
<pre class="r"><code>recentgrads[74,]</code></pre>
<pre><code>##    Major_code                 Major Total Men Women
## 74       3801 MILITARY TECHNOLOGIES   124 124     0
##                         Major_category Employed Full_time Part_time
## 74 Industrial Arts &amp; Consumer Services        0       111         0
##    Full_time_year_round Unemployed Unemployment_rate Median P25th P75th
## 74                  111          0                 0  40000 40000 40000
##    womengrads
## 74          0</code></pre>
<pre class="r"><code>order(recentgrads$womengrads, na.last = F)</code></pre>
<pre><code>##   [1]  22  74  67  27   2   4   9   1 107 112  12   6   3  51  53  82  15  29
##  [19]  10  11  66  21  26  76  20  46  39  32  18  43  54  25  44  72  23  85
##  [37] 113  14  16 111  64  34  28  24 144  36   5  31  17  19  37 106 108  73
##  [55]  80 159  33 136  65 142  63  70  38  48  58  13   7 148  42 115  59  86
##  [73]  77  95  90  79 103 140  75 147 118  83  68  41  47  84 126   8  69 123
##  [91]  30  98  55 122 133  81  93 161  60  91  62 134 124 143  78 102 168  61
## [109]  57 169 109 131  71 128 121 117 167 150  94  88  97 145 137 141  50 166
## [127]  96 158 138  92 163  49 125 100 160 127 120 162 116 130 154  87  40 153
## [145]  45  99 132 105 110 135 146 119 172 156 171 155 114 170 149  56 104 129
## [163] 173  89  35 152 157 101 151 139  52 164 165</code></pre>
<pre class="r"><code>recentgrads[165,]</code></pre>
<pre><code>##     Major_code                     Major Total  Men Women Major_category
## 165       2307 EARLY CHILDHOOD EDUCATION 37589 1167 36422      Education
##     Employed Full_time Part_time Full_time_year_round Unemployed
## 165    32551     27569      7001                20748       1360
##     Unemployment_rate Median P25th P75th womengrads
## 165        0.04010498  28000 21000 35000  0.9689537</code></pre>
<p>The major that had the highest percentage of women graduates is education, with a percentage of 96.90%. The major that had the lowest percentage of women graduates is military technologies, with a percentage if 0%.</p>
<p><strong>Question 4</strong> Random sampling is such a vital component of survey research because it ensures that there is no bias within the sample. If people were chosen to take a survey, the surveyor could have picked specific people who they know will prove their hypothesis and therefore discredit the validity and accuracy of the survey. Random sampling also ensures that the results are representative of the entire population, which is why a sample of 1500 people is enough to learn about the whole US population. If the sample is completely random, then we can be confident that a sample of only 1500 people will include people who represent all different backgrounds and interests within the country.</p>
</div>
<div id="problem-set-2" class="section level3">
<h3>Problem Set 2</h3>
<p><strong>Question 1a</strong></p>
<pre class="r"><code>load(&quot;/Users/briannafisher/Dropbox/Github/BriannaFisher/data/exitpoll2016.RData&quot;)
require(tidyverse)
exit.untouched &lt;- exit

#The unit of observation is people, and the dataset had more than one row for every observation.
#Because there are two rows for each observation, using the spread function will condense each repeated row into one. Since the favorable candidate and favorable rating variables are the ones repeated, they are used to create the new columns
exit &lt;- spread(exit,
                 key = favorable.cand,
                 value = favorable.rating)
head(exit)</code></pre>
<pre><code>##       id PRSPA16 PHIL3 partyid married       sex.age.race educ.hs educ.somecoll
## 1 138951       2     3       2       1   male 30-44 White       1             0
## 2 138952       1     2       1       1     male 65+ White       0             0
## 3 138953       2     3       1       2   male 45-65 White       1             0
## 4 138954       1     1       1       1   female 65+ White       0             0
## 5 138955       1     1       2       2 female 18-29 White       0             1
## 6 138956       2     3       2       1     male 65+ White       1             0
##   educ.bach educ.postgrad clinton trump
## 1         0             0       2     1
## 2         0             1       1     2
## 3         0             0       2     1
## 4         0             1       1     2
## 5         0             0       1     2
## 6         0             0       2     1</code></pre>
<pre class="r"><code>#Using the recode function, the values of 1 and 2 can be replaced for favorable and unfavorable
attributes(exit.untouched$favorable.rating)</code></pre>
<pre><code>## $label
## [1] &quot;Is your opinion of [favorable.cand]:&quot;
## 
## $labels
##   favorable unfavorable        omit 
##           1           2           9</code></pre>
<pre class="r"><code>exit$clinton &lt;- recode(exit$clinton, &quot;1&quot; = &quot;Favorable&quot;, &quot;2&quot; = &quot;Unfavorable&quot;)
exit$trump &lt;- recode(exit$trump, &quot;1&quot; = &quot;Favorable&quot;, &quot;2&quot; = &quot;Unfavorable&quot;)</code></pre>
<p><strong>Question 1b</strong></p>
<pre class="r"><code>#the gather function brings responses that are spread over multiple columns into one. The recode function
#changes the data from numeric values (0/1) that don&#39;t make sense
exit &lt;- gather(exit,
                 key = &quot;educ&quot;, 
                 value = &quot;val&quot;,
               starts_with(&quot;educ.&quot;))

exit$educ &lt;- recode(exit$educ, &quot;educ.hs&quot; = &quot;hs&quot;, &quot;educ.somecoll&quot; = &quot;some college&quot;, 
                    &quot;educ.bach&quot; = &quot;bachelors&quot;, &quot;educ.postgrad&quot; = &quot;postgrad&quot;)

#Since all unknown values are coded as 99 (using attributes checks this), I can recode those values to NA
attributes(exit.untouched$educ.hs)</code></pre>
<pre><code>## $label
## [1] &quot;What was the last grade of school you completed? [high school or less]&quot;
## 
## $labels
##     yes      no unknown 
##       1       0      99</code></pre>
<pre class="r"><code>attributes(exit.untouched$educ.somecoll)</code></pre>
<pre><code>## $label
## [1] &quot;What was the last grade of school you completed? [some college/assoc. degree]&quot;
## 
## $labels
##     yes      no unknown 
##       1       0      99</code></pre>
<pre class="r"><code>attributes(exit.untouched$educ.bach)</code></pre>
<pre><code>## $label
## [1] &quot;What was the last grade of school you completed? [college graduate]&quot;
## 
## $labels
##     yes      no unknown 
##       1       0      99</code></pre>
<pre class="r"><code>attributes(exit.untouched$educ.postgrad)</code></pre>
<pre><code>## $label
## [1] &quot;What was the last grade of school you completed? [postgraduate study]&quot;
## 
## $labels
##     yes      no unknown 
##       1       0      99</code></pre>
<pre class="r"><code>exit[exit$educ == &quot;99&quot;] &lt;- NA

exit$val &lt;- NULL

#Could have also changed the names by reshaping the education data
exit$educ[exit$educ == &quot;educ.hs&quot;] &lt;- &quot;hs&quot;
exit$educ[exit$educ == &quot;educ.somecoll&quot;] &lt;- &quot;some college&quot;
exit$educ[exit$educ == &quot;educ.bach&quot;] &lt;- &quot;bachelors&quot;
exit$educ[exit$educ == &quot;educ.postgrad&quot;] &lt;- &quot;postgrad&quot;</code></pre>
<p><strong>Question 1c</strong></p>
<pre class="r"><code>#The separate function splits the sex.age.race column into three separate columns
exit &lt;- separate(exit,
         col = &quot;sex.age.race&quot;,
         into = c(&quot;sex&quot;,&quot;age&quot;,&quot;race&quot;), sep = &quot; &quot;)

#Converting the columns to factors and then replacing the missing/unknown values with NA cleans the data
exit$age = as.factor(exit$age)
summary(exit$age)</code></pre>
<pre><code>##  -999 18-29 30-44 45-65   65+ 
##    52  1948  2924  4600  2304</code></pre>
<pre class="r"><code>exit$age[which(exit$age == &quot;-999&quot;)] = NA
summary(exit$age)</code></pre>
<pre><code>##  -999 18-29 30-44 45-65   65+  NA&#39;s 
##     0  1948  2924  4600  2304    52</code></pre>
<pre class="r"><code>exit$sex = as.factor(exit$sex)
summary(exit$sex)</code></pre>
<pre><code>##  female    male unknown 
##    6484    5328      16</code></pre>
<pre class="r"><code>exit$sex[which(exit$sex == &quot;unknown&quot;)] = NA
summary(exit$sex)</code></pre>
<pre><code>##  female    male unknown    NA&#39;s 
##    6484    5328       0      16</code></pre>
<pre class="r"><code>#The race values are already coded as NA for missing, but could have done this 
exit$race = as.factor(exit$race)
summary(exit$race)</code></pre>
<pre><code>##           Asian           Black Hispanic/Latino              NA           Other 
##             124            1268             768              92             180 
##           White 
##            9396</code></pre>
<pre class="r"><code>exit$race[which(exit$race == &quot;NA&quot;)] = NA
summary(exit$race)</code></pre>
<pre><code>##           Asian           Black Hispanic/Latino              NA           Other 
##             124            1268             768               0             180 
##           White            NA&#39;s 
##            9396              92</code></pre>
<p><strong>Question 1d</strong></p>
<pre class="r"><code>#the new varible third.party is created by recoding everything as NA and then recoding each value to the 
#new value. Using NULL removes the variable from the data set
attributes(exit.untouched$PRSPA16)</code></pre>
<pre><code>## $label
## [1] &quot;In today&#39;s election for president, did you just vote for:&quot;
## 
## $format.stata
## [1] &quot;%8.0g&quot;
## 
## $labels
##    Did not vote Hillary Clinton    Donald Trump    Gary Johnson      Jill Stein 
##               0               1               2               3               4 
##           Other 
##               9</code></pre>
<pre class="r"><code>exit$third.party &lt;- &quot;NA&quot;
exit$third.party[exit$PRSPA16 == 1] &lt;- &quot;0&quot;
exit$third.party[exit$PRSPA16 == 2] &lt;- &quot;0&quot;
exit$third.party[exit$PRSPA16 == 3] &lt;- &quot;1&quot;
exit$third.party[exit$PRSPA16 == 4] &lt;- &quot;1&quot;
exit$third.party[exit$PRSPA16 == 9] &lt;- &quot;1&quot;

exit$PRSPA16 &lt;- NULL</code></pre>
<p><strong>Question 1e</strong></p>
<pre class="r"><code>#the as.numeric function converts the married variable into a dummy variable, coding 1 for married and 
#0 for not married
attributes(exit.untouched$married) #tells us that 1 is yes and 2 is no</code></pre>
<pre><code>## $label
## [1] &quot;Are you currently married?&quot;
## 
## $format.stata
## [1] &quot;%8.0g&quot;
## 
## $labels
## Yes  No 
##   1   2</code></pre>
<pre class="r"><code>exit$married &lt;- as.numeric(exit$married==1)</code></pre>
<p><strong>Question 1f</strong></p>
<pre class="r"><code>#the factor function recodes the PHIL3 and partyid variables into meaningful labels 
attributes(exit.untouched$PHIL3)</code></pre>
<pre><code>## $label
## [1] &quot;On most political matters, do you consider yourself:&quot;
## 
## $format.stata
## [1] &quot;%8.0g&quot;
## 
## $labels
##      Liberal     Moderate Conservative 
##            1            2            3</code></pre>
<pre class="r"><code>exit$PHIL3 &lt;- factor(exit$PHIL3, labels = c(&quot;Liberal&quot;, &quot;Moderate&quot;, &quot;Conservative&quot;))

attributes(exit.untouched$partyid)</code></pre>
<pre><code>## $label
## [1] &quot;No matter how you voted today, do you usually think of yourself as a:&quot;
## 
## $format.stata
## [1] &quot;%8.0g&quot;
## 
## $labels
##       Democrat     Republican    Independent Something else 
##              1              2              3              4</code></pre>
<pre class="r"><code>exit$partyid &lt;- factor(exit$partyid, labels = c(&quot;Democrat&quot;, &quot;Republican&quot;, &quot;Independent&quot;,
                                                &quot;Something Else&quot;))</code></pre>
<p><strong>Question 1g</strong></p>
<pre class="r"><code>#the rename function will change the name of a column to something more meaningful
exit &lt;- rename(exit, ideology = PHIL3)</code></pre>
<p><strong>Question 1h</strong></p>
<pre class="r"><code>#I split the age variable into the different groups and then also made the partyid ordinal so that they can be compared. From there I made them into a table, and then did the frequencies of the results. Lastly, I added together all of the values in the table to make sure that they are equal to 1. 
exit$Age.group &lt;- &quot;NA&quot;
exit$Age.group[exit$age == &quot;18-29&quot;] &lt;- 1
exit$Age.group[exit$age == &quot;30-44&quot;] &lt;- 2
exit$Age.group[exit$age == &quot;45-65&quot;] &lt;- 3
exit$Age.group[exit$age == &quot;65+&quot;] &lt;- 4

exit$ID &lt;- &quot;NA&quot;
exit$ID[exit$partyid == &quot;Republican&quot;] &lt;- 5
exit$ID[exit$partyid == &quot;Democrat&quot;] &lt;- 6
exit$ID[exit$partyid == &quot;Independent&quot;] &lt;- 7
exit$ID[exit$partyid == &quot;Something Else&quot;] &lt;- 8

mytable &lt;- table(exit$Age.group, exit$ID)
prop.table(mytable)</code></pre>
<pre><code>##     
##                 5            6            7            8           NA
##   1  0.0568143389 0.0696652012 0.0229962800 0.0064254312 0.0087926953
##   2  0.0825160636 0.0980723706 0.0480216436 0.0121745012 0.0064254312
##   3  0.1531958066 0.1531958066 0.0520798106 0.0125126818 0.0179235712
##   4  0.0723706459 0.0798106189 0.0280689888 0.0030436253 0.0114981400
##   NA 0.0006763612 0.0020290835 0.0013527224 0.0000000000 0.0003381806</code></pre>
<pre class="r"><code>sum(prop.table(mytable))</code></pre>
<pre><code>## [1] 1</code></pre>
<p>Comparing the frequencies of the age group and ID variables, there is a 6.97% chance of people in the age group of 18-29 being democratic and a 5.68% chance of people being 18-29 and republican. The values are lower for independents and ‘something else,’ with a 0.64% chance of someone 18-29 being independent and a 0.88% chance of someone being 18-29 and something else. This is fairly expected, as young people are more likely to be democratic than any other party. Another interesting observation is that there is the same 15.32% chance of someone being 45-65 years old and either a republican or democrat. The 45-65-year-old age group also has the highest chance of being independent (5.21%) and something else (1.25%) than any other group. This may be explained by the fact that middle aged and older people are more likely to watch the news and therefore align with a particular political party, or because this age group has particularly high voter turnout and therefore need to be registered to a party to participate.</p>
<p><strong>Question 2a</strong></p>
<pre class="r"><code>library(rio)
UNICEF_untouched &lt;- rio::import(&quot;/Users/briannafisher/Dropbox/Github/BriannaFisher/data/unicefdata.xlsx&quot;)

UNICEF &lt;- UNICEF_untouched

#Problems with the data:
#1. Columns are named with numbers
#2. Column names are in the actual columns
#3. Have dashes and x&#39;s within the data</code></pre>
<p><strong>Question 2b</strong></p>
<pre class="r"><code>#The names function renames the columns with the names in the first row, and then the first two rows can be deleted. Using rownames will renumber the rows so that it does not start at 3.
names(UNICEF) &lt;- lapply(UNICEF[1, ], as.character)
UNICEF = UNICEF[-1,] 
UNICEF = UNICEF[-1,] 
row.names(UNICEF) &lt;- 1:nrow(UNICEF)</code></pre>
<p><strong>Question 2c</strong></p>
<pre class="r"><code>#rowmeans tells us the mean value of each row in the data set. The rows that have &quot;1&quot; as their mean 
#are blank and should be removed. The -c function lets you drop rows or 
#columns from the data set
rowMeans(is.na(UNICEF))</code></pre>
<pre><code>##          1          2          3          4          5          6          7 
## 0.14285714 0.14285714 0.07142857 0.14285714 0.14285714 0.14285714 0.14285714 
##          8          9         10         11         12         13         14 
## 0.14285714 0.14285714 0.14285714 0.14285714 0.14285714 0.14285714 0.14285714 
##         15         16         17         18         19         20         21 
## 0.14285714 0.14285714 0.14285714 0.14285714 0.07142857 0.07142857 0.14285714 
##         22         23         24         25         26         27         28 
## 0.14285714 0.14285714 0.14285714 0.14285714 0.14285714 0.07142857 0.07142857 
##         29         30         31         32         33         34         35 
## 0.14285714 0.14285714 0.14285714 0.14285714 0.14285714 0.14285714 0.14285714 
##         36         37         38         39         40         41         42 
## 0.14285714 0.07142857 0.14285714 0.14285714 0.14285714 0.14285714 0.14285714 
##         43         44         45         46         47         48         49 
## 0.14285714 0.14285714 0.14285714 0.14285714 0.00000000 0.14285714 0.14285714 
##         50         51         52         53         54         55         56 
## 0.14285714 0.07142857 0.14285714 0.14285714 0.14285714 0.14285714 0.14285714 
##         57         58         59         60         61         62         63 
## 0.14285714 0.14285714 0.07142857 0.14285714 0.14285714 0.14285714 0.14285714 
##         64         65         66         67         68         69         70 
## 0.14285714 0.14285714 0.14285714 0.14285714 0.14285714 0.14285714 0.14285714 
##         71         72         73         74         75         76         77 
## 0.14285714 0.14285714 0.14285714 0.07142857 0.14285714 0.14285714 0.14285714 
##         78         79         80         81         82         83         84 
## 0.14285714 0.14285714 0.14285714 0.14285714 0.14285714 0.14285714 0.14285714 
##         85         86         87         88         89         90         91 
## 0.14285714 0.14285714 0.14285714 0.14285714 0.14285714 0.07142857 0.14285714 
##         92         93         94         95         96         97         98 
## 0.14285714 0.14285714 0.07142857 0.14285714 0.07142857 0.14285714 0.07142857 
##         99        100        101        102        103        104        105 
## 0.14285714 0.14285714 0.14285714 0.14285714 0.14285714 0.07142857 0.14285714 
##        106        107        108        109        110        111        112 
## 0.00000000 0.14285714 0.14285714 0.14285714 0.07142857 0.14285714 0.14285714 
##        113        114        115        116        117        118        119 
## 0.14285714 0.14285714 0.14285714 0.14285714 0.14285714 0.14285714 0.14285714 
##        120        121        122        123        124        125        126 
## 0.07142857 0.14285714 0.14285714 0.14285714 0.14285714 0.07142857 0.14285714 
##        127        128        129        130        131        132        133 
## 0.07142857 0.14285714 0.14285714 0.14285714 0.14285714 0.14285714 0.14285714 
##        134        135        136        137        138        139        140 
## 0.14285714 0.14285714 0.14285714 0.07142857 0.14285714 0.14285714 0.14285714 
##        141        142        143        144        145        146        147 
## 0.14285714 0.14285714 0.14285714 0.14285714 0.14285714 0.14285714 0.14285714 
##        148        149        150        151        152        153        154 
## 0.14285714 0.14285714 0.14285714 0.07142857 0.14285714 0.14285714 0.14285714 
##        155        156        157        158        159        160        161 
## 0.14285714 0.14285714 0.14285714 0.14285714 0.14285714 0.14285714 0.14285714 
##        162        163        164        165        166        167        168 
## 0.14285714 0.07142857 0.14285714 0.14285714 0.14285714 0.14285714 0.14285714 
##        169        170        171        172        173        174        175 
## 0.14285714 0.14285714 0.14285714 0.14285714 0.14285714 0.07142857 0.14285714 
##        176        177        178        179        180        181        182 
## 0.14285714 0.14285714 0.14285714 0.14285714 0.14285714 0.14285714 0.14285714 
##        183        184        185        186        187        188        189 
## 0.14285714 0.14285714 0.14285714 0.07142857 0.14285714 0.14285714 0.14285714 
##        190        191        192        193        194        195        196 
## 0.14285714 0.14285714 0.14285714 0.14285714 0.14285714 0.14285714 0.07142857 
##        197        198        199        200        201        202        203 
## 0.14285714 1.00000000 0.92857143 0.14285714 0.14285714 0.14285714 0.14285714 
##        204        205        206        207        208        209        210 
## 0.14285714 0.14285714 0.14285714 0.14285714 0.14285714 0.14285714 1.00000000 
##        211        212        213        214        215        216        217 
## 0.92857143 0.92857143 0.92857143 0.92857143 0.92857143 0.92857143 0.92857143 
##        218 
## 0.92857143</code></pre>
<pre class="r"><code>which(rowMeans(is.na(UNICEF)) == 1)</code></pre>
<pre><code>## 198 210 
## 198 210</code></pre>
<pre class="r"><code>UNICEF &lt;- UNICEF[,-c(12,14)]
UNICEF &lt;- UNICEF[-c(198),]
row.names(UNICEF) &lt;- 1:nrow(UNICEF)
UNICEF &lt;- UNICEF[-c(209),]
row.names(UNICEF) &lt;- 1:nrow(UNICEF)

#Now, the dataset has 12 columns and 216 rows. (When I take out the summary indicators on 2. h.,
#the dataset has 12 columns and 215 rows).NICEF)) == 1)</code></pre>
<p><strong>Question 2d</strong></p>
<pre class="r"><code>UNICEF &lt;- rename(UNICEF, c(&quot;Countries&quot; = &quot;Countries and areas&quot;, 
                 &quot;U5MR.1990&quot; = &quot;Under-5 mortality rate (U5MR) (1990)&quot;,
                 &quot;U5MR.2015&quot; = &quot;Under-5 mortality rate (U5MR) 2015&quot;,
                 &quot;U5MR.Male&quot; = &quot;U5MR (male)&quot;, &quot;U5MR.Female&quot; = &quot;U5MR (female)&quot;, 
                 &quot;Total.Pop&quot; = &quot;Total population (thousands)&quot;,
                 &quot;Annual.Births&quot; = &quot;Annual no. of births (thousands)&quot;,
                 &quot;GNI.Per.Capita&quot; = &quot;GNI per capita (US$)&quot;, 
                 &quot;Neonatal.Mortality.Rate&quot; = &quot;Neonatal  mortality  rate&quot;,
                 &quot;Life.Expect.Birth&quot; = &quot;Life expectancy at birth (years)&quot;,
                 &quot;Total.Adult.Lit.Rate&quot; = &quot;Total adult literacy rate          (%)&quot;,
                 &quot;Primary.School.Net.Enrollment.Ratio&quot; = &quot;Primary school net enrolment ratio      (%)&quot;))</code></pre>
<p><strong>Question 2e</strong></p>
<pre class="r"><code>which(UNICEF$Countries == &quot;Notes:&quot;)</code></pre>
<pre><code>## [1] 209</code></pre>
<pre class="r"><code>UNICEF &lt;- UNICEF[-c(209:216),] </code></pre>
<p><strong>Question 2f</strong></p>
<pre class="r"><code>#This recodes all values of - in the dataset to NA
UNICEF[UNICEF == &quot;-&quot;] &lt;- NA

#This converts the columns to be numeric and replaces the letters with NAs
UNICEF[,2:12] &lt;- as.numeric(as.character(unlist(UNICEF[,2:12])))</code></pre>
<p><strong>Question 2g</strong></p>
<pre class="r"><code>#The round function will round the values to the largest whole number after multiplying the variable by 1000
UNICEF$Total.Pop &lt;- round(UNICEF$Total.Pop*1000)
UNICEF$Annual.Births &lt;- round(UNICEF$Annual.Births*1000)</code></pre>
<p><strong>Question 2h</strong></p>
<pre class="r"><code>#Subsetting the data creates a new dataset with only the wanted obeservations.
summary.indicators &lt;- subset(UNICEF[199:208,])
UNICEF &lt;- UNICEF[-c(198:208),]

#Now, the UNICEF dataset has 197 rows and the summary indicators dataset has 10 rows.</code></pre>
<p><strong>Question 2i</strong></p>
<pre class="r"><code>#to find the change in mortality rate from 1990 to 2015, the two can be subtracted (any countries with a positive value had an increase in mortality rate)
change.mortality &lt;- (UNICEF$U5MR.2015) - (UNICEF$U5MR.1990)
print(change.mortality)</code></pre>
<pre><code>##   [1]  -90  -27  -21   -6  -69  -18  -15  -36   -5   -6  -63  -12  -17 -106   -5
##  [16]  -12   -6  -23  -80 -101  -86  -13  -10  -45   -2  -12 -113  -90  -38  -88
##  [31]  -50   -3  -47  -76  -11  -43  -19  -51  -49  -16   -7  -60   -9   -7   -8
##  [46]  -12  -18  -89   -5  -54    4  -29  -35  -62  -42  -96 -104  -17 -146   -8
##  [61]   -5   -5  -42 -101  -36   -5  -65   -8  -11  -52 -144 -136  -21  -77   NA
##  [76]  -38  -13   -4  -78  -58  -42  -22   -5   -8   -6  -15   -3  -19  -39  -53
##  [91]  -40   -9  -44  -95  -12  -25    2 -185  -29   NA  -12   -7 -111 -178  -10
## [106]  -85 -139   -5  -14  -33   -9  -34  -21   -4  -86  -12  -52 -161  -60  -29
## [121]  -22 -105   -4   -5  -45 -232 -104    9   -6  -27  -58  -20  -14  -32  -26
## [136]  -63  -30  -12  -11  -13   -4  -17  -27  -16 -110  -17   -9   -7  -13   -8
## [151]  -64  -29  -93  -21   -3 -144   -5  -11   -7  -12  -43  -19 -160   -7  -11
## [166]  -23  -58  -27  -14   -4   -4  -24  -63  -25  -31 -123  -68   -5  -11  -43
## [181]  -61  -40  -30 -132  -11  -10   -5 -116   -4  -13  -33   -8  -15  -29  -84
## [196] -127   -5</code></pre>
<p>Three countries had a mortality rate that increased over this 25-year period. The countries are Dominica, Lesotho, and Niue.</p>
<p><strong>Question 2j</strong></p>
<pre class="r"><code>#the cor functions finds the correlation between the GNI per captia and neonatal mortality rate
cor(UNICEF$GNI.Per.Capita, 
    UNICEF$Neonatal.Mortality.Rate, &quot;complete.obs&quot;)</code></pre>
<pre><code>## [1] -0.560275</code></pre>
<pre class="r"><code>#the plot function creates a scatterplot of the GNI per capita and neonatal mortality rate 
plot(y=UNICEF$Neonatal.Mortality.Rate, x=UNICEF$GNI.Per.Capita,
     xlab = &quot;Gross National Income Per Capita in U.S. Dollars&quot;,
     ylab = &quot;Neonatal Mortality Rate&quot;, 
     main = &quot;Gross National Income Per Capita in U.S. Dollars and Neonatal Mortality&quot;)</code></pre>
<p><img src="portfolio2_files/figure-html/unnamed-chunk-35-1.png" width="672" /> When looking at the relationship between Gross National Income per capita and Neonatal Mortality Rate, the correlation can be calculated as -0.56. This indicates that there is a negative association between Gross National Income per capita and Neonatal Mortality Rate. This can also be seen in the plot of Gross National Income per capita and Neonatal Mortality Rate, with Neonatal Morality Rate decreasing as Gross National Income per capita increases.</p>
</div>
<div id="problem-set-3" class="section level3">
<h3>Problem Set 3</h3>
<p><strong>Question 1a</strong></p>
<pre class="r"><code>library(rio)
library(tidyr)
library(dplyr)

#the rio package reads in the data from excel
mont_untouched &lt;- rio::import(&quot;/Users/briannafisher/Dropbox/Github/BriannaFisher/data/2018-General-Montgomery.xls&quot;)
mont &lt;- mont_untouched
dekalb &lt;- read.csv(&quot;/Users/briannafisher/Dropbox/Github/BriannaFisher/data/dekalb-cleaned.csv&quot;)

#first, dim is used to see how many columns are coded as precincts. Then the gather function is used to 
#put all of the precincts in one column
dim(mont)</code></pre>
<pre><code>## [1] 195  54</code></pre>
<pre class="r"><code>mont &lt;- gather(mont, key = &quot;precinct&quot;, value = &quot;votes&quot;, 4:54)

#Using !grepl, I can remove the columns with the over and under votes and the number of registered voters and 
#ballots cast in each precinct
mont &lt;- mont[!grepl(&quot;Over Votes&quot;, mont$Candidate),]
mont &lt;- mont[!grepl(&quot;Under Votes&quot;, mont$Candidate),]
mont &lt;- mont[!grepl(&quot;REGISTERED VOTERS&quot;, mont$`Contest Title`),]
mont &lt;- mont[!grepl(&quot;BALLOTS CAST&quot;, mont$`Contest Title`),]
row.names(mont) &lt;- 1:nrow(mont)

#na.omit is used to remove the rows with missing vote data
mont &lt;- na.omit(mont)

mont &lt;- rename(mont, &quot;office&quot; = &quot;Contest Title&quot;, &quot;party&quot; = &quot;Party&quot;,
               &quot;candidate&quot; = &quot;Candidate&quot;)

#the recode function is used to clean the values within the party variable
unique(mont$party)</code></pre>
<pre><code>## [1] &quot;DEM&quot; &quot;REP&quot; &quot;NON&quot; &quot;IND&quot;</code></pre>
<pre class="r"><code>mont$party &lt;- recode(mont$party, &quot;DEM&quot; = &quot;Democrat&quot;, &quot;REP&quot; = &quot;Republican&quot;, &quot;NON&quot; = &quot;No party&quot;,
               &quot;IND&quot; = &quot;Independent&quot;)

#you can create new variables for the state and county
mont$state &lt;- &quot;Alabama&quot;
mont$county &lt;- &quot;Montgomery&quot;

#the &quot;c&quot; function reorders the columns
mont &lt;- mont[, c(6, 7, 4, 1, 3, 2, 5)]</code></pre>
<p><strong>Question 1b</strong></p>
<pre class="r"><code>#first create vectors with what you want to loop over
office &lt;- unique(mont$office)
office</code></pre>
<pre><code>##  [1] &quot;STRAIGHT PARTY&quot;                                          
##  [2] &quot;UNITED STATES REPRESENTATIVE, 2ND CONGRESSIONAL DISTRICT&quot;
##  [3] &quot;GOVERNOR&quot;                                                
##  [4] &quot;LIEUTENANT GOVERNOR&quot;                                     
##  [5] &quot;ATTORNEY GENERAL&quot;                                        
##  [6] &quot;CHIEF JUSTICE OF THE SUPREME COURT&quot;                      
##  [7] &quot;ASSOCIATE JUSTICE OF THE SUPREME COURT, PLACE 1&quot;         
##  [8] &quot;ASSOCIATE JUSTICE OF THE SUPREME COURT, PLACE 2&quot;         
##  [9] &quot;ASSOCIATE JUSTICE OF THE SUPREME COURT, PLACE 3&quot;         
## [10] &quot;ASSOCIATE JUSTICE OF THE SUPREME COURT, PLACE 4&quot;         
## [11] &quot;STATE TREASURER&quot;                                         
## [12] &quot;COMMISSIONER OF AGRICULTURE AND INDUSTRIES&quot;              
## [13] &quot;SECRETARY OF STATE&quot;                                      
## [14] &quot;STATE AUDITOR&quot;                                           
## [15] &quot;COURT OF CIVIL APPEALS JUDGE, PLACE 1&quot;                   
## [16] &quot;COURT OF CIVIL APPEALS JUDGE, PLACE 2&quot;                   
## [17] &quot;COURT OF CIVIL APPEALS JUDGE, PLACE 3&quot;                   
## [18] &quot;COURT OF CRIMINAL APPEALS JUDGE, PLACE 1&quot;                
## [19] &quot;COURT OF CRIMINAL APPEALS JUDGE, PLACE 2&quot;                
## [20] &quot;COURT OF CRIMINAL APPEALS JUDGE, PLACE 3&quot;                
## [21] &quot;PUBLIC SERVICE COMMISSION, PLACE 1&quot;                      
## [22] &quot;PUBLIC SERVICE COMMISSION, PLACE 2&quot;                      
## [23] &quot;CIRCUIT COURT JUDGE, 15TH JUDICIAL CIRCUIT, PLACE 6&quot;     
## [24] &quot;STATE SENATOR, DISTRICT 26&quot;                              
## [25] &quot;STATE REPRESENTATIVE, DISTRICT 77&quot;                       
## [26] &quot;PROPOSED STATEWIDE AMENDMENT NUMBER ONE (1)&quot;             
## [27] &quot;PROPOSED STATEWIDE AMENDMENT NUMBER TWO (2)&quot;             
## [28] &quot;PROPOSED STATEWIDE AMENDMENT NUMBER THREE (3)&quot;           
## [29] &quot;PROPOSED STATEWIDE AMENDMENT NUMBER FOUR (4)&quot;            
## [30] &quot;CIRCUIT CLERK, MONTGOMERY COUNTY&quot;                        
## [31] &quot;DISTRICT COURT JUDGE, MONTGOMERY COUNTY, PLACE NO. 2&quot;    
## [32] &quot;DISTRICT COURT JUDGE, MONTGOMERY COUNTY, PLACE NO. 3&quot;    
## [33] &quot;MONTGOMERY COUNTY JUDGE OF PROBATE&quot;                      
## [34] &quot;MONTGOMERY COUNTY SHERIFF&quot;                               
## [35] &quot;PROPOSED LOCAL AMENDMENT NUMBER ONE (1)&quot;                 
## [36] &quot;STATE SENATOR, DISTRICT 25&quot;                              
## [37] &quot;STATE REPRESENTATIVE, DISTRICT 74&quot;                       
## [38] &quot;STATE REPRESENTATIVE, DISTRICT 76&quot;                       
## [39] &quot;UNITED STATES REPRESENTATIVE, 7TH CONGRESSIONAL DISTRICT&quot;
## [40] &quot;STATE REPRESENTATIVE, DISTRICT 69&quot;                       
## [41] &quot;STATE REPRESENTATIVE, DISTRICT 78&quot;                       
## [42] &quot;UNITED STATES REPRESENTATIVE, 3RD CONGRESSIONAL DISTRICT&quot;
## [43] &quot;STATE REPRESENTATIVE, DISTRICT 75&quot;                       
## [44] &quot;STATE REPRESENTATIVE, DISTRICT 90&quot;</code></pre>
<pre class="r"><code>precinct &lt;- unique(mont$precinct)
precinct</code></pre>
<pre><code>##  [1] &quot;101 D&quot; &quot;102 V&quot; &quot;103 M&quot; &quot;104 W&quot; &quot;105 A&quot; &quot;106 P&quot; &quot;107 T&quot; &quot;201 S&quot; &quot;202 B&quot;
## [10] &quot;203 H&quot; &quot;204 F&quot; &quot;205 S&quot; &quot;206 M&quot; &quot;207 H&quot; &quot;208 C&quot; &quot;209 F&quot; &quot;210 P&quot; &quot;211 R&quot;
## [19] &quot;301 D&quot; &quot;302 F&quot; &quot;303 E&quot; &quot;304 L&quot; &quot;305 F&quot; &quot;306 E&quot; &quot;401 S&quot; &quot;402 M&quot; &quot;403 C&quot;
## [28] &quot;404 A&quot; &quot;405 H&quot; &quot;406 N&quot; &quot;407 K&quot; &quot;408 H&quot; &quot;409 C&quot; &quot;410 S&quot; &quot;411 U&quot; &quot;412 U&quot;
## [37] &quot;413 W&quot; &quot;501 T&quot; &quot;502 S&quot; &quot;503 L&quot; &quot;504 R&quot; &quot;505 F&quot; &quot;506 D&quot; &quot;507 D&quot; &quot;508 P&quot;
## [46] &quot;509 W&quot; &quot;510 G&quot; &quot;511 A&quot; &quot;512 S&quot; &quot;ABSEN&quot; &quot;PROVI&quot;</code></pre>
<pre class="r"><code>#create a matrix to store the results of the loop
office.precinct &lt;- matrix(NA, nrow=length(precinct), ncol=length(office))

#loop over the votes for the precincts and offices
for(j in 1: length(office)){
  
  for(i in 1:length(precinct)){
    office.precinct[i,j] &lt;-  sum(mont$votes[mont$precinct==precinct[i] &amp; mont$office==office[j]], 
                                 na.rm=T)
  }
  
}

#you can use the max function to find the maximum number of votes in one precinct/office
#combination
max(office.precinct)</code></pre>
<pre><code>## [1] 4675</code></pre>
<pre class="r"><code>#which will tell you the exact row / column of the office / precinct
which(office.precinct == max(office.precinct), arr.ind = T)</code></pre>
<pre><code>##      row col
## [1,]  23   3</code></pre>
<pre class="r"><code>#I can subset from my vectors to find the names of the combination
office[3]</code></pre>
<pre><code>## [1] &quot;GOVERNOR&quot;</code></pre>
<pre class="r"><code>precinct[23]</code></pre>
<pre><code>## [1] &quot;305 F&quot;</code></pre>
<p>The office-precinct combination that had the highest number of votes is the 305 F precinct and Governor office with 4675 votes.</p>
<p><strong>Question 1c</strong></p>
<pre class="r"><code>#You can first find the mean since this is the statistic we want
mean(mont$votes[mont$party==&quot;Democrat&quot; &amp; mont$office==&quot;GOVERNOR&quot;],na.rm=T)</code></pre>
<pre><code>## [1] 955.3333</code></pre>
<pre class="r"><code>mean(mont$votes[mont$party==&quot;Republican&quot; &amp; mont$office==&quot;GOVERNOR&quot;],na.rm=T)</code></pre>
<pre><code>## [1] 558.6471</code></pre>
<pre class="r"><code>#you can then use a t test to find out if either means are statistically significant
diff.test &lt;- t.test(mont$votes[mont$party==&quot;Democrat&quot; &amp; mont$office==&quot;GOVERNOR&quot;],
                    mont$votes[mont$party==&quot;Republican&quot; &amp; mont$office==&quot;GOVERNOR&quot;])

diff.test</code></pre>
<pre><code>## 
##  Welch Two Sample t-test
## 
## data:  mont$votes[mont$party == &quot;Democrat&quot; &amp; mont$office == &quot;GOVERNOR&quot;] and mont$votes[mont$party == &quot;Republican&quot; &amp; mont$office == &quot;GOVERNOR&quot;]
## t = 2.9114, df = 99.392, p-value = 0.004442
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  126.3468 667.0257
## sample estimates:
## mean of x mean of y 
##  955.3333  558.6471</code></pre>
<p>The average number of votes for the Democratic candidate for Governor was 955. The average number of votes for the Republican candidate for Governor was 559. These two numbers are statistically distinguishable from one another. If the average number of votes for the Democratic and Republican candidates for Governor is the same, we would expect to see a difference in the means 0.44% of the time. Since the p-value (0.0044) is so low, we can reject the null hypothesis. There is significant statistical evidence to support that the two means are statistically distinguishable from each other.</p>
<p><strong>Question 2a</strong></p>
<pre class="r"><code># You can use the sample function to simulate fliping a coin
dodgers.win.prob &lt;- c(1,1,1,1,1,1,0,0,0,0)

sample(dodgers.win.prob, size = 7, replace = TRUE) #output: 0 0 1 1 1 0 1</code></pre>
<pre><code>## [1] 1 1 1 1 0 1 1</code></pre>
<pre class="r"><code>dodgers &lt;- sum(sample(dodgers.win.prob, size = 7, replace = TRUE))</code></pre>
<p>In my simulation, the Dodgers won a majority of the games (actually four exactly), therefore winning the world series.</p>
<p><strong>Question 2b</strong></p>
<pre class="r"><code>#first create an empty vector to put the results
dodgers.wins &lt;- rep(NA, 10000)

#Then you can use a for loop to simulate the same 7-game world series 10,000 times
for(i in 1:10000){
  dodgers.wins[i]&lt;- sum(sample(dodgers.win.prob, size = 7, replace = TRUE))
  
}

#you can create a probability table of the results
prob.dodgers.wins &lt;- prop.table(table(dodgers.wins))
print(prob.dodgers.wins)</code></pre>
<pre><code>## dodgers.wins
##      0      1      2      3      4      5      6      7 
## 0.0013 0.0172 0.0748 0.2006 0.2865 0.2662 0.1273 0.0261</code></pre>
<pre class="r"><code>#to find the proportion of times the Dodgers won 4 or more games, you can sum the results
sum(prob.dodgers.wins[5:8])</code></pre>
<pre><code>## [1] 0.7061</code></pre>
<p>The Dodgers win four or more games 71.33% of the time.</p>
<p><strong>Question 2c</strong></p>
<pre class="r"><code>#You can use sequence to make a vector with every second game
odd.games &lt;- seq(7, 151, by = 2)
dodgers.win.95 &lt;- rep(NA, length(odd.games))

#you can use a double for loop to find the wins for the length of the series
for(j in 1:length(odd.games)){
  for(i in 1:10000){
    dodgers.wins[i]&lt;- sum(sample(dodgers.win.prob, size = odd.games[j], replace = TRUE))
    
  }
  dodgers.win.95[j]&lt;- prop.table(table(dodgers.wins &gt;= (odd.games[j]/2)))[&quot;TRUE&quot;]
}

print(dodgers.win.95)</code></pre>
<pre><code>##  [1] 0.7101 0.7347 0.7515 0.7768 0.7866 0.7984 0.8134 0.8236 0.8369 0.8455
## [11] 0.8557 0.8709 0.8733 0.8757 0.8834 0.8976 0.8983 0.9016 0.9111 0.9156
## [21] 0.9178 0.9203 0.9248 0.9305 0.9326 0.9356 0.9423 0.9420 0.9467 0.9526
## [31] 0.9488 0.9553 0.9559 0.9596 0.9626 0.9615 0.9647 0.9667 0.9707 0.9705
## [41] 0.9708 0.9759 0.9743 0.9742 0.9775 0.9774 0.9773 0.9816 0.9808 0.9786
## [51] 0.9827 0.9822 0.9836 0.9828 0.9849 0.9853 0.9851 0.9867 0.9869 0.9862
## [61] 0.9892 0.9902 0.9871 0.9902 0.9919 0.9897 0.9907 0.9915 0.9900 0.9927
## [71] 0.9945 0.9933 0.9932</code></pre>
<pre class="r"><code>#you can use the plot function to make a graph of the proportion of times the better team
# wins and the series length
plot(x = odd.games, y = dodgers.win.95, xlab = &quot;Series Length&quot;, ylab = 
&quot;Proportion of Times the Better Team Wins&quot;, main = &quot;Simulated World Series Wins&quot;)
abline(h=0.95)</code></pre>
<p><img src="portfolio2_files/figure-html/unnamed-chunk-41-1.png" width="672" /> The series would have to be around 67 games in order for the better team to win 95% of the 10,000 simulated world series games.</p>
<p><strong>Question 2d</strong> Given the current series length, we cannot reject the null hypothesis that the better team should win 50% of the time. Because the standard is that better team should win 95% of the time, our value of 71.33% is statistically insignificant when they only play seven games.</p>
</div>
<div id="problem-set-4" class="section level3">
<h3>Problem Set 4</h3>
<pre class="r"><code>fem &lt;- read.csv(&quot;/Users/briannafisher/Dropbox/Github/BriannaFisher/data/washington_replication_data.csv&quot;)

#You can use the dim full get the number of members in Congress since each row corresponds to a member
dim(fem)</code></pre>
<pre><code>## [1] 435  16</code></pre>
<pre class="r"><code>#you can use the sum function to add the number of females and divide it by the total number of members to
#get the proportion of females in Congress
sum(fem$female)/435</code></pre>
<pre><code>## [1] 0.1103448</code></pre>
<pre class="r"><code>#doing this gets the same answer
mean(fem$female, na.rm = T)</code></pre>
<pre><code>## [1] 0.1103448</code></pre>
<pre class="r"><code>#you can use the sum function to add the number of republicans (when party = 2) and divide it by the 
#total number of members to get the proportion of females in Congress
sum(fem$party==2)/435</code></pre>
<pre><code>## [1] 0.5241379</code></pre>
<pre class="r"><code>#doing this gets the same answer
mean(fem$party == 2, na.rm = T)</code></pre>
<pre><code>## [1] 0.5241379</code></pre>
<pre class="r"><code>#you can create logical variables for democrats and women in order to find the proportions
fem$women &lt;- fem$female == 1
fem$democrat &lt;- fem$party == 1
mean(fem$women[fem$democrat], na.rm = T)</code></pre>
<pre><code>## [1] 0.1650485</code></pre>
<pre class="r"><code>#you can do the same thing for republicans
fem$rep &lt;- fem$party == 2
mean(fem$women[fem$rep], na.rm = T)</code></pre>
<pre><code>## [1] 0.06140351</code></pre>
<p>There are 435 members of Congress in the dataset. 11.03% of the representations are women. 52.41% of the representatives are republicans. 16.50% of democrats are women. 6.14% of republicans are women.</p>
<p><strong>Question 1b</strong></p>
<pre class="r"><code>#you can use the summary function to find the summary statistics of the AAUW variable
summary(fem$aauw)</code></pre>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##    0.00    0.00   38.00   47.31  100.00  100.00</code></pre>
<pre class="r"><code>#you can use the table function to see how many legislators have each score
table(fem$aauw)</code></pre>
<pre><code>## 
##   0  13  14  25  38  40  50  60  63  75  88 100 
## 135  42   1  25  16   1  13   1  31  17  41 112</code></pre>
<pre class="r"><code>#you can create logical variables for democrats and people who have a score of 100 in order to 
#find the proportions
fem$dem.100 &lt;- fem$aauw == 100
sum(fem$women[fem$dem.100], na.rm = T)</code></pre>
<pre><code>## [1] 30</code></pre>
<pre class="r"><code>#you can create logical variables for democrats and people who have a score of 0 in order to 
#find the proportions
fem$dem.0 &lt;- fem$aauw == 0
sum(fem$women[fem$dem.0], na.rm = T)</code></pre>
<pre><code>## [1] 5</code></pre>
<p>The mean of the AAUW’s legislative score variable is 47.31, the median is 38, the minimum is 0, and the maximum is 100. 135 legislators have a score of 0, while 112 legislators have a score of 100. 30 democrats have a score of 100, while 5 have a score of 0.</p>
<p><strong>Question 1c</strong></p>
<pre class="r"><code>#you can use the linear model function to run a regression, and the summary function to display the output
reg1 &lt;- lm(aauw ~ female, data=fem)
summary(reg1)</code></pre>
<pre><code>## 
## Call:
## lm(formula = aauw ~ female, data = fem)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -75.875 -43.765  -5.765  44.235  56.235 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   43.765      2.076  21.080  &lt; 2e-16 ***
## female        32.110      6.250   5.138 4.22e-07 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 40.84 on 433 degrees of freedom
## Multiple R-squared:  0.05745,    Adjusted R-squared:  0.05528 
## F-statistic: 26.39 on 1 and 433 DF,  p-value: 4.218e-07</code></pre>
<p>The coefficient for the intercept (legislative support for feminist issues) is 43.765 and the coefficient for the legislator’s gender (whether or not they are female) is 32.11. Women are more likely to support feminist issues than men by 32.11 points, on average. When the legislator is male (when the female variable equals zero), the average legislative support for feminist issues is 43.765 points.</p>
<p><strong>Question 1d</strong></p>
<pre class="r"><code>#you can create a republican variable by subsetting for the people who responded 2 to the party question
fem$republican &lt;- NA
fem$republican[fem$party == 1] &lt;- 0
fem$republican[fem$party == 2] &lt;- 1
fem$republican[fem$party == 3] &lt;- 0

#you can use the linear model function to run a regression, and the summary function to display the output
reg2 &lt;- lm(aauw ~ female + republican, data=fem)
summary(reg2)</code></pre>
<pre><code>## 
## Call:
## lm(formula = aauw ~ female + republican, data = fem)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -84.07 -11.18   1.82  15.93  76.82 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   84.072      1.431  58.766  &lt; 2e-16 ***
## female        13.063      2.998   4.357 1.65e-05 ***
## republican   -72.891      1.881 -38.756  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 19.33 on 432 degrees of freedom
## Multiple R-squared:  0.7895, Adjusted R-squared:  0.7885 
## F-statistic:   810 on 2 and 432 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>The coefficient for the intercept (legislative support for feminist issues) is 84.072, the coefficient for the legislator’s gender (whether or not they are female) is 13.063, and the coefficient for the legislator being republican is -72.891. When the legislator is male and a democrat (or independent), the average legislative support for feminist issues is 84.072. Women are more likely to support feminist issues than men by 13.063 points, on average, when holding republicans fixed. Republicans are less likely to support feminist issues than Democrats or Independents by 72.891 points, on average, when holding women fixed.</p>
<p><strong>Question 1e</strong></p>
<pre class="r"><code>#you can use the linear model function to run a regression, and the summary function to display the output
reg3 &lt;- lm(aauw ~ female + demvote, data=fem)
summary(reg3)</code></pre>
<pre><code>## 
## Call:
## lm(formula = aauw ~ female + demvote, data = fem)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -80.561 -25.249  -3.584  23.222  72.585 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  -63.565      5.994 -10.605  &lt; 2e-16 ***
## female        16.870      4.742   3.558 0.000415 ***
## demvote      216.619     11.685  18.538  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 30.52 on 432 degrees of freedom
## Multiple R-squared:  0.475,  Adjusted R-squared:  0.4726 
## F-statistic: 195.5 on 2 and 432 DF,  p-value: &lt; 2.2e-16</code></pre>
<pre class="r"><code>#this tells you the change when you increase democratic vote share by 10 percentage points
216.619/10</code></pre>
<pre><code>## [1] 21.6619</code></pre>
<p>Holding gender fixed, the AAUW score increases by 21.662 points when you increase the Democratic vote share by 10 percentage points.</p>
<p><strong>Question 1f</strong></p>
<pre class="r"><code>#you can create separte variables for the different religions
#none coded
fem$rel.none &lt;- NA
fem$rel.none[fem$rgroup == 0] &lt;- 1
fem$rel.none[fem$rgroup == 1] &lt;- 0
fem$rel.none[fem$rgroup == 2] &lt;- 0
fem$rel.none[fem$rgroup == 3] &lt;- 0
fem$rel.none[fem$rgroup == 4] &lt;- 0

#protestant
fem$rel.prot &lt;- NA
fem$rel.prot[fem$rgroup == 0] &lt;- 0
fem$rel.prot[fem$rgroup == 1] &lt;- 1
fem$rel.prot[fem$rgroup == 2] &lt;- 0
fem$rel.prot[fem$rgroup == 3] &lt;- 0
fem$rel.prot[fem$rgroup == 4] &lt;- 0

#catholic/orthodox
fem$rel.cath &lt;- NA
fem$rel.cath[fem$rgroup == 0] &lt;- 0
fem$rel.cath[fem$rgroup == 1] &lt;- 0
fem$rel.cath[fem$rgroup == 2] &lt;- 1
fem$rel.cath[fem$rgroup == 3] &lt;- 0
fem$rel.cath[fem$rgroup == 4] &lt;- 0

#christian
fem$rel.chris &lt;- NA
fem$rel.chris[fem$rgroup == 0] &lt;- 0
fem$rel.chris[fem$rgroup == 1] &lt;- 0
fem$rel.chris[fem$rgroup == 2] &lt;- 0
fem$rel.chris[fem$rgroup == 3] &lt;- 1
fem$rel.chris[fem$rgroup == 4] &lt;- 0

#jewish
fem$rel.jew &lt;- NA
fem$rel.jew[fem$rgroup == 0] &lt;- 0
fem$rel.jew[fem$rgroup == 1] &lt;- 0
fem$rel.jew[fem$rgroup == 2] &lt;- 0
fem$rel.jew[fem$rgroup == 3] &lt;- 0
fem$rel.jew[fem$rgroup == 4] &lt;- 1

#you can use the linear model function to run a regression, and the summary function to display the output
reg4 &lt;- lm(aauw ~ female + demvote + rel.prot + rel.cath + rel.chris + rel.jew, data=fem)
summary(reg4)</code></pre>
<pre><code>## 
## Call:
## lm(formula = aauw ~ female + demvote + rel.prot + rel.cath + 
##     rel.chris + rel.jew, data = fem)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -72.186 -23.628  -3.245  21.369  74.360 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  -23.749     14.077  -1.687 0.092311 .  
## female        17.924      4.640   3.863 0.000129 ***
## demvote      201.269     11.986  16.792  &lt; 2e-16 ***
## rel.prot     -35.144     12.370  -2.841 0.004712 ** 
## rel.cath     -31.692     12.462  -2.543 0.011340 *  
## rel.chris    -39.369     14.475  -2.720 0.006800 ** 
## rel.jew       -7.602     13.542  -0.561 0.574838    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 29.78 on 428 degrees of freedom
## Multiple R-squared:  0.5049, Adjusted R-squared:  0.4979 
## F-statistic: 72.73 on 6 and 428 DF,  p-value: &lt; 2.2e-16</code></pre>
<pre class="r"><code>#this tells you the change when you increase democratic vote share by 10 percentage points
201.269/10</code></pre>
<pre><code>## [1] 20.1269</code></pre>
<p>When the legislator is male, has no religion, and has a 0 for the democratic vote share, the average legislative support for feminist issues is 17.924. When holding religion and democratic vote share fixed, women are more likely to support feminist issues than men by 17.924 points. When holding religion and sex fixed, the democratic vote share increases by 20.1269 points. When holding sex, democratic vote share, Catholics, Christians, and Jews fixed, legislators who are Protestant are less likely than those who have no religion to support feminist issues by 35.144 points. When holding sex, democratic vote share, Protestants, Christians, and Jews fixed, legislators who are Catholic are less likely than those who have no religion to support feminist issues by 31.692 points. When holding sex, democratic vote share, Catholics, Protestants, and Jews fixed, legislators who are Christian are less likely than those who have no religion to support feminist issues by 39.369 points. When holding sex, democratic vote share, Catholics, Christians, and Protestants fixed, legislators who are Jewish are less likely than those who have no religion to support feminist issues by 7.602 points.</p>
</div>
<div id="problem-set-6" class="section level3">
<h3>Problem Set 6</h3>
<p>Because of the importance of the economy during an election and the different platforms on taxes and spending by both the Democratic and Republican parties, as well as the large difference between the average feeling thermometer score in regard to approval of the economy, I chose to model how a respondent feels about how the President (Barack Obama) is handling the economy to help explain why people like Donald Trump.</p>
<p>After running a bivariate regression between these two variables, I found that people who approved of how Obama was handling the economy were less likely to like Trump by 33 points than someone who disapproved of how the economy was handled. I also found that the average support for Trump when someone does not approve of how the economy was handled by Obama was 58 points.</p>
<p>When controlling for party, sex, and age, people who approved of how Obama was handling the economy were still less likely to like Trump, but now by 21 points. Also similar to the bivariate regression, when someone was over 65 years old, male, republican, and disapproved of how Obama was handling the economy, the average support for Trump was 73 points. When holding sex and age fixed, democrats were less likely to like Trump than republicans by 23 points, while independents were less likely to like Trump than republicans by 15 points. When holding party and sex fixed, people who were aged 30 to 49 were less likely to like Trump than people aged 65 and older by 14 points. I did not see any significant difference in support for Trump between males and females, between people aged 18 to 29 and people aged 65 and older, and between people aged 50 to 64 and people aged 65 and older.</p>
<p>Both of the results for how the economy was being handled by Obama from the regressions are statistically significant, with p-values less than 0.01, meaning that we can reject the null hypothesis that approval of how Obama was handling the economy would not impact whether or not people like Trump.</p>
</div>
<div id="final-project---public-defender-representation-leads-to-longer-prison-sentences" class="section level3">
<h3>Final Project - Public Defender Representation Leads to Longer Prison Sentences</h3>
<p>Public defenders make up the backbone of our society. They guarantee the right to representation, a fair trial, and above all else, the ability to have someone with real, legal knowledge stand up for you in court.</p>
<p>The Sixth amendment guarantees everyone the right to counsel in all criminal prosecutions; however, public defenders are underpaid and overworked, as well as have little time to prepare for each case. In effect, the Sixth amendment was created to make sure that everybody has an adequate defense regardless of the severity of the crime, their ability to pay, or any other circumstance that could interfere with a fair trial. When public defenders do not have the time or resources to properly craft a defense, it uncovers a systemic crack within the Justice System: is the Sixth amendment actually more detrimental to a defendant than helpful, rendering this guarantee essentially useless?</p>
<p>This idea can be studied by looking at whether or not court appointed counsel has a larger impact on sentence length than other representation types. After analyzing data from official court records for defendants convicted and sentenced to serve time in jail and those convicted and sentenced to pay a fine for Driving While Intoxicated in Minnesota in 1982, the answer is yes, a defendant represented by a public defender is more likely to have a longer prison sentence than someone represented by a private attorney or someone that represented themselves.</p>
<p>On average, people represented by public defenders spend almost 10 days in prison. However, those represented by private attorneys or pro se (those that represented themselves), spend as little as 3.15 days in prison.</p>
<p>To model this further, I examined the relationship between representing yourself in court and being represented by a public defender or private attorney, as well as controlling for age and sex (since females are less likely than males to be convicted of Driving While Intoxicated and people over 65 are less likely to be driving).</p>
<p>When a defendant was male, older than 65 years old, and represented by a public defender, their average sentence length for Driving While Intoxicated was 9.67 days. However, when holding sex and age fixed, having a private attorney as representation is associated with a 7 day decrease in sentence length. Seven fewer days in prison for the same crime because someone was fortunate enough to be represented by a private attorney rather than a public defender clearly indicates that there are foundational problems that need to be investigated within public defender offices as a whole.</p>
<p>After looking at the data, I also thought that it was unusual that so many people were not only representing themselves, but also receiving lessor sentences than people represented by public defenders. Originally, I thought that people who represent themselves might have less serious cases, and therefore get shorter sentences regardless of representation. However, people who represent themselves were actually more likely to have a blood alcohol content over 0.10 (with 0.08 being the legal limit) than those represented by public defenders and private attorneys, as well as be convicted of a second charge of Driving While Intoxicated. This could possibly be caused by whether or not Minnesota public defender offices have less resources than other areas and public defenders are more accustomed to receiving longer sentences for their defendants, but I would need more research and data in order to determine the actual cause.</p>
<p>This leads to the question, why is the Sixth amendment failing so many defendants?</p>
<p>Public defender offices act more like factories, where cases come in the front door and go out the back within the same breath. Each case gets a formulaic defense that is applied within the couple of minutes that public defenders have to review it before acting as representation in court. There is a focus on brevity and completeness, rather than a fair and personalized defense for each individual.</p>
<p>This has, in turn, led to the increased implementation of plea deals, which help to alleviate the number of trials carried out by prosecutors but are used in place of putting in the time and resources to thoroughly review a case. As a result, prisoners are carrying out sentences that are almost always too long for the crime committed but act as a result of an insufficient plea deal.</p>
<p>The crutch of using a plea deal could be a factor in the additional seven days spent in prison by someone represented by a public defender. This highlights the disparity between being able to afford better representation and invoking one’s right to counsel, which should hold up to the “adequate” standard set by the Constitution.</p>
<p>This is clearly a flaw within the American Justice System, but what can be done to fix this?</p>
<p>First, and perhaps most importantly, public defender offices need to have an increase in funding so that they can complete their jobs more effectively. Second, public defender offices should create subdivisions within each office based upon certain infractions and categories within the Justice System. When an office assigns their attorneys to a case based upon their preferential and desired division, the lawyer is more inclined to become passionate and have greater knowledge in the case.</p>
<p>Additional research needs to be completed within other areas of the law to determine if this pattern carries over to crimes other than Driving While Intoxicated. If so, the entire premise of public defender offices needs to be evaluated in order to ensure that the Sixth amendment is effective and can be used as a support to defendants, rather than a detriment to them.</p>
<p>Anyone put on trial deserves, and is required by law, to have an attentive and interested lawyer to defend them. When lawyers take on too many cases, they ultimately contribute to the decline in effectiveness of the Sixth amendment and legal system as a whole. If a legal system cannot act effectively, there is no way to guarantee that justice will guide the decisions of prosecutors and defenders alike.</p>
</div>
</div>
<div id="statistical-methods-in-political-science" class="section level2">
<h2>Statistical Methods in Political Science</h2>
<h2>
Statistical Methods in Political Science
</h2>
<div id="midterm" class="section level3">
<h3>Midterm</h3>
<p><strong>Theory</strong></p>
<p>As COVID-19 started to worsen throughout the country, there was a stark difference in the way that Democratic versus Republican government officials handled the outbreak. States with Republican governors quickly ended stay at home orders and reopened nonessential businesses, while states with Democratic governors saw extensive statewide lockdowns and stricter rules about going out in public. These two ideals were met with both support and criticism from higher ranking government officials, such as praise by the President for reopening states and criticism from Democratic congressmen who supported a lockdown. These differing views on how to handle the virus were also seen at the local level, with everyday citizens sharing the same ideas about social distancing practices depending on their ideology. Similarly, the support from higher ranking government officials for one practice over the other influenced how people followed protocol.</p>
<p>I theorize that people who identify as liberal are more likely to socially distance than those who identify as conservative. States with a majority of people who identify as liberal have Democratic governors and state governments, so these areas already had lengthy stay at home orders and strict rules in place to limit the virus. People in these states mostly agreed with their government’s policies and were already used to social distancing and quarantining when the states reopened. States with a majority of people who identify as conservative, however, have Republican governments that emphasized keeping businesses and schools open. Florida and Texas, for example, saw crowded beaches and malls all summer while New York, and especially New York City, had quiet streets and closed restaurants. The reasons why people with different ideologies followed different social distancing practices also has to do with the core beliefs of those ideologies. Conservatives heavily value the economy, so it was expected for conservative governments to not order mandatory lockdowns in order for nonessential businesses to stay open. Liberals, however, generally believe in government action to solve problems and protect its citizens, so following lockdown orders and strictly social distancing was expected. I hypothesize that ideological views caused liberals to socially distance more than conservatives.</p>
<p><strong>Empirical Tests</strong></p>
<p>Based on my theory, I hypothesize that people who identify as liberal were less likely to partake in everyday activities (such as shopping for food, medicine, or essential household items, visiting close friends or family, going to work, using public transportation, and dining at a restaurant) than people who identify as conservative. A maintained assumption for this theory is that all of these activities have the same level of importance to each person. Shopping for food, medicine, or essential household items is necessary for people to survive, while dining at a restaurant depends on the person’s comfort level. This would cause me to expect that the percentage of people who were liberal and went shopping for those items is similar to the percentage of people who were conservative and went shopping for those items, while the other activities would vary depending on how greatly that person needed to complete them.</p>
<p>Additionally, I hypothesize that people who approve of Trump were more likely to partake in these activities than people who don’t approve of Trump. A maintained assumption of this is that people who approve of Trump therefore value his opinion and will follow his example (such as not socially distancing). However, some people may not take his opinion into consideration when deciding whether or not to participate in these activities. Also, people who approve of Trump mostly identify as conservative, while those who do not identify as liberal. Thus, I would expect the same as before that people who are liberal were less likely to partake in these activities then people who are conservative.</p>
<p><strong>Variable Coding</strong></p>
<p>In order to test my theory and hypothesis, I use data from a study completed by the Kaiser Family Foundation. The study was completed from June 8, 2020 to June 14, 2020, and focuses on the perception of health, race, and COVID-19 in the United States.</p>
<p>My dependent variable is constructed using a combination of four everyday activities that people abstained from. In question 18 of the survey, the respondents were asked how often they (18A) shop for food, medicine, or essential items, (18B) visit close friends or family, (18C) go to work, (18D) use public transit, and (18E) dine at a restaurant. The respondents had four response options: 1) “4 times or more”, 2)” 2-3 times”, 3) “1 time”, or 4) “Not at all.” Because shopping for food, medicine, or essential items was necessary for everybody, no matter their ideology, to continue during the pandemic, my dependent variable is a combination between questions 18B, 18C, 18D, and 18E. Also, since I am looking at whether or not people abstained from these activities, I only focus on whether or not the respondent said 4, or not at all, to any of the four options. My dependent variable is coded as a dummy variable that equals 1 if the respondent abstained from any of the four activities (visiting close family or friends, going to work, using public transit, or dining in a restaurant) and 0 if they participated in any of these activities at least once. A measurement assumption for this variable is that I am measuring social distancing as a whole by only four activities, when in reality people could be going out in public for a variety of reasons that do not match up with the variable.</p>
<p>My key independent variables are two dummy variables coded for whether or not someone is conservative or moderate. The “Conservative” dummy variable is coded as 1 if the respondent answered the ideology question as conservative and 0 if they responded as liberal, moderate, don’t know, or refused. The “Moderate” dummy variable is coded as 1 if the respondent the ideology question as moderate and 0 if they responded as liberal, conservative, don’t know, or refused. Both variables are coded as missing if someone did not answer the question. A measurement assumption for this variable is that people only conform to these specific ideologies, when in reality ideology is measured on more of a spectrum.</p>
<p><strong>Control Variables</strong></p>
<p>One control variable when analyzing the relationship between ideology and social distancing is whether or not someone approves of Trump. Because Trump is in such a large position of power and has control over the narrative of the virus, people look up to him to determine how they should act. When Trump does not socially distance or wear a mask, normal people see this as a sign that they should not either. I coded this variable (trump.approve) as a dummy variable that equals one if someone strongly or somewhat approves of Trump and 0 if they somewhat disapprove, strongly disapprove, don’t know, ore refused. I would expect someone who is liberal to somewhat or strongly disapprove of Trump, and therefore made it my excluded group.</p>
<p>Another control variable when analyzing the relationship between ideology and social distancing is a person’s age. I expect people over the age of 65 to social distance more, as the elderly are at a higher risk for catching the virus than those that are younger. As a result, I made people 65 years old to 97 years old my excluded group. I created dummy variables for each age group (18-29, 30-49, 50-64), with that specific group being coded as 1 and the other responses being coded as 0.</p>
<p>A third control variable is a person’s race. On average, people who are White are more likely to be liberal than people of another race. The biggest block of the Democratic vote, for example, has shifted to white liberals from African Americans. Because of this, I excluded people who identify as White from my regression. I created a dummy variable to represent minority groups, with 1 being for people who responded that they were Black or African American, Asian, other or mixed race, don’t know, or refused and 0 for people who responded that they were White.</p>
<p><strong>Descriptive Statistics</strong></p>
<pre><code>## 
## Table 1: Descriptive Statistics on Ideology and Social Distancing
## ======================================================
## Statistic                   N   Mean  St. Dev. Min Max
## ------------------------------------------------------
## Abstained from Activities 1,296 0.235  0.424    0   1 
## Conservatie Ideology      1,296 0.350  0.477    0   1 
## Moderate Ideology         1,296 0.374  0.484    0   1 
## Trump Approval            1,269 0.406  0.491    0   1 
## Age 18-29                 1,273 0.135  0.342    0   1 
## Age 35-49                 1,273 0.270  0.444    0   1 
## Age 50-64                 1,273 0.288  0.453    0   1 
## Minority                  1,268 0.259  0.439    0   1 
## ------------------------------------------------------</code></pre>
<p>Table 1 presents descriptive statistics for my dependent variable, independent variables, and control variables. The table depicts the number of observations, mean, standard deviation, minimum, and maximum values for the following variables: Abstained From Activities, Conservative Ideology, Moderate Ideology, Trump Approval, Age 18-29, Age 35-49, Age 64, and Minorities.</p>
<p><strong>Results</strong> <img src="portfolio2_files/figure-html/unnamed-chunk-56-1.png" width="672" /> Figure 1 shows, as I predicted, that conservatives were less likely to socially distance than liberals or moderates. The “0” block represents people who responded to the survey as liberal, moderate, don’t know, or other, and is about 0.8 units higher than the conservative, or “1”, block.</p>
<pre><code>## 
## Table 2: Correlation of Abstained From Activities During COVID-19
## =============================================
##                      Dependent variable:     
##                 -----------------------------
##                     Abstained.activities     
##                 Ideology     All    Liberals 
##                    (1)       (2)       (3)   
## ---------------------------------------------
## Conservative    -0.081*** -0.073**           
##                  (0.030)   (0.034)           
##                                              
## Moderate         -0.006    -0.019            
##                  (0.030)   (0.031)           
##                                              
## Trump Approval             -0.049*    0.091  
##                            (0.028)   (0.069) 
##                                              
## Age 18-29                 -0.258*** -0.209***
##                            (0.039)   (0.069) 
##                                              
## Age 30-49                 -0.234*** -0.252***
##                            (0.031)   (0.063) 
##                                              
## Age 50-64                 -0.188***  -0.130* 
##                            (0.031)   (0.070) 
##                                              
## Minority Groups             0.022     0.031  
##                            (0.028)   (0.056) 
##                                              
## Constant        0.266***  0.437***  0.398*** 
##                  (0.022)   (0.030)   (0.046) 
##                                              
## ---------------------------------------------
## Observations      1,296     1,219      330   
## R2                0.008     0.071     0.055  
## =============================================
## Note:             *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01</code></pre>
<p>Table 2 presents a regression analysis for three subsets, all regressed on the dependent variable of abstained activities. The first column represents just the independent variable of ideology, for both conservatives and moderates. The average number of activities liberals abstained from was 0.26 units, while conservatives were 0.08 units less likely to abstain from any activities. This provides evidence for my hypothesis, as liberals were more likely to socially distance than those who identify as conservative. Moderates were 0.006 units less likely to abstain from any activities than liberals, which was also expected as moderates fall between liberals and conservatives on the ideology spectrum and subsequently should have fallen in the middle of the regression.</p>
<p>The second column in the regression includes all of the control variables that I used to test my theory. The average number of activities liberals abstained from activities was 0.437 units, while conservatives were 0.073 unites less likely to abstain from activities, holding fixed Trump approval, minority status, and age. This coefficient most likely increased because it now included my excluded groups of liberals, people who are white, people who are 65 years old and older, and people who do not approve of Trump. Theoretically, all of these categories would lead to increased social distancing, which is seen when the coefficient changes. The coefficient on Trump Approval indicates that people who support Trump are an additional 0.049 units less likely to abstain from any activities than people who do not support Trump. This was expected, since people who approve of Trump are likely to follow his behavior of not social distancing. Additionally, the coefficients on all three age groups (18-29, 20-49, 50-64) are negative, indicating that they are less likely to social distance than people who are aged 65 years old and older. This result was expected, as people who are younger are both at less of a risk of the virus and do not take the virus as seriously as those who are older. Finally, the coefficient on the minority groups variable indicates that people who identify as a minority are 0.022 units more likely to social distance than those that identify as White. Originally, I had hypothesized that people who identify as White would socially distance more since they make up the largest demographic of liberals. However, this result indicates that people who make up a minority group are more likely to socially distance than those who are White.</p>
<p>Similarly, to the second column, column three shows the same general patterns for the coefficients of the age and minority group variables. However, among liberals, people who approve of Trump are 0.091 units more likely to socially distance than liberals who do not approve of Trump. This result was not expected, as I would think that people who approve of Trump (who promotes not social distancing) would be less likely than people who do not approve of Trump (liberals especially) to socially distance. When looking at the data though, only 14.45% of liberals approve of Trump, while 85.55% disapprove (out of 357 observations). This makes it clear that the result is just unusual and there was little data to work with.</p>
<p><strong>Conclusion</strong></p>
<p>I was able to find evidence that people who identify as liberal are more likely to socially distance than those who identify as conservative. Because social distancing is such a broad topic, I would have wanted to have more information on the extent to which people social distanced (for example visiting family or friends while staying six feet apart and wearing a mask versus going inside of someone else’s house). This most likely would have changed the respondent’s attitude towards social distancing, as going inside of another person’s house does not adhere to the “definition” of social distancing set forth by the CDC. As a control variable, I would have wanted to look at the type of job a respondent has. If a respondent has a job where they are deemed an essential worker, then they would have had to respond yes to the “Did you go to work” (18C) question even if it was involuntary. I would have also wanted to look at a respondent’s religion. If a respondent goes to church twice a week, for example, then they might have a more relaxed attitude on social distancing if they were still going throughout the pandemic.</p>
<p>If I was able to look at these variables as well, I would expect the regression coefficient to increase. The majority of people in the country were not deemed essential workers, so I would expect more people to socially distance than the proportion of those who had to go to work. I would also expect the coefficient to increase in regard to religion because when the survey was taken in June, most places of worship were closed due to the pandemic. This would have caused more people to social distance if they were not able to practice their religion in person.</p>
<p>In regard to measurement error, it worries me that ideology is measured by only three choices. I would have wanted to have a more continuous variable to measure ideology, rather than just three options. In today’s political climate, there are numerous divisions within each political party and ideology separating one person’s view of being liberal or conservative from another. Right now, my study only analyzes ideology as if it is cut and dry, when in reality there are many different options to the question. This might have made respondents more open to answering the question if they had more options, especially if they responded as they don’t know.</p>
</div>
<div id="final" class="section level3">
<h3>Final</h3>
<p><strong>Introduction</strong></p>
<p>The process of scientific jury selection was first applied to a major case in the Harrisburg Seven trial in 1972. During the trial, social scientists used demographical information of the jurors to identify whether or not they would be biased towards a conviction and subsequently to serve on the jury. Ever since this case, prosecutors and defense attorneys alike have become accustomed to considering demographics – such as race, age, sex, economic background, marital status, religion, and relationship with the law – when picking a jury. During the voir dire process, lawyers have the opportunity to use peremptory and causal challenges in order to dismiss jurors that would not maintain fairness when listening to the case. A challenge for cause occurs when a lawyer removes someone for a legal reason (these are unlimited during a trial). A peremptory challenge occurs when a lawyer removes someone without a reason or explanation, but cannot be on the basis of race, ethnicity, or sex (the number is limited by the statute being tried). Increasingly, lawyers have been using these challenges in a subtle (in order to remain legal) way to achieve a jury that is more likely to either side in favor or against the defendant, depending on whether it is the prosecution or defense. According to the Equal Justice Initiative’s 2010 report on illegal racial discrimination in jury selection, 8 out of 10 African Americans in Houston County, Alabama that qualified for jury service have been struck by prosecutors from death penalty cases. It was also reported that in Jefferson Parish, Louisiana, there is no effective African American representation on the jury in 80 percent of criminal trials. This idea of deciding a case before presenting evidence just based upon racial biases and stereotypes seems like it should be a significant problem in the evaluation of trials and within the criminal justice system as a whole. This led me to the question “Are jurors more sympathetic to defendants of the same race?” and to my hypothesis that “juries in which at least 50% of the jurors are the same race as the defendant are more likely to side in favor of the defendant.”</p>
<p>In order to test my hypothesis, I analyzed data on four courthouses (Bronx County Supreme Court in New York, Los Angeles County Superior Court in California, Maricopa County Superior Court in Arizona, and District of Columbia Superior Court in Washington, DC). I ran a baseline regression between whether or not the defendant had at least one conviction and the proportion of the jury whose members are less than 50% racially similar to the defendant, as well as a controlled regression including victim believability, defendant sympathy, if the crime was a misdemeanor, and if the victim was not white. For both regressions, I found that the defendant was more likely to be convicted when the jury was less than 50% racially similar to the defendant than when the jury was at least 50% racially similar to the defendant, providing evidence for my hypothesis.</p>
<p><strong>Theory and Previous Literature</strong></p>
<p>While completing preliminary research, two sources emerged as predominantly important for this paper. In Professor of Law at Washington University School of Law Peter A. Joy’s 2015 paper for the Northwestern University Law Review entitled “Race Matters in Jury Selection,” he analyzed a study conducted by Samuel Sommers and Phoebe Ellsworth on implicit bias during the voir dire process. During the study, one group of mock jurors received a questionnaire about their racial attitudes and racial biases in the legal system while the other group was asked questions that disregarded race as a whole. According to Joy, the purpose of the questions was “not to identify racial bias in particular jurors, but rather to cause prospective jurors to think about their attitudes toward race to help jurors consciously guard against implicit bias.” The study found that both White and African American jurors were less likely to convict African American defendants after being asked the race-related questions during the voir dire, as well as that all-White juries were more likely to convict African American defendants than White defendants (Joy 2015). Ideally, all jurors would be asked these race-based questions in the real world during their voir dire in order to spark introspection and make themselves aware of any biases they may hold. However, race-relevant questions are only allowed during capital punishment cases, and the inclusion of a race-relevant voir dire is up to the discretion of the trial judge in all other cases. Originally, I planned on studying multiple demographics and how they impacted a juror’s decision on the defendant’s sentence as a whole. However, after this explanatory research, this paper became the foundation of my theory: implicit racial bias impacts jury decision making.</p>
<p>Similarly, in Justin D. Levinson (Associate Professor of Law at the University of Hawaii), Huajian Cai (Professor at the Key Laboratory of Mental Health and Institute of Psychology for the Chinese Academy of Sciences), and Danielle Young’s (member of the Department of Psychology at the University of Hawaii) research paper for the Ohio State Journal of Criminal Law entitled “Guilty By Implicit Racial Bias: The Guilty/Not Guilty Implicit Association Test,” they completed a study on how the Implicit Association Test (IAT) can be used in a legal setting. The study had participants (67 jury eligible students from the University of Hawaii) complete multiple tasks in order to measure racial beliefs and preferences. The first test was a Guilty/Not Guilty IAT test developed as a race IAT with “the attribute concepts of Guilty and Not Guilty and target concepts of Black and White” (Levinson 2010). The second test was a Pleasant/Unpleasant IAT test also developed as a race IAT to evaluate the concepts of Pleasant and Unpleasant with the target concepts of Black and White. The participants were also given the Modern Racism Scale, which has a series of questions in regard to racial beliefs, a feeling thermometer, which evaluates explicit racial preferences, and finally a robbery evidence evaluation task, which asked participants to decide whether a defendant was guilty or not guilty in a mock trial. The study found that participants in the Guilty/Not Guilty IAT displayed a “significant association between Black and Guilty compared to White and Guilty” and that participants in the Pleasant/Unpleasant IAT displayed a “significant association between Black and Unpleasant compared to White and Unpleasant” (Levinson 2010). Ultimately, Levinson, Cai, and Young were able to conclude that people are more likely to perceive black people as guilty, and that the implicit associations led to “predicted judgments of the probative value of evidence” (Levinson 2010). This study was crucial to the refinement of my theory and hypothesis, as it is such a significant problem that some trials are already decided before hearing any evidence, completely violating the “fair trial” requirement set forth by the Constitution.</p>
<p>After reviewing this previous literature, I have decided to focus on the proportion of jurors whose race matches the race of the defendant and whether or not that impacts their trial outcome. I have also decided to look at jury sympathy for the victim and defendant, as the second study proves the prominence of implicit biases when making decisions in regard to trial outcome. My research will add a unique perspective to this literature as I will be analyzing data from four different courthouses, all of which are located in demographically different areas (Bronx County, New York, Los Angeles County, California, Maricopa County, Arizona, and Washington, DC). I will also be analyzing the outcomes of the trials, rather than just the process of jury selection. This will allow me to connect the issue of racial biases in jury decision making to these different cities in order to highlight this significant fault within the justice system and the fact that it is present within all juries and not one particular area.</p>
<p><strong>Data</strong></p>
<p>I will use the data from the “Evaluation of Hung Juries in Bronx County, New York, Los Angeles County, California, Maricopa County, Arizona, and Washington, DC, 2000-2001 (ICPSR 3689)” by Paula Hannaford-Agor, Valerie Hans, Nicole Mott, and G. Thomas Munsterman. The data includes information on four courts (Bronx County Supreme Court in New York, Los Angeles County Superior Court in California, Maricopa County Superior Court in Arizona, and District of Columbia Superior Court in Washington, DC). Each court was sent a case data form and count sheet data form, as well as three questionnaires for the judges, attorneys, and jurors. The case data form includes the demographic information for the defendant and the victim(s) and the type of representation for the defendant. The count sheet data includes the case type, the jury’s decision for each count the defendant was charged with, the total number of convictions, and the sentence length. The judge questionnaire includes the evaluation of the evidence, case complexity, likelihood that the jury understood the case, importance of the victim’s testimony, and importance of the defendant’s testimony. The attorney questionnaire includes information assessing the case complexity, type of defense, whether or not the jury would become hung, and their own demographical information. The juror questionnaire includes responses regarding case complexity, whether or not the evidence was convincing, whether or not they had sympathy towards the defendant or victim(s), whether or not the defense had a strong case, which side they favored before, during, and after deliberations, and demographical information on themselves.</p>
<p>In order to analyze this data as a whole, I reshaped the attorney and jury datasets so that each row corresponded to a singular court site and case number. Once the data was widened, I was able to merge all five datasets together to create one larger dataset, entitled “law.” To construct my key independent variable (the proportion of the jury whose members are less than 50% racially similar to the defendant), I first created three dummy variables for the race of each jury member (White, not White, and unknown). Once all 36 variables were created (since trials could have up to 12 jurors), I added them together so that I would have a total count of the jury members of each race per case number (becoming the variables jury.white, jury.notwhite, and jury.unknown). Next, I created the same three dummy variables for the defendant’s race (def.white, def.notwhite, and def.unknown). Once these six variables were created, I constructed the continuous proportion variable (becoming the variable prop.race) by matching the race of the defendant with the number of people who matched that race on the jury and dividing that number by the total number of jurors for that case. I constructed my actual independent variable (becoming prop.race.less50) as a dummy variable that equals 1 if the proportion of the jury whose race matches the defendant was less than half of the members and 0 if the proportion of the jury is equal to or more than half of the members. Because my hypothesis is that juries in which at least 50% of the jurors are the same race as the defendant are more likely to side in favor of the defendant, I made the group in which the proportion of the jury whose race is equal to or more than half the same as the defendant the excluded group.</p>
<p>Afterwards, I constructed my dependent variable by combining the results for whether or not a defendant had a least one conviction for the six possible counts they could have been charged with in that particular case (becoming the variable yes.conv). The variable is coded as 1 if they had at least one conviction and 0 if they had no convictions. A measurement assumption of this variable, however, is that I am assuming that these juries had negative racial biases, when it could have been the opposite and positive, resulting in a lesser sentence or charge rather than a conviction for the defendant. Additionally, I chose to control for four different variables that all could influence both the proportion of jury members with a similar race to the defendant and whether or not the defendant was convicted on at least one count. First, I chose to control for whether or not the jury felt “a great deal of sympathy” for the defendant. It seems like having a large amount of sympathy for the defendant would cause the jury to rule in favor of the defendant, regardless of their race. I coded this variable (def.sympt) as a dummy variable that equals 1 if at least one of the jury members felt a great deal of sympathy for the defendant and 0 if none of the jury members felt a great deal of sympathy for the defendant. I would expect that someone who has no sympathy towards the defendant would rule more harshly, so I made that my excluded group. Similarly, I chose to control for whether or not the jury felt that the victim(s) was very believable. It seems like thinking that the victim(s) was very believable would cause the jury to rule against the defendant, regardless of race. I coded this variable (believe.vict) as a dummy variable that equals 1 if at least one of the jury members felt that the victim(s) was very believable and 0 if none of the jury members felt that the victims(s) was very believable. I would expect that someone who does not think that the victim was believable would rule less harshly against the defendant, so I made that my excluded group. My third control variable is the crime the defendant was charged with. I created two variables: the first (felony) equals 1 if the crime is classified as a felony and 0 if the crime is classified as a misdemeanor and the second (misdemeanor) equals 1 if the crime is classified as a misdemeanor and 0 if the crime is classified as a felony. I would expect that if someone was charged with a crime as serious as murder or rape, a juror would weigh that more heavily than whether or not they were the same race. Because of this, I made the felony variable my excluded group. Finally, my fourth control variable is the victim’s race. Because of the preconceived biases made by the jury in the research I previously discussed in my Literature Review, I decided to look at whether or not the victim was White, as most people in the study associated White with “Not Guilty” and “Pleasant.” I created two variables: the first (vict.white) equals 1 if the victim was White and 0 if victim was any other race and the second (vict.notwhite) equals 1 if the victim was any race other than White and 0 if the victim was White. Because I would expect the jury to favor White victims, I made that my excluded group.</p>
<pre><code>## 
## Table 1: Descriptive Statistics for Convictions and Proportion of Similar Race
## ===================================================================================================================
## Statistic                                                                                 N  Mean  St. Dev. Min Max
## -------------------------------------------------------------------------------------------------------------------
## At least one conviction                                                                  185 0.600  0.491    0   1 
## Proportion of the jury whose members are less than 50% racially similar to the defendant 184 0.489  0.501    0   1 
## Victim Believability                                                                     185 0.508  0.501    0   1 
## Defendant Sympathy                                                                       185 0.308  0.463    0   1 
## Not White Victim                                                                         185 0.989  0.104    0   1 
## Misdemeanor                                                                              185 0.141  0.348    0   1 
## -------------------------------------------------------------------------------------------------------------------</code></pre>
<p>Table 1 presents descriptive statistics for my dependent variable, independent variable, and control variables. The table depicts the number of observations, mean, standard deviation, minimum, and maximum values for the following variables: the defendant having at least one conviction, the proportion of the jury whose members are less than 50% racially similar to the defendant, at least one jury member thinking the victim was very believable, at least one jury member having sympathy for the defendant, if the case had a victim that was not White, and if the crime was a misdemeanor.</p>
<p><strong>Hypothesis and Empirical Tests</strong></p>
<p>Like I previously mentioned, my hypothesis is that “juries in which at least 50% of the jurors are the same race as the defendant are more likely to side in favor of the defendant.” I plan on testing this hypothesis through a quantitative analysis by running a regression between whether or not the defendant had at least one conviction and the proportion of the jury whose members are less than 50% racially similar to the defendant. By doing this, I will be able to see how much more likely juries with a greater proportion of members who are the same race as the defendant are to rule in favor of the defendant than juries with a smaller proportion.</p>
<p>In this case, my null hypothesis is that juries in which at least 50% of the jurors are the same race as the defendant would make the same decision on the outcome of a case as juries that were not mostly the same race as the defendant. In order to reject my null hypothesis, I would need to see the coefficient for the proportion of the jury whose members are less than 50% racially similar to the defendant be zero after running the regression, meaning that there was no difference in the likelihood of having at least one conviction between juries that were more or less racially similar to the defendant. I would also need to see the p-value for the proportion of the jury whose members are less than 50% racially similar to the defendant be 0.05 or less, meaning that there was such a small chance of committing a type I error, or rejecting the null hypothesis that juries in which at least 50% of the jurors are the same race as the defendant would make the same decision on the outcome of a case as juries that were not mostly the same race as the defendant, when it is true.</p>
<p><strong>Results</strong> <img src="portfolio2_files/figure-html/unnamed-chunk-94-1.png" width="672" /> Figure 1 displays the average proportion of times that someone is convicted with a jury similar in race to the defendant. The first panel displays the average proportions when the jury members were both at least 50% racially similar to the defendant and less than 50% racially similar to the defendant for when the defendant was convicted on at least one count and was not white. The second panel also displays the average proportions when the jury members were both at least 50% racially similar to the defendant and less than 50% racially similar to the defendant, but now for when the defendant was convicted on at least one count and was white.</p>
<p>Both panels highlight, as I hypothesized, the difference in jury decision making when the jury is made up of a different percent of members that match the race of the defendant. When the jury is made up of at least 50% of members of the same race as the defendant, they are more likely to not convict the defendant than juries made up of members that are less than 50% of the same race. If the defendant was not white and the majority of the jury was not white, the defendant was less likely to be convicted by a larger margin than if the defendant was white and the majority of the jury was also white.</p>
<p>To model this further, I ran two regressions between having at least one conviction and the proportion of the jury whose members were less than 50% racially similar to the defendant, controlling for victim believability, defendant sympathy, if the crime was a misdemeanor, and if the victim was not white in the second regression.</p>
<pre><code>## 
## Table 2: Proportion of the Jury whose Race Matches the Defendant and Total Convictions
## =========================================================================================
##                                                                  Dependent variable:     
##                                                              ----------------------------
##                                                                        yes.conv          
##                                                                 Baseline      Controls   
##                                                                   (1)            (2)     
## -----------------------------------------------------------------------------------------
## Prop of the jury less than 50% racially similar to defendant     0.124*        0.165**   
##                                                                 (0.072)        (0.074)   
##                                                                                          
## Victim Believability                                                            0.004    
##                                                                                (0.075)   
##                                                                                          
## Sympathy for the Defendant                                                     0.197**   
##                                                                                (0.082)   
##                                                                                          
## Not White Victim                                                               -0.366    
##                                                                                (0.349)   
##                                                                                          
## Misdemeanor                                                                     0.145    
##                                                                                (0.105)   
##                                                                                          
## Constant                                                        0.543***       0.801**   
##                                                                 (0.050)        (0.350)   
##                                                                                          
## -----------------------------------------------------------------------------------------
## Observations                                                      184            184     
## R2                                                               0.016          0.062    
## =========================================================================================
## Note:                                                         *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01</code></pre>
<p>Table 2 presents both regression analyses, regressed on the dependent variable of having at least one conviction. The average chance of the defendant having at least one conviction in their case when the jury was at least 50% racially similar to the defendant was 54.3 percentage points. When the proportion of the jury whose members were less than 50% racially similar to the defendant, the defendant was more likely to be convicted by 12.4 percentage points. This baseline provides evidence for my hypothesis, as juries with more members who matched the race of the defendant were less likely to convict the defendant. Additionally, the p-value for the average chance of the defendant having at least one conviction in their case when the jury was at least 50% racially similar to the defendant is 2 X 10 ^ -16. Since this is an extremely small value, I can reject the null hypothesis that juries in which at least 50% of the jurors are the same race as the defendant would make the same decision on the outcome of a case as juries that were not mostly the same race as the defendant.</p>
<p>Furthermore, when no jury members thought that the victim was believable or had sympathy for the defendant, the crime was a felony, and the victim was white, the average chance of a defendant having at least one conviction in their case when the jury was at least 50% racially similar to the defendant was 80.1 percentage points. When the proportion of the jury whose members were less than 50% racially similar to the defendant, the defendant was more likely to be convicted by 16.5 percentage points than when the jury was at least 50% racially similar to the defendant, holding fixed victim believability, defendant sympathy, if the crime was a misdemeanor, and if the victim was not white. I expected there to be an increase in the coefficient, as juries without a majority of the same race should be more likely to convict when there is no overarching demographical connection. When at least one jury member thought that the victim was very believable, the defendant was more likely to be convicted than if none of the jury members thought that the victim was very believable by only 0.4 percentage points. I expected there to be an increase in the likelihood of a conviction since I assumed the jury would feel bad for the victim, but the small increase could be accounted for by the fact that maybe only one out of the 12 jurors believed the victim, or they believed the victim but not to a “very believable” extent. When the victim was not white, the defendant was less likely to be convicted than if the victim was white by 36.6 percentage points. This seemed strange at first, as I expected juries to be harsher on defendants when the victim was white. However, the majority of defendants were not white (136 out of 185) and 58% of the time, juries were made up of a majority of people who identified as not white. This indicates that juries had more sympathy towards defendants that were not white, rather than white defendants. This is also proven in Figure 1, as not white defendants with a jury that was mostly not white were less likely to be convicted than white defendants with a jury was mostly white.</p>
<p>Additionally, there were two results from the second regression that surprised me. When at least one jury member had a great deal of sympathy for the defendant, the defendant was more likely to be convicted than if none of the jury had sympathy for the defendant by 19.7 percentage points. I expected this coefficient to be negative, since feeling bad for the defendant would theoretically lead the jury to not convict them. Similarly to the victim believability variable, I was only measuring if a jury member had “a great deal of sympathy” for the defendant, and they could have felt some sympathy but did not reach the “great deal” threshold. Criminal cases also require a unanimous decision by the jury, so it could be possible that at least one juror felt a “great deal of sympathy” but was overpowered by the rest of the jury, leading to a conviction. Likewise, when the crime was a misdemeanor, the defendant was more likely to be convicted than if it was a felony by 14.5 percentage points. I expected this result to be negative as well, since I thought that people charged with felonies would be more likely to be convicted than someone charged with a less serious crime. A juror could possibly have more sympathy for a defendant if the defendant was going to jail versus if they were sentenced to a fine or probation (usually the outcome of misdemeanor cases), and maybe most of the cases in the data did not result in jail or prison sentences, accounting for both of these discrepancies.</p>
<p><strong>Discussion and Conclusion</strong></p>
<p>I was able to find evidence that juries in which at least 50% of the jurors are the same race as the defendant are more likely to side in favor of the defendant. For both regressions, the defendant was more likely to be convicted when the jury was less than 50% racially similar to the defendant than when the jury was at least 50% racially similar to the defendant, including when I held fixed victim believability, defendant sympathy, if the crime was a misdemeanor, and if the victim was not white. I also found that when at least one jury member thought that the victim was very believable, the defendant was more likely to be convicted than if none of the jury members thought that the victim was very believable and when the victim was not white, the defendant was less likely to be convicted than if the victim was white. Surprisingly, I found that when at least one jury member had a great deal of sympathy for the defendant, the defendant was more likely to be convicted than if none of the jury had sympathy for the defendant and when the crime was a misdemeanor, the defendant was more likely to be convicted than if it was a felony. More research needs to be conducted on these two variables (for example, splitting the cases up by type of crime rather than overall category) in order to account for these discrepancies.</p>
<p>My results are consistent with previous research completed on the topic. Racially similar juries are more likely to side the same way as each other, as well as in favor of the defendant if they matched the race. In a 2003 study completed by law professor Phoebe C. Ellsworth for the University of Michigan Law School Scholarship Repository researching jury decision making in a race salient and non-race salient mock trial, Ellsworth found that “White mock jurors were more likely to vote to convict the Black defendant (90% of jurors voted to convict) than the White defendant (70% conviction rate).” This is consistent with my results, as juries that were mostly White with a non-White defendant and juries that were mostly not-White with a White defendant were more likely to convict than if the races matched. My results also matched the studies discussed in the Literature Review, as the first paper written by Joy (actually analyzing another study completed by Ellsworth) found that that all-White juries were more likely to convict African American defendants than White defendants. The second paper, written by Levinson, Cai, and Young, also found that people are more likely to perceive black people as guilty and therefore convict them. While I did not look at race in depth and rather as White or not-White, my results are consistent with all three studies and the idea that implicit racial bias impacts jury decision making.</p>
<p>Some potential confounds for interpreting my results and stopping me from finding a causal effect between my variables are other demographical information that I did not have available in the data. Controlling for a juror’s religion could have been useful since different religions value different punishments and sentences. For example, Catholics are less likely to support the death penalty than Protestants and would be more lenient towards a defendant in a death penalty case (Miller 2007). Similarly, controlling for whether or not a juror was married or had kids would be helpful to better explain the relationship between my independent and dependent variables. Picking parents and grandparents for a trial of a teenager, for example, would make the jury more sympathetic towards the defendant when the defendant could have been their own kid. Additionally, a potential confound for interpreting my results is whether or not a juror has any experience or strong opinions on the criminal justice system. If a juror was a lawyer or police officer, or had a family member arrested or in jail, they would have a different opinion and perspective on the case than if they had no or very limited knowledge on the topic. Ideally, I would have been able to control for all of these demographical characteristics, as well as harder to measure variables (empathy, feelings on the legal system, feelings the day of the trial), in order to be more confident that the proportion of the jury being a certain race impacts how the jury decides in the case.</p>
<p>Based on my results, it is clear that jury selection needs to be better regulated so that juries do not have preconceived biases before making life changing decisions. A case should not be decided before evidence is even presented, and attorneys should have a responsibly to create a diverse, fair jury rather than one crafted just to win. Further research needs to be completed on other demographical information in order to create a more comprehensive way to reshape the voir dire process and ensure that the legal system works more efficiently.</p>
<p><strong>Works Cited</strong></p>
<p>Hannaford-Agor, Paula L., Hans, Valerie P., Mott, Nicole L., and Munsterman, G. Thomas. Evaluation of Hung Juries in Bronx County, New York, Los Angeles County, California, Maricopa County, Arizona, and Washington, DC, 2000-2001. [distributor], 2006-03-30. Illegal Racial Discrimination in Jury Selection: A Continuing Legacy. (2020, August 21). Retrieved December 17, 2020, from <a href="https://eji.org/reports/illegal-racial-discrimination-in-jury-selection/" class="uri">https://eji.org/reports/illegal-racial-discrimination-in-jury-selection/</a> Joy, P. (109). RACE MATTERS IN JURY SELECTION. Northwestern University Law Review. Levinson, J., Cai, H., &amp; Young, D. (2010). Guilty By Implicit Racial Bias: The Guilty/Not Guilty Implicit Association Test. OHIO STATE JOURNAL OF CRIMINAL LAW, 8, 187-208. Miller, M.K., Hayward, R.D. Religious Characteristics and the Death Penalty. Law Hum Behav 32, 113–123 (2008). Sommers, S., &amp; Ellsworth, P. (2003). How Much Do We Really Know about Race and Juries? A Review of Social Science Theory and Research. University of Michigan Law School Scholarship Repository, 3, 997-1031.</p>
</div>
</div>
<div id="statistics-for-the-social-sciences" class="section level2">
<h2>Statistics for the Social Sciences</h2>
<h2>
Statistics for the Social Sciences
</h2>
<div id="assignment-1" class="section level3">
<h3>Assignment 1</h3>
<p><strong>Problem 1</strong></p>
<p><strong>Install the datasets package on the console below using install.packages(“datasets”). Now load the library.</strong></p>
<pre class="r"><code>#Install the dataset package  
#install.packages(&quot;datasets&quot;)

#load in the library 
library(datasets)</code></pre>
<p><strong>Load the USArrests dataset and rename it dat. Note that this dataset comes with R, in the package datasets, so there’s no need to load data from your computer. Why is it useful to rename the dataset?</strong></p>
<pre class="r"><code>#Load in the dataset
USArrests</code></pre>
<pre><code>##                Murder Assault UrbanPop Rape
## Alabama          13.2     236       58 21.2
## Alaska           10.0     263       48 44.5
## Arizona           8.1     294       80 31.0
## Arkansas          8.8     190       50 19.5
## California        9.0     276       91 40.6
## Colorado          7.9     204       78 38.7
## Connecticut       3.3     110       77 11.1
## Delaware          5.9     238       72 15.8
## Florida          15.4     335       80 31.9
## Georgia          17.4     211       60 25.8
## Hawaii            5.3      46       83 20.2
## Idaho             2.6     120       54 14.2
## Illinois         10.4     249       83 24.0
## Indiana           7.2     113       65 21.0
## Iowa              2.2      56       57 11.3
## Kansas            6.0     115       66 18.0
## Kentucky          9.7     109       52 16.3
## Louisiana        15.4     249       66 22.2
## Maine             2.1      83       51  7.8
## Maryland         11.3     300       67 27.8
## Massachusetts     4.4     149       85 16.3
## Michigan         12.1     255       74 35.1
## Minnesota         2.7      72       66 14.9
## Mississippi      16.1     259       44 17.1
## Missouri          9.0     178       70 28.2
## Montana           6.0     109       53 16.4
## Nebraska          4.3     102       62 16.5
## Nevada           12.2     252       81 46.0
## New Hampshire     2.1      57       56  9.5
## New Jersey        7.4     159       89 18.8
## New Mexico       11.4     285       70 32.1
## New York         11.1     254       86 26.1
## North Carolina   13.0     337       45 16.1
## North Dakota      0.8      45       44  7.3
## Ohio              7.3     120       75 21.4
## Oklahoma          6.6     151       68 20.0
## Oregon            4.9     159       67 29.3
## Pennsylvania      6.3     106       72 14.9
## Rhode Island      3.4     174       87  8.3
## South Carolina   14.4     279       48 22.5
## South Dakota      3.8      86       45 12.8
## Tennessee        13.2     188       59 26.9
## Texas            12.7     201       80 25.5
## Utah              3.2     120       80 22.9
## Vermont           2.2      48       32 11.2
## Virginia          8.5     156       63 20.7
## Washington        4.0     145       73 26.2
## West Virginia     5.7      81       39  9.3
## Wisconsin         2.6      53       66 10.8
## Wyoming           6.8     161       60 15.6</code></pre>
<pre class="r"><code>#rename the USArrests dataset
dat &lt;- USArrests</code></pre>
<p>It is useful to rename the dataset because it is easier to work with. If the data set had a longer or more complicated name, it would be difficult and time consuming to type out the dataset name every time when you want to perform a function on the data. It also lets you keep track of your work if you make different versions of it so that it is not contaminated by changes that were meant to be on one version and not the other. This will let you replicate the work if changes were made to different versions.</p>
<p><strong>Problem 2</strong></p>
<p><strong>Use this command to make the state names into a new variable called State.</strong></p>
<pre class="r"><code>dat$state &lt;- tolower(rownames(USArrests))</code></pre>
<p>This dataset has the state names as row names, so we just want to make them into a new variable. We also make them all lower case, because that will help us draw a map later - the map function requires the states to be lower case.</p>
<p><strong>List the variables contained in the dataset USArrests.</strong></p>
<pre class="r"><code>#find the variables in the dataset
names(dat)</code></pre>
<pre><code>## [1] &quot;Murder&quot;   &quot;Assault&quot;  &quot;UrbanPop&quot; &quot;Rape&quot;     &quot;state&quot;</code></pre>
<p>The variables in the USArrests dataset are Murder, Assault, UrbanPop, Rape, and State.</p>
<p><strong>Problem 3</strong></p>
<p><strong>What type of variable (from the DVB chapter) is Murder?</strong> Murder is a quantitative variable from the DVB chapter since it is a count of numbers.</p>
<p><strong>What R Type of variable is it?</strong></p>
<p>Murder is a numeric variable from the R type since it is also a count of numbers and functions such as mean or median can be applied.</p>
<p><strong>Problem 4</strong></p>
<p><strong>What information is contained in this dataset, in general? What do the numbers mean?</strong> The dataset contains arrest numbers for 4 types of crimes within all 50 states. Each state has a corresponding arrest rate for murder, assault, and rape, as well as the percent of urban population within the state. The numbers mean the number of arrests per 100,000 people in that state.</p>
<p><strong>Problem 5</strong></p>
<p><strong>Draw a histogram of Murder with proper labels and title.</strong></p>
<pre class="r"><code>hist(dat$Murder, main = &quot;Histogram of Murder Arrests&quot;, xlab = &quot;Number of Murder Arrests&quot;, ylab = &quot;Frequency&quot;)</code></pre>
<p><img src="portfolio2_files/figure-html/unnamed-chunk-102-1.png" width="672" /></p>
<p><strong>Problem 6</strong></p>
<p><strong>Please summarize Murder quantitatively. What are its mean and median? What is the difference between mean and median? What is a quartile, and why do you think R gives you the 1st Qu. and 3rd Qu.?</strong></p>
<pre class="r"><code>#finding the summary statistics of the murder variable
summary(dat$Murder)</code></pre>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##   0.800   4.075   7.250   7.788  11.250  17.400</code></pre>
<p>The mean of the murder variable is 7.788 murders, while the median is 7.250 murders. The mean is the sum of all data values divided by the number of values, or the average of the values within the dataset. The median, however, is the middle value after all of the values are put in numerical order. When distributions are skewed or there are outliers in the data, the median is better to use than the mean because the mean changes with skew or outliers and the median is more robust. A quartile is each of three values in which the data can be distributed into even fourths. I think that R gives us the 1st quartile and 3rd quartile because they can be used to calculate the interquartile range, which tells us the interval where half of the values within the data set lie. The median is also the 2nd quartile, so the three groups are given that split the data in even fourths.</p>
<p><strong>Problem 7</strong></p>
<p><strong>Repeat the same steps you followed for Murder, for the variables Assault and Rape. Now plot all three histograms together. You can do this by using the command par(mfrow=c(3,1)) and then plotting each of the three.</strong></p>
<pre class="r"><code>#make a histogram of assault
hist(dat$Assault, main = &quot;Histogram of Assault Arrests&quot;, xlab = &quot;Number of Assault Arrests&quot;, ylab = &quot;Frequency&quot;)</code></pre>
<p><img src="portfolio2_files/figure-html/unnamed-chunk-104-1.png" width="672" /></p>
<pre class="r"><code>#make a histogram of rape
hist(dat$Rape, main = &quot;Histogram of Rape Arrests&quot;, xlab = &quot;Number of Rape Arrests&quot;, ylab = &quot;Frequency&quot;)</code></pre>
<p><img src="portfolio2_files/figure-html/unnamed-chunk-104-2.png" width="672" /></p>
<pre class="r"><code>#plot all three histograms together
par(mfrow=c(3,1))
hist(dat$Murder, main = &quot;Histogram of Murder Arrests&quot;, xlab = &quot;Number of Murder Arrests&quot;, ylab = &quot;Frequency&quot;)
hist(dat$Assault, main = &quot;Histogram of Assault Arrests&quot;, xlab = &quot;Number of Assault Arrests&quot;, ylab = &quot;Frequency&quot;)
hist(dat$Rape, main = &quot;Histogram of Rape Arrests&quot;, xlab = &quot;Number of Rape Arrests&quot;, ylab = &quot;Frequency&quot;)</code></pre>
<p><img src="portfolio2_files/figure-html/unnamed-chunk-104-3.png" width="672" /></p>
<p><strong>What does the command par do, in your own words (you can look this up by asking R ?par)?</strong> Par can be used to set the parameters on a graph, making it easier to combine multiple graphs into one.</p>
<p><strong>What can you learn from plotting the histograms together?</strong> By plotting these histograms together, you can compare the arrest rates for each crime. Murders happen the least frequently and assaults happen the most frequently. You can also see that the histogram for murder is unimodal and skewed, the histogram for assaults is bimodal, and the histogram for rapes is also unimodal and skewed.</p>
<p><strong>Problem 8</strong></p>
<p><strong>In the console below (not in text), type install.packages(“maps”) and press Enter, and then type install.packages(“ggplot2”) and press Enter. This will install the packages so you can load the libraries.</strong></p>
<pre class="r"><code>#install and load in the maps and ggplot2 packages
library(&#39;maps&#39;) 
library(&#39;ggplot2&#39;)</code></pre>
<p><strong>Run this code:</strong></p>
<pre class="r"><code>ggplot(dat, aes(map_id=state, fill=Murder)) + 
  geom_map(map=map_data(&quot;state&quot;)) + 
  expand_limits(x=map_data(&quot;state&quot;)$long, y=map_data(&quot;state&quot;)$lat)</code></pre>
<p><img src="portfolio2_files/figure-html/unnamed-chunk-106-1.png" width="672" /></p>
<p><strong>What does this code do? Explain what each line is doing.</strong> The first line above the map code loads the library for both packages. The first line of the map code is creating a plot of murder. The ggplot function is telling R to create a plot, the “dat” is telling R which dataset to use in the plot, and the “aes(map_id=state, fill=Murder))” is telling R to plot each state and fill it with the corresponding murder arrest rate. The geom_map function creates shapes for a reference map, and the map=map_data(“state”) function is telling R to map the data that corresponds with the state variable that we created earlier. The expand_limits function makes sure that the entire map fits within the plot of the graph and the (x=map_data(“state”)long,y=mapdata(“state”)lat) tells R which data to base the plot limits off of, which in this case is the state data.</p>
</div>
<div id="assignment-2" class="section level3">
<h3>Assignment 2</h3>
<p><strong>Problem 1</strong></p>
<p><strong>Load in the data.</strong></p>
<pre class="r"><code>dat &lt;- read.csv(file = &quot;data/Assignment2datacopy.csv&quot;)</code></pre>
<p><strong>What are the dimensions of the dataset?</strong></p>
<pre class="r"><code>dim(dat)</code></pre>
<pre><code>## [1] 171   7</code></pre>
<p>There are 171 columns and 7 rows (or 171 respondents and 7 questions).</p>
<p><strong>Problem 2</strong></p>
<p><strong>Describe the variables in the dataset.</strong></p>
<pre class="r"><code>names(dat)</code></pre>
<pre><code>## [1] &quot;mjage&quot;     &quot;cigage&quot;    &quot;iralcage&quot;  &quot;age2&quot;      &quot;sexatract&quot; &quot;speakengl&quot;
## [7] &quot;irsex&quot;</code></pre>
<p>There are 7 variables in the dataset: 1. “mjage” (How old were you the first time you used marijuana or hashish?) 2. “cigage” (How old were you when you first started smoking cigarettes everyday?) 3. “iralcage” (How old were you when you first tried alcohol?) 4. “age2” (Recoded final edited age (since respondents had multiple chances to change their age throughout the survey)) 5. “sexatract” (Sexual attraction) 6. “speakengl” (How well do you speak English) 7. “irsex” (Imputation revised gender)</p>
<p>Mjage, cigage, and iralcage are numeric variables (or quantitative) because the respondent gave an exact number for their answers for each variable and functions like mean can be applied to find the average age the respondents tried marijuana, cigarettes, and alcohol. Age2, sexatract, speakengl, and irsex are categorical variables because the respondents’ answers were split into categories when coded. Because respondents had the opportunity to change their age throughout the interview, the age variable was calculated from the raw birth date and the final edited interview date, the age entered in the questionnaire roster (if it exists), and the pre-interview screener age because interviewees had the opportunity to change their age throughout the interview.</p>
<p><strong>What is this dataset about? Who collected the data, what kind of sample is it, and what was the purpose of generating the data?</strong> The dataset is a small sample from the National Survey of Drug Use and Health, which was conducted by the Center for Behavioral Health Statistics and Quality (CBHSQ, formerly the Office of Applied Studies) within the Substance Abuse and Mental Health Services Administration (SAMHSA) and is conducted by RTI International, Research Triangle Park, North Carolina. The survey was conducted through a computer assisted administration, and was changed from a strictly national design to a state-based sampling plan in 1999. The primary purpose of generating the data was to measure the prevalence and correlation of substance use and mental health issues in the United States, according to the NSDUH 2019 Codebook.</p>
<p><strong>Problem 3: Age and gender</strong></p>
<p><strong>What is the age distribution of the sample like? Make sure you read the codebook to know what the variable values mean.</strong></p>
<pre class="r"><code>hist(dat$age2, main = &quot;Histogram of Recoded Final Edited Age Categories&quot;, xlab = &quot;Recoded Final Edited Age Categories&quot;)</code></pre>
<p><img src="portfolio2_files/figure-html/unnamed-chunk-110-1.png" width="672" /> The age variable is skewed to the left, with the majority of the values in the 14-16 bin (which means that the majority of the people in the dataset are 30 to 64 years old, according to the codebook). There are fewer people who were very young when filling out the survey, with only a few in the 4-6 and 6-8 bins (meaning that the respondents in these bins were 15-17 and 18-19, respectively).</p>
<p><strong>Do you think this age distribution representative of the US population? Why or why not?</strong></p>
<pre class="r"><code>min(dat$age2) #the youngest respondent was 15 (category 4)</code></pre>
<pre><code>## [1] 4</code></pre>
<pre class="r"><code>max(dat$age2) #the oldest respondent was 65 years old or older (category 17)</code></pre>
<pre><code>## [1] 17</code></pre>
<p>Yes, I think that this age distribution is representative of the US population. The survey was conducted in order to evaluate drug use, and I would think that people would not try drugs before turning 15 (the youngest respondent) and very few people would continue using drugs when they are 65 years old or older (the oldest respondent). Also, according to the codebook, the participants were randomly selected to complete the survey, which fulfills one requirement of a representative sample. It makes sense that the number of respondents increased when the respondents were 19 to 23 (8 to 12 categories) as those are the ages when most people would be exposed to marijuana, drugs, and alcohol for the first time, and that the number of respondents increased again when the respondents were 24 to 64 (categories 12 to 16), as those are the ages that people would continue to use marijuana, drugs, and alcohol as adults (especially after potentially being exposed in college). I also think that it makes sense that the majority of respondents were 34 to 64 years old, because older generations are more likely to have smoked cigarettes everyday before perception and knowledge changed.</p>
<p><strong>Is the sample balanced in terms of gender? If not, are there more females or males?</strong></p>
<pre class="r"><code>table(dat$irsex, dat$age2)</code></pre>
<pre><code>##    
##      4  6  7  8  9 10 11 12 13 14 15 16 17
##   1  1  1  1  0  1  1  3  3 14 10 33 14  9
##   2  1  0  0  2  6  2  3  4 13  6 29 10  4</code></pre>
<p>The sample is not balanced in terms of gender. There were 91 males included in the dataset and 80 females included.</p>
<p><strong>Use this code to draw a stacked bar plot to view the relationship between sex and age. What can you conclude from this plot?</strong></p>
<pre class="r"><code>tab.agesex &lt;- table(dat$irsex, dat$age2)
barplot(tab.agesex,
        main = &quot;Stacked barchart&quot;,
        xlab = &quot;Age category&quot;, ylab = &quot;Frequency&quot;,
        legend.text = rownames(tab.agesex),
        beside = FALSE) # Stacked bars (default)</code></pre>
<p><img src="portfolio2_files/figure-html/unnamed-chunk-113-1.png" width="672" /> From this plot, I can conclude that more males answered the survey than females, as most age categories have a higher frequency of males than females (especially in categories 6 and 7). I can also conclude than more older males answered the survey than older females. As indicated in both the plot and the table of sex and age categories, the highest five categories (13, 14, 15, 16, and 17) had more male responses than females (1 more, 4 more, 4 more, 4 more, and 5 more, respectively).</p>
<p><strong>Problem 4: Substance use</strong></p>
<p><strong>For which of the three substances included in the dataset (marijuana, alcohol, and cigarettes) do individuals tend to use the substance earlier?</strong></p>
<pre class="r"><code>boxplot(dat$mjage, dat$cigage, dat$iralcage, main = &quot;Substance Usage and Age&quot;,
        ylab=&quot;Age&quot;, xlab=&quot;Types of Substances&quot;, 
        names=c(&quot;Marijuana or Hashish&quot;,&quot;Cigarettes&quot;,&quot;Alcohol&quot;))</code></pre>
<p><img src="portfolio2_files/figure-html/unnamed-chunk-114-1.png" width="672" /> Based on the boxplot of substance usage and age, it looks like individuals tend to use alcohol earlier than marijuana / hashish or earlier than they started smoking cigarettes every day.</p>
<pre class="r"><code>min(dat$mjage) </code></pre>
<pre><code>## [1] 7</code></pre>
<pre class="r"><code>min(dat$cigage) </code></pre>
<pre><code>## [1] 10</code></pre>
<pre class="r"><code>min(dat$iralcage) </code></pre>
<pre><code>## [1] 5</code></pre>
<p>Looking at the minimum values for each type of substance, the minimum recorded age for when an individual first tried marijuana / hashish was 7, the minimum recorded age for when an individual first started smoking cigarettes everyday was 10, and the minimum recorded age for when an individual first tried alcohol was 5. This also confirms that like individuals tend to use alcohol earlier than marijuana / hashish or earlier than they started smoking cigarettes every day.</p>
<p><strong>Problem 5: Sexual attraction</strong></p>
<p><strong>What does the distribution of sexual attraction look like? Is this what you expected?</strong></p>
<pre class="r"><code>dat.sexat &lt;- subset(dat$sexatract, subset = dat$sexatract&lt;7)

hist(dat.sexat, main = &quot;Distribution of Sexual Attraction&quot;, xlab = &quot;Sexual Attraction&quot;)</code></pre>
<p><img src="portfolio2_files/figure-html/unnamed-chunk-116-1.png" width="672" /> The distribution of sexual attraction is skewed to the right, with the majority of respondents answering that they are only attracted to the opposite sex (category one). The next greatest frequency of response is that the respondent is mostly attracted to the opposite sex (category 2), and then followed by the respondent is equally attracted to males and females (category 3). This is exactly what I expected because I would think that an overwhelming majority of people would be straight as that is most common in the United States.</p>
<p><strong>What is the distribution of sexual attraction by gender?</strong></p>
<pre class="r"><code>table(dat$irsex, dat$sexatract)</code></pre>
<pre><code>##    
##      1  2  3  4  5  6 99
##   1 82  3  0  1  2  1  2
##   2 54 13  9  2  1  0  1</code></pre>
<pre class="r"><code>library(dplyr) 

dat$sexatract &lt;- dat$sexatract %&gt;% na_if(., &quot;85&quot;)
dat$sexatract &lt;- dat$sexatract %&gt;% na_if(., &quot;94&quot;)
dat$sexatract &lt;- dat$sexatract %&gt;% na_if(., &quot;97&quot;)
dat$sexatract &lt;- dat$sexatract %&gt;% na_if(., &quot;98&quot;)
dat$sexatract &lt;- dat$sexatract %&gt;% na_if(., &quot;99&quot;)

dat.five &lt;- data.frame(dat$sexatract, dat$irsex)

barplot &lt;- barplot(table(dat.five$dat.irsex, dat.five$dat.sexatract),
        main = &quot;Sexual Attraction and Gender&quot;,
        xlab = &quot;Sexaul Attraction Category&quot;,
        ylab = &quot;Count&quot;,
        border = &quot;black&quot;,
        col = c(&quot;hotpink1&quot;, &quot;blue&quot;),
        ylim = c(0,171), legend.text = c(&quot;Males&quot;,&quot;Females&quot;),
        )</code></pre>
<p><img src="portfolio2_files/figure-html/unnamed-chunk-117-1.png" width="672" /></p>
<pre class="r"><code>barplot</code></pre>
<pre><code>## [1] 0.7 1.9 3.1 4.3 5.5 6.7</code></pre>
<p>Looking at the stacked bar plot of sexual attraction and gender, it confirms what was seen in the table that more males than females responded that they are only attracted to the opposite sex (category one). It also confirms that more females than males answered that they are mostly attracted to the opposite sex (category 2) and are equally attracted to males and females (category 3).</p>
<p><strong>Problem 6: English speaking</strong></p>
<p><strong>What does the distribution of English speaking look like in the sample?</strong></p>
<pre class="r"><code>hist(dat$speakengl, main = &quot;Histogram of English Speakers&quot;, xlab = &quot;How Well You Speak English (1 - lowest, 4 - highest)&quot;)</code></pre>
<p><img src="portfolio2_files/figure-html/unnamed-chunk-118-1.png" width="672" /> The distribution of English speaking looks extremely skewed to the right, with the majority of respondents answering that they speak English very well (category one).</p>
<pre class="r"><code>table(dat$speakengl)</code></pre>
<pre><code>## 
##   1   2   3 
## 161   8   2</code></pre>
<p>Looking at the table of respondents who answered the “Speak English” question,161 people answered that the speak English very well, eight answered that they speak English well, and only two answered that they speak English not well. This confirms the skew seen in the histogram.</p>
<p><strong>Is this what you might expect for a random sample of the US population?</strong> This is what I would expect a random sample of the US population to look like, as the majority of people in the US speak English and speak it very well. Even if there were people included in the random sample from places that do not speak as much English, like Texas or Miami, for example, the large amount of people who do speak English well would account for what is seen in the histogram.</p>
<p><strong>Are there more English speaker females or males?</strong></p>
<pre class="r"><code>table(dat$irsex, dat$speakengl)</code></pre>
<pre><code>##    
##      1  2  3
##   1 84  7  0
##   2 77  1  2</code></pre>
<pre class="r"><code>barplot(table(dat$irsex, dat$speakengl),
        main=&quot;English Speaking Level and Gender&quot;,
        xlab=&quot;English Speaking Level Category&quot;,
        ylab=&quot;Count&quot;,
        col=c(&quot;hotpink1&quot;, &quot;blue&quot;),
        ylim = c(0,200),  legend.text = c(&quot;Males&quot;,&quot;Females&quot;)
)</code></pre>
<p><img src="portfolio2_files/figure-html/unnamed-chunk-120-1.png" width="672" /> Looking at the stacked bar plot of English speaking level and gender, it looks like the number of males and females that answered that they spoke English very well was pretty close, will a few more males (exactly 11, according to the table). The plot also confirms that more men responded that they spoke English well than women, and that no men responded that they spoke English not well.</p>
</div>
<div id="exam-1" class="section level3">
<h3>Exam 1</h3>
<p><strong>Load the data into an R data frame.</strong></p>
<pre class="r"><code>dat &lt;- read.csv(file = &quot;data/fatal-police-shootings-datacopy.csv&quot;)</code></pre>
<p>))Problem 1 (10 points)__</p>
<p><strong>Describe the dataset. This is the source: <a href="https://github.com/washingtonpost/data-police-shootings" class="uri">https://github.com/washingtonpost/data-police-shootings</a> . Write two sentences (max.) about this.</strong> The dataset is made up of every fatal police shooting in the US since January 1, 2015, as collected by the Washington Post. The dataset includes 6594 people and 17 variables, which contain important information about each shooting, such as the name of the person shot, their mental health status, and their race.</p>
<p><strong>How many observations are there in the data frame?</strong></p>
<pre class="r"><code>dim(dat)</code></pre>
<pre><code>## [1] 6594   17</code></pre>
<p>There are 6594 observations in the data frame.</p>
<p><strong>Look at the names of the variables in the data frame. Describe what “body_camera”, “flee”, and “armed” represent, according to the codebook. Again, only write one sentence (max) per variable.</strong></p>
<pre class="r"><code>names(dat)</code></pre>
<pre><code>##  [1] &quot;id&quot;                      &quot;name&quot;                   
##  [3] &quot;date&quot;                    &quot;manner_of_death&quot;        
##  [5] &quot;armed&quot;                   &quot;age&quot;                    
##  [7] &quot;gender&quot;                  &quot;race&quot;                   
##  [9] &quot;city&quot;                    &quot;state&quot;                  
## [11] &quot;signs_of_mental_illness&quot; &quot;threat_level&quot;           
## [13] &quot;flee&quot;                    &quot;body_camera&quot;            
## [15] &quot;longitude&quot;               &quot;latitude&quot;               
## [17] &quot;is_geocoding_exact&quot;</code></pre>
<p>The “body_camera” variable indicates whether or not news reports stated that a police officer that was at the scene of the incident was wearing a body camera and may have recorded parts of the incident. The “flee” variable indicates whether or not news reports have started that the victim was moving away from the officer during the incident. The “armed” variable indicates whether or not the victim was armed with any type of weapon that could have been thought to as possible to cause harm by an officer.</p>
<p><strong>What are three weapons that you are surprised to find in the “armed” variable? Make a table of the values in “armed” to see the options.</strong></p>
<pre class="r"><code>head(table(dat$armed))</code></pre>
<pre><code>## 
##                 air conditioner      air pistol  Airsoft pistol              ax 
##             207               1               1               3              24 
##        barstool 
##               1</code></pre>
<p>Three weapons that I was surprised to find in the dataset were an air conditioner, microphone, and pen.I feel like an air conditioner and microphone are definitely unusual weapons, and the pen does not seem like it would do anything against an officer’s gun.</p>
<p><strong>Problem 2 (10 points)</strong></p>
<p><strong>Describe the age distribution of the sample. Is this what you would expect to see?</strong></p>
<pre class="r"><code>hist(dat$age, main = &quot;Age Distribution of the Sample&quot;, xlab = &quot;Age&quot;, xlim = c(0, 100))</code></pre>
<p><img src="portfolio2_files/figure-html/unnamed-chunk-125-1.png" width="672" /> The age distribution of the sample is skewed to the right, with a large number of values between ages 20 and 40. This indicates that most people killed by the police in fatal shootings are young, and that older people between ages 60 and 100 are being killed in fatal police shootings at a much lower rate. This is exactly what I expected to see in the age distribution because younger people, especially in the 20 to 40 year old range, are more likely to have encounters with the police, as well as be healthy and be able to try to talk to or provoke the police and try to run away.</p>
<p><strong>To understand the center of the age distribution, would you use a mean or a median, and why? Find the one you picked.</strong></p>
<pre class="r"><code>median(dat$age, na.rm = TRUE)</code></pre>
<pre><code>## [1] 35</code></pre>
<p>To understand the center of the age distribution, I would use the median because the data is skewed to the right and the median is a more robust measure of skewed data as the mean changes with skew or outliers. The median of the age distribution for this dataset is 35 years old, and I removed the missing values since there are only 308 of them out of 6594 observations and they indicate that the person’s age was unknown or missing.</p>
<p><strong>Describe the gender distribution of the sample. Do you find this surprising?</strong></p>
<pre class="r"><code>table(dat$gender)</code></pre>
<pre><code>## 
##         F    M 
##    3  293 6298</code></pre>
<pre class="r"><code>counts &lt;- table(dat$gender, useNA = &quot;ifany&quot;)
barplot(counts, main = &quot;Gender Distrubution&quot;, xlab = &quot;Gender&quot;, ylab = &quot;Counts&quot;, names=c(&quot;None&quot;, &quot;Females&quot;, &quot;Males&quot;))</code></pre>
<p><img src="portfolio2_files/figure-html/unnamed-chunk-127-1.png" width="672" /> The gender distribution is definitely skewed, with 6005 more males being fatally shot by police officers than females. This can also be seen in the barplot, with the majority of respondents being males. There were also 3 unknown values in the data, indicating no gender according to the codebook. I do not find this surprising, however, because the majority of police shootings that we hear about in the news are of males, with the rare occurrence of a female. While females are definitely still being killed by the police, it is happening disproportionately to males which is indicated by both the news and the data.</p>
<p><strong>Problem 3 (10 points)</strong></p>
<p><strong>How many police officers had a body camera, according to news reports? What proportion is this of all the incidents in the data? Are you surprised that it is so high or low?</strong></p>
<pre class="r"><code>table(dat$body_camera)</code></pre>
<pre><code>## 
## False  True 
##  5684   910</code></pre>
<pre class="r"><code>910/6594</code></pre>
<pre><code>## [1] 0.1380042</code></pre>
<p>According to the news reports, 910 police officers had a body camera, which is about 13.80% of all incidents in the data. I am surprised that this is so low because I would think that after the 2014 killing of Michael Brown and subsequent police shootings, police offices and the public would call for an increased use of body cameras.</p>
<p><strong>In how many of the incidents was the victim fleeing? What proportion is this of the total number of incidents in the data? Is this what you would expect?</strong></p>
<pre class="r"><code>table(dat$flee)</code></pre>
<pre><code>## 
##                     Car        Foot Not fleeing       Other 
##         491        1058         845        3952         248</code></pre>
<pre class="r"><code>1058+845+248 #fleeing</code></pre>
<pre><code>## [1] 2151</code></pre>
<pre class="r"><code>2151/6594</code></pre>
<pre><code>## [1] 0.3262056</code></pre>
<p>There are 2151 incidents of the victim fleeing, which is about 32.62% of all incidents in the data. This was calculated by including the 491 unknown observations in the “not fleeing” group, as what this category of observations represents was not included in the codebook and cannot be assumed to be fleeing, especially since there is already an “other” group. This is pretty much what I would expect because I would think that the majority of people when interacting with the police would not flee, since it is known that the consequences would probably be worse because of it.</p>
<p><strong>Problem 4 (10 points)</strong></p>
<p><strong>Describe the relationship between the variables “body camera” and “flee” using a stacked barplot. What can you conclude from this relationship?</strong></p>
<p><strong>Hint 1: The categories along the x-axis are the options for “flee”, each bar contains information about whether the police officer had a body camera (vertically), and the height along the y-axis shows the frequency of that category).</strong></p>
<p><strong>Hint 2: Also, if you are unsure about the syntax for barplot, run ?barplot in R and see some examples at the bottom of the documentation. This is usually a good way to look up the syntax of R code. You can also Google it.</strong></p>
<pre class="r"><code>library(ggplot2) 
ggplot(dat, aes(fill=body_camera, y=frequency(body_camera), x=flee)) + 
  geom_bar(position=&quot;stack&quot;, stat=&quot;identity&quot;) +
  ggtitle(&quot;Stacked Barplot of Body Camera Usage and Victim Fleeing&quot;) +
  labs(y=&quot;Frequency of Body Camera Usage&quot;, x = &quot;How the Victim Fled&quot;) +
  labs(fill = &quot;Body Camera Usage&quot;)</code></pre>
<p><img src="portfolio2_files/figure-html/unnamed-chunk-130-1.png" width="672" /> From the plot, it can be seen that everybody that fled from the police did so more often when the police were not wearing a body camera. It looks like not fleeing and the police wearing a body camera are related, as when more police wore a body camera less people fled (since the not fleeing bar had the most police wearing a body camera). You can also see that the most people fled by using a car, which during those indicidents police were less likely to wear a body camera than to actually have it on. While it is unknown what the first bar represents as it is left out of the codebook, it follows the same pattern of the other bars that the police did not wear body cameras more often than they did.</p>
<p><strong>Describe the relationship between age and race by using a boxplot. What can you conclude from this relationship?</strong></p>
<p><strong>Hint 1: The categories along the x-axis are the race categories and the height along the y-axis is age.</strong></p>
<p><strong>Hint 2: Also, if you are unsure about the syntax for boxplot, run ?boxplot in R and see some examples at the bottom of the documentation. This is usually a good way to look up the syntax of R code. You can also Google it.</strong></p>
<pre class="r"><code>boxplot &lt;- ggplot(dat, aes(x=race, y=age)) + 
  geom_boxplot() +
  ggtitle(&quot;Boxplot of Race and Age&quot;)
boxplot</code></pre>
<p><img src="portfolio2_files/figure-html/unnamed-chunk-131-1.png" width="672" /> The relationship between race and age looks pretty even, with the median values of age for each race category between 25 and 37. The range for all ages except White is between 12 and 62, while the White range extends from about 5 to 80. There are a significant number of outliers, however, for the Black, Hispanic, and White categories. The NAs for age were removed, and the unknown race category was plotted first on the graph but cannot be interpreted as it is not in the codebook. From this relationship, I can conclude that on average, all races of a similar age between 25 and 37 are killed at similar rates. While there are some outliers to this, especially for the Black and Hispanic categories, all of the medians of age for each race is almost identical.</p>
<p><strong>Extra credit (10 points)</strong></p>
<p><strong>What does this code tell us?</strong></p>
<pre class="r"><code>mydates &lt;- as.Date(dat$date)
head(mydates)</code></pre>
<pre><code>## [1] &quot;2015-01-02&quot; &quot;2015-01-02&quot; &quot;2015-01-03&quot; &quot;2015-01-04&quot; &quot;2015-01-04&quot;
## [6] &quot;2015-01-04&quot;</code></pre>
<pre class="r"><code>(mydates[length(mydates)] - mydates[1])</code></pre>
<pre><code>## Time difference of 2458 days</code></pre>
<p>The as.Date function in R converts the string of date values into actual dates that functions can be applied to. The head function makes sure that this conversion was done correctly by showing us the first 6 values of the data. The “(mydates[length(mydates)] - mydates[1])” function tells us the time difference between the last observation (which is the entire length of mydates) and the first obeservation (which is "mydates[1]), which ends up being 2458 days.</p>
<p><strong>On Friday, a new report was published that was described as follows by The Guardian: “More than half of US police killings are mislabelled or not reported, study finds.” Without reading this article now (due to limited time), why do you think police killings might be mislabelled or underreported?</strong> I think that police killings may be mislabeled or underreported because police offices do not want to admit to have killing anyone or engaging in illegal or overly forceful activities. I think that there may be disparities between the police reporting shooting and witnesses observing shootings, as police offices may be less likely to do so. I also think that police offices may mislabel the shooting as something that was not their fault so that they do not get attacked by the public for the incident.</p>
<p><strong>Regarding missing values in problem 4, do you see any? If so, do you think that’s all that’s missing from the data?</strong> Yes, I saw missing values in problem 4 in the age category. The race and fleeing variable also had unknown values, as it was not indicated by the codebook. I do not think that this is all that is missing from the data, as other variables, such as gender, also had missing or unknown values. I think that going along with part b, some of the data reported was mislabeled or incorrect, and this may be represented by the missing or unknown values in the data.</p>
</div>
<div id="assignment-3" class="section level3">
<h3>Assignment 3</h3>
<p><strong>Load the data.</strong></p>
<pre class="r"><code>library(readr)
library(knitr)
dat.crime &lt;- read_delim(&quot;/Users/briannafisher/Dropbox/Github/BriannaFisher/data/crime_simple.txt&quot;, delim = &quot;\t&quot;)</code></pre>
<p>This is a dataset from a textbook by Brian S. Everitt about crime in the US in 1960. The data originate from the Uniform Crime Report of the FBI and other government sources. The data for 47 states of the USA are given.</p>
<p>Here is the codebook:</p>
<p>R: Crime rate: # of offenses reported to police per million population</p>
<p>Age: The number of males of age 14-24 per 1000 population</p>
<p>S: Indicator variable for Southern states (0 = No, 1 = Yes)</p>
<p>Ed: Mean of years of schooling x 10 for persons of age 25 or older</p>
<p>Ex0: 1960 per capita expenditure on police by state and local government</p>
<p>Ex1: 1959 per capita expenditure on police by state and local government</p>
<p>LF: Labor force participation rate per 1000 civilian urban males age 14-24</p>
<p>M: The number of males per 1000 females</p>
<p>N: State population size in hundred thousands</p>
<p>NW: The number of non-whites per 1000 population</p>
<p>U1: Unemployment rate of urban males per 1000 of age 14-24</p>
<p>U2: Unemployment rate of urban males per 1000 of age 35-39</p>
<p>W: Median value of transferable goods and assets or family income in tens of $</p>
<p>X: The number of families per 1000 earning below 1/2 the median income</p>
<p>We are interested in checking whether the reported crime rate (# of offenses reported to police per million population) and the average education (mean number of years of schooling for persons of age 25 or older) are related.</p>
<p><strong>Problem 1</strong></p>
<p><strong>How many observations are there in the dataset? To what does each observation correspond?</strong></p>
<pre class="r"><code>dim(dat.crime)</code></pre>
<pre><code>## [1] 47 14</code></pre>
<p>There are 47 observations in the dataset, with 14 different variables. Each observation corresponds to a particular state.</p>
<p><strong>Problem 2</strong></p>
<p><strong>Draw a scatterplot of the two variables. Calculate the correlation between the two variables. Can you come up with an explanation for this relationship?</strong></p>
<pre class="r"><code>plot(dat.crime$Ed, dat.crime$R, main = &quot;Scatterplot of Average Education and Reported Crime Rate&quot;, xlab = &quot;mean number of years of schooling for persons of age 25 or older times 10&quot;, ylab = &quot;# of offenses reported to police per million population&quot;)</code></pre>
<p><img src="portfolio2_files/figure-html/unnamed-chunk-135-1.png" width="672" /></p>
<pre class="r"><code>cor(dat.crime$R, dat.crime$Ed)</code></pre>
<pre><code>## [1] 0.3228349</code></pre>
<p>The correlation of the reported crime rate (measured in the number of offenses reported to police per million population) and average education (measured in the mean number of years of schooling for persons of age 25 or older times 10) is 0.32, which is pretty weak. The scatterplot of these variables proves this, as it is positive but fairly spread out. One explanation for this relationship may be that states with bigger cities are populated by people with more years of education than states with rural areas, and states with bigger cities have higher reported crime rates. While these two variables specificaly are not highly correlated (since the value was 0.32), high average education and high reported crime rates are both characteristic of states with big cities.</p>
<p><strong>Problem 3</strong></p>
<p><strong>Regress reported crime rate (y) on average education (x) and call this linear model crime.lm and write the summary of the regression by using this code, which makes it look a little nicer {r, eval=FALSE} kable(summary(crime.lm)$coef, digits = 2).</strong></p>
<pre class="r"><code>crime.lm &lt;- lm(formula = R ~ Ed, data = dat.crime)

summary(crime.lm)</code></pre>
<pre><code>## 
## Call:
## lm(formula = R ~ Ed, data = dat.crime)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -60.061 -27.125  -4.654  17.133  91.646 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)  
## (Intercept) -27.3967    51.8104  -0.529   0.5996  
## Ed            1.1161     0.4878   2.288   0.0269 *
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 37.01 on 45 degrees of freedom
## Multiple R-squared:  0.1042, Adjusted R-squared:  0.08432 
## F-statistic: 5.236 on 1 and 45 DF,  p-value: 0.02688</code></pre>
<p><strong>Problem 4</strong></p>
<p><strong>Are the four assumptions of linear regression satisfied? To answer this, draw the relevant plots. (Write a maximum of one sentence per assumption.)</strong></p>
<pre class="r"><code>#linearity and independence assumptions - residuals vs. x plot
plot(dat.crime$Ed, crime.lm$residuals, ylim=c(-15,15), main=&quot;Residuals vs. Average Education&quot;, xlab=&quot;mean number of years of schooling for persons of age 25 or older times 10&quot;, ylab=&quot;Residuals&quot;)
abline(h = 0, lty=&quot;dashed&quot;)</code></pre>
<p><img src="portfolio2_files/figure-html/unnamed-chunk-137-1.png" width="672" /></p>
<pre class="r"><code>#linearity assumption - residuals vs. fitted
plot(crime.lm, which=1)</code></pre>
<p><img src="portfolio2_files/figure-html/unnamed-chunk-137-2.png" width="672" /> Both the residuals vs. x plot and residuals vs. fitted plot show no clear linear patterns and the residuals appear evenly spread out above and below both lines, so it satisfies the linearity assumption (because there are also only 47 observations, with the number that are given we can assume this is good enough for linear regression).</p>
<p>Looking again at the residuals vs. x plot, we see that there are no patterns in the plot, so the independence assumption is fulfilled.</p>
<pre class="r"><code>#equal variance / homoscedasticity assumption - resuiduals vs. predicted values
plot(crime.lm, which=3)</code></pre>
<p><img src="portfolio2_files/figure-html/unnamed-chunk-138-1.png" width="672" /> Looking at the residuals plotted against the predicted values, the red line looks pretty flat and there are no significant trends in the red line, so the equal variance / homoscedasticity assumption looks satisfied, but the scatterplot we made earlier shows no strong linear association.</p>
<pre class="r"><code>#Normal population assumption - residuals vs. leverage plot
plot(crime.lm, which=5)</code></pre>
<p><img src="portfolio2_files/figure-html/unnamed-chunk-139-1.png" width="672" /></p>
<pre class="r"><code>#Normal population assumption - Normal qq plot
plot(crime.lm, which=2)</code></pre>
<p><img src="portfolio2_files/figure-html/unnamed-chunk-139-2.png" width="672" /> The residuals vs. leverage plot fulfills the normal population assumption as the values are within Cook’s distance, but the normal qq plot looks like there is an issue with some of the values curving, especially since we know these are not outliers.</p>
<p><strong>Problem 5</strong></p>
<p><strong>Is the relationship between reported crime and average education statistically significant? Report the estimated coefficient of the slope, the standard error, and the p-value. What does it mean for the relationship to be statistically significant?</strong> The relationship between reported crime rates and average education is statistically significant. The coefficient of the slope is 1.1161, which means that on average, for every additional year of average education, the reported crime rate increases by 1.1161 offenses reported to police per million population. The standard error is 0.4878, which means that the number of offenses reported to the police per million population can vary by 0.4878 offenses. The p-value is 0.02688, which means that we can reject the null hypothesis and conclude that there is a relationship between reported crime rates and average education. For the relationship to be statistically significant, it would mean that the p-value is less than 0.05, telling us that it is unlikely that the relationship between reported crime rates and average education is due to chance.</p>
<p><strong>Problem 6</strong></p>
<p><strong>How are reported crime and average education related? In other words, for every unit increase in average education, how does reported crime rate change (per million) per state?</strong> On average, for every additional year of average education, the reported crime rate increases by 1.1161 offenses reported to police per million population per state.</p>
<p><strong>Problem 7</strong></p>
<p><strong>Can you conclude that if individuals were to receive more education, then crime will be reported more often? Why or why not?</strong> You cannot conclude that if individuals were to receive more education, then crime will be reported more often. While the p-value indicates that there is some relationship between the two variables, the correlation between them is only 0.32 and the r-squared value is 0.1042. Neither of these values indicate a strong relationship between average education and reported crime rate. This statement also implies causation, that if people received more education then crime will decrease. Causation cannot be assumed, as there may be other causes or hidden variables that influence the decrease in crime rate with increased education. Similarly, this dataset is in relation to states, not individuals, so this statement could not be proven by this linear model.</p>
</div>
<div id="exam-2" class="section level3">
<h3>Exam 2</h3>
<p>Instructions</p>
<p>Create a folder in your computer (a good place would be under Crim 250, Exams).</p>
<p>Download the dataset from the Canvas website (sim.data.csv) onto that folder, and save your Exam 2.Rmd file in the same folder.</p>
<p>Data description: This dataset provides (simulated) data about 200 police departments in one year. It contains information about the funding received by the department as well as incidents of police brutality. Suppose this dataset (sim.data.csv) was collected by researchers to answer this question: “Does having more funding in a police department lead to fewer incidents of police brutality?”</p>
<p>Codebook:</p>
<p>funds: How much funding the police department received in that year in millions of dollars. po.brut: How many incidents of police brutality were reported by the department that year. po.dept.code: Police department code</p>
<p><strong>Problem 1: EDA (10 points)</strong></p>
<p><strong>Describe the dataset and variables. Perform exploratory data analysis for the two variables of interest: funds and po.brut.</strong></p>
<pre class="r"><code>dat &lt;- read.csv(file = &#39;/Users/briannafisher/Dropbox/Github/BriannaFisher/data/sim.data.2.csv&#39;)

dim(dat)</code></pre>
<pre><code>## [1] 200   3</code></pre>
<pre class="r"><code>names(dat)</code></pre>
<pre><code>## [1] &quot;po.dept.code&quot; &quot;funds&quot;        &quot;po.brut&quot;</code></pre>
<p>The dataset has 200 observations and 3 variables, with each observation corresponding to a particular police department. The variables are “po.dept.code”, which is the police department code, “funds”, which is the amount of funding the department received that year in millions of dollars, and “po.brut”, which is the number of incidents of police brutality reported by the department that year.</p>
<pre class="r"><code>plot(dat$funds, dat$po.brut, main = &quot;Scatterplot of Department Funding and Police Brutality&quot;, xlab = &quot;Department Funding in Millions of Dollars that Year&quot;, ylab = &quot;Number of Incidents of Police Brutality that Year&quot;, xlim = c(0,100))</code></pre>
<p><img src="portfolio2_files/figure-html/unnamed-chunk-141-1.png" width="672" /></p>
<pre class="r"><code>cor(dat$funds, dat$po.brut)</code></pre>
<pre><code>## [1] -0.9854706</code></pre>
<p>Looking at the scatterplot of department funding and police brutality, it looks like the two have a strong, negative association. As department funding increases, it looks like reported police brutality incidents decreases. The two variables also have a correlation of -0.985, indicating that the two are strongly, negatively correlated.</p>
<p><strong>Problem 2: Linear regression (30 points)</strong></p>
<p><strong>Perform a simple linear regression to answer the question of interest. To do this, name your linear model “reg.output” and write the summary of the regression by using “summary(reg.output)”.</strong></p>
<pre class="r"><code>reg.output &lt;- lm(formula = po.brut ~ funds, data = dat)
summary(reg.output)</code></pre>
<pre><code>## 
## Call:
## lm(formula = po.brut ~ funds, data = dat)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -3.9433 -0.2233  0.2544  0.5952  1.1803 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 40.543069   0.282503  143.51   &lt;2e-16 ***
## funds       -0.367099   0.004496  -81.64   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.9464 on 198 degrees of freedom
## Multiple R-squared:  0.9712, Adjusted R-squared:  0.971 
## F-statistic:  6666 on 1 and 198 DF,  p-value: &lt; 2.2e-16</code></pre>
<p><strong>Report the estimated coefficient, standard error, and p-value of the slope. Is the relationship between funds and incidents statistically significant? Explain.</strong> The relationship between reported incidents of police brutality and department funding is statistically significant. The estimated coefficient is -0.367, which means that one unit higher of funding is associated with 0.367 less reported incidents of police brutality. The standard error is 0.0045, which means that the number of reported incidents of police brutality can vary by 0.0045 incidents. The p-value is less than 2.2e-16, which means that we can reject the null hypothesis and conclude that there is a relationship between reported incidents of police brutality and department funding. For the relationship to be statistically significant, it would mean that the p-value is less than 0.05 (which 2.2e-16 is), telling us that it is unlikely that the relationship between reported incidents of police brutality and department funding is due to chance.</p>
<p><strong>Draw a scatterplot of po.brut (y-axis) and funds (x-axis). Right below your plot command, use abline to draw the fitted regression line, like this:</strong></p>
<pre class="r"><code>plot(dat$funds, dat$po.brut, main = &quot;Scatterplot of Department Funding and Police Brutality&quot;, xlab = &quot;Department Funding in Millions of Dollars that Year&quot;, ylab = &quot;Number of Incidents of Police Brutality that Year&quot;, xlim = c(0,100))
abline(reg.output, col = &quot;red&quot;, lwd=2)</code></pre>
<p><img src="portfolio2_files/figure-html/unnamed-chunk-143-1.png" width="672" /></p>
<p><strong>Does the line look like a good fit? Why or why not?</strong> Looking at the scatterplot, the line does not look like a good fit. The points on the scatterplot look curved, with the values on both ends of the line curving away from the line. If the line was a good fit, it would have no pattern and the data would also form a straight line. However, looking at the regression output, the R squared is 0.9712, indicating that the model fits the data incredibly well. Because my eyes can be deceiving and I changed the x-axis of the plot to include 0 squishing the data more towards the end of the plot, I would go with the R squared value and say that the line is a good fit.</p>
<p><strong>Are the four assumptions of linear regression satisfied? To answer this, draw the relevant plots. (Write a maximum of one sentence per assumption.) If not, what might you try to do to improve this (if you had more time)?</strong> Assumption 1</p>
<pre class="r"><code>#linearity and independence assumptions - residuals vs. x plot
plot(dat$funds, reg.output$residuals, ylim=c(-15,15), main=&quot;Residuals vs. Department Funding&quot;, xlab=&quot;Department Funding in Millions of Dollars that Year&quot;, ylab=&quot;Residuals&quot;)
abline(h = 0, lty=&quot;dashed&quot;)</code></pre>
<p><img src="portfolio2_files/figure-html/unnamed-chunk-144-1.png" width="672" /></p>
<pre class="r"><code>#linearity assumption - residuals vs. fitted
plot(reg.output, which=1)</code></pre>
<p><img src="portfolio2_files/figure-html/unnamed-chunk-144-2.png" width="672" /> Because both the residuals vs. x plot and residuals vs. fitted plot show clear curved patterns in the plots instead of no pattern at all, I would say that the linearity assumption is not satisfied.</p>
<p>Assumption 2 Looking again at the residuals vs. x plot, we see that there is a curved pattern in the plot, so the independence assumption is not satisfied.</p>
<p>Assumption 3</p>
<pre class="r"><code>#equal variance / homoscedasticity assumption - resuiduals vs. predicted values
plot(reg.output, which=3)</code></pre>
<p><img src="portfolio2_files/figure-html/unnamed-chunk-145-1.png" width="672" /> Looking at both the scatterplot from question 1 and the scale-location plot, there is a clear pattern in the plot, so the equal variance / homoscedasticity assumption is not satisfied.</p>
<p>Assumption 4</p>
<pre class="r"><code>#Normal population assumption - residuals vs. leverage plot
plot(reg.output, which=5)</code></pre>
<p><img src="portfolio2_files/figure-html/unnamed-chunk-146-1.png" width="672" /></p>
<pre class="r"><code>#Normal population assumption - Normal qq plot
plot(reg.output, which=2)</code></pre>
<p><img src="portfolio2_files/figure-html/unnamed-chunk-146-2.png" width="672" /> Looking at the residuals vs. leverage plot (it looks like many values are clustered at the top of the line) and the normal qq plot (the values on the ends of the line are curving away from the line), the normal population assumption is not satisfied.</p>
<p>Because none of the assumptions are satisfied, if I had more time I would perform some sort of transformation to the data. I would probably start with logging funds, because I know that wages are usually logged when performing linear regression and funds are a pretty similar type of variable.</p>
<p><strong>Answer the question of interest based on your analysis: “Does having more funding in a police department lead to fewer incidents of police brutality?”</strong> Based on my analysis, it cannot be concluded that having more funding in a police department leads to fewer incidents of police brutality, as this implies causation and there could be hidden variables influencing the relationship. However,it does seem like having more funding in a police department is associated with fewer incidents of police brutality. The scatterplot and correlation show a strong negative relationship between the variables, and the p-value is statistically significant indicating that this relationship is not due to chance. Also, I do not think that the linear model is the best way to represent the data without performing any transformations. All of the assumptions were not satisfied, and even the scatterplot indicates a slight curving pattern. Transforming the data may give more insight into the association between department funding and incidents of police brutality.</p>
<p><strong>Problem 3: Data ethics (10 points)</strong></p>
<p><strong>Describe the dataset. Considering our lecture on data ethics, what concerns do you have about the dataset? Once you perform your analysis to answer the question of interest using this dataset, what concerns might you have about the results?</strong></p>
<p>Considering our lecture on data ethics, I am concerned that the dataset is biased because the police brutality variable is based off of the reported incidents of police brutality by the departments themselves. There is no way to know if departments are under reporting brutality, so the numbers in the dataset may not be correct or may not actually be reporting the ground truth of police brutality. Once I performed my analysis, I am concerned that the results may interpreted that more funding leads to less brutality (as even stated in the question of interest). This, however, implies causation, and while there is a relationship between the two variables there may be another hidden variable that is truly causing the association. It may be that having more funding leads to better service programs being provided by the police which leads to decreased police brutality, but that is something that cannot be proven with this dataset and analysis. In terms of implications, a policy maker may look at this analysis and think that increasing funding is the best solution to decreasing police brutality, which other research has proven that may not be the case. This analysis could, essentially, cause more harm if all police departments had an increase in funding but the funding was misused or put towards other things than decreasing police brutality.</p>
</div>
<div id="final-project---marijuana-possession-charges-an-exploratory-look-at-the-relationship-between-race-and-sentencing-outcomes-by-brianna-fisher-sophie-faircloth-anna-sophia-lotman-hannah-wassermann" class="section level3">
<h3>Final Project - Marijuana Possession Charges An exploratory look at the relationship between race and sentencing outcomes By Brianna Fisher, Sophie Faircloth, Anna Sophia Lotman, Hannah Wassermann</h3>
<p><strong>INTRODUCTION</strong> Following Nixon’s call for the War on Drugs in June 1971, there was a push for mandatory sentencing in drug-related crimes, effectively expanding the role of the federal government in drug-related arrests and sentencing (Drug Policy Alliance, 2021). Recently, there has been an uptick of discussion in the political world and in pop culture of the United States on the War on Drugs, namely regarding the adjustment of the severity of sentencing and its disproportionate effect on minority communities. These racial disparities are particularly discussed in regards to marijuana-related charges, as Black Americans have been found to be four times more likely to be arrested for marijuana charges than White Americans and six times more likely to be incarcerated for drug-related charges (Rahamatulla, 2017). Many agree that a solution to the disproportionate effects of drug-related charges needs to be created, and through the work discussed in this paper, we hope to focus our attention on sentencing outcomes and race for marijuana charges to further understand where disparities lie. Due to the increasing prevalence and history of drug-related sentencing, we wanted to examine the relationships in drug-related sentencing between race and sentencing likelihood, especially focusing on marijuana. We expect, from past studies examined in and outside of this course, that the rate of prison sentencing for Black people would be higher than the rate of prison sentencing of white people. These motivations lead to the research question: Are Black people sentenced federally to prison for marijuana at a higher rate than white people?</p>
<p><strong>DESCRIPTION OF THE DATA USED</strong> The data set we utilized for this review is a record of federal criminal sentences as provided by the US Sentencing Committee (United States Sentencing Commission, 2007). This data set includes information on federal cases sentenced under the guidelines of the Sentencing Reform Act of 1984. Because of the research question prompting this paper, we chose to look at only cases where the defendant was charged with possession of marijuana. We used the “Drug Type 1” variable in the dataset to create a subset with these cases, as this variable indicated that marijuana was the highest penalty incurring drug the defendant was found with. Because we wanted to look at the relationship between race and being sentenced to prison, our independent variable was the defendant’s race (either Black or white cases) and our dependent variable was the type of sentence (either prison or no prison). We extrapolated specifically Black and white instantiations in the race variable so as to control for the number of independent variables being observed. We also decided to control for the defendant’s age, the defendant’s gender, and whether or not the defendant has a criminal record. We thought that these three variables would be the most influential in determining sentence type, both as legal (criminal record) and extralegal (age and gender) variables.</p>
<p><strong>EXPLORATORY DATA ANALYSIS</strong> <img src="portfolio2_files/figure-html/unnamed-chunk-150-1.png" width="672" /> To most successfully represent the variables being examined in this paper, we chose to create a bar plot representing the proportion of people sentenced and not sentenced to prison for both races included in the dataset.</p>
<p><strong>REPRESENTATIVE MODEL AND DIAGNOSTIC INFORMATION</strong> For the sake of our data set, we used a logistic regression. A logistic regression model is very similar to a linear regression; however, it is used to evaluate relationships between binary variables. Because our variables - race and sentencing outcome - both have only two options for the purpose of our study, we can examine this relationship between the binaries. Rather than a standard line, the graph of fit is a logit. The application of this model is to categorical variables, and the dependent variable matches the variable type of the independent.</p>
<p><strong>LOGISTIC REGRESSION ASSUMPTIONS</strong> <img src="portfolio2_files/figure-html/unnamed-chunk-152-1.png" width="672" /> For the sake of our data set, we used a logistic regression. A logistic regression model is very similar to a linear regression; however, it is used to evaluate relationships between binary variables. Because our variables - race and sentencing outcome - both have only two options for the purpose of our study, we can examine this relationship between the binaries. Rather than a standard line, the graph of fit is a logit. The application of this model is to categorical variables, and the dependent variable matches the variable type of the independent.</p>
<p>The Residual vs. Fitted Plots in this figure look to see if there are any curvilinear trends in the plots that were originally missed. Because logistic regression is already curvilinear - as demonstrated by the logit that was previously displayed - these plots do not tell us any definitive information on the validity of this regression.</p>
<p>The QQ plot in the figure determines if the residuals are normally distributed. This plot is not indicative of anything definitive either because residuals do not have to be normally distributed in a logistic regression.</p>
<p>The Residuals vs. Leverage plots help identify outliers, but this plot too is not particularly useful because the results are not definitive either. From the models demonstrated in the assumptions, we do not gain information that definitively determines the strength of the logistic regression model for our data set, but the assumption display is crucial to data analysis so as to examine any particularly significant data that strays from the norm.</p>
<p><strong>Regression Model</strong></p>
<pre><code>## 
## Logistic Regression Outputs
## ================================================
##                         Dependent variable:     
##                     ----------------------------
##                                prison           
##                        Baseline      Controls   
##                          (1)            (2)     
## ------------------------------------------------
## Black                 -0.684***      -0.845***  
##                        (0.132)        (0.140)   
##                                                 
## Ages 70-97                             0.260    
##                                       (1.036)   
##                                                 
## Ages 50-69                             0.100    
##                                       (0.207)   
##                                                 
## Ages 30-49                           0.441***   
##                                       (0.116)   
##                                                 
## Female                               -1.194***  
##                                       (0.120)   
##                                                 
## No Criminal History                    0.071    
##                                       (0.117)   
##                                                 
## Constant               2.829***      2.881***   
##                        (0.060)        (0.102)   
##                                                 
## ------------------------------------------------
## Observations            6,123          6,123    
## ================================================
## Note:                *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01</code></pre>
<p>Looking at the baseline regression, we can see that Black people in the dataset were less likely to be sentenced to prison at a significant rate. Similarly, looking at the controlled regression, we can see that Black people were more likely to not be sentenced when compared to white people in the dataset. We split the age variable into three groups (of 16-29, 30-49, 50-69, and 70-97), leaving the 16-29 group out of the regression as our control because we thought that this group would be most likely to be in possession of marijuana. To our surprise, all three age groups were more likely to be sentenced to prison for marijuana charges than people that were 16-29. This may be due to the fact that there could have been more people in these other groups, or there could have been a large number of minors in the 16-29 group that were not sentenced to prison. We split the gender variable into male or female, leaving out the male group since we thought that this group would be more likely to be sentenced to prison. Looking at the model, we can see that this is true, and females were significantly less likely to be sentenced to prison than males. Finally, we split the criminal history variable into yes or no groups, leaving out the yes group since we thought that this group would be more likely to be sentenced to prison. To our surprise, having no criminal history made the defendant more likely to be sentenced to prison, but by an insignificant amount.</p>
<p><strong>CAUSAL ANALYSIS</strong> Because we used the “Drug Type 1” variable, we assumed that the defendant was either only found with marijuana or the other drug(s) did not incur any penalty. This did not take into account whether or not the defendant was charged with something incurring a felony charge, such as possession of drug paraphernalia or intent to sell. In an ideal world, our data would have been clear about what the defendant was actually charged with on all fronts, rather than just what drugs they were in possession of at the time of their arrest. We also only looked at about 6,000 observations, since we dropped everyone who was not Black or white. However, there were more white people in the dataset and more white people in prison in the dataset, so the groups may not have been proportional.</p>
<p><strong>DAG:</strong></p>
<p>BEING ARRESTED ^ | | v RACE ——-&gt; BEING SENTENCED TO PRISON</p>
<p>Additionally, the DAG portrays the situation where the defendant’s race determines whether or not they will be arrested, and therefore the arrest determines whether they will be sentenced. Not everyone who is caught with marijuana is arrested, and not everyone who is arrested for marijuana charges is convicted. Similarly, the biases of the police and prosecutors could be at play, influencing both the arrest and sentence outcome. Because of these confounders, we would not be able to conclude that there was a causal analysis.</p>
<p><strong>LIMITATIONS AND FUTURE DIRECTIONS</strong></p>
<p>While setting out to examine sentencing outcomes and their relationship to race for marijuana-related charges, we observed a series of confounds:</p>
<p>Sentencing charges are not equated to arrests. It is worth looking in the future into the relationship between arrests and race for marijuana-related charges. Our analysis did not include sentencing duration. Sentencing severity is a large component of the discussion for racial disparities in sentencing, not just the binary of whether someone was sentenced or not. Though we controlled for different factors such as past arrests because they are crucial in determining sentencing outcomes they should be analyzed further in conjunction with the information we observed for future studies. This dataset is also a really interesting example of how a failure through data analysis can lead to false projections and misleading statistics. This is also a useful showcase of how easily data can also be manipulated depending on the neglect of specific outliers or parameters for the research. As previously stated, this data set is very limited. We don’t feel it can answer our research question in an accurate way, but it still provides a good lesson on the sensitivity of datasets with outlying variables and unobserved confounders.</p>
<p>For future research, it could be extremely valuable to look at the current different sentencing rates across states with different laws regarding the legality and decriminalization of marijuana. All marijuana usage (whether medical or recreational) is a federal crime, so theoretically everyone in the dataset should have been arrested regardless of race. However, this is not the case, and it is important to look at how there are disparities between federal and state sentences. Additionally, state police and prosecutors have much more discretion in deciding who to arrest, and what crimes to charge. We also were only able to look at sentencing as a binary factor without the important information of arrests records in general or whether or not the defendant has been arrested for marijuana in the past. In the future, we want to do a more well-rounded in-depth data analysis including everyone who was arrested (regardless of their conviction status), as well as the state’s current laws regarding marijuana.</p>
<p><strong>References</strong> Commission, U. S. S. (2014, June 25). Monitoring of federal criminal sentences, [united states], 2007. Monitoring of Federal Criminal Sentences, [United States], 2007. Retrieved December 12, 2021, from <a href="https://www.icpsr.umich.edu/web/NACJD/studies/22623" class="uri">https://www.icpsr.umich.edu/web/NACJD/studies/22623</a>. Cusick Director, J., Cusick, J., Director, Director, C. M. A., Montecinos, C., Director, A., Director, S. H. A., Hananel, S., Oduyeru Manager, L., Oduyeru, L., Manager, Gordon Director, P., Gordon, P., Director, J. P. D., Parshall, J., Director, D., Pearl, B., Perez, M., Chung, E., … Simpson, E. (2021, October 28). Ending the war on drugs: By the numbers. Center for American Progress. Retrieved December 12, 2021, from <a href="https://www.americanprogress.org/article/ending-war-drugs-numbers/" class="uri">https://www.americanprogress.org/article/ending-war-drugs-numbers/</a>. Rahamatulla, A. (2017, March 23). The War on Drugs has failed. what’s next? Ford Foundation. Retrieved December 12, 2021, from <a href="https://www.fordfoundation.org/just-matters/just-matters/posts/the-war-on-drugs-has-failed-what-s-next/" class="uri">https://www.fordfoundation.org/just-matters/just-matters/posts/the-war-on-drugs-has-failed-what-s-next/</a>. We Are The Drug Policy Alliance. (n.d.). A history of the Drug War. Drug Policy Alliance. Retrieved December 12, 2021, from <a href="https://drugpolicy.org/issues/brief-history-drug-war" class="uri">https://drugpolicy.org/issues/brief-history-drug-war</a>.</p>
</div>
</div>
<div id="criminal-justice-data-analytics" class="section level2">
<h2>Criminal Justice Data Analytics</h2>
<h2>
Criminal Justice Data Analytics
</h2>
<div id="problem-set-1-1" class="section level3">
<h3>Problem Set 1</h3>
<p><strong>Question 1</strong></p>
<pre class="r"><code>#load in the LEOKA data
leoka &lt;- read.csv(&quot;/Users/briannafisher/Dropbox/Github/BriannaFisher/data/leoka-feloniously killed.csv&quot;)</code></pre>
<p><strong>Question 2</strong></p>
<pre class="r"><code>#Use square brackets to print the first 3 rows of the data set
leoka[1:3,]</code></pre>
<pre><code>##            Area   Region1     Region2 X2004 X2005 X2006 X2007 X2008 X2009 X2010
## 1   Connecticut Northeast New England     1     0     0     0     0     0     0
## 2         Maine Northeast New England     0     0     0     0     0     0     0
## 3 Massachusetts Northeast New England     0     0     0     1     0     0     1
##   X2011 X2012 X2013
## 1     0     0     0
## 2     0     0     0
## 3     0     1     1</code></pre>
<p>The first three rows of data are from Connecticut, Maine, and Massachusetts.</p>
<p><strong>Question 3</strong></p>
<pre class="r"><code>#use a subset to get the number of officers killed in Ohio in 2007
subset(leoka, grepl(&quot;Ohio&quot;, Area) &amp; (X2007)) </code></pre>
<pre><code>##    Area Region1            Region2 X2004 X2005 X2006 X2007 X2008 X2009 X2010
## 13 Ohio Midwest East North Central     1     2     1     2     2     0     1
##    X2011 X2012 X2013
## 13     4     1     0</code></pre>
<p>Two officers were killed in Ohio in 2007.</p>
<p><strong>Question 4</strong></p>
<pre class="r"><code>#use a subset to get the states in the East North Central region
east.north &lt;- subset(leoka, grepl(&quot;East North Central&quot;, Region2))

#use a table to see how many officers were killed in 2012
table(east.north$X2012)</code></pre>
<pre><code>## 
## 0 1 
## 3 2</code></pre>
<p>Two officers were killed in the East North Central region in 2012.</p>
<p><strong>Question 5</strong></p>
<pre class="r"><code>#Create a dataframe with the columns I want to add up
cols &lt;- c(&quot;X2004&quot;, &quot;X2005&quot;, &quot;X2006&quot;, &quot;X2007&quot;, &quot;X2008&quot;, &quot;X2009&quot;,&quot;X2010&quot;, &quot;X2011&quot;, &quot;X2012&quot;, &quot;X2013&quot;)

#use row sums to add the colums and create a new variable
leoka$total &lt;- rowSums(leoka[,cols])</code></pre>
<pre class="r"><code>#I could have also done this by adding the columns together
leoka$total &lt;- leoka$X2004 + leoka$X2005 + leoka$X2006 + leoka$X2007 + 
  leoka$X2008 + leoka$X2009 + leoka$X2010 + leoka$X2011 + leoka$X2012 +
  leoka$X2013</code></pre>
<p><strong>Question 6</strong></p>
<pre class="r"><code>#use max to find the largest number of officers killed
max(leoka$total, na.rm=TRUE)</code></pre>
<pre><code>## [1] 44</code></pre>
<pre class="r"><code>#use which to find the Area that had 44 officers killed
leoka[which(leoka$total == 44),]</code></pre>
<pre><code>##          Area Region1            Region2 X2004 X2005 X2006 X2007 X2008 X2009
## 38      Texas   South West South Central     3     3     3     9     3     6
## 48 California    West            Pacific     5     6     6     4     3     5
##    X2010 X2011 X2012 X2013 total
## 38     2     4     5     6    44
## 48     5     3     2     5    44</code></pre>
<p>Texas and California both had the largest number of officers killed, which was 44 officers.</p>
<p><strong>Question 7</strong></p>
<pre class="r"><code>#use aggregate to find the number of officers killed per region
aggregate(total~Region1, data=leoka, sum) </code></pre>
<pre><code>##     Region1 total
## 1   Midwest    90
## 2 Northeast    58
## 3     Other    21
## 4     South   238
## 5      West   104</code></pre>
<p>The region with the largest number of officers killed is the South.</p>
<p><strong>Question 8</strong></p>
<pre class="r"><code>#use which to find the Areas with 0 officers killed
leoka[which(leoka$total == &quot;0&quot;),]</code></pre>
<pre><code>##               Area   Region1            Region2 X2004 X2005 X2006 X2007 X2008
## 2            Maine Northeast        New England     0     0     0     0     0
## 6          Vermont Northeast        New England     0     0     0     0     0
## 19        Nebraska   Midwest West North Central     0     0     0     0     0
## 46         Wyoming      West           Mountain     0     0     0     0     0
## 52  American Samoa     Other              Other     0     0     0     0     0
## 53            Guam     Other              Other     0     0     0     0     0
## 54 Mariana Islands     Other              Other     0     0     0     0     0
##    X2009 X2010 X2011 X2012 X2013 total
## 2      0     0     0     0     0     0
## 6      0     0     0     0     0     0
## 19     0     0     0     0     0     0
## 46     0     0     0     0     0     0
## 52     0     0     0     0     0     0
## 53     0     0     0     0     0     0
## 54     0     0     0     0     0     0</code></pre>
<p>The areas that had no officers killed between 2004 and 2013 are Maine, Vermont, Nebraska, Wyoming, American Samoa, Guam, and the Mariana Islands.</p>
<p><strong>Question 9</strong></p>
<pre class="r"><code>#use which to look where and when 9 officers were killed
leoka[which(leoka$X2004 == &quot;9&quot;),]</code></pre>
<pre><code>##  [1] Area    Region1 Region2 X2004   X2005   X2006   X2007   X2008   X2009  
## [10] X2010   X2011   X2012   X2013   total  
## &lt;0 rows&gt; (or 0-length row.names)</code></pre>
<pre class="r"><code>leoka[which(leoka$X2005 == &quot;9&quot;),]</code></pre>
<pre><code>##  [1] Area    Region1 Region2 X2004   X2005   X2006   X2007   X2008   X2009  
## [10] X2010   X2011   X2012   X2013   total  
## &lt;0 rows&gt; (or 0-length row.names)</code></pre>
<pre class="r"><code>leoka[which(leoka$X2006 == &quot;9&quot;),]</code></pre>
<pre><code>##  [1] Area    Region1 Region2 X2004   X2005   X2006   X2007   X2008   X2009  
## [10] X2010   X2011   X2012   X2013   total  
## &lt;0 rows&gt; (or 0-length row.names)</code></pre>
<pre class="r"><code>leoka[which(leoka$X2007 == &quot;9&quot;),]</code></pre>
<pre><code>##     Area Region1            Region2 X2004 X2005 X2006 X2007 X2008 X2009 X2010
## 38 Texas   South West South Central     3     3     3     9     3     6     2
##    X2011 X2012 X2013 total
## 38     4     5     6    44</code></pre>
<pre class="r"><code>leoka[which(leoka$X2008 == &quot;9&quot;),]</code></pre>
<pre><code>##  [1] Area    Region1 Region2 X2004   X2005   X2006   X2007   X2008   X2009  
## [10] X2010   X2011   X2012   X2013   total  
## &lt;0 rows&gt; (or 0-length row.names)</code></pre>
<pre class="r"><code>leoka[which(leoka$X2009 == &quot;9&quot;),]</code></pre>
<pre><code>##  [1] Area    Region1 Region2 X2004   X2005   X2006   X2007   X2008   X2009  
## [10] X2010   X2011   X2012   X2013   total  
## &lt;0 rows&gt; (or 0-length row.names)</code></pre>
<pre class="r"><code>leoka[which(leoka$X2010 == &quot;9&quot;),]</code></pre>
<pre><code>##  [1] Area    Region1 Region2 X2004   X2005   X2006   X2007   X2008   X2009  
## [10] X2010   X2011   X2012   X2013   total  
## &lt;0 rows&gt; (or 0-length row.names)</code></pre>
<pre class="r"><code>leoka[which(leoka$X2011 == &quot;9&quot;),]</code></pre>
<pre><code>##  [1] Area    Region1 Region2 X2004   X2005   X2006   X2007   X2008   X2009  
## [10] X2010   X2011   X2012   X2013   total  
## &lt;0 rows&gt; (or 0-length row.names)</code></pre>
<pre class="r"><code>leoka[which(leoka$X2012 == &quot;9&quot;),]</code></pre>
<pre><code>##  [1] Area    Region1 Region2 X2004   X2005   X2006   X2007   X2008   X2009  
## [10] X2010   X2011   X2012   X2013   total  
## &lt;0 rows&gt; (or 0-length row.names)</code></pre>
<pre class="r"><code>leoka[which(leoka$X2013 == &quot;9&quot;),]</code></pre>
<pre><code>##  [1] Area    Region1 Region2 X2004   X2005   X2006   X2007   X2008   X2009  
## [10] X2010   X2011   X2012   X2013   total  
## &lt;0 rows&gt; (or 0-length row.names)</code></pre>
<p>There were nine officers killed in Texas in 2007.</p>
<p><strong>Question 10</strong></p>
<pre class="r"><code>#use aggregate to find the number of officers killed per region in 2013
region.2013 &lt;- aggregate(X2013~Region1, data=leoka, sum) 

#use order to sort the data frame from smallest to largest
region.2013.sorted &lt;- region.2013[order(region.2013$X2013),]</code></pre>
<p>The Northeast had two officers killed in 2013, the Midwest had four officers killed in 2013, the West had six officers killed in 2013, and the South had 15 officers killed in 2013.</p>
<p><strong>Question 11</strong></p>
<pre class="r"><code>#use aggregate to find the number of officers killed per region
region.full &lt;- aggregate(total~Region1, data=leoka, sum)

#use the bar plot function to create a bar plot of the number of officers killed by region
barplot(region.full$total, main = &quot;Number of Officers Killed Per Region&quot;, xlab = &quot;Region&quot;, ylab = &quot;Number of Officers Killed&quot;, names = c(&quot;Midwest&quot;, &quot;Northeast&quot;, &quot;Other&quot;, &quot;South&quot;, &quot;West&quot;), ylim=c(0,250), col = c(&quot;red&quot;, &quot;orange&quot;, &quot;yellow&quot;, &quot;green&quot;, &quot;blue&quot;))</code></pre>
<p><img src="portfolio2_files/figure-html/unnamed-chunk-167-1.png" width="672" /></p>
<p><strong>Question 12</strong></p>
<pre class="r"><code>#use the col sums function and the cols data frame created earlier
off.by.year &lt;- colSums(leoka[,cols])

plot(off.by.year, main = &quot;Total Number of Officers Killed By Year&quot;, xlab = &quot;Year&quot;, ylab = &quot;Number of Officers Killed&quot;, xaxt = &quot;n&quot;)
axis(1, at = seq(1:10), labels = c(&quot;2004&quot;, &quot;2005&quot;, &quot;2006&quot;, &quot;2007&quot;, &quot;2008&quot;, &quot;2009&quot;, &quot;2010&quot;, &quot;2011&quot;, &quot;2012&quot;, &quot;2013&quot;))</code></pre>
<p><img src="portfolio2_files/figure-html/unnamed-chunk-168-1.png" width="672" /></p>
<pre class="r"><code>barplot(off.by.year)</code></pre>
<p><img src="portfolio2_files/figure-html/unnamed-chunk-168-2.png" width="672" /></p>
</div>
<div id="problem-set-2-1" class="section level3">
<h3>Problem Set 2</h3>
<p><strong>Question 1</strong></p>
<pre class="r"><code>#load in UCR data
load(&quot;/Users/briannafisher/Dropbox/CRIM 4002/UCR Assignment/UCRdata copy.rda&quot;)

#create a clean ucr data frame
ucr &lt;- data.frame(ORI   =as.character(da35021.0001$V3),
                  AGENCY=as.character(da35021.0001$V29),
                  AREA  =as.character(da35021.0001$V26),
                  POP   =da35021.0001$V14+
                         da35021.0001$V17+
                         da35021.0001$V20,
                  MONTHS=as.character(da35021.0001$V12),
                  STATE=as.character(da35021.0001$V2))

# variable definitions stored in the dataset&#39;s attributes
var.lookup &lt;- attributes(da35021.0001)$variable.labels

# tabulate all the murder numbers
var.names &lt;- grep(&quot;ACT NUM MURDER&quot;,var.lookup,value=TRUE)
var.names &lt;- names(var.names)
ucr$murder &lt;- rowSums(da35021.0001[,var.names])

var.names &lt;- grep(&quot;ACT NUM RAPE&quot;,var.lookup,value=TRUE)
var.names &lt;- names(var.names)
ucr$rape &lt;- rowSums(da35021.0001[,var.names])

# robbery - taking something by force/threat of force
var.names &lt;- grep(&quot;ACT NUM ROBBRY&quot;,var.lookup,value=TRUE)
var.names &lt;- names(var.names)
ucr$robbery &lt;- rowSums(da35021.0001[,var.names])

# aggravated assault are #assaults - #simple assaults
#    aggravated assaults - purpose is severe injury, normally with
#       a weapon, 25% guns, 15% knives, 25% hands/feet, rest other
var.names &lt;- grep(&quot;ACT NUM ASSLT&quot;,var.lookup,value=TRUE)
var.names &lt;- names(var.names)
ucr$assault &lt;- rowSums(da35021.0001[,var.names])
var.names &lt;- grep(&quot;ACT # SIMPLE ASSLT&quot;,var.lookup,value=TRUE)
var.names &lt;- names(var.names)
ucr$assault &lt;- ucr$assault - rowSums(da35021.0001[,var.names])

# burglary - entering a home/business to steal something
var.names &lt;- grep(&quot;ACT # BURGLARY&quot;,var.lookup,value=TRUE)
var.names &lt;- names(var.names)
ucr$burglary &lt;- rowSums(da35021.0001[,var.names])

# larceny - stealing something, generally serious
var.names &lt;- grep(&quot;ACT # LARCENY&quot;,var.lookup,value=TRUE)
var.names &lt;- names(var.names)
ucr$larceny &lt;- rowSums(da35021.0001[,var.names])

# vehicle theft
var.names &lt;- grep(&quot;ACT # VHC THEFT&quot;,var.lookup,value=TRUE)
var.names &lt;- names(var.names)
ucr$gta &lt;- rowSums(da35021.0001[,var.names])</code></pre>
<pre class="r"><code>#now that the UCR data frame is set up, I can use if else to calculate the homicide rate per 100,000
ucr$hom.rate &lt;- ifelse(ucr$POP == 0, 0, (ucr$murder/ucr$POP)*100000)

#use order to sort the homicide rate from greatest to smallest
i &lt;- order(ucr$hom.rate, decreasing = TRUE)
ucr &lt;- ucr[i,]

#use square brackets to pull the 10 cities with the highest homicide rate
ucr[1:10,]</code></pre>
<pre><code>##           ORI                         AGENCY                     AREA  POP
## 1219  CA01973 VERNON POLICE DEPARTMENT       VERNON                    114
## 5211  IL08222 SAUGET POLICE DEPARTMENT       SAUGET                    160
## 10306 MO09533 GLEN ECHO PARK POLICE DEPT     GLEN ECHO PARK            160
## 20508 VA09202 POCAHONTAS POLICE DEPARTMENT   POCAHONTAS                389
## 320   AL04606 SHORTER POLICE DEPARTMENT      SHORTER                   469
## 10312 MO09542 KINLOCH POLICE DEPARTMENT      KINLOCH                   299
## 18703 TN08102 CUMBERLAND CITY POLICE DEPT    CUMBERLAND CITY           310
## 19940 UT00403 HELPER POLICE DEPARTMENT       HELPER                   2219
## 1300  CA02709 SAND CITY POLICE DEPARTMENT    SAND CITY                 343
## 13631 NC06407 WHITAKERS POLICE DEPARTMENT    WHITAKERS                 748
##                       MONTHS               STATE murder rape robbery assault
## 1219  (12) Dec last reported     (04) California      1    1      16       9
## 5211  (12) Dec last reported       (12) Illinois      1    7       4       2
## 10306 (12) Dec last reported       (24) Missouri      1    0       0       0
## 20508 (12) Dec last reported       (45) Virginia      2    0       0       1
## 320   (09) Sep last reported        (01) Alabama      2    0       1       4
## 10312 (12) Dec last reported       (24) Missouri      1    0       1       6
## 18703 (12) Dec last reported      (41) Tennessee      1    0       0       0
## 19940 (12) Dec last reported           (43) Utah      7    0       1       0
## 1300  (12) Dec last reported     (04) California      1    1       2       3
## 13631 (12) Dec last reported (32) North Carolina      2    0       1       4
##       burglary larceny gta hom.rate
## 1219        26     199  86 877.1930
## 5211         5      67  11 625.0000
## 10306        2       2   0 625.0000
## 20508        1       0   0 514.1388
## 320          6       0   0 426.4392
## 10312        5       2   2 334.4482
## 18703        6       2   0 322.5806
## 19940       11      41   0 315.4574
## 1300         2      68   6 291.5452
## 13631       11      12   4 267.3797</code></pre>
<p>The ten cities with the highest homicide rate per 100,000 residents are Vernon, Suget, Glen Echo Park, Pocahontas, Shorter, Kinloch, Cumberland City, Helper, Sand City, and Whitakers.</p>
<p><strong>Question 2</strong></p>
<pre class="r"><code>#subsetting for cities with more than 100,000 residents
large.city &lt;- subset(ucr, subset = POP &gt; 100000)

#use order to sort the homicide rate from greatest to smallest
hom.order &lt;- order(large.city$hom.rate, decreasing = TRUE)
large.city &lt;- large.city[hom.order,]

#use square brackets to pull the 10 cities with the highest homicide rate
large.city[1:10,]</code></pre>
<pre><code>##           ORI                         AGENCY                     AREA    POP
## 8502  MI25398 FLINT POLICE DEPARTMENT        FLINT                    101632
## 9085  MI82349 DETROIT POLICE DEPARTMENT      DETROIT                  707096
## 7147  LANPD00 RECORDS &amp; IDENTIFICATION       NEW ORLEANS              362874
## 9578  MS02501 JACKSON POLICE DEPARTMENT      JACKSON                  175939
## 9754  MOSPD00 SAINT LOUIS POLICE DEPARTMENT  ST. LOUIS                318667
## 7645  MDBPD00 BALTIMORE CITY POLICE DEPT     BALTIMORE                625474
## 11221 NJNPD00 NEWARK POLICE DEPARTMENT       NEWARK                   278906
## 928   CA00109 OAKLAND POLICE DEPARTMENT      OAKLAND                  399487
## 5     AL00102 BIRMINGHAM POLICE DEPARTMENT   BIRMINGHAM               213266
## 7216  LA01702 BATON ROUGE POLICE DEPARTMENT  BATON ROUGE              231500
##                       MONTHS            STATE murder rape robbery assault
## 8502  (12) Dec last reported    (21) Michigan     64  108     673    1929
## 9085  (12) Dec last reported    (21) Michigan    386  442    4850    9345
## 7147  (12) Dec last reported   (17) Louisiana    193  136    1065    1564
## 9578  (12) Dec last reported (23) Mississippi     63  135     799     671
## 9754  (12) Dec last reported    (24) Missouri    113  199    1778    3571
## 7645  (12) Dec last reported    (19) Maryland    216  317    3605    4651
## 11221 (12) Dec last reported  (29) New Jersey     96   55    1976    1093
## 928   (12) Dec last reported  (04) California    127  271    4338    3227
## 5     (12) Dec last reported     (01) Alabama     67  152     983    2035
## 7216  (12) Dec last reported   (17) Louisiana     66   64    1033    1344
##       burglary larceny   gta hom.rate
## 8502      2979    2211   458 62.97229
## 9085     13504   15992 11514 54.58948
## 7147      3423    8051  2215 53.18651
## 9578      4124    6308  1136 35.80787
## 9754      4986   13520  3489 35.46021
## 7645      7770   17397  3982 34.53381
## 11221     2144    4093  3962 34.42020
## 928       6168   13198  6976 31.79077
## 5         4704    9042  1042 31.41617
## 7216      3826    7751   482 28.50972</code></pre>
<p>The ten cities with more than 100,000 residents that have the highest homicide rate per 100,000 residents are Flint, Detroit, New Orleans, Jackson, St. Louis, Baltimore, Newark, Oakland, Birmingham, and Baton Rouge.</p>
<p><strong>Question 3</strong></p>
<p><strong>Which ten cities have the most costly crime burden?</strong></p>
<pre class="r"><code>#creating a cost of homicide variable
ucr$cost.hom &lt;- ucr$murder*5000000

#creating a cost of rape variable
ucr$cost.rape &lt;- ucr$rape*150000

#creating a cost of robbery variable
ucr$cost.robbery &lt;- ucr$robbery*23000

#creating a cost of assault variable
ucr$cost.assault &lt;- ucr$assault*55000

#creating a cost of burglary variable
ucr$cost.burglary &lt;- ucr$burglary*5000

#creating a cost of rape variable
ucr$cost.larceny &lt;- ucr$larceny*2800

#creating a cost of vehicle theft variable
ucr$cost.gta &lt;- ucr$gta*9000

#adding up all the costs of the seven crimes
ucr$total.costs &lt;- with(ucr, cost.hom + cost.rape + cost.robbery + cost.assault + cost.burglary + cost.larceny + cost.gta)

#use order to sort the total costs from greatest to smallest
large.costs &lt;- order(ucr$total.costs, decreasing = TRUE)
ucrCost &lt;- ucr[large.costs,]

#use square brackets to pull the 10 cities with the highest homicide rate
ucrCost[1:10,]</code></pre>
<pre><code>##           ORI                         AGENCY                     AREA     POP
## 12338 NY03030 NEW YORK CITY POLICE DEPT      NEW YORK                 8289415
## 4396  ILCPD00 CHICAGO POLICE DEPARTMENT      CHICAGO                  2708382
## 9085  MI82349 DETROIT POLICE DEPARTMENT      DETROIT                   707096
## 1188  CA01942 LOS ANGELES POLICE DEPARTMENT  LOS ANGELES              3855122
## 15664 PAPEP00 PHILADELPHIA POLICE DEPARTMENT PHILADELPHIA             1538957
## 18784 TXHPD00 HOUSTON POLICE DEPARTMENT      HOUSTON                  2177273
## 7645  MDBPD00 BALTIMORE CITY POLICE DEPT     BALTIMORE                 625474
## 18200 TNMPD00 MEMPHIS POLICE DEPARTMENT      MEMPHIS                   657436
## 18783 TXDPD00 DALLAS POLICE DEPARTMENT       DALLAS                   1241549
## 532   AZ00723 PHOENIX POLICE DEPARTMENT      PHOENIX                  1485509
##                       MONTHS             STATE murder rape robbery assault
## 12338 (12) Dec last reported     (31) New York    419 1162   20201   31211
## 4396  (12) Dec last reported     (12) Illinois    500    0   13476   12272
## 9085  (12) Dec last reported     (21) Michigan    386  442    4850    9345
## 1188  (12) Dec last reported   (04) California    299  936    8983    8329
## 15664 (12) Dec last reported (37) Pennsylvania    331  880    7984    8658
## 18784 (12) Dec last reported        (42) Texas    217  665    9385   11343
## 7645  (12) Dec last reported     (19) Maryland    216  317    3605    4651
## 18200 (12) Dec last reported    (41) Tennessee    134  428    3384    7471
## 18783 (12) Dec last reported        (42) Texas    154  486    4093    3647
## 532   (12) Dec last reported      (02) Arizona    123  556    3516    5263
##       burglary larceny   gta  hom.rate  cost.hom cost.rape cost.robbery
## 12338    18635  115935  8190  5.054639 2.095e+09 174300000    464623000
## 4396     22748   72717 17001 18.461207 2.500e+09         0    309948000
## 9085     13504   15992 11514 54.589476 1.930e+09  66300000    111550000
## 1188     16388   56006 15084  7.755915 1.495e+09 140400000    206609000
## 15664    12004   38592  6401 21.508073 1.655e+09 132000000    183632000
## 18784    26630   67978 13070  9.966596 1.085e+09  99750000    215855000
## 7645      7770   17397  3982 34.533810 1.080e+09  47550000     82915000
## 18200    12593   25992  2973 20.382212 6.700e+08  64200000     77832000
## 18783    16090   31148  7062 12.403860 7.700e+08  72900000     94139000
## 532      17912   35678  7187  8.279990 6.150e+08  83400000     80868000
##       cost.assault cost.burglary cost.larceny  cost.gta total.costs
## 12338   1716605000      93175000    324618000  73710000  4942031000
## 4396     674960000     113740000    203607600 153009000  3955264600
## 9085     513975000      67520000     44777600 103626000  2837748600
## 1188     458095000      81940000    156816800 135756000  2674616800
## 15664    476190000      60020000    108057600  57609000  2672508600
## 18784    623865000     133150000    190338400 117630000  2465588400
## 7645     255805000      38850000     48711600  35838000  1589669600
## 18200    410905000      62965000     72777600  26757000  1385436600
## 18783    200585000      80450000     87214400  63558000  1368846400
## 532      289465000      89560000     99898400  64683000  1322874400</code></pre>
<pre class="r"><code>#calculate cost per capita
ucrCost$costpercapita &lt;- with(ucrCost, total.costs/POP)
ucrCost &lt;- subset(ucrCost, POP &gt; 0)</code></pre>
<p>Using the accounting method from study 1, the ten cities that have the most costly crime burdens are New York, Chicago, Detroit, Los Angeles, Philadelphia, Houston, Baltimore, Memphis, Dallas, and Phoenix.</p>
</div>
<div id="problem-set-3-1" class="section level3">
<h3>Problem Set 3</h3>
<pre class="r"><code>#scan in the file with the words
words &lt;- scan(file=&quot;/Users/briannafisher/Dropbox/CRIM 4002/Scrabble Assignment/scrabble4letter.txt&quot;, what=&quot;&quot;)</code></pre>
<p><strong>Question 1</strong></p>
<pre class="r"><code>grep(&quot;^[z]&quot;, words, value=TRUE)</code></pre>
<pre><code>##  [1] &quot;zags&quot; &quot;zany&quot; &quot;zaps&quot; &quot;zarf&quot; &quot;zeal&quot; &quot;zebu&quot; &quot;zeds&quot; &quot;zees&quot; &quot;zein&quot; &quot;zeks&quot;
## [11] &quot;zeps&quot; &quot;zerk&quot; &quot;zero&quot; &quot;zest&quot; &quot;zeta&quot; &quot;zigs&quot; &quot;zill&quot; &quot;zinc&quot; &quot;zine&quot; &quot;zing&quot;
## [21] &quot;zins&quot; &quot;zips&quot; &quot;ziti&quot; &quot;zits&quot; &quot;zoea&quot; &quot;zoic&quot; &quot;zona&quot; &quot;zone&quot; &quot;zonk&quot; &quot;zoom&quot;
## [31] &quot;zoon&quot; &quot;zoos&quot; &quot;zori&quot; &quot;zouk&quot; &quot;zyme&quot;</code></pre>
<p><strong>Question 2</strong></p>
<pre class="r"><code>grep(&quot;zz&quot;, words, value=TRUE)</code></pre>
<pre><code>## [1] &quot;buzz&quot; &quot;fizz&quot; &quot;fuzz&quot; &quot;jazz&quot; &quot;razz&quot;</code></pre>
<p><strong>Question 3</strong></p>
<pre class="r"><code>grep(&quot;[^aeiou][^aeiou][^aeiou][^aeiou]&quot;, words, value=TRUE)</code></pre>
<pre><code>##  [1] &quot;brrr&quot; &quot;byrl&quot; &quot;cwms&quot; &quot;cyst&quot; &quot;drys&quot; &quot;gyms&quot; &quot;gyps&quot; &quot;hymn&quot; &quot;hyps&quot; &quot;lych&quot;
## [11] &quot;lynx&quot; &quot;mycs&quot; &quot;myth&quot; &quot;pfft&quot; &quot;psst&quot; &quot;rynd&quot; &quot;scry&quot; &quot;spry&quot; &quot;sync&quot; &quot;syph&quot;
## [21] &quot;tsks&quot; &quot;typp&quot; &quot;typy&quot; &quot;whys&quot; &quot;wych&quot; &quot;wynd&quot; &quot;wynn&quot; &quot;wyns&quot; &quot;xyst&quot;</code></pre>
<p><strong>Question 4</strong></p>
<pre class="r"><code>grep(&quot;[r]...&quot;, words, value=TRUE) #185</code></pre>
<pre><code>##   [1] &quot;race&quot; &quot;rack&quot; &quot;racy&quot; &quot;rads&quot; &quot;raff&quot; &quot;raft&quot; &quot;raga&quot; &quot;rage&quot; &quot;ragg&quot; &quot;ragi&quot;
##  [11] &quot;rags&quot; &quot;raia&quot; &quot;raid&quot; &quot;rail&quot; &quot;rain&quot; &quot;rais&quot; &quot;raja&quot; &quot;rake&quot; &quot;raki&quot; &quot;raku&quot;
##  [21] &quot;rale&quot; &quot;rami&quot; &quot;ramp&quot; &quot;rams&quot; &quot;rand&quot; &quot;rang&quot; &quot;rani&quot; &quot;rank&quot; &quot;rant&quot; &quot;rape&quot;
##  [31] &quot;raps&quot; &quot;rapt&quot; &quot;rare&quot; &quot;rase&quot; &quot;rash&quot; &quot;rasp&quot; &quot;rate&quot; &quot;rath&quot; &quot;rato&quot; &quot;rats&quot;
##  [41] &quot;rave&quot; &quot;raws&quot; &quot;raya&quot; &quot;rays&quot; &quot;raze&quot; &quot;razz&quot; &quot;read&quot; &quot;real&quot; &quot;ream&quot; &quot;reap&quot;
##  [51] &quot;rear&quot; &quot;rebs&quot; &quot;reck&quot; &quot;recs&quot; &quot;redd&quot; &quot;rede&quot; &quot;redo&quot; &quot;reds&quot; &quot;reed&quot; &quot;reef&quot;
##  [61] &quot;reek&quot; &quot;reel&quot; &quot;rees&quot; &quot;refs&quot; &quot;reft&quot; &quot;regs&quot; &quot;reif&quot; &quot;rein&quot; &quot;reis&quot; &quot;rely&quot;
##  [71] &quot;rems&quot; &quot;rend&quot; &quot;rent&quot; &quot;repo&quot; &quot;repp&quot; &quot;reps&quot; &quot;resh&quot; &quot;rest&quot; &quot;rete&quot; &quot;rets&quot;
##  [81] &quot;revs&quot; &quot;rhea&quot; &quot;rhos&quot; &quot;rhus&quot; &quot;rial&quot; &quot;rias&quot; &quot;ribs&quot; &quot;rice&quot; &quot;rich&quot; &quot;rick&quot;
##  [91] &quot;ride&quot; &quot;rids&quot; &quot;riel&quot; &quot;rife&quot; &quot;riff&quot; &quot;rifs&quot; &quot;rift&quot; &quot;rigs&quot; &quot;rile&quot; &quot;rill&quot;
## [101] &quot;rime&quot; &quot;rims&quot; &quot;rimy&quot; &quot;rind&quot; &quot;ring&quot; &quot;rink&quot; &quot;rins&quot; &quot;riot&quot; &quot;ripe&quot; &quot;rips&quot;
## [111] &quot;rise&quot; &quot;risk&quot; &quot;rite&quot; &quot;ritz&quot; &quot;rive&quot; &quot;road&quot; &quot;roam&quot; &quot;roan&quot; &quot;roar&quot; &quot;robe&quot;
## [121] &quot;robs&quot; &quot;rock&quot; &quot;rocs&quot; &quot;rode&quot; &quot;rods&quot; &quot;roes&quot; &quot;roil&quot; &quot;role&quot; &quot;rolf&quot; &quot;roll&quot;
## [131] &quot;romp&quot; &quot;roms&quot; &quot;rood&quot; &quot;roof&quot; &quot;rook&quot; &quot;room&quot; &quot;root&quot; &quot;rope&quot; &quot;ropy&quot; &quot;rose&quot;
## [141] &quot;rosy&quot; &quot;rota&quot; &quot;rote&quot; &quot;roti&quot; &quot;rotl&quot; &quot;roto&quot; &quot;rots&quot; &quot;roue&quot; &quot;roup&quot; &quot;rout&quot;
## [151] &quot;roux&quot; &quot;rove&quot; &quot;rows&quot; &quot;rube&quot; &quot;rubs&quot; &quot;ruby&quot; &quot;ruck&quot; &quot;rudd&quot; &quot;rude&quot; &quot;rued&quot;
## [161] &quot;ruer&quot; &quot;rues&quot; &quot;ruff&quot; &quot;ruga&quot; &quot;rugs&quot; &quot;ruin&quot; &quot;rule&quot; &quot;ruly&quot; &quot;rump&quot; &quot;rums&quot;
## [171] &quot;rune&quot; &quot;rung&quot; &quot;runs&quot; &quot;runt&quot; &quot;ruse&quot; &quot;rush&quot; &quot;rusk&quot; &quot;rust&quot; &quot;ruth&quot; &quot;ruts&quot;
## [181] &quot;ryas&quot; &quot;ryes&quot; &quot;ryke&quot; &quot;rynd&quot; &quot;ryot&quot;</code></pre>
<pre class="r"><code>grep(&quot;.[r]..&quot;, words, value=TRUE) #200</code></pre>
<pre><code>##   [1] &quot;arak&quot; &quot;arbs&quot; &quot;arch&quot; &quot;arco&quot; &quot;arcs&quot; &quot;area&quot; &quot;ares&quot; &quot;arfs&quot; &quot;aria&quot; &quot;arid&quot;
##  [11] &quot;aril&quot; &quot;arks&quot; &quot;arms&quot; &quot;army&quot; &quot;arse&quot; &quot;arts&quot; &quot;arty&quot; &quot;arum&quot; &quot;arvo&quot; &quot;aryl&quot;
##  [21] &quot;brad&quot; &quot;brae&quot; &quot;brag&quot; &quot;bran&quot; &quot;bras&quot; &quot;brat&quot; &quot;braw&quot; &quot;bray&quot; &quot;bred&quot; &quot;bree&quot;
##  [31] &quot;bren&quot; &quot;brew&quot; &quot;brie&quot; &quot;brig&quot; &quot;brim&quot; &quot;brin&quot; &quot;brio&quot; &quot;bris&quot; &quot;brit&quot; &quot;broo&quot;
##  [41] &quot;bros&quot; &quot;brow&quot; &quot;brrr&quot; &quot;brut&quot; &quot;brux&quot; &quot;crab&quot; &quot;crag&quot; &quot;cram&quot; &quot;crap&quot; &quot;craw&quot;
##  [51] &quot;cred&quot; &quot;crew&quot; &quot;crib&quot; &quot;cris&quot; &quot;crit&quot; &quot;croc&quot; &quot;crop&quot; &quot;crow&quot; &quot;crud&quot; &quot;crus&quot;
##  [61] &quot;crux&quot; &quot;drab&quot; &quot;drag&quot; &quot;dram&quot; &quot;drat&quot; &quot;draw&quot; &quot;dray&quot; &quot;dree&quot; &quot;dreg&quot; &quot;drek&quot;
##  [71] &quot;drew&quot; &quot;drib&quot; &quot;drip&quot; &quot;drop&quot; &quot;drub&quot; &quot;drug&quot; &quot;drum&quot; &quot;drys&quot; &quot;eras&quot; &quot;ergo&quot;
##  [81] &quot;ergs&quot; &quot;erne&quot; &quot;erns&quot; &quot;eros&quot; &quot;errs&quot; &quot;erst&quot; &quot;frae&quot; &quot;frag&quot; &quot;frap&quot; &quot;frat&quot;
##  [91] &quot;fray&quot; &quot;free&quot; &quot;fret&quot; &quot;frig&quot; &quot;frit&quot; &quot;friz&quot; &quot;froe&quot; &quot;frog&quot; &quot;from&quot; &quot;frow&quot;
## [101] &quot;frug&quot; &quot;grab&quot; &quot;grad&quot; &quot;gram&quot; &quot;gran&quot; &quot;grat&quot; &quot;gray&quot; &quot;gree&quot; &quot;grew&quot; &quot;grey&quot;
## [111] &quot;grid&quot; &quot;grig&quot; &quot;grim&quot; &quot;grin&quot; &quot;grip&quot; &quot;grit&quot; &quot;grog&quot; &quot;grok&quot; &quot;grot&quot; &quot;grow&quot;
## [121] &quot;grub&quot; &quot;grue&quot; &quot;grum&quot; &quot;ired&quot; &quot;ires&quot; &quot;irid&quot; &quot;iris&quot; &quot;irks&quot; &quot;iron&quot; &quot;kris&quot;
## [131] &quot;orad&quot; &quot;oral&quot; &quot;orbs&quot; &quot;orby&quot; &quot;orca&quot; &quot;orcs&quot; &quot;ordo&quot; &quot;ores&quot; &quot;orgy&quot; &quot;orle&quot;
## [141] &quot;orra&quot; &quot;orts&quot; &quot;oryx&quot; &quot;orzo&quot; &quot;pram&quot; &quot;prao&quot; &quot;prat&quot; &quot;prau&quot; &quot;pray&quot; &quot;pree&quot;
## [151] &quot;prep&quot; &quot;prex&quot; &quot;prey&quot; &quot;prez&quot; &quot;prig&quot; &quot;prim&quot; &quot;proa&quot; &quot;prod&quot; &quot;prof&quot; &quot;prog&quot;
## [161] &quot;prom&quot; &quot;prop&quot; &quot;pros&quot; &quot;prow&quot; &quot;sris&quot; &quot;trad&quot; &quot;tram&quot; &quot;trap&quot; &quot;tray&quot; &quot;tree&quot;
## [171] &quot;tref&quot; &quot;trek&quot; &quot;tres&quot; &quot;tret&quot; &quot;trey&quot; &quot;trig&quot; &quot;trim&quot; &quot;trio&quot; &quot;trip&quot; &quot;trod&quot;
## [181] &quot;trog&quot; &quot;trop&quot; &quot;trot&quot; &quot;trow&quot; &quot;troy&quot; &quot;true&quot; &quot;trug&quot; &quot;urbs&quot; &quot;urds&quot; &quot;urea&quot;
## [191] &quot;urge&quot; &quot;uric&quot; &quot;urns&quot; &quot;urps&quot; &quot;ursa&quot; &quot;urus&quot; &quot;vrow&quot; &quot;wrap&quot; &quot;wren&quot; &quot;writ&quot;</code></pre>
<pre class="r"><code>grep(&quot;..[r].&quot;, words, value=TRUE) #354 </code></pre>
<pre><code>##   [1] &quot;abri&quot; &quot;acre&quot; &quot;aero&quot; &quot;aery&quot; &quot;airn&quot; &quot;airs&quot; &quot;airt&quot; &quot;airy&quot; &quot;aura&quot; &quot;awry&quot;
##  [11] &quot;barb&quot; &quot;bard&quot; &quot;bare&quot; &quot;barf&quot; &quot;bark&quot; &quot;barm&quot; &quot;barn&quot; &quot;bars&quot; &quot;berg&quot; &quot;berk&quot;
##  [21] &quot;berm&quot; &quot;bird&quot; &quot;birk&quot; &quot;birl&quot; &quot;biro&quot; &quot;birr&quot; &quot;bora&quot; &quot;bore&quot; &quot;bork&quot; &quot;born&quot;
##  [31] &quot;bort&quot; &quot;brrr&quot; &quot;bura&quot; &quot;burb&quot; &quot;burd&quot; &quot;burg&quot; &quot;burl&quot; &quot;burn&quot; &quot;burp&quot; &quot;burr&quot;
##  [41] &quot;burs&quot; &quot;bury&quot; &quot;byre&quot; &quot;byrl&quot; &quot;carb&quot; &quot;card&quot; &quot;care&quot; &quot;cark&quot; &quot;carl&quot; &quot;carn&quot;
##  [51] &quot;carp&quot; &quot;carr&quot; &quot;cars&quot; &quot;cart&quot; &quot;cere&quot; &quot;cero&quot; &quot;cire&quot; &quot;cord&quot; &quot;core&quot; &quot;corf&quot;
##  [61] &quot;cork&quot; &quot;corm&quot; &quot;corn&quot; &quot;cors&quot; &quot;cory&quot; &quot;curb&quot; &quot;curd&quot; &quot;cure&quot; &quot;curf&quot; &quot;curl&quot;
##  [71] &quot;curn&quot; &quot;curr&quot; &quot;curs&quot; &quot;curt&quot; &quot;darb&quot; &quot;dare&quot; &quot;dark&quot; &quot;darn&quot; &quot;dart&quot; &quot;dere&quot;
##  [81] &quot;derm&quot; &quot;dire&quot; &quot;dirk&quot; &quot;dirl&quot; &quot;dirt&quot; &quot;dore&quot; &quot;dork&quot; &quot;dorm&quot; &quot;dorp&quot; &quot;dorr&quot;
##  [91] &quot;dors&quot; &quot;dory&quot; &quot;dura&quot; &quot;dure&quot; &quot;durn&quot; &quot;duro&quot; &quot;durr&quot; &quot;earl&quot; &quot;earn&quot; &quot;ears&quot;
## [101] &quot;ecru&quot; &quot;eery&quot; &quot;errs&quot; &quot;euro&quot; &quot;eyra&quot; &quot;eyre&quot; &quot;eyry&quot; &quot;fard&quot; &quot;fare&quot; &quot;farl&quot;
## [111] &quot;farm&quot; &quot;faro&quot; &quot;fart&quot; &quot;fere&quot; &quot;fern&quot; &quot;fire&quot; &quot;firm&quot; &quot;firn&quot; &quot;firs&quot; &quot;fora&quot;
## [121] &quot;forb&quot; &quot;ford&quot; &quot;fore&quot; &quot;fork&quot; &quot;form&quot; &quot;fort&quot; &quot;furl&quot; &quot;furs&quot; &quot;fury&quot; &quot;garb&quot;
## [131] &quot;gars&quot; &quot;germ&quot; &quot;gird&quot; &quot;girl&quot; &quot;girn&quot; &quot;giro&quot; &quot;girt&quot; &quot;gore&quot; &quot;gorm&quot; &quot;gorp&quot;
## [141] &quot;gory&quot; &quot;guru&quot; &quot;gyre&quot; &quot;gyri&quot; &quot;gyro&quot; &quot;hard&quot; &quot;hare&quot; &quot;hark&quot; &quot;harl&quot; &quot;harm&quot;
## [151] &quot;harp&quot; &quot;hart&quot; &quot;herb&quot; &quot;herd&quot; &quot;here&quot; &quot;herl&quot; &quot;herm&quot; &quot;hern&quot; &quot;hero&quot; &quot;hers&quot;
## [161] &quot;hire&quot; &quot;hora&quot; &quot;horn&quot; &quot;hurl&quot; &quot;hurt&quot; &quot;inro&quot; &quot;jarl&quot; &quot;jars&quot; &quot;jerk&quot; &quot;jura&quot;
## [171] &quot;jury&quot; &quot;karn&quot; &quot;kart&quot; &quot;kerb&quot; &quot;kerf&quot; &quot;kern&quot; &quot;kirk&quot; &quot;kirn&quot; &quot;kirs&quot; &quot;kora&quot;
## [181] &quot;kore&quot; &quot;kors&quot; &quot;kuru&quot; &quot;lard&quot; &quot;lari&quot; &quot;lark&quot; &quot;lars&quot; &quot;lira&quot; &quot;lire&quot; &quot;liri&quot;
## [191] &quot;lord&quot; &quot;lore&quot; &quot;lorn&quot; &quot;lory&quot; &quot;lure&quot; &quot;lurk&quot; &quot;lyre&quot; &quot;mara&quot; &quot;marc&quot; &quot;mare&quot;
## [201] &quot;mark&quot; &quot;marl&quot; &quot;mars&quot; &quot;mart&quot; &quot;merc&quot; &quot;mere&quot; &quot;merk&quot; &quot;merl&quot; &quot;mire&quot; &quot;miri&quot;
## [211] &quot;mirk&quot; &quot;mirs&quot; &quot;miry&quot; &quot;mora&quot; &quot;more&quot; &quot;morn&quot; &quot;mors&quot; &quot;mort&quot; &quot;mura&quot; &quot;mure&quot;
## [221] &quot;murk&quot; &quot;murr&quot; &quot;narc&quot; &quot;nard&quot; &quot;nark&quot; &quot;nary&quot; &quot;nerd&quot; &quot;nori&quot; &quot;norm&quot; &quot;nurd&quot;
## [231] &quot;nurl&quot; &quot;oars&quot; &quot;ogre&quot; &quot;okra&quot; &quot;orra&quot; &quot;ours&quot; &quot;para&quot; &quot;pard&quot; &quot;pare&quot; &quot;park&quot;
## [241] &quot;parr&quot; &quot;pars&quot; &quot;part&quot; &quot;pere&quot; &quot;peri&quot; &quot;perk&quot; &quot;perm&quot; &quot;perp&quot; &quot;pert&quot; &quot;perv&quot;
## [251] &quot;pirn&quot; &quot;pore&quot; &quot;pork&quot; &quot;porn&quot; &quot;port&quot; &quot;pure&quot; &quot;puri&quot; &quot;purl&quot; &quot;purr&quot; &quot;purs&quot;
## [261] &quot;pyre&quot; &quot;pyro&quot; &quot;rare&quot; &quot;sard&quot; &quot;sari&quot; &quot;sark&quot; &quot;scry&quot; &quot;sera&quot; &quot;sere&quot; &quot;serf&quot;
## [271] &quot;sers&quot; &quot;shri&quot; &quot;sire&quot; &quot;sirs&quot; &quot;sora&quot; &quot;sorb&quot; &quot;sord&quot; &quot;sore&quot; &quot;sori&quot; &quot;sorn&quot;
## [281] &quot;sort&quot; &quot;spry&quot; &quot;sura&quot; &quot;surd&quot; &quot;sure&quot; &quot;surf&quot; &quot;tare&quot; &quot;tarn&quot; &quot;taro&quot; &quot;tarp&quot;
## [291] &quot;tars&quot; &quot;tart&quot; &quot;term&quot; &quot;tern&quot; &quot;thro&quot; &quot;thru&quot; &quot;tire&quot; &quot;tirl&quot; &quot;tiro&quot; &quot;tora&quot;
## [301] &quot;torc&quot; &quot;tore&quot; &quot;tori&quot; &quot;torn&quot; &quot;toro&quot; &quot;torr&quot; &quot;tors&quot; &quot;tort&quot; &quot;tory&quot; &quot;turd&quot;
## [311] &quot;turf&quot; &quot;turk&quot; &quot;turn&quot; &quot;tyre&quot; &quot;tyro&quot; &quot;vara&quot; &quot;vars&quot; &quot;vary&quot; &quot;vera&quot; &quot;verb&quot;
## [321] &quot;vert&quot; &quot;very&quot; &quot;virl&quot; &quot;ward&quot; &quot;ware&quot; &quot;wark&quot; &quot;warm&quot; &quot;warn&quot; &quot;warp&quot; &quot;wars&quot;
## [331] &quot;wart&quot; &quot;wary&quot; &quot;were&quot; &quot;wert&quot; &quot;wire&quot; &quot;wiry&quot; &quot;word&quot; &quot;wore&quot; &quot;work&quot; &quot;worm&quot;
## [341] &quot;worn&quot; &quot;wort&quot; &quot;yard&quot; &quot;yare&quot; &quot;yarn&quot; &quot;yerk&quot; &quot;yird&quot; &quot;yirr&quot; &quot;yore&quot; &quot;yurt&quot;
## [351] &quot;zarf&quot; &quot;zerk&quot; &quot;zero&quot; &quot;zori&quot;</code></pre>
<pre class="r"><code>grep(&quot;...[r]&quot;, words, value=TRUE) #123</code></pre>
<pre><code>##   [1] &quot;afar&quot; &quot;agar&quot; &quot;ager&quot; &quot;ajar&quot; &quot;alar&quot; &quot;amir&quot; &quot;aper&quot; &quot;aver&quot; &quot;bear&quot; &quot;beer&quot;
##  [11] &quot;bier&quot; &quot;birr&quot; &quot;blur&quot; &quot;boar&quot; &quot;boor&quot; &quot;brrr&quot; &quot;buhr&quot; &quot;burr&quot; &quot;carr&quot; &quot;char&quot;
##  [21] &quot;coir&quot; &quot;curr&quot; &quot;czar&quot; &quot;dear&quot; &quot;deer&quot; &quot;doer&quot; &quot;door&quot; &quot;dorr&quot; &quot;dour&quot; &quot;durr&quot;
##  [31] &quot;dyer&quot; &quot;eger&quot; &quot;emir&quot; &quot;ever&quot; &quot;ewer&quot; &quot;eyer&quot; &quot;fair&quot; &quot;fear&quot; &quot;fiar&quot; &quot;flir&quot;
##  [41] &quot;four&quot; &quot;gaur&quot; &quot;gear&quot; &quot;gnar&quot; &quot;goer&quot; &quot;guar&quot; &quot;haar&quot; &quot;hair&quot; &quot;hear&quot; &quot;heir&quot;
##  [51] &quot;hoar&quot; &quot;hoer&quot; &quot;hour&quot; &quot;izar&quot; &quot;jeer&quot; &quot;kbar&quot; &quot;keir&quot; &quot;kier&quot; &quot;knar&quot; &quot;knur&quot;
##  [61] &quot;kyar&quot; &quot;lair&quot; &quot;lear&quot; &quot;leer&quot; &quot;lehr&quot; &quot;liar&quot; &quot;lier&quot; &quot;lour&quot; &quot;maar&quot; &quot;mair&quot;
##  [71] &quot;moor&quot; &quot;murr&quot; &quot;near&quot; &quot;noir&quot; &quot;odor&quot; &quot;omer&quot; &quot;osar&quot; &quot;over&quot; &quot;oyer&quot; &quot;pair&quot;
##  [81] &quot;parr&quot; &quot;pear&quot; &quot;peer&quot; &quot;pier&quot; &quot;poor&quot; &quot;pour&quot; &quot;purr&quot; &quot;rear&quot; &quot;roar&quot; &quot;ruer&quot;
##  [91] &quot;scar&quot; &quot;sear&quot; &quot;seer&quot; &quot;slur&quot; &quot;soar&quot; &quot;sour&quot; &quot;spar&quot; &quot;spur&quot; &quot;star&quot; &quot;stir&quot;
## [101] &quot;suer&quot; &quot;tahr&quot; &quot;tear&quot; &quot;thir&quot; &quot;tier&quot; &quot;torr&quot; &quot;tour&quot; &quot;tsar&quot; &quot;tyer&quot; &quot;tzar&quot;
## [111] &quot;user&quot; &quot;vair&quot; &quot;veer&quot; &quot;vier&quot; &quot;wair&quot; &quot;waur&quot; &quot;wear&quot; &quot;weer&quot; &quot;weir&quot; &quot;whir&quot;
## [121] &quot;year&quot; &quot;yirr&quot; &quot;your&quot;</code></pre>
<p>You are most likely to find an “r” in the third letter position.</p>
<p><strong>Question 5</strong></p>
<pre class="r"><code>rhyme &lt;- grep(&quot;(it$)|(itt$)&quot;, words, value=TRUE)
rhyme2 &lt;- grep(&quot;.[^a]..&quot;, rhyme, value=TRUE)
rhyme3 &lt;- grep(&quot;.[^o]..&quot;, rhyme2, value=TRUE)
rhyme4 &lt;- grep(&quot;.[^u]..&quot;, rhyme3, value=TRUE)</code></pre>
</div>
<div id="problem-set-4-1" class="section level3">
<h3>Problem Set 4</h3>
<pre class="r"><code>#scan in the file with the words
words &lt;- scan(file=&quot;/Users/briannafisher/Dropbox/CRIM 4002/Scrabble Assignment/scrabble4letter.txt&quot;, what=&quot;&quot;)</code></pre>
<p><strong>GREP:</strong></p>
<p><strong>Question 1</strong></p>
<pre class="r"><code>grep(&quot;(.)\\1&quot;, words, value=TRUE)</code></pre>
<pre><code>##   [1] &quot;aahs&quot; &quot;aals&quot; &quot;abba&quot; &quot;abbe&quot; &quot;adds&quot; &quot;agee&quot; &quot;ajee&quot; &quot;akee&quot; &quot;alee&quot; &quot;alls&quot;
##  [11] &quot;ally&quot; &quot;ammo&quot; &quot;anna&quot; &quot;apps&quot; &quot;awee&quot; &quot;baal&quot; &quot;baas&quot; &quot;baff&quot; &quot;ball&quot; &quot;bass&quot;
##  [21] &quot;batt&quot; &quot;beef&quot; &quot;been&quot; &quot;beep&quot; &quot;beer&quot; &quot;bees&quot; &quot;beet&quot; &quot;bell&quot; &quot;bibb&quot; &quot;biff&quot;
##  [31] &quot;bill&quot; &quot;birr&quot; &quot;bitt&quot; &quot;boff&quot; &quot;boll&quot; &quot;boob&quot; &quot;book&quot; &quot;boom&quot; &quot;boon&quot; &quot;boor&quot;
##  [41] &quot;boos&quot; &quot;boot&quot; &quot;boss&quot; &quot;bott&quot; &quot;bree&quot; &quot;broo&quot; &quot;brrr&quot; &quot;buff&quot; &quot;bull&quot; &quot;bunn&quot;
##  [51] &quot;burr&quot; &quot;buss&quot; &quot;butt&quot; &quot;buzz&quot; &quot;caff&quot; &quot;call&quot; &quot;carr&quot; &quot;cees&quot; &quot;cell&quot; &quot;cess&quot;
##  [61] &quot;cobb&quot; &quot;coff&quot; &quot;conn&quot; &quot;coof&quot; &quot;cook&quot; &quot;cool&quot; &quot;coon&quot; &quot;coop&quot; &quot;coos&quot; &quot;coot&quot;
##  [71] &quot;coss&quot; &quot;cuff&quot; &quot;cull&quot; &quot;curr&quot; &quot;cuss&quot; &quot;daff&quot; &quot;deed&quot; &quot;deem&quot; &quot;deep&quot; &quot;deer&quot;
##  [81] &quot;dees&quot; &quot;deet&quot; &quot;dell&quot; &quot;diff&quot; &quot;dill&quot; &quot;diss&quot; &quot;doff&quot; &quot;doll&quot; &quot;doom&quot; &quot;door&quot;
##  [91] &quot;dorr&quot; &quot;doss&quot; &quot;dree&quot; &quot;duff&quot; &quot;dull&quot; &quot;durr&quot; &quot;ebbs&quot; &quot;eddo&quot; &quot;eddy&quot; &quot;eels&quot;
## [101] &quot;eely&quot; &quot;eery&quot; &quot;effs&quot; &quot;eggs&quot; &quot;eggy&quot; &quot;ells&quot; &quot;emmy&quot; &quot;epee&quot; &quot;errs&quot; &quot;fall&quot;
## [111] &quot;feeb&quot; &quot;feed&quot; &quot;feel&quot; &quot;fees&quot; &quot;feet&quot; &quot;fell&quot; &quot;fess&quot; &quot;fill&quot; &quot;fizz&quot; &quot;flee&quot;
## [121] &quot;food&quot; &quot;fool&quot; &quot;foot&quot; &quot;foss&quot; &quot;free&quot; &quot;full&quot; &quot;fuss&quot; &quot;fuzz&quot; &quot;gaff&quot; &quot;gall&quot;
## [131] &quot;geed&quot; &quot;geek&quot; &quot;gees&quot; &quot;geez&quot; &quot;ghee&quot; &quot;gill&quot; &quot;glee&quot; &quot;good&quot; &quot;goof&quot; &quot;gook&quot;
## [141] &quot;goon&quot; &quot;goop&quot; &quot;goos&quot; &quot;gree&quot; &quot;guff&quot; &quot;gull&quot; &quot;haaf&quot; &quot;haar&quot; &quot;hajj&quot; &quot;hall&quot;
## [151] &quot;heed&quot; &quot;heel&quot; &quot;hell&quot; &quot;hill&quot; &quot;hiss&quot; &quot;hogg&quot; &quot;hood&quot; &quot;hoof&quot; &quot;hook&quot; &quot;hoop&quot;
## [161] &quot;hoot&quot; &quot;huff&quot; &quot;hull&quot; &quot;iffy&quot; &quot;iggs&quot; &quot;ills&quot; &quot;illy&quot; &quot;immy&quot; &quot;inns&quot; &quot;jagg&quot;
## [171] &quot;jazz&quot; &quot;jeed&quot; &quot;jeep&quot; &quot;jeer&quot; &quot;jees&quot; &quot;jeez&quot; &quot;jell&quot; &quot;jess&quot; &quot;jibb&quot; &quot;jiff&quot;
## [181] &quot;jill&quot; &quot;jinn&quot; &quot;joss&quot; &quot;kaas&quot; &quot;keef&quot; &quot;keek&quot; &quot;keel&quot; &quot;keen&quot; &quot;keep&quot; &quot;keet&quot;
## [191] &quot;kill&quot; &quot;kiss&quot; &quot;knee&quot; &quot;kook&quot; &quot;koss&quot; &quot;lall&quot; &quot;lass&quot; &quot;leek&quot; &quot;leer&quot; &quot;lees&quot;
## [201] &quot;leet&quot; &quot;less&quot; &quot;linn&quot; &quot;loll&quot; &quot;loof&quot; &quot;look&quot; &quot;loom&quot; &quot;loon&quot; &quot;loop&quot; &quot;loos&quot;
## [211] &quot;loot&quot; &quot;loss&quot; &quot;luff&quot; &quot;lull&quot; &quot;maar&quot; &quot;mall&quot; &quot;mass&quot; &quot;matt&quot; &quot;meed&quot; &quot;meek&quot;
## [221] &quot;meet&quot; &quot;mell&quot; &quot;mess&quot; &quot;miff&quot; &quot;migg&quot; &quot;mill&quot; &quot;miss&quot; &quot;mitt&quot; &quot;moll&quot; &quot;mood&quot;
## [231] &quot;mool&quot; &quot;moon&quot; &quot;moor&quot; &quot;moos&quot; &quot;moot&quot; &quot;moss&quot; &quot;mott&quot; &quot;muff&quot; &quot;mugg&quot; &quot;mull&quot;
## [241] &quot;mumm&quot; &quot;murr&quot; &quot;muss&quot; &quot;mutt&quot; &quot;naan&quot; &quot;naff&quot; &quot;need&quot; &quot;neem&quot; &quot;neep&quot; &quot;ness&quot;
## [251] &quot;nett&quot; &quot;nill&quot; &quot;nogg&quot; &quot;nook&quot; &quot;noon&quot; &quot;null&quot; &quot;odds&quot; &quot;offs&quot; &quot;ogee&quot; &quot;olla&quot;
## [261] &quot;oohs&quot; &quot;oops&quot; &quot;oots&quot; &quot;ooze&quot; &quot;oozy&quot; &quot;orra&quot; &quot;ossa&quot; &quot;otto&quot; &quot;pall&quot; &quot;parr&quot;
## [271] &quot;pass&quot; &quot;peed&quot; &quot;peek&quot; &quot;peel&quot; &quot;peen&quot; &quot;peep&quot; &quot;peer&quot; &quot;pees&quot; &quot;pfft&quot; &quot;pill&quot;
## [281] &quot;piss&quot; &quot;poll&quot; &quot;pood&quot; &quot;poof&quot; &quot;pooh&quot; &quot;pool&quot; &quot;poon&quot; &quot;poop&quot; &quot;poor&quot; &quot;poos&quot;
## [291] &quot;pree&quot; &quot;psst&quot; &quot;puff&quot; &quot;pull&quot; &quot;purr&quot; &quot;puss&quot; &quot;putt&quot; &quot;raff&quot; &quot;ragg&quot; &quot;razz&quot;
## [301] &quot;redd&quot; &quot;reed&quot; &quot;reef&quot; &quot;reek&quot; &quot;reel&quot; &quot;rees&quot; &quot;repp&quot; &quot;riff&quot; &quot;rill&quot; &quot;roll&quot;
## [311] &quot;rood&quot; &quot;roof&quot; &quot;rook&quot; &quot;room&quot; &quot;root&quot; &quot;rudd&quot; &quot;ruff&quot; &quot;sall&quot; &quot;sass&quot; &quot;seed&quot;
## [321] &quot;seek&quot; &quot;seel&quot; &quot;seem&quot; &quot;seen&quot; &quot;seep&quot; &quot;seer&quot; &quot;sees&quot; &quot;sell&quot; &quot;sett&quot; &quot;shoo&quot;
## [331] &quot;sibb&quot; &quot;sill&quot; &quot;skee&quot; &quot;sook&quot; &quot;soon&quot; &quot;soot&quot; &quot;sudd&quot; &quot;sunn&quot; &quot;suss&quot; &quot;tall&quot;
## [341] &quot;tass&quot; &quot;teed&quot; &quot;teel&quot; &quot;teem&quot; &quot;teen&quot; &quot;tees&quot; &quot;teff&quot; &quot;tegg&quot; &quot;tell&quot; &quot;thee&quot;
## [351] &quot;tiff&quot; &quot;till&quot; &quot;toff&quot; &quot;toll&quot; &quot;took&quot; &quot;tool&quot; &quot;toom&quot; &quot;toon&quot; &quot;toot&quot; &quot;torr&quot;
## [361] &quot;toss&quot; &quot;tree&quot; &quot;tuff&quot; &quot;twee&quot; &quot;tyee&quot; &quot;typp&quot; &quot;veep&quot; &quot;veer&quot; &quot;vees&quot; &quot;vill&quot;
## [371] &quot;vugg&quot; &quot;waff&quot; &quot;wall&quot; &quot;watt&quot; &quot;weed&quot; &quot;week&quot; &quot;weel&quot; &quot;ween&quot; &quot;weep&quot; &quot;weer&quot;
## [381] &quot;wees&quot; &quot;weet&quot; &quot;well&quot; &quot;whee&quot; &quot;will&quot; &quot;wiss&quot; &quot;wood&quot; &quot;woof&quot; &quot;wool&quot; &quot;woos&quot;
## [391] &quot;wuss&quot; &quot;wynn&quot; &quot;yaff&quot; &quot;yegg&quot; &quot;yell&quot; &quot;yett&quot; &quot;yill&quot; &quot;yirr&quot; &quot;zees&quot; &quot;zill&quot;
## [401] &quot;zoom&quot; &quot;zoon&quot; &quot;zoos&quot;</code></pre>
<pre class="r"><code>#letter one stored in register one followed by letter one called from register one</code></pre>
<p><strong>Question 2</strong></p>
<pre class="r"><code>grep(&quot;(.)(.)\\2\\1&quot;, words, value=TRUE)</code></pre>
<pre><code>##  [1] &quot;abba&quot; &quot;anna&quot; &quot;boob&quot; &quot;deed&quot; &quot;keek&quot; &quot;kook&quot; &quot;naan&quot; &quot;noon&quot; &quot;otto&quot; &quot;peep&quot;
## [11] &quot;poop&quot; &quot;sees&quot; &quot;toot&quot;</code></pre>
<pre class="r"><code>#letter one stored in register one, letter two stored in register two, letter two called from register two, letter one called from register one</code></pre>
<p><strong>GSUB:</strong></p>
<p><strong>Question 1</strong></p>
<pre class="r"><code>gsub(&quot;ll&quot;, &quot;l&quot;, words)</code></pre>
<pre><code>##    [1] &quot;aahs&quot; &quot;aals&quot; &quot;abas&quot; &quot;abba&quot; &quot;abbe&quot; &quot;abed&quot; &quot;abet&quot; &quot;able&quot; &quot;ably&quot; &quot;abos&quot;
##   [11] &quot;abri&quot; &quot;abut&quot; &quot;abye&quot; &quot;abys&quot; &quot;aced&quot; &quot;aces&quot; &quot;ache&quot; &quot;achy&quot; &quot;acid&quot; &quot;acme&quot;
##   [21] &quot;acne&quot; &quot;acre&quot; &quot;acta&quot; &quot;acts&quot; &quot;acyl&quot; &quot;adds&quot; &quot;adit&quot; &quot;ados&quot; &quot;adze&quot; &quot;aeon&quot;
##   [31] &quot;aero&quot; &quot;aery&quot; &quot;afar&quot; &quot;agar&quot; &quot;agas&quot; &quot;aged&quot; &quot;agee&quot; &quot;ager&quot; &quot;ages&quot; &quot;agha&quot;
##   [41] &quot;agin&quot; &quot;agio&quot; &quot;agly&quot; &quot;agma&quot; &quot;agog&quot; &quot;agon&quot; &quot;ague&quot; &quot;ahed&quot; &quot;ahem&quot; &quot;ahis&quot;
##   [51] &quot;ahoy&quot; &quot;aide&quot; &quot;aids&quot; &quot;ails&quot; &quot;aims&quot; &quot;ains&quot; &quot;airn&quot; &quot;airs&quot; &quot;airt&quot; &quot;airy&quot;
##   [61] &quot;aits&quot; &quot;ajar&quot; &quot;ajee&quot; &quot;akee&quot; &quot;akin&quot; &quot;alae&quot; &quot;alan&quot; &quot;alar&quot; &quot;alas&quot; &quot;alba&quot;
##   [71] &quot;albs&quot; &quot;alec&quot; &quot;alee&quot; &quot;alef&quot; &quot;ales&quot; &quot;alfa&quot; &quot;alga&quot; &quot;alif&quot; &quot;alit&quot; &quot;alky&quot;
##   [81] &quot;als&quot;  &quot;aly&quot;  &quot;alma&quot; &quot;alme&quot; &quot;alms&quot; &quot;aloe&quot; &quot;alow&quot; &quot;alps&quot; &quot;also&quot; &quot;alto&quot;
##   [91] &quot;alts&quot; &quot;alum&quot; &quot;amah&quot; &quot;amas&quot; &quot;ambo&quot; &quot;amen&quot; &quot;amia&quot; &quot;amid&quot; &quot;amie&quot; &quot;amin&quot;
##  [101] &quot;amir&quot; &quot;amis&quot; &quot;ammo&quot; &quot;amok&quot; &quot;amps&quot; &quot;amus&quot; &quot;amyl&quot; &quot;anal&quot; &quot;anas&quot; &quot;ands&quot;
##  [111] &quot;anes&quot; &quot;anew&quot; &quot;anga&quot; &quot;anil&quot; &quot;anis&quot; &quot;ankh&quot; &quot;anna&quot; &quot;anoa&quot; &quot;anon&quot; &quot;ansa&quot;
##  [121] &quot;anta&quot; &quot;ante&quot; &quot;anti&quot; &quot;ants&quot; &quot;anus&quot; &quot;aped&quot; &quot;aper&quot; &quot;apes&quot; &quot;apex&quot; &quot;apod&quot;
##  [131] &quot;apos&quot; &quot;apps&quot; &quot;apse&quot; &quot;aqua&quot; &quot;arak&quot; &quot;arbs&quot; &quot;arch&quot; &quot;arco&quot; &quot;arcs&quot; &quot;area&quot;
##  [141] &quot;ares&quot; &quot;arfs&quot; &quot;aria&quot; &quot;arid&quot; &quot;aril&quot; &quot;arks&quot; &quot;arms&quot; &quot;army&quot; &quot;arse&quot; &quot;arts&quot;
##  [151] &quot;arty&quot; &quot;arum&quot; &quot;arvo&quot; &quot;aryl&quot; &quot;asci&quot; &quot;asea&quot; &quot;ashy&quot; &quot;asks&quot; &quot;asps&quot; &quot;atap&quot;
##  [161] &quot;ates&quot; &quot;atma&quot; &quot;atom&quot; &quot;atop&quot; &quot;auks&quot; &quot;auld&quot; &quot;aunt&quot; &quot;aura&quot; &quot;auto&quot; &quot;aver&quot;
##  [171] &quot;aves&quot; &quot;avid&quot; &quot;avos&quot; &quot;avow&quot; &quot;away&quot; &quot;awed&quot; &quot;awee&quot; &quot;awes&quot; &quot;awls&quot; &quot;awns&quot;
##  [181] &quot;awny&quot; &quot;awol&quot; &quot;awry&quot; &quot;axal&quot; &quot;axed&quot; &quot;axel&quot; &quot;axes&quot; &quot;axil&quot; &quot;axis&quot; &quot;axle&quot;
##  [191] &quot;axon&quot; &quot;ayah&quot; &quot;ayes&quot; &quot;ayin&quot; &quot;azan&quot; &quot;azon&quot; &quot;baal&quot; &quot;baas&quot; &quot;baba&quot; &quot;babe&quot;
##  [201] &quot;babu&quot; &quot;baby&quot; &quot;bach&quot; &quot;back&quot; &quot;bade&quot; &quot;bads&quot; &quot;baff&quot; &quot;bags&quot; &quot;baht&quot; &quot;bail&quot;
##  [211] &quot;bait&quot; &quot;bake&quot; &quot;bald&quot; &quot;bale&quot; &quot;balk&quot; &quot;bal&quot;  &quot;balm&quot; &quot;bals&quot; &quot;bams&quot; &quot;band&quot;
##  [221] &quot;bane&quot; &quot;bang&quot; &quot;bani&quot; &quot;bank&quot; &quot;bans&quot; &quot;baps&quot; &quot;barb&quot; &quot;bard&quot; &quot;bare&quot; &quot;barf&quot;
##  [231] &quot;bark&quot; &quot;barm&quot; &quot;barn&quot; &quot;bars&quot; &quot;base&quot; &quot;bash&quot; &quot;bask&quot; &quot;bass&quot; &quot;bast&quot; &quot;bate&quot;
##  [241] &quot;bath&quot; &quot;bats&quot; &quot;batt&quot; &quot;baud&quot; &quot;bawd&quot; &quot;bawl&quot; &quot;bays&quot; &quot;bead&quot; &quot;beak&quot; &quot;beam&quot;
##  [251] &quot;bean&quot; &quot;bear&quot; &quot;beat&quot; &quot;beau&quot; &quot;beck&quot; &quot;beds&quot; &quot;bedu&quot; &quot;beef&quot; &quot;been&quot; &quot;beep&quot;
##  [261] &quot;beer&quot; &quot;bees&quot; &quot;beet&quot; &quot;begs&quot; &quot;bel&quot;  &quot;bels&quot; &quot;belt&quot; &quot;bema&quot; &quot;bend&quot; &quot;bene&quot;
##  [271] &quot;bens&quot; &quot;bent&quot; &quot;berg&quot; &quot;berk&quot; &quot;berm&quot; &quot;best&quot; &quot;beta&quot; &quot;beth&quot; &quot;bets&quot; &quot;bevy&quot;
##  [281] &quot;beys&quot; &quot;bhut&quot; &quot;bias&quot; &quot;bibb&quot; &quot;bibs&quot; &quot;bice&quot; &quot;bide&quot; &quot;bidi&quot; &quot;bids&quot; &quot;bier&quot;
##  [291] &quot;biff&quot; &quot;bigs&quot; &quot;bike&quot; &quot;bile&quot; &quot;bilk&quot; &quot;bil&quot;  &quot;bima&quot; &quot;bind&quot; &quot;bine&quot; &quot;bins&quot;
##  [301] &quot;bint&quot; &quot;biog&quot; &quot;bios&quot; &quot;bird&quot; &quot;birk&quot; &quot;birl&quot; &quot;biro&quot; &quot;birr&quot; &quot;bise&quot; &quot;bisk&quot;
##  [311] &quot;bite&quot; &quot;bits&quot; &quot;bitt&quot; &quot;bize&quot; &quot;blab&quot; &quot;blae&quot; &quot;blah&quot; &quot;blam&quot; &quot;blat&quot; &quot;blaw&quot;
##  [321] &quot;bleb&quot; &quot;bled&quot; &quot;blet&quot; &quot;blew&quot; &quot;blin&quot; &quot;blip&quot; &quot;blob&quot; &quot;bloc&quot; &quot;blog&quot; &quot;blot&quot;
##  [331] &quot;blow&quot; &quot;blub&quot; &quot;blue&quot; &quot;blur&quot; &quot;boar&quot; &quot;boas&quot; &quot;boat&quot; &quot;bobs&quot; &quot;bock&quot; &quot;bode&quot;
##  [341] &quot;bods&quot; &quot;body&quot; &quot;boff&quot; &quot;bogs&quot; &quot;bogy&quot; &quot;boho&quot; &quot;boil&quot; &quot;bola&quot; &quot;bold&quot; &quot;bole&quot;
##  [351] &quot;bol&quot;  &quot;bolo&quot; &quot;bolt&quot; &quot;bomb&quot; &quot;bond&quot; &quot;bone&quot; &quot;bong&quot; &quot;bonk&quot; &quot;bony&quot; &quot;boob&quot;
##  [361] &quot;book&quot; &quot;boom&quot; &quot;boon&quot; &quot;boor&quot; &quot;boos&quot; &quot;boot&quot; &quot;bops&quot; &quot;bora&quot; &quot;bore&quot; &quot;bork&quot;
##  [371] &quot;born&quot; &quot;bort&quot; &quot;bosh&quot; &quot;bosk&quot; &quot;boss&quot; &quot;bota&quot; &quot;both&quot; &quot;bots&quot; &quot;bott&quot; &quot;bout&quot;
##  [381] &quot;bowl&quot; &quot;bows&quot; &quot;boxy&quot; &quot;boyo&quot; &quot;boys&quot; &quot;bozo&quot; &quot;brad&quot; &quot;brae&quot; &quot;brag&quot; &quot;bran&quot;
##  [391] &quot;bras&quot; &quot;brat&quot; &quot;braw&quot; &quot;bray&quot; &quot;bred&quot; &quot;bree&quot; &quot;bren&quot; &quot;brew&quot; &quot;brie&quot; &quot;brig&quot;
##  [401] &quot;brim&quot; &quot;brin&quot; &quot;brio&quot; &quot;bris&quot; &quot;brit&quot; &quot;broo&quot; &quot;bros&quot; &quot;brow&quot; &quot;brrr&quot; &quot;brut&quot;
##  [411] &quot;brux&quot; &quot;bubo&quot; &quot;bubs&quot; &quot;bubu&quot; &quot;buck&quot; &quot;buds&quot; &quot;buff&quot; &quot;bugs&quot; &quot;buhl&quot; &quot;buhr&quot;
##  [421] &quot;bulb&quot; &quot;bulk&quot; &quot;bul&quot;  &quot;bumf&quot; &quot;bump&quot; &quot;bums&quot; &quot;buna&quot; &quot;bund&quot; &quot;bung&quot; &quot;bunk&quot;
##  [431] &quot;bunn&quot; &quot;buns&quot; &quot;bunt&quot; &quot;buoy&quot; &quot;bura&quot; &quot;burb&quot; &quot;burd&quot; &quot;burg&quot; &quot;burl&quot; &quot;burn&quot;
##  [441] &quot;burp&quot; &quot;burr&quot; &quot;burs&quot; &quot;bury&quot; &quot;bush&quot; &quot;busk&quot; &quot;buss&quot; &quot;bust&quot; &quot;busy&quot; &quot;bute&quot;
##  [451] &quot;buts&quot; &quot;butt&quot; &quot;buys&quot; &quot;buzz&quot; &quot;byes&quot; &quot;byre&quot; &quot;byrl&quot; &quot;byte&quot; &quot;cabs&quot; &quot;caca&quot;
##  [461] &quot;cade&quot; &quot;cadi&quot; &quot;cads&quot; &quot;cafe&quot; &quot;caff&quot; &quot;cage&quot; &quot;cagy&quot; &quot;caid&quot; &quot;cain&quot; &quot;cake&quot;
##  [471] &quot;caky&quot; &quot;calf&quot; &quot;calk&quot; &quot;cal&quot;  &quot;calm&quot; &quot;calo&quot; &quot;calx&quot; &quot;came&quot; &quot;camo&quot; &quot;camp&quot;
##  [481] &quot;cams&quot; &quot;cane&quot; &quot;cans&quot; &quot;cant&quot; &quot;cape&quot; &quot;caph&quot; &quot;capo&quot; &quot;caps&quot; &quot;carb&quot; &quot;card&quot;
##  [491] &quot;care&quot; &quot;cark&quot; &quot;carl&quot; &quot;carn&quot; &quot;carp&quot; &quot;carr&quot; &quot;cars&quot; &quot;cart&quot; &quot;casa&quot; &quot;case&quot;
##  [501] &quot;cash&quot; &quot;cask&quot; &quot;cast&quot; &quot;cate&quot; &quot;cats&quot; &quot;caul&quot; &quot;cave&quot; &quot;cavy&quot; &quot;caws&quot; &quot;cays&quot;
##  [511] &quot;ceca&quot; &quot;cede&quot; &quot;cedi&quot; &quot;cees&quot; &quot;ceil&quot; &quot;cel&quot;  &quot;cels&quot; &quot;celt&quot; &quot;cent&quot; &quot;cepe&quot;
##  [521] &quot;ceps&quot; &quot;cere&quot; &quot;cero&quot; &quot;cess&quot; &quot;cete&quot; &quot;chad&quot; &quot;chai&quot; &quot;cham&quot; &quot;chao&quot; &quot;chap&quot;
##  [531] &quot;char&quot; &quot;chat&quot; &quot;chaw&quot; &quot;chay&quot; &quot;chef&quot; &quot;chew&quot; &quot;chez&quot; &quot;chia&quot; &quot;chic&quot; &quot;chid&quot;
##  [541] &quot;chin&quot; &quot;chip&quot; &quot;chis&quot; &quot;chit&quot; &quot;chon&quot; &quot;chop&quot; &quot;chow&quot; &quot;chub&quot; &quot;chug&quot; &quot;chum&quot;
##  [551] &quot;ciao&quot; &quot;cigs&quot; &quot;cine&quot; &quot;cion&quot; &quot;cire&quot; &quot;cist&quot; &quot;cite&quot; &quot;city&quot; &quot;clad&quot; &quot;clag&quot;
##  [561] &quot;clam&quot; &quot;clan&quot; &quot;clap&quot; &quot;claw&quot; &quot;clay&quot; &quot;clef&quot; &quot;clew&quot; &quot;clip&quot; &quot;clod&quot; &quot;clog&quot;
##  [571] &quot;clon&quot; &quot;clop&quot; &quot;clot&quot; &quot;cloy&quot; &quot;club&quot; &quot;clue&quot; &quot;coal&quot; &quot;coat&quot; &quot;coax&quot; &quot;cobb&quot;
##  [581] &quot;cobs&quot; &quot;coca&quot; &quot;cock&quot; &quot;coco&quot; &quot;coda&quot; &quot;code&quot; &quot;cods&quot; &quot;coed&quot; &quot;coff&quot; &quot;coft&quot;
##  [591] &quot;cogs&quot; &quot;coho&quot; &quot;coif&quot; &quot;coil&quot; &quot;coin&quot; &quot;coir&quot; &quot;coke&quot; &quot;coky&quot; &quot;cola&quot; &quot;cold&quot;
##  [601] &quot;cole&quot; &quot;cols&quot; &quot;colt&quot; &quot;coly&quot; &quot;coma&quot; &quot;comb&quot; &quot;come&quot; &quot;comp&quot; &quot;cone&quot; &quot;coni&quot;
##  [611] &quot;conk&quot; &quot;conn&quot; &quot;cons&quot; &quot;cony&quot; &quot;coof&quot; &quot;cook&quot; &quot;cool&quot; &quot;coon&quot; &quot;coop&quot; &quot;coos&quot;
##  [621] &quot;coot&quot; &quot;cope&quot; &quot;cops&quot; &quot;copy&quot; &quot;cord&quot; &quot;core&quot; &quot;corf&quot; &quot;cork&quot; &quot;corm&quot; &quot;corn&quot;
##  [631] &quot;cors&quot; &quot;cory&quot; &quot;cosh&quot; &quot;coss&quot; &quot;cost&quot; &quot;cosy&quot; &quot;cote&quot; &quot;cots&quot; &quot;coup&quot; &quot;cove&quot;
##  [641] &quot;cowl&quot; &quot;cows&quot; &quot;cowy&quot; &quot;coxa&quot; &quot;coys&quot; &quot;cozy&quot; &quot;crab&quot; &quot;crag&quot; &quot;cram&quot; &quot;crap&quot;
##  [651] &quot;craw&quot; &quot;cred&quot; &quot;crew&quot; &quot;crib&quot; &quot;cris&quot; &quot;crit&quot; &quot;croc&quot; &quot;crop&quot; &quot;crow&quot; &quot;crud&quot;
##  [661] &quot;crus&quot; &quot;crux&quot; &quot;cube&quot; &quot;cubs&quot; &quot;cuds&quot; &quot;cued&quot; &quot;cues&quot; &quot;cuff&quot; &quot;cuif&quot; &quot;cuke&quot;
##  [671] &quot;cul&quot;  &quot;culm&quot; &quot;cult&quot; &quot;cunt&quot; &quot;cups&quot; &quot;curb&quot; &quot;curd&quot; &quot;cure&quot; &quot;curf&quot; &quot;curl&quot;
##  [681] &quot;curn&quot; &quot;curr&quot; &quot;curs&quot; &quot;curt&quot; &quot;cusk&quot; &quot;cusp&quot; &quot;cuss&quot; &quot;cute&quot; &quot;cuts&quot; &quot;cwms&quot;
##  [691] &quot;cyan&quot; &quot;cyma&quot; &quot;cyme&quot; &quot;cyst&quot; &quot;czar&quot; &quot;dabs&quot; &quot;dace&quot; &quot;dada&quot; &quot;dado&quot; &quot;dads&quot;
##  [701] &quot;daff&quot; &quot;daft&quot; &quot;dago&quot; &quot;dags&quot; &quot;dahl&quot; &quot;dahs&quot; &quot;dais&quot; &quot;daks&quot; &quot;dale&quot; &quot;dals&quot;
##  [711] &quot;dame&quot; &quot;damn&quot; &quot;damp&quot; &quot;dams&quot; &quot;dang&quot; &quot;dank&quot; &quot;dans&quot; &quot;daps&quot; &quot;darb&quot; &quot;dare&quot;
##  [721] &quot;dark&quot; &quot;darn&quot; &quot;dart&quot; &quot;dash&quot; &quot;data&quot; &quot;date&quot; &quot;dato&quot; &quot;daub&quot; &quot;daut&quot; &quot;davy&quot;
##  [731] &quot;dawk&quot; &quot;dawn&quot; &quot;daws&quot; &quot;dawt&quot; &quot;days&quot; &quot;daze&quot; &quot;dead&quot; &quot;deaf&quot; &quot;deal&quot; &quot;dean&quot;
##  [741] &quot;dear&quot; &quot;debs&quot; &quot;debt&quot; &quot;deck&quot; &quot;deco&quot; &quot;deed&quot; &quot;deem&quot; &quot;deep&quot; &quot;deer&quot; &quot;dees&quot;
##  [751] &quot;deet&quot; &quot;defi&quot; &quot;deft&quot; &quot;defy&quot; &quot;deil&quot; &quot;deke&quot; &quot;dele&quot; &quot;delf&quot; &quot;deli&quot; &quot;del&quot; 
##  [761] &quot;dels&quot; &quot;delt&quot; &quot;deme&quot; &quot;demo&quot; &quot;demy&quot; &quot;dene&quot; &quot;deni&quot; &quot;dens&quot; &quot;dent&quot; &quot;deny&quot;
##  [771] &quot;dere&quot; &quot;derm&quot; &quot;desk&quot; &quot;deva&quot; &quot;devs&quot; &quot;dews&quot; &quot;dewy&quot; &quot;dexy&quot; &quot;deys&quot; &quot;dhak&quot;
##  [781] &quot;dhal&quot; &quot;dhow&quot; &quot;dial&quot; &quot;dibs&quot; &quot;dice&quot; &quot;dick&quot; &quot;dido&quot; &quot;didy&quot; &quot;died&quot; &quot;diel&quot;
##  [791] &quot;dies&quot; &quot;diet&quot; &quot;diff&quot; &quot;difs&quot; &quot;digs&quot; &quot;dike&quot; &quot;dil&quot;  &quot;dime&quot; &quot;dims&quot; &quot;dine&quot;
##  [801] &quot;ding&quot; &quot;dink&quot; &quot;dino&quot; &quot;dins&quot; &quot;dint&quot; &quot;diol&quot; &quot;dips&quot; &quot;dipt&quot; &quot;dire&quot; &quot;dirk&quot;
##  [811] &quot;dirl&quot; &quot;dirt&quot; &quot;disc&quot; &quot;dish&quot; &quot;disk&quot; &quot;diss&quot; &quot;dita&quot; &quot;dite&quot; &quot;dits&quot; &quot;ditz&quot;
##  [821] &quot;diva&quot; &quot;dive&quot; &quot;djin&quot; &quot;doat&quot; &quot;doby&quot; &quot;dock&quot; &quot;docs&quot; &quot;dodo&quot; &quot;doer&quot; &quot;does&quot;
##  [831] &quot;doff&quot; &quot;doge&quot; &quot;dogs&quot; &quot;dogy&quot; &quot;doit&quot; &quot;dojo&quot; &quot;dole&quot; &quot;dol&quot;  &quot;dols&quot; &quot;dolt&quot;
##  [841] &quot;dome&quot; &quot;doms&quot; &quot;dona&quot; &quot;done&quot; &quot;dong&quot; &quot;dons&quot; &quot;doom&quot; &quot;door&quot; &quot;dopa&quot; &quot;dope&quot;
##  [851] &quot;dopy&quot; &quot;dore&quot; &quot;dork&quot; &quot;dorm&quot; &quot;dorp&quot; &quot;dorr&quot; &quot;dors&quot; &quot;dory&quot; &quot;dose&quot; &quot;doss&quot;
##  [861] &quot;dost&quot; &quot;dote&quot; &quot;doth&quot; &quot;dots&quot; &quot;doty&quot; &quot;doum&quot; &quot;dour&quot; &quot;doux&quot; &quot;dove&quot; &quot;down&quot;
##  [871] &quot;dows&quot; &quot;doxy&quot; &quot;doze&quot; &quot;dozy&quot; &quot;drab&quot; &quot;drag&quot; &quot;dram&quot; &quot;drat&quot; &quot;draw&quot; &quot;dray&quot;
##  [881] &quot;dree&quot; &quot;dreg&quot; &quot;drek&quot; &quot;drew&quot; &quot;drib&quot; &quot;drip&quot; &quot;drop&quot; &quot;drub&quot; &quot;drug&quot; &quot;drum&quot;
##  [891] &quot;drys&quot; &quot;duad&quot; &quot;dual&quot; &quot;dubs&quot; &quot;duce&quot; &quot;duci&quot; &quot;duck&quot; &quot;duct&quot; &quot;dude&quot; &quot;duds&quot;
##  [901] &quot;duel&quot; &quot;dues&quot; &quot;duet&quot; &quot;duff&quot; &quot;dugs&quot; &quot;duit&quot; &quot;duke&quot; &quot;dul&quot;  &quot;duly&quot; &quot;duma&quot;
##  [911] &quot;dumb&quot; &quot;dump&quot; &quot;dune&quot; &quot;dung&quot; &quot;dunk&quot; &quot;duns&quot; &quot;dunt&quot; &quot;duos&quot; &quot;dupe&quot; &quot;dups&quot;
##  [921] &quot;dura&quot; &quot;dure&quot; &quot;durn&quot; &quot;duro&quot; &quot;durr&quot; &quot;dusk&quot; &quot;dust&quot; &quot;duty&quot; &quot;dyad&quot; &quot;dyed&quot;
##  [931] &quot;dyer&quot; &quot;dyes&quot; &quot;dyke&quot; &quot;dyne&quot; &quot;each&quot; &quot;earl&quot; &quot;earn&quot; &quot;ears&quot; &quot;ease&quot; &quot;east&quot;
##  [941] &quot;easy&quot; &quot;eath&quot; &quot;eats&quot; &quot;eaux&quot; &quot;eave&quot; &quot;ebbs&quot; &quot;ebon&quot; &quot;eche&quot; &quot;echo&quot; &quot;echt&quot;
##  [951] &quot;ecru&quot; &quot;ecus&quot; &quot;eddo&quot; &quot;eddy&quot; &quot;edge&quot; &quot;edgy&quot; &quot;edhs&quot; &quot;edit&quot; &quot;eels&quot; &quot;eely&quot;
##  [961] &quot;eery&quot; &quot;effs&quot; &quot;efts&quot; &quot;egad&quot; &quot;egal&quot; &quot;eger&quot; &quot;eggs&quot; &quot;eggy&quot; &quot;egis&quot; &quot;egos&quot;
##  [971] &quot;eide&quot; &quot;eked&quot; &quot;ekes&quot; &quot;elan&quot; &quot;elds&quot; &quot;elhi&quot; &quot;elks&quot; &quot;els&quot;  &quot;elms&quot; &quot;elmy&quot;
##  [981] &quot;else&quot; &quot;emes&quot; &quot;emeu&quot; &quot;emic&quot; &quot;emir&quot; &quot;emit&quot; &quot;emmy&quot; &quot;emus&quot; &quot;emyd&quot; &quot;ends&quot;
##  [991] &quot;engs&quot; &quot;enol&quot; &quot;enow&quot; &quot;enuf&quot; &quot;envy&quot; &quot;eons&quot; &quot;epee&quot; &quot;epha&quot; &quot;epic&quot; &quot;epos&quot;
## [1001] &quot;eras&quot; &quot;ergo&quot; &quot;ergs&quot; &quot;erne&quot; &quot;erns&quot; &quot;eros&quot; &quot;errs&quot; &quot;erst&quot; &quot;eses&quot; &quot;esne&quot;
## [1011] &quot;espy&quot; &quot;etas&quot; &quot;etch&quot; &quot;eths&quot; &quot;etic&quot; &quot;etna&quot; &quot;etui&quot; &quot;euro&quot; &quot;even&quot; &quot;ever&quot;
## [1021] &quot;eves&quot; &quot;evil&quot; &quot;ewer&quot; &quot;ewes&quot; &quot;exam&quot; &quot;exec&quot; &quot;exed&quot; &quot;exes&quot; &quot;exit&quot; &quot;exon&quot;
## [1031] &quot;expo&quot; &quot;eyas&quot; &quot;eyed&quot; &quot;eyen&quot; &quot;eyer&quot; &quot;eyes&quot; &quot;eyne&quot; &quot;eyra&quot; &quot;eyre&quot; &quot;eyry&quot;
## [1041] &quot;fabs&quot; &quot;face&quot; &quot;fact&quot; &quot;fade&quot; &quot;fado&quot; &quot;fads&quot; &quot;fags&quot; &quot;fail&quot; &quot;fain&quot; &quot;fair&quot;
## [1051] &quot;fake&quot; &quot;fal&quot;  &quot;falx&quot; &quot;fame&quot; &quot;fane&quot; &quot;fang&quot; &quot;fano&quot; &quot;fans&quot; &quot;fard&quot; &quot;fare&quot;
## [1061] &quot;farl&quot; &quot;farm&quot; &quot;faro&quot; &quot;fart&quot; &quot;fash&quot; &quot;fast&quot; &quot;fate&quot; &quot;fats&quot; &quot;faun&quot; &quot;faux&quot;
## [1071] &quot;fava&quot; &quot;fave&quot; &quot;fawn&quot; &quot;fays&quot; &quot;faze&quot; &quot;feal&quot; &quot;fear&quot; &quot;feat&quot; &quot;feck&quot; &quot;feds&quot;
## [1081] &quot;feeb&quot; &quot;feed&quot; &quot;feel&quot; &quot;fees&quot; &quot;feet&quot; &quot;fehs&quot; &quot;fel&quot;  &quot;felt&quot; &quot;feme&quot; &quot;fems&quot;
## [1091] &quot;fend&quot; &quot;fens&quot; &quot;feod&quot; &quot;fere&quot; &quot;fern&quot; &quot;fess&quot; &quot;fest&quot; &quot;feta&quot; &quot;fete&quot; &quot;fets&quot;
## [1101] &quot;feud&quot; &quot;feus&quot; &quot;fiar&quot; &quot;fiat&quot; &quot;fibs&quot; &quot;fice&quot; &quot;fico&quot; &quot;fido&quot; &quot;fids&quot; &quot;fief&quot;
## [1111] &quot;fife&quot; &quot;figs&quot; &quot;fila&quot; &quot;file&quot; &quot;fil&quot;  &quot;film&quot; &quot;filo&quot; &quot;fils&quot; &quot;find&quot; &quot;fine&quot;
## [1121] &quot;fink&quot; &quot;fino&quot; &quot;fins&quot; &quot;fire&quot; &quot;firm&quot; &quot;firn&quot; &quot;firs&quot; &quot;fisc&quot; &quot;fish&quot; &quot;fist&quot;
## [1131] &quot;fits&quot; &quot;five&quot; &quot;fixt&quot; &quot;fizz&quot; &quot;flab&quot; &quot;flag&quot; &quot;flak&quot; &quot;flam&quot; &quot;flan&quot; &quot;flap&quot;
## [1141] &quot;flat&quot; &quot;flaw&quot; &quot;flax&quot; &quot;flay&quot; &quot;flea&quot; &quot;fled&quot; &quot;flee&quot; &quot;flew&quot; &quot;flex&quot; &quot;fley&quot;
## [1151] &quot;flic&quot; &quot;flip&quot; &quot;flir&quot; &quot;flit&quot; &quot;floc&quot; &quot;floe&quot; &quot;flog&quot; &quot;flop&quot; &quot;flow&quot; &quot;flub&quot;
## [1161] &quot;flue&quot; &quot;flus&quot; &quot;flux&quot; &quot;foal&quot; &quot;foam&quot; &quot;fobs&quot; &quot;foci&quot; &quot;foes&quot; &quot;fogs&quot; &quot;fogy&quot;
## [1171] &quot;fohn&quot; &quot;foil&quot; &quot;foin&quot; &quot;fold&quot; &quot;folk&quot; &quot;fond&quot; &quot;fons&quot; &quot;font&quot; &quot;food&quot; &quot;fool&quot;
## [1181] &quot;foot&quot; &quot;fops&quot; &quot;fora&quot; &quot;forb&quot; &quot;ford&quot; &quot;fore&quot; &quot;fork&quot; &quot;form&quot; &quot;fort&quot; &quot;foss&quot;
## [1191] &quot;foul&quot; &quot;four&quot; &quot;fowl&quot; &quot;foxy&quot; &quot;foys&quot; &quot;fozy&quot; &quot;frae&quot; &quot;frag&quot; &quot;frap&quot; &quot;frat&quot;
## [1201] &quot;fray&quot; &quot;free&quot; &quot;fret&quot; &quot;frig&quot; &quot;frit&quot; &quot;friz&quot; &quot;froe&quot; &quot;frog&quot; &quot;from&quot; &quot;frow&quot;
## [1211] &quot;frug&quot; &quot;fubs&quot; &quot;fuci&quot; &quot;fuck&quot; &quot;fuds&quot; &quot;fuel&quot; &quot;fugs&quot; &quot;fugu&quot; &quot;fuji&quot; &quot;ful&quot; 
## [1221] &quot;fume&quot; &quot;fumy&quot; &quot;fund&quot; &quot;funk&quot; &quot;funs&quot; &quot;furl&quot; &quot;furs&quot; &quot;fury&quot; &quot;fuse&quot; &quot;fuss&quot;
## [1231] &quot;futz&quot; &quot;fuze&quot; &quot;fuzz&quot; &quot;fyce&quot; &quot;fyke&quot; &quot;gabs&quot; &quot;gaby&quot; &quot;gadi&quot; &quot;gads&quot; &quot;gaed&quot;
## [1241] &quot;gaen&quot; &quot;gaes&quot; &quot;gaff&quot; &quot;gaga&quot; &quot;gage&quot; &quot;gags&quot; &quot;gain&quot; &quot;gait&quot; &quot;gala&quot; &quot;gale&quot;
## [1251] &quot;gal&quot;  &quot;gals&quot; &quot;gama&quot; &quot;gamb&quot; &quot;game&quot; &quot;gamp&quot; &quot;gams&quot; &quot;gamy&quot; &quot;gane&quot; &quot;gang&quot;
## [1261] &quot;gaol&quot; &quot;gape&quot; &quot;gaps&quot; &quot;gapy&quot; &quot;garb&quot; &quot;gars&quot; &quot;gash&quot; &quot;gasp&quot; &quot;gast&quot; &quot;gate&quot;
## [1271] &quot;gats&quot; &quot;gaud&quot; &quot;gaum&quot; &quot;gaun&quot; &quot;gaur&quot; &quot;gave&quot; &quot;gawk&quot; &quot;gawp&quot; &quot;gays&quot; &quot;gaze&quot;
## [1281] &quot;gear&quot; &quot;geck&quot; &quot;geds&quot; &quot;geed&quot; &quot;geek&quot; &quot;gees&quot; &quot;geez&quot; &quot;geld&quot; &quot;gels&quot; &quot;gelt&quot;
## [1291] &quot;gems&quot; &quot;gene&quot; &quot;gens&quot; &quot;gent&quot; &quot;genu&quot; &quot;germ&quot; &quot;gest&quot; &quot;geta&quot; &quot;gets&quot; &quot;geum&quot;
## [1301] &quot;ghat&quot; &quot;ghee&quot; &quot;ghis&quot; &quot;gibe&quot; &quot;gibs&quot; &quot;gids&quot; &quot;gied&quot; &quot;gien&quot; &quot;gies&quot; &quot;gift&quot;
## [1311] &quot;giga&quot; &quot;gigs&quot; &quot;gild&quot; &quot;gil&quot;  &quot;gilt&quot; &quot;gimp&quot; &quot;gink&quot; &quot;gins&quot; &quot;gips&quot; &quot;gird&quot;
## [1321] &quot;girl&quot; &quot;girn&quot; &quot;giro&quot; &quot;girt&quot; &quot;gist&quot; &quot;gite&quot; &quot;gits&quot; &quot;give&quot; &quot;glad&quot; &quot;glam&quot;
## [1331] &quot;gled&quot; &quot;glee&quot; &quot;gleg&quot; &quot;glen&quot; &quot;gley&quot; &quot;glia&quot; &quot;glib&quot; &quot;glim&quot; &quot;glob&quot; &quot;glom&quot;
## [1341] &quot;glop&quot; &quot;glow&quot; &quot;glue&quot; &quot;glug&quot; &quot;glum&quot; &quot;glut&quot; &quot;gnar&quot; &quot;gnat&quot; &quot;gnaw&quot; &quot;gnus&quot;
## [1351] &quot;goad&quot; &quot;goal&quot; &quot;goas&quot; &quot;goat&quot; &quot;gobo&quot; &quot;gobs&quot; &quot;goby&quot; &quot;gods&quot; &quot;goer&quot; &quot;goes&quot;
## [1361] &quot;gogo&quot; &quot;gold&quot; &quot;golf&quot; &quot;gone&quot; &quot;gong&quot; &quot;good&quot; &quot;goof&quot; &quot;gook&quot; &quot;goon&quot; &quot;goop&quot;
## [1371] &quot;goos&quot; &quot;gore&quot; &quot;gorm&quot; &quot;gorp&quot; &quot;gory&quot; &quot;gosh&quot; &quot;goth&quot; &quot;gout&quot; &quot;gowd&quot; &quot;gowk&quot;
## [1381] &quot;gown&quot; &quot;goys&quot; &quot;grab&quot; &quot;grad&quot; &quot;gram&quot; &quot;gran&quot; &quot;grat&quot; &quot;gray&quot; &quot;gree&quot; &quot;grew&quot;
## [1391] &quot;grey&quot; &quot;grid&quot; &quot;grig&quot; &quot;grim&quot; &quot;grin&quot; &quot;grip&quot; &quot;grit&quot; &quot;grog&quot; &quot;grok&quot; &quot;grot&quot;
## [1401] &quot;grow&quot; &quot;grub&quot; &quot;grue&quot; &quot;grum&quot; &quot;guan&quot; &quot;guar&quot; &quot;guck&quot; &quot;gude&quot; &quot;guff&quot; &quot;guid&quot;
## [1411] &quot;gulf&quot; &quot;gul&quot;  &quot;gulp&quot; &quot;guls&quot; &quot;gums&quot; &quot;gunk&quot; &quot;guns&quot; &quot;guru&quot; &quot;gush&quot; &quot;gust&quot;
## [1421] &quot;guts&quot; &quot;guvs&quot; &quot;guys&quot; &quot;gybe&quot; &quot;gyms&quot; &quot;gyps&quot; &quot;gyre&quot; &quot;gyri&quot; &quot;gyro&quot; &quot;gyve&quot;
## [1431] &quot;haaf&quot; &quot;haar&quot; &quot;habu&quot; &quot;hack&quot; &quot;hade&quot; &quot;hadj&quot; &quot;haed&quot; &quot;haem&quot; &quot;haen&quot; &quot;haes&quot;
## [1441] &quot;haet&quot; &quot;haft&quot; &quot;hags&quot; &quot;haha&quot; &quot;hahs&quot; &quot;haik&quot; &quot;hail&quot; &quot;hair&quot; &quot;haji&quot; &quot;hajj&quot;
## [1451] &quot;hake&quot; &quot;haku&quot; &quot;hale&quot; &quot;half&quot; &quot;hal&quot;  &quot;halm&quot; &quot;halo&quot; &quot;halt&quot; &quot;hame&quot; &quot;hams&quot;
## [1461] &quot;hand&quot; &quot;hang&quot; &quot;hank&quot; &quot;hant&quot; &quot;haps&quot; &quot;hard&quot; &quot;hare&quot; &quot;hark&quot; &quot;harl&quot; &quot;harm&quot;
## [1471] &quot;harp&quot; &quot;hart&quot; &quot;hash&quot; &quot;hasp&quot; &quot;hast&quot; &quot;hate&quot; &quot;hath&quot; &quot;hats&quot; &quot;haul&quot; &quot;haut&quot;
## [1481] &quot;have&quot; &quot;hawk&quot; &quot;haws&quot; &quot;hays&quot; &quot;haze&quot; &quot;hazy&quot; &quot;head&quot; &quot;heal&quot; &quot;heap&quot; &quot;hear&quot;
## [1491] &quot;heat&quot; &quot;hebe&quot; &quot;heck&quot; &quot;heed&quot; &quot;heel&quot; &quot;heft&quot; &quot;hehs&quot; &quot;heil&quot; &quot;heir&quot; &quot;held&quot;
## [1501] &quot;hel&quot;  &quot;helm&quot; &quot;helo&quot; &quot;help&quot; &quot;heme&quot; &quot;hemp&quot; &quot;hems&quot; &quot;hens&quot; &quot;hent&quot; &quot;herb&quot;
## [1511] &quot;herd&quot; &quot;here&quot; &quot;herl&quot; &quot;herm&quot; &quot;hern&quot; &quot;hero&quot; &quot;hers&quot; &quot;hest&quot; &quot;heth&quot; &quot;hets&quot;
## [1521] &quot;hewn&quot; &quot;hews&quot; &quot;hick&quot; &quot;hide&quot; &quot;hied&quot; &quot;hies&quot; &quot;high&quot; &quot;hike&quot; &quot;hila&quot; &quot;hili&quot;
## [1531] &quot;hil&quot;  &quot;hilt&quot; &quot;hims&quot; &quot;hind&quot; &quot;hins&quot; &quot;hint&quot; &quot;hips&quot; &quot;hire&quot; &quot;hisn&quot; &quot;hiss&quot;
## [1541] &quot;hist&quot; &quot;hits&quot; &quot;hive&quot; &quot;hoar&quot; &quot;hoax&quot; &quot;hobo&quot; &quot;hobs&quot; &quot;hock&quot; &quot;hods&quot; &quot;hoed&quot;
## [1551] &quot;hoer&quot; &quot;hoes&quot; &quot;hogg&quot; &quot;hogs&quot; &quot;hoke&quot; &quot;hold&quot; &quot;hole&quot; &quot;holk&quot; &quot;holm&quot; &quot;holp&quot;
## [1561] &quot;hols&quot; &quot;holt&quot; &quot;holy&quot; &quot;home&quot; &quot;homo&quot; &quot;homy&quot; &quot;hone&quot; &quot;hong&quot; &quot;honk&quot; &quot;hons&quot;
## [1571] &quot;hood&quot; &quot;hoof&quot; &quot;hook&quot; &quot;hoop&quot; &quot;hoot&quot; &quot;hope&quot; &quot;hops&quot; &quot;hora&quot; &quot;horn&quot; &quot;hose&quot;
## [1581] &quot;host&quot; &quot;hots&quot; &quot;hour&quot; &quot;hove&quot; &quot;howe&quot; &quot;howf&quot; &quot;howk&quot; &quot;howl&quot; &quot;hows&quot; &quot;hoya&quot;
## [1591] &quot;hoys&quot; &quot;hubs&quot; &quot;huck&quot; &quot;hued&quot; &quot;hues&quot; &quot;huff&quot; &quot;huge&quot; &quot;hugs&quot; &quot;huic&quot; &quot;hula&quot;
## [1601] &quot;hulk&quot; &quot;hul&quot;  &quot;hump&quot; &quot;hums&quot; &quot;hung&quot; &quot;hunh&quot; &quot;hunk&quot; &quot;huns&quot; &quot;hunt&quot; &quot;hurl&quot;
## [1611] &quot;hurt&quot; &quot;hush&quot; &quot;husk&quot; &quot;huts&quot; &quot;hwan&quot; &quot;hyla&quot; &quot;hymn&quot; &quot;hype&quot; &quot;hypo&quot; &quot;hyps&quot;
## [1621] &quot;hyte&quot; &quot;iamb&quot; &quot;ibex&quot; &quot;ibis&quot; &quot;iced&quot; &quot;ices&quot; &quot;ichs&quot; &quot;icky&quot; &quot;icon&quot; &quot;idea&quot;
## [1631] &quot;idem&quot; &quot;ides&quot; &quot;idle&quot; &quot;idly&quot; &quot;idol&quot; &quot;idyl&quot; &quot;iffy&quot; &quot;iggs&quot; &quot;iglu&quot; &quot;ikat&quot;
## [1641] &quot;ikon&quot; &quot;ilea&quot; &quot;ilex&quot; &quot;ilia&quot; &quot;ilka&quot; &quot;ilks&quot; &quot;ils&quot;  &quot;ily&quot;  &quot;imam&quot; &quot;imid&quot;
## [1651] &quot;immy&quot; &quot;impi&quot; &quot;imps&quot; &quot;inby&quot; &quot;inch&quot; &quot;info&quot; &quot;inia&quot; &quot;inks&quot; &quot;inky&quot; &quot;inly&quot;
## [1661] &quot;inns&quot; &quot;inro&quot; &quot;inti&quot; &quot;into&quot; &quot;ions&quot; &quot;iota&quot; &quot;ired&quot; &quot;ires&quot; &quot;irid&quot; &quot;iris&quot;
## [1671] &quot;irks&quot; &quot;iron&quot; &quot;isba&quot; &quot;isle&quot; &quot;isms&quot; &quot;itch&quot; &quot;item&quot; &quot;iwis&quot; &quot;ixia&quot; &quot;izar&quot;
## [1681] &quot;jabs&quot; &quot;jack&quot; &quot;jade&quot; &quot;jagg&quot; &quot;jags&quot; &quot;jail&quot; &quot;jake&quot; &quot;jamb&quot; &quot;jams&quot; &quot;jane&quot;
## [1691] &quot;jape&quot; &quot;jarl&quot; &quot;jars&quot; &quot;jato&quot; &quot;jauk&quot; &quot;jaup&quot; &quot;java&quot; &quot;jaws&quot; &quot;jays&quot; &quot;jazz&quot;
## [1701] &quot;jean&quot; &quot;jeed&quot; &quot;jeep&quot; &quot;jeer&quot; &quot;jees&quot; &quot;jeez&quot; &quot;jefe&quot; &quot;jehu&quot; &quot;jel&quot;  &quot;jeon&quot;
## [1711] &quot;jerk&quot; &quot;jess&quot; &quot;jest&quot; &quot;jete&quot; &quot;jets&quot; &quot;jeux&quot; &quot;jews&quot; &quot;jiao&quot; &quot;jibb&quot; &quot;jibe&quot;
## [1721] &quot;jibs&quot; &quot;jiff&quot; &quot;jigs&quot; &quot;jil&quot;  &quot;jilt&quot; &quot;jimp&quot; &quot;jink&quot; &quot;jinn&quot; &quot;jins&quot; &quot;jinx&quot;
## [1731] &quot;jism&quot; &quot;jive&quot; &quot;jivy&quot; &quot;jobs&quot; &quot;jock&quot; &quot;joes&quot; &quot;joey&quot; &quot;jogs&quot; &quot;john&quot; &quot;join&quot;
## [1741] &quot;joke&quot; &quot;joky&quot; &quot;jole&quot; &quot;jolt&quot; &quot;josh&quot; &quot;joss&quot; &quot;jota&quot; &quot;jots&quot; &quot;jouk&quot; &quot;jowl&quot;
## [1751] &quot;jows&quot; &quot;joys&quot; &quot;juba&quot; &quot;jube&quot; &quot;juco&quot; &quot;judo&quot; &quot;juga&quot; &quot;jugs&quot; &quot;juju&quot; &quot;juke&quot;
## [1761] &quot;juku&quot; &quot;jump&quot; &quot;junk&quot; &quot;jupe&quot; &quot;jura&quot; &quot;jury&quot; &quot;just&quot; &quot;jute&quot; &quot;juts&quot; &quot;kaas&quot;
## [1771] &quot;kabs&quot; &quot;kadi&quot; &quot;kaes&quot; &quot;kafs&quot; &quot;kagu&quot; &quot;kaif&quot; &quot;kail&quot; &quot;kain&quot; &quot;kaka&quot; &quot;kaki&quot;
## [1781] &quot;kale&quot; &quot;kame&quot; &quot;kami&quot; &quot;kana&quot; &quot;kane&quot; &quot;kaon&quot; &quot;kapa&quot; &quot;kaph&quot; &quot;karn&quot; &quot;kart&quot;
## [1791] &quot;kata&quot; &quot;kats&quot; &quot;kava&quot; &quot;kayo&quot; &quot;kays&quot; &quot;kbar&quot; &quot;keas&quot; &quot;keck&quot; &quot;keef&quot; &quot;keek&quot;
## [1801] &quot;keel&quot; &quot;keen&quot; &quot;keep&quot; &quot;keet&quot; &quot;kefs&quot; &quot;kegs&quot; &quot;keir&quot; &quot;kelp&quot; &quot;kelt&quot; &quot;kemp&quot;
## [1811] &quot;keno&quot; &quot;kens&quot; &quot;kent&quot; &quot;kepi&quot; &quot;keps&quot; &quot;kept&quot; &quot;kerb&quot; &quot;kerf&quot; &quot;kern&quot; &quot;keto&quot;
## [1821] &quot;keys&quot; &quot;khaf&quot; &quot;khan&quot; &quot;khat&quot; &quot;khet&quot; &quot;khis&quot; &quot;kibe&quot; &quot;kick&quot; &quot;kids&quot; &quot;kief&quot;
## [1831] &quot;kier&quot; &quot;kifs&quot; &quot;kike&quot; &quot;kil&quot;  &quot;kiln&quot; &quot;kilo&quot; &quot;kilt&quot; &quot;kina&quot; &quot;kind&quot; &quot;kine&quot;
## [1841] &quot;king&quot; &quot;kink&quot; &quot;kino&quot; &quot;kins&quot; &quot;kips&quot; &quot;kirk&quot; &quot;kirn&quot; &quot;kirs&quot; &quot;kiss&quot; &quot;kist&quot;
## [1851] &quot;kite&quot; &quot;kith&quot; &quot;kits&quot; &quot;kiva&quot; &quot;kiwi&quot; &quot;klik&quot; &quot;knap&quot; &quot;knar&quot; &quot;knee&quot; &quot;knew&quot;
## [1861] &quot;knit&quot; &quot;knob&quot; &quot;knop&quot; &quot;knot&quot; &quot;know&quot; &quot;knur&quot; &quot;koan&quot; &quot;koas&quot; &quot;kobo&quot; &quot;kobs&quot;
## [1871] &quot;koel&quot; &quot;kohl&quot; &quot;kois&quot; &quot;koji&quot; &quot;kola&quot; &quot;kolo&quot; &quot;konk&quot; &quot;kook&quot; &quot;koph&quot; &quot;kops&quot;
## [1881] &quot;kora&quot; &quot;kore&quot; &quot;kors&quot; &quot;koss&quot; &quot;koto&quot; &quot;kris&quot; &quot;kudo&quot; &quot;kudu&quot; &quot;kues&quot; &quot;kufi&quot;
## [1891] &quot;kuna&quot; &quot;kune&quot; &quot;kuru&quot; &quot;kvas&quot; &quot;kyak&quot; &quot;kyar&quot; &quot;kyat&quot; &quot;kyes&quot; &quot;kyte&quot; &quot;labs&quot;
## [1901] &quot;lace&quot; &quot;lack&quot; &quot;lacs&quot; &quot;lacy&quot; &quot;lade&quot; &quot;lads&quot; &quot;lady&quot; &quot;lags&quot; &quot;laic&quot; &quot;laid&quot;
## [1911] &quot;lain&quot; &quot;lair&quot; &quot;lake&quot; &quot;lakh&quot; &quot;laky&quot; &quot;lal&quot;  &quot;lama&quot; &quot;lamb&quot; &quot;lame&quot; &quot;lamp&quot;
## [1921] &quot;lams&quot; &quot;land&quot; &quot;lane&quot; &quot;lang&quot; &quot;lank&quot; &quot;laps&quot; &quot;lard&quot; &quot;lari&quot; &quot;lark&quot; &quot;lars&quot;
## [1931] &quot;lase&quot; &quot;lash&quot; &quot;lass&quot; &quot;last&quot; &quot;late&quot; &quot;lath&quot; &quot;lati&quot; &quot;lats&quot; &quot;latu&quot; &quot;laud&quot;
## [1941] &quot;lava&quot; &quot;lave&quot; &quot;lavs&quot; &quot;lawn&quot; &quot;laws&quot; &quot;lays&quot; &quot;laze&quot; &quot;lazy&quot; &quot;lead&quot; &quot;leaf&quot;
## [1951] &quot;leak&quot; &quot;leal&quot; &quot;lean&quot; &quot;leap&quot; &quot;lear&quot; &quot;leas&quot; &quot;lech&quot; &quot;leek&quot; &quot;leer&quot; &quot;lees&quot;
## [1961] &quot;leet&quot; &quot;left&quot; &quot;legs&quot; &quot;lehr&quot; &quot;leis&quot; &quot;leke&quot; &quot;leks&quot; &quot;leku&quot; &quot;lend&quot; &quot;leno&quot;
## [1971] &quot;lens&quot; &quot;lent&quot; &quot;lept&quot; &quot;less&quot; &quot;lest&quot; &quot;lets&quot; &quot;leud&quot; &quot;leva&quot; &quot;levo&quot; &quot;levy&quot;
## [1981] &quot;lewd&quot; &quot;leys&quot; &quot;liar&quot; &quot;libs&quot; &quot;lice&quot; &quot;lich&quot; &quot;lick&quot; &quot;lido&quot; &quot;lids&quot; &quot;lied&quot;
## [1991] &quot;lief&quot; &quot;lien&quot; &quot;lier&quot; &quot;lies&quot; &quot;lieu&quot; &quot;life&quot; &quot;lift&quot; &quot;like&quot; &quot;lilo&quot; &quot;lilt&quot;
## [2001] &quot;lily&quot; &quot;lima&quot; &quot;limb&quot; &quot;lime&quot; &quot;limn&quot; &quot;limo&quot; &quot;limp&quot; &quot;limy&quot; &quot;line&quot; &quot;ling&quot;
## [2011] &quot;link&quot; &quot;linn&quot; &quot;lino&quot; &quot;lins&quot; &quot;lint&quot; &quot;liny&quot; &quot;lion&quot; &quot;lipa&quot; &quot;lipe&quot; &quot;lips&quot;
## [2021] &quot;lira&quot; &quot;lire&quot; &quot;liri&quot; &quot;lisp&quot; &quot;list&quot; &quot;lite&quot; &quot;lits&quot; &quot;litu&quot; &quot;live&quot; &quot;load&quot;
## [2031] &quot;loaf&quot; &quot;loam&quot; &quot;loan&quot; &quot;lobe&quot; &quot;lobo&quot; &quot;lobs&quot; &quot;loca&quot; &quot;loch&quot; &quot;loci&quot; &quot;lock&quot;
## [2041] &quot;loco&quot; &quot;lode&quot; &quot;loft&quot; &quot;loge&quot; &quot;logo&quot; &quot;logs&quot; &quot;logy&quot; &quot;loid&quot; &quot;loin&quot; &quot;lol&quot; 
## [2051] &quot;lone&quot; &quot;long&quot; &quot;loof&quot; &quot;look&quot; &quot;loom&quot; &quot;loon&quot; &quot;loop&quot; &quot;loos&quot; &quot;loot&quot; &quot;lope&quot;
## [2061] &quot;lops&quot; &quot;lord&quot; &quot;lore&quot; &quot;lorn&quot; &quot;lory&quot; &quot;lose&quot; &quot;loss&quot; &quot;lost&quot; &quot;lota&quot; &quot;loth&quot;
## [2071] &quot;loti&quot; &quot;lots&quot; &quot;loud&quot; &quot;loup&quot; &quot;lour&quot; &quot;lout&quot; &quot;love&quot; &quot;lowe&quot; &quot;lown&quot; &quot;lows&quot;
## [2081] &quot;luau&quot; &quot;lube&quot; &quot;luce&quot; &quot;luck&quot; &quot;lude&quot; &quot;lues&quot; &quot;luff&quot; &quot;luge&quot; &quot;lugs&quot; &quot;lul&quot; 
## [2091] &quot;lulu&quot; &quot;luma&quot; &quot;lump&quot; &quot;lums&quot; &quot;luna&quot; &quot;lune&quot; &quot;lung&quot; &quot;lunk&quot; &quot;lunt&quot; &quot;luny&quot;
## [2101] &quot;lure&quot; &quot;lurk&quot; &quot;lush&quot; &quot;lust&quot; &quot;lute&quot; &quot;lutz&quot; &quot;luvs&quot; &quot;luxe&quot; &quot;lwei&quot; &quot;lych&quot;
## [2111] &quot;lyes&quot; &quot;lynx&quot; &quot;lyre&quot; &quot;lyse&quot; &quot;maar&quot; &quot;mabe&quot; &quot;mace&quot; &quot;mach&quot; &quot;mack&quot; &quot;macs&quot;
## [2121] &quot;made&quot; &quot;mads&quot; &quot;maes&quot; &quot;mage&quot; &quot;magi&quot; &quot;mags&quot; &quot;maid&quot; &quot;mail&quot; &quot;maim&quot; &quot;main&quot;
## [2131] &quot;mair&quot; &quot;make&quot; &quot;mako&quot; &quot;male&quot; &quot;mal&quot;  &quot;malm&quot; &quot;malt&quot; &quot;mama&quot; &quot;mana&quot; &quot;mane&quot;
## [2141] &quot;mano&quot; &quot;mans&quot; &quot;many&quot; &quot;maps&quot; &quot;mara&quot; &quot;marc&quot; &quot;mare&quot; &quot;mark&quot; &quot;marl&quot; &quot;mars&quot;
## [2151] &quot;mart&quot; &quot;masa&quot; &quot;mash&quot; &quot;mask&quot; &quot;mass&quot; &quot;mast&quot; &quot;mate&quot; &quot;math&quot; &quot;mats&quot; &quot;matt&quot;
## [2161] &quot;maud&quot; &quot;maul&quot; &quot;maun&quot; &quot;maut&quot; &quot;mawn&quot; &quot;maws&quot; &quot;maxi&quot; &quot;maya&quot; &quot;mayo&quot; &quot;mays&quot;
## [2171] &quot;maze&quot; &quot;mazy&quot; &quot;mead&quot; &quot;meal&quot; &quot;mean&quot; &quot;meat&quot; &quot;meds&quot; &quot;meed&quot; &quot;meek&quot; &quot;meet&quot;
## [2181] &quot;mega&quot; &quot;megs&quot; &quot;meld&quot; &quot;mel&quot;  &quot;mels&quot; &quot;melt&quot; &quot;meme&quot; &quot;memo&quot; &quot;mems&quot; &quot;mend&quot;
## [2191] &quot;meno&quot; &quot;menu&quot; &quot;meou&quot; &quot;meow&quot; &quot;merc&quot; &quot;mere&quot; &quot;merk&quot; &quot;merl&quot; &quot;mesa&quot; &quot;mesh&quot;
## [2201] &quot;mess&quot; &quot;meta&quot; &quot;mete&quot; &quot;meth&quot; &quot;mewl&quot; &quot;mews&quot; &quot;meze&quot; &quot;mhos&quot; &quot;mibs&quot; &quot;mica&quot;
## [2211] &quot;mice&quot; &quot;mick&quot; &quot;mics&quot; &quot;midi&quot; &quot;mids&quot; &quot;mien&quot; &quot;miff&quot; &quot;migg&quot; &quot;migs&quot; &quot;mike&quot;
## [2221] &quot;mild&quot; &quot;mile&quot; &quot;milk&quot; &quot;mil&quot;  &quot;milo&quot; &quot;mils&quot; &quot;milt&quot; &quot;mime&quot; &quot;mina&quot; &quot;mind&quot;
## [2231] &quot;mine&quot; &quot;mini&quot; &quot;mink&quot; &quot;mint&quot; &quot;minx&quot; &quot;mips&quot; &quot;mire&quot; &quot;miri&quot; &quot;mirk&quot; &quot;mirs&quot;
## [2241] &quot;miry&quot; &quot;mise&quot; &quot;miso&quot; &quot;miss&quot; &quot;mist&quot; &quot;mite&quot; &quot;mitt&quot; &quot;mity&quot; &quot;mixt&quot; &quot;moan&quot;
## [2251] &quot;moas&quot; &quot;moat&quot; &quot;mobs&quot; &quot;mock&quot; &quot;mocs&quot; &quot;mode&quot; &quot;modi&quot; &quot;mods&quot; &quot;mogs&quot; &quot;moil&quot;
## [2261] &quot;mojo&quot; &quot;moke&quot; &quot;mola&quot; &quot;mold&quot; &quot;mole&quot; &quot;mol&quot;  &quot;mols&quot; &quot;molt&quot; &quot;moly&quot; &quot;mome&quot;
## [2271] &quot;momi&quot; &quot;moms&quot; &quot;monk&quot; &quot;mono&quot; &quot;mons&quot; &quot;mony&quot; &quot;mood&quot; &quot;mool&quot; &quot;moon&quot; &quot;moor&quot;
## [2281] &quot;moos&quot; &quot;moot&quot; &quot;mope&quot; &quot;mops&quot; &quot;mopy&quot; &quot;mora&quot; &quot;more&quot; &quot;morn&quot; &quot;mors&quot; &quot;mort&quot;
## [2291] &quot;mosh&quot; &quot;mosk&quot; &quot;moss&quot; &quot;most&quot; &quot;mote&quot; &quot;moth&quot; &quot;mots&quot; &quot;mott&quot; &quot;moue&quot; &quot;move&quot;
## [2301] &quot;mown&quot; &quot;mows&quot; &quot;moxa&quot; &quot;mozo&quot; &quot;much&quot; &quot;muck&quot; &quot;muds&quot; &quot;muff&quot; &quot;mugg&quot; &quot;mugs&quot;
## [2311] &quot;mule&quot; &quot;mul&quot;  &quot;mumm&quot; &quot;mump&quot; &quot;mums&quot; &quot;mumu&quot; &quot;muni&quot; &quot;muns&quot; &quot;muon&quot; &quot;mura&quot;
## [2321] &quot;mure&quot; &quot;murk&quot; &quot;murr&quot; &quot;muse&quot; &quot;mush&quot; &quot;musk&quot; &quot;muss&quot; &quot;must&quot; &quot;mute&quot; &quot;muts&quot;
## [2331] &quot;mutt&quot; &quot;mycs&quot; &quot;myna&quot; &quot;myth&quot; &quot;naan&quot; &quot;nabe&quot; &quot;nabs&quot; &quot;nada&quot; &quot;naff&quot; &quot;nags&quot;
## [2341] &quot;naif&quot; &quot;nail&quot; &quot;nala&quot; &quot;name&quot; &quot;nana&quot; &quot;nans&quot; &quot;naoi&quot; &quot;naos&quot; &quot;napa&quot; &quot;nape&quot;
## [2351] &quot;naps&quot; &quot;narc&quot; &quot;nard&quot; &quot;nark&quot; &quot;nary&quot; &quot;nave&quot; &quot;navy&quot; &quot;nays&quot; &quot;nazi&quot; &quot;neap&quot;
## [2361] &quot;near&quot; &quot;neat&quot; &quot;nebs&quot; &quot;neck&quot; &quot;need&quot; &quot;neem&quot; &quot;neep&quot; &quot;negs&quot; &quot;neif&quot; &quot;nema&quot;
## [2371] &quot;nene&quot; &quot;neon&quot; &quot;nerd&quot; &quot;ness&quot; &quot;nest&quot; &quot;nets&quot; &quot;nett&quot; &quot;neuk&quot; &quot;neum&quot; &quot;neve&quot;
## [2381] &quot;nevi&quot; &quot;news&quot; &quot;newt&quot; &quot;next&quot; &quot;nibs&quot; &quot;nice&quot; &quot;nick&quot; &quot;nide&quot; &quot;nidi&quot; &quot;nigh&quot;
## [2391] &quot;nil&quot;  &quot;nils&quot; &quot;nims&quot; &quot;nine&quot; &quot;nipa&quot; &quot;nips&quot; &quot;nisi&quot; &quot;nite&quot; &quot;nits&quot; &quot;nixe&quot;
## [2401] &quot;nixy&quot; &quot;nobs&quot; &quot;nock&quot; &quot;node&quot; &quot;nodi&quot; &quot;nods&quot; &quot;noel&quot; &quot;noes&quot; &quot;nogg&quot; &quot;nogs&quot;
## [2411] &quot;noil&quot; &quot;noir&quot; &quot;nolo&quot; &quot;noma&quot; &quot;nome&quot; &quot;noms&quot; &quot;nona&quot; &quot;none&quot; &quot;nook&quot; &quot;noon&quot;
## [2421] &quot;nope&quot; &quot;nori&quot; &quot;norm&quot; &quot;nose&quot; &quot;nosh&quot; &quot;nosy&quot; &quot;nota&quot; &quot;note&quot; &quot;noun&quot; &quot;nous&quot;
## [2431] &quot;nova&quot; &quot;nows&quot; &quot;nowt&quot; &quot;nubs&quot; &quot;nude&quot; &quot;nuke&quot; &quot;nul&quot;  &quot;numb&quot; &quot;nuns&quot; &quot;nurd&quot;
## [2441] &quot;nurl&quot; &quot;nuts&quot; &quot;oafs&quot; &quot;oaks&quot; &quot;oaky&quot; &quot;oars&quot; &quot;oast&quot; &quot;oath&quot; &quot;oats&quot; &quot;obas&quot;
## [2451] &quot;obes&quot; &quot;obey&quot; &quot;obia&quot; &quot;obis&quot; &quot;obit&quot; &quot;oboe&quot; &quot;obol&quot; &quot;ocas&quot; &quot;odah&quot; &quot;odas&quot;
## [2461] &quot;odds&quot; &quot;odea&quot; &quot;odes&quot; &quot;odic&quot; &quot;odor&quot; &quot;odyl&quot; &quot;ofay&quot; &quot;offs&quot; &quot;ogam&quot; &quot;ogee&quot;
## [2471] &quot;ogle&quot; &quot;ogre&quot; &quot;ohed&quot; &quot;ohia&quot; &quot;ohms&quot; &quot;oils&quot; &quot;oily&quot; &quot;oink&quot; &quot;okas&quot; &quot;okay&quot;
## [2481] &quot;okeh&quot; &quot;okes&quot; &quot;okra&quot; &quot;olds&quot; &quot;oldy&quot; &quot;olea&quot; &quot;oleo&quot; &quot;oles&quot; &quot;olio&quot; &quot;ola&quot; 
## [2491] &quot;omen&quot; &quot;omer&quot; &quot;omit&quot; &quot;once&quot; &quot;ones&quot; &quot;only&quot; &quot;onos&quot; &quot;onto&quot; &quot;onus&quot; &quot;onyx&quot;
## [2501] &quot;oohs&quot; &quot;oops&quot; &quot;oots&quot; &quot;ooze&quot; &quot;oozy&quot; &quot;opah&quot; &quot;opal&quot; &quot;oped&quot; &quot;open&quot; &quot;opes&quot;
## [2511] &quot;opts&quot; &quot;opus&quot; &quot;orad&quot; &quot;oral&quot; &quot;orbs&quot; &quot;orby&quot; &quot;orca&quot; &quot;orcs&quot; &quot;ordo&quot; &quot;ores&quot;
## [2521] &quot;orgy&quot; &quot;orle&quot; &quot;orra&quot; &quot;orts&quot; &quot;oryx&quot; &quot;orzo&quot; &quot;osar&quot; &quot;oses&quot; &quot;ossa&quot; &quot;otic&quot;
## [2531] &quot;otto&quot; &quot;ouch&quot; &quot;ouds&quot; &quot;ouph&quot; &quot;ours&quot; &quot;oust&quot; &quot;outs&quot; &quot;ouzo&quot; &quot;oval&quot; &quot;oven&quot;
## [2541] &quot;over&quot; &quot;ovum&quot; &quot;owed&quot; &quot;owes&quot; &quot;owls&quot; &quot;owns&quot; &quot;owse&quot; &quot;oxen&quot; &quot;oxes&quot; &quot;oxid&quot;
## [2551] &quot;oxim&quot; &quot;oyer&quot; &quot;oyes&quot; &quot;oyez&quot; &quot;paca&quot; &quot;pace&quot; &quot;pack&quot; &quot;pacs&quot; &quot;pact&quot; &quot;pacy&quot;
## [2561] &quot;padi&quot; &quot;pads&quot; &quot;page&quot; &quot;paid&quot; &quot;paik&quot; &quot;pail&quot; &quot;pain&quot; &quot;pair&quot; &quot;pale&quot; &quot;pal&quot; 
## [2571] &quot;palm&quot; &quot;palp&quot; &quot;pals&quot; &quot;paly&quot; &quot;pams&quot; &quot;pane&quot; &quot;pang&quot; &quot;pans&quot; &quot;pant&quot; &quot;papa&quot;
## [2581] &quot;paps&quot; &quot;para&quot; &quot;pard&quot; &quot;pare&quot; &quot;park&quot; &quot;parr&quot; &quot;pars&quot; &quot;part&quot; &quot;pase&quot; &quot;pash&quot;
## [2591] &quot;pass&quot; &quot;past&quot; &quot;pate&quot; &quot;path&quot; &quot;pats&quot; &quot;paty&quot; &quot;pave&quot; &quot;pawl&quot; &quot;pawn&quot; &quot;paws&quot;
## [2601] &quot;pays&quot; &quot;peag&quot; &quot;peak&quot; &quot;peal&quot; &quot;pean&quot; &quot;pear&quot; &quot;peas&quot; &quot;peat&quot; &quot;pech&quot; &quot;peck&quot;
## [2611] &quot;pecs&quot; &quot;peds&quot; &quot;peed&quot; &quot;peek&quot; &quot;peel&quot; &quot;peen&quot; &quot;peep&quot; &quot;peer&quot; &quot;pees&quot; &quot;pegs&quot;
## [2621] &quot;pehs&quot; &quot;pein&quot; &quot;peke&quot; &quot;pele&quot; &quot;pelf&quot; &quot;pelt&quot; &quot;pend&quot; &quot;pens&quot; &quot;pent&quot; &quot;peon&quot;
## [2631] &quot;pepo&quot; &quot;peps&quot; &quot;pere&quot; &quot;peri&quot; &quot;perk&quot; &quot;perm&quot; &quot;perp&quot; &quot;pert&quot; &quot;perv&quot; &quot;peso&quot;
## [2641] &quot;pest&quot; &quot;pets&quot; &quot;pews&quot; &quot;pfft&quot; &quot;pfui&quot; &quot;phat&quot; &quot;phew&quot; &quot;phis&quot; &quot;phiz&quot; &quot;phon&quot;
## [2651] &quot;phot&quot; &quot;phut&quot; &quot;pial&quot; &quot;pian&quot; &quot;pias&quot; &quot;pica&quot; &quot;pice&quot; &quot;pick&quot; &quot;pics&quot; &quot;pied&quot;
## [2661] &quot;pier&quot; &quot;pies&quot; &quot;pigs&quot; &quot;pika&quot; &quot;pike&quot; &quot;piki&quot; &quot;pile&quot; &quot;pili&quot; &quot;pil&quot;  &quot;pily&quot;
## [2671] &quot;pima&quot; &quot;pimp&quot; &quot;pina&quot; &quot;pine&quot; &quot;ping&quot; &quot;pink&quot; &quot;pins&quot; &quot;pint&quot; &quot;piny&quot; &quot;pion&quot;
## [2681] &quot;pipe&quot; &quot;pips&quot; &quot;pipy&quot; &quot;pirn&quot; &quot;pish&quot; &quot;piso&quot; &quot;piss&quot; &quot;pita&quot; &quot;pith&quot; &quot;pits&quot;
## [2691] &quot;pity&quot; &quot;pixy&quot; &quot;plan&quot; &quot;plat&quot; &quot;play&quot; &quot;plea&quot; &quot;pleb&quot; &quot;pled&quot; &quot;plew&quot; &quot;plex&quot;
## [2701] &quot;plie&quot; &quot;plod&quot; &quot;plop&quot; &quot;plot&quot; &quot;plow&quot; &quot;ploy&quot; &quot;plug&quot; &quot;plum&quot; &quot;plus&quot; &quot;pock&quot;
## [2711] &quot;poco&quot; &quot;pods&quot; &quot;poem&quot; &quot;poet&quot; &quot;pogy&quot; &quot;pois&quot; &quot;poke&quot; &quot;poky&quot; &quot;pole&quot; &quot;pol&quot; 
## [2721] &quot;polo&quot; &quot;pols&quot; &quot;poly&quot; &quot;pome&quot; &quot;pomo&quot; &quot;pomp&quot; &quot;poms&quot; &quot;pond&quot; &quot;pone&quot; &quot;pong&quot;
## [2731] &quot;pons&quot; &quot;pony&quot; &quot;pood&quot; &quot;poof&quot; &quot;pooh&quot; &quot;pool&quot; &quot;poon&quot; &quot;poop&quot; &quot;poor&quot; &quot;poos&quot;
## [2741] &quot;pope&quot; &quot;pops&quot; &quot;pore&quot; &quot;pork&quot; &quot;porn&quot; &quot;port&quot; &quot;pose&quot; &quot;posh&quot; &quot;post&quot; &quot;posy&quot;
## [2751] &quot;pots&quot; &quot;pouf&quot; &quot;pour&quot; &quot;pout&quot; &quot;pows&quot; &quot;poxy&quot; &quot;pram&quot; &quot;prao&quot; &quot;prat&quot; &quot;prau&quot;
## [2761] &quot;pray&quot; &quot;pree&quot; &quot;prep&quot; &quot;prex&quot; &quot;prey&quot; &quot;prez&quot; &quot;prig&quot; &quot;prim&quot; &quot;proa&quot; &quot;prod&quot;
## [2771] &quot;prof&quot; &quot;prog&quot; &quot;prom&quot; &quot;prop&quot; &quot;pros&quot; &quot;prow&quot; &quot;psis&quot; &quot;psst&quot; &quot;ptui&quot; &quot;pubs&quot;
## [2781] &quot;puce&quot; &quot;puck&quot; &quot;puds&quot; &quot;puff&quot; &quot;pugh&quot; &quot;pugs&quot; &quot;puja&quot; &quot;puke&quot; &quot;pula&quot; &quot;pule&quot;
## [2791] &quot;puli&quot; &quot;pul&quot;  &quot;pulp&quot; &quot;puls&quot; &quot;puma&quot; &quot;pump&quot; &quot;puna&quot; &quot;pung&quot; &quot;punk&quot; &quot;puns&quot;
## [2801] &quot;punt&quot; &quot;puny&quot; &quot;pupa&quot; &quot;pups&quot; &quot;pupu&quot; &quot;pure&quot; &quot;puri&quot; &quot;purl&quot; &quot;purr&quot; &quot;purs&quot;
## [2811] &quot;push&quot; &quot;puss&quot; &quot;puts&quot; &quot;putt&quot; &quot;putz&quot; &quot;pyas&quot; &quot;pyes&quot; &quot;pyic&quot; &quot;pyin&quot; &quot;pyre&quot;
## [2821] &quot;pyro&quot; &quot;qadi&quot; &quot;qaid&quot; &quot;qats&quot; &quot;qoph&quot; &quot;quad&quot; &quot;quag&quot; &quot;quai&quot; &quot;quay&quot; &quot;quey&quot;
## [2831] &quot;quid&quot; &quot;quin&quot; &quot;quip&quot; &quot;quit&quot; &quot;quiz&quot; &quot;quod&quot; &quot;race&quot; &quot;rack&quot; &quot;racy&quot; &quot;rads&quot;
## [2841] &quot;raff&quot; &quot;raft&quot; &quot;raga&quot; &quot;rage&quot; &quot;ragg&quot; &quot;ragi&quot; &quot;rags&quot; &quot;raia&quot; &quot;raid&quot; &quot;rail&quot;
## [2851] &quot;rain&quot; &quot;rais&quot; &quot;raja&quot; &quot;rake&quot; &quot;raki&quot; &quot;raku&quot; &quot;rale&quot; &quot;rami&quot; &quot;ramp&quot; &quot;rams&quot;
## [2861] &quot;rand&quot; &quot;rang&quot; &quot;rani&quot; &quot;rank&quot; &quot;rant&quot; &quot;rape&quot; &quot;raps&quot; &quot;rapt&quot; &quot;rare&quot; &quot;rase&quot;
## [2871] &quot;rash&quot; &quot;rasp&quot; &quot;rate&quot; &quot;rath&quot; &quot;rato&quot; &quot;rats&quot; &quot;rave&quot; &quot;raws&quot; &quot;raya&quot; &quot;rays&quot;
## [2881] &quot;raze&quot; &quot;razz&quot; &quot;read&quot; &quot;real&quot; &quot;ream&quot; &quot;reap&quot; &quot;rear&quot; &quot;rebs&quot; &quot;reck&quot; &quot;recs&quot;
## [2891] &quot;redd&quot; &quot;rede&quot; &quot;redo&quot; &quot;reds&quot; &quot;reed&quot; &quot;reef&quot; &quot;reek&quot; &quot;reel&quot; &quot;rees&quot; &quot;refs&quot;
## [2901] &quot;reft&quot; &quot;regs&quot; &quot;reif&quot; &quot;rein&quot; &quot;reis&quot; &quot;rely&quot; &quot;rems&quot; &quot;rend&quot; &quot;rent&quot; &quot;repo&quot;
## [2911] &quot;repp&quot; &quot;reps&quot; &quot;resh&quot; &quot;rest&quot; &quot;rete&quot; &quot;rets&quot; &quot;revs&quot; &quot;rhea&quot; &quot;rhos&quot; &quot;rhus&quot;
## [2921] &quot;rial&quot; &quot;rias&quot; &quot;ribs&quot; &quot;rice&quot; &quot;rich&quot; &quot;rick&quot; &quot;ride&quot; &quot;rids&quot; &quot;riel&quot; &quot;rife&quot;
## [2931] &quot;riff&quot; &quot;rifs&quot; &quot;rift&quot; &quot;rigs&quot; &quot;rile&quot; &quot;ril&quot;  &quot;rime&quot; &quot;rims&quot; &quot;rimy&quot; &quot;rind&quot;
## [2941] &quot;ring&quot; &quot;rink&quot; &quot;rins&quot; &quot;riot&quot; &quot;ripe&quot; &quot;rips&quot; &quot;rise&quot; &quot;risk&quot; &quot;rite&quot; &quot;ritz&quot;
## [2951] &quot;rive&quot; &quot;road&quot; &quot;roam&quot; &quot;roan&quot; &quot;roar&quot; &quot;robe&quot; &quot;robs&quot; &quot;rock&quot; &quot;rocs&quot; &quot;rode&quot;
## [2961] &quot;rods&quot; &quot;roes&quot; &quot;roil&quot; &quot;role&quot; &quot;rolf&quot; &quot;rol&quot;  &quot;romp&quot; &quot;roms&quot; &quot;rood&quot; &quot;roof&quot;
## [2971] &quot;rook&quot; &quot;room&quot; &quot;root&quot; &quot;rope&quot; &quot;ropy&quot; &quot;rose&quot; &quot;rosy&quot; &quot;rota&quot; &quot;rote&quot; &quot;roti&quot;
## [2981] &quot;rotl&quot; &quot;roto&quot; &quot;rots&quot; &quot;roue&quot; &quot;roup&quot; &quot;rout&quot; &quot;roux&quot; &quot;rove&quot; &quot;rows&quot; &quot;rube&quot;
## [2991] &quot;rubs&quot; &quot;ruby&quot; &quot;ruck&quot; &quot;rudd&quot; &quot;rude&quot; &quot;rued&quot; &quot;ruer&quot; &quot;rues&quot; &quot;ruff&quot; &quot;ruga&quot;
## [3001] &quot;rugs&quot; &quot;ruin&quot; &quot;rule&quot; &quot;ruly&quot; &quot;rump&quot; &quot;rums&quot; &quot;rune&quot; &quot;rung&quot; &quot;runs&quot; &quot;runt&quot;
## [3011] &quot;ruse&quot; &quot;rush&quot; &quot;rusk&quot; &quot;rust&quot; &quot;ruth&quot; &quot;ruts&quot; &quot;ryas&quot; &quot;ryes&quot; &quot;ryke&quot; &quot;rynd&quot;
## [3021] &quot;ryot&quot; &quot;sabe&quot; &quot;sabs&quot; &quot;sack&quot; &quot;sacs&quot; &quot;sade&quot; &quot;sadi&quot; &quot;safe&quot; &quot;saga&quot; &quot;sage&quot;
## [3031] &quot;sago&quot; &quot;sags&quot; &quot;sagy&quot; &quot;said&quot; &quot;sail&quot; &quot;sain&quot; &quot;sake&quot; &quot;saki&quot; &quot;sale&quot; &quot;sal&quot; 
## [3041] &quot;salp&quot; &quot;sals&quot; &quot;salt&quot; &quot;same&quot; &quot;samp&quot; &quot;sand&quot; &quot;sane&quot; &quot;sang&quot; &quot;sank&quot; &quot;sans&quot;
## [3051] &quot;saps&quot; &quot;sard&quot; &quot;sari&quot; &quot;sark&quot; &quot;sash&quot; &quot;sass&quot; &quot;sate&quot; &quot;sati&quot; &quot;saul&quot; &quot;save&quot;
## [3061] &quot;sawn&quot; &quot;saws&quot; &quot;says&quot; &quot;scab&quot; &quot;scad&quot; &quot;scag&quot; &quot;scam&quot; &quot;scan&quot; &quot;scar&quot; &quot;scat&quot;
## [3071] &quot;scop&quot; &quot;scot&quot; &quot;scow&quot; &quot;scry&quot; &quot;scud&quot; &quot;scum&quot; &quot;scup&quot; &quot;scut&quot; &quot;seal&quot; &quot;seam&quot;
## [3081] &quot;sear&quot; &quot;seas&quot; &quot;seat&quot; &quot;secs&quot; &quot;sect&quot; &quot;seed&quot; &quot;seek&quot; &quot;seel&quot; &quot;seem&quot; &quot;seen&quot;
## [3091] &quot;seep&quot; &quot;seer&quot; &quot;sees&quot; &quot;sego&quot; &quot;segs&quot; &quot;seif&quot; &quot;seis&quot; &quot;self&quot; &quot;sel&quot;  &quot;sels&quot;
## [3101] &quot;seme&quot; &quot;semi&quot; &quot;send&quot; &quot;sene&quot; &quot;sent&quot; &quot;sept&quot; &quot;sera&quot; &quot;sere&quot; &quot;serf&quot; &quot;sers&quot;
## [3111] &quot;seta&quot; &quot;sets&quot; &quot;sett&quot; &quot;sewn&quot; &quot;sews&quot; &quot;sext&quot; &quot;sexy&quot; &quot;shad&quot; &quot;shag&quot; &quot;shah&quot;
## [3121] &quot;sham&quot; &quot;shat&quot; &quot;shaw&quot; &quot;shay&quot; &quot;shea&quot; &quot;shed&quot; &quot;shes&quot; &quot;shew&quot; &quot;shim&quot; &quot;shin&quot;
## [3131] &quot;ship&quot; &quot;shit&quot; &quot;shiv&quot; &quot;shmo&quot; &quot;shod&quot; &quot;shoe&quot; &quot;shog&quot; &quot;shoo&quot; &quot;shop&quot; &quot;shot&quot;
## [3141] &quot;show&quot; &quot;shri&quot; &quot;shul&quot; &quot;shun&quot; &quot;shut&quot; &quot;shwa&quot; &quot;sial&quot; &quot;sibb&quot; &quot;sibs&quot; &quot;sice&quot;
## [3151] &quot;sick&quot; &quot;sics&quot; &quot;side&quot; &quot;sidh&quot; &quot;sift&quot; &quot;sigh&quot; &quot;sign&quot; &quot;sika&quot; &quot;sike&quot; &quot;sild&quot;
## [3161] &quot;silk&quot; &quot;sil&quot;  &quot;silo&quot; &quot;silt&quot; &quot;sima&quot; &quot;simp&quot; &quot;sims&quot; &quot;sine&quot; &quot;sing&quot; &quot;sinh&quot;
## [3171] &quot;sink&quot; &quot;sins&quot; &quot;sipe&quot; &quot;sips&quot; &quot;sire&quot; &quot;sirs&quot; &quot;site&quot; &quot;sith&quot; &quot;sits&quot; &quot;size&quot;
## [3181] &quot;sizy&quot; &quot;skag&quot; &quot;skas&quot; &quot;skat&quot; &quot;skee&quot; &quot;skeg&quot; &quot;skep&quot; &quot;skew&quot; &quot;skid&quot; &quot;skim&quot;
## [3191] &quot;skin&quot; &quot;skip&quot; &quot;skis&quot; &quot;skit&quot; &quot;skua&quot; &quot;slab&quot; &quot;slag&quot; &quot;slam&quot; &quot;slap&quot; &quot;slat&quot;
## [3201] &quot;slaw&quot; &quot;slay&quot; &quot;sled&quot; &quot;slew&quot; &quot;slid&quot; &quot;slim&quot; &quot;slip&quot; &quot;slit&quot; &quot;slob&quot; &quot;sloe&quot;
## [3211] &quot;slog&quot; &quot;slop&quot; &quot;slot&quot; &quot;slow&quot; &quot;slub&quot; &quot;slue&quot; &quot;slug&quot; &quot;slum&quot; &quot;slur&quot; &quot;slut&quot;
## [3221] &quot;smew&quot; &quot;smit&quot; &quot;smog&quot; &quot;smug&quot; &quot;smut&quot; &quot;snag&quot; &quot;snap&quot; &quot;snaw&quot; &quot;sned&quot; &quot;snib&quot;
## [3231] &quot;snip&quot; &quot;snit&quot; &quot;snob&quot; &quot;snog&quot; &quot;snot&quot; &quot;snow&quot; &quot;snub&quot; &quot;snug&quot; &quot;snye&quot; &quot;soak&quot;
## [3241] &quot;soap&quot; &quot;soar&quot; &quot;soba&quot; &quot;sobs&quot; &quot;soca&quot; &quot;sock&quot; &quot;soda&quot; &quot;sods&quot; &quot;sofa&quot; &quot;soft&quot;
## [3251] &quot;soil&quot; &quot;soja&quot; &quot;soke&quot; &quot;sola&quot; &quot;sold&quot; &quot;sole&quot; &quot;soli&quot; &quot;solo&quot; &quot;sols&quot; &quot;soma&quot;
## [3261] &quot;some&quot; &quot;soms&quot; &quot;sone&quot; &quot;song&quot; &quot;sons&quot; &quot;sook&quot; &quot;soon&quot; &quot;soot&quot; &quot;soph&quot; &quot;sops&quot;
## [3271] &quot;sora&quot; &quot;sorb&quot; &quot;sord&quot; &quot;sore&quot; &quot;sori&quot; &quot;sorn&quot; &quot;sort&quot; &quot;soth&quot; &quot;sots&quot; &quot;souk&quot;
## [3281] &quot;soul&quot; &quot;soup&quot; &quot;sour&quot; &quot;sous&quot; &quot;sown&quot; &quot;sows&quot; &quot;soya&quot; &quot;soys&quot; &quot;spae&quot; &quot;spam&quot;
## [3291] &quot;span&quot; &quot;spar&quot; &quot;spas&quot; &quot;spat&quot; &quot;spay&quot; &quot;spaz&quot; &quot;spec&quot; &quot;sped&quot; &quot;spew&quot; &quot;spic&quot;
## [3301] &quot;spik&quot; &quot;spin&quot; &quot;spit&quot; &quot;spiv&quot; &quot;spot&quot; &quot;spry&quot; &quot;spud&quot; &quot;spue&quot; &quot;spun&quot; &quot;spur&quot;
## [3311] &quot;sris&quot; &quot;stab&quot; &quot;stag&quot; &quot;star&quot; &quot;stat&quot; &quot;staw&quot; &quot;stay&quot; &quot;stem&quot; &quot;step&quot; &quot;stet&quot;
## [3321] &quot;stew&quot; &quot;stey&quot; &quot;stir&quot; &quot;stoa&quot; &quot;stob&quot; &quot;stop&quot; &quot;stot&quot; &quot;stow&quot; &quot;stub&quot; &quot;stud&quot;
## [3331] &quot;stum&quot; &quot;stun&quot; &quot;stye&quot; &quot;suba&quot; &quot;subs&quot; &quot;such&quot; &quot;suck&quot; &quot;sudd&quot; &quot;suds&quot; &quot;sued&quot;
## [3341] &quot;suer&quot; &quot;sues&quot; &quot;suet&quot; &quot;sugh&quot; &quot;suit&quot; &quot;suks&quot; &quot;sulk&quot; &quot;sulu&quot; &quot;sumo&quot; &quot;sump&quot;
## [3351] &quot;sums&quot; &quot;sung&quot; &quot;sunk&quot; &quot;sunn&quot; &quot;suns&quot; &quot;supe&quot; &quot;sups&quot; &quot;suqs&quot; &quot;sura&quot; &quot;surd&quot;
## [3361] &quot;sure&quot; &quot;surf&quot; &quot;suss&quot; &quot;swab&quot; &quot;swag&quot; &quot;swam&quot; &quot;swan&quot; &quot;swap&quot; &quot;swat&quot; &quot;sway&quot;
## [3371] &quot;swig&quot; &quot;swim&quot; &quot;swob&quot; &quot;swop&quot; &quot;swot&quot; &quot;swum&quot; &quot;sybo&quot; &quot;syce&quot; &quot;syke&quot; &quot;syli&quot;
## [3381] &quot;sync&quot; &quot;syne&quot; &quot;syph&quot; &quot;tabs&quot; &quot;tabu&quot; &quot;tace&quot; &quot;tach&quot; &quot;tack&quot; &quot;taco&quot; &quot;tact&quot;
## [3391] &quot;tads&quot; &quot;tael&quot; &quot;tags&quot; &quot;tahr&quot; &quot;tail&quot; &quot;tain&quot; &quot;taka&quot; &quot;take&quot; &quot;tala&quot; &quot;talc&quot;
## [3401] &quot;tale&quot; &quot;tali&quot; &quot;talk&quot; &quot;tal&quot;  &quot;tame&quot; &quot;tamp&quot; &quot;tams&quot; &quot;tang&quot; &quot;tank&quot; &quot;tans&quot;
## [3411] &quot;taos&quot; &quot;tapa&quot; &quot;tape&quot; &quot;taps&quot; &quot;tare&quot; &quot;tarn&quot; &quot;taro&quot; &quot;tarp&quot; &quot;tars&quot; &quot;tart&quot;
## [3421] &quot;task&quot; &quot;tass&quot; &quot;tate&quot; &quot;tats&quot; &quot;taus&quot; &quot;taut&quot; &quot;tavs&quot; &quot;taws&quot; &quot;taxa&quot; &quot;taxi&quot;
## [3431] &quot;teak&quot; &quot;teal&quot; &quot;team&quot; &quot;tear&quot; &quot;teas&quot; &quot;teat&quot; &quot;tech&quot; &quot;teds&quot; &quot;teed&quot; &quot;teel&quot;
## [3441] &quot;teem&quot; &quot;teen&quot; &quot;tees&quot; &quot;teff&quot; &quot;tegg&quot; &quot;tegs&quot; &quot;tela&quot; &quot;tele&quot; &quot;tel&quot;  &quot;tels&quot;
## [3451] &quot;temp&quot; &quot;tend&quot; &quot;tens&quot; &quot;tent&quot; &quot;tepa&quot; &quot;term&quot; &quot;tern&quot; &quot;test&quot; &quot;teth&quot; &quot;tets&quot;
## [3461] &quot;tews&quot; &quot;text&quot; &quot;thae&quot; &quot;than&quot; &quot;that&quot; &quot;thaw&quot; &quot;thee&quot; &quot;them&quot; &quot;then&quot; &quot;thew&quot;
## [3471] &quot;they&quot; &quot;thin&quot; &quot;thio&quot; &quot;thir&quot; &quot;this&quot; &quot;thou&quot; &quot;thro&quot; &quot;thru&quot; &quot;thud&quot; &quot;thug&quot;
## [3481] &quot;thus&quot; &quot;tick&quot; &quot;tics&quot; &quot;tide&quot; &quot;tidy&quot; &quot;tied&quot; &quot;tier&quot; &quot;ties&quot; &quot;tiff&quot; &quot;tike&quot;
## [3491] &quot;tiki&quot; &quot;tile&quot; &quot;til&quot;  &quot;tils&quot; &quot;tilt&quot; &quot;time&quot; &quot;tine&quot; &quot;ting&quot; &quot;tins&quot; &quot;tint&quot;
## [3501] &quot;tiny&quot; &quot;tipi&quot; &quot;tips&quot; &quot;tire&quot; &quot;tirl&quot; &quot;tiro&quot; &quot;titi&quot; &quot;tits&quot; &quot;tivy&quot; &quot;toad&quot;
## [3511] &quot;toby&quot; &quot;tods&quot; &quot;tody&quot; &quot;toea&quot; &quot;toed&quot; &quot;toes&quot; &quot;toff&quot; &quot;toft&quot; &quot;tofu&quot; &quot;toga&quot;
## [3521] &quot;togs&quot; &quot;toil&quot; &quot;toit&quot; &quot;toke&quot; &quot;tola&quot; &quot;told&quot; &quot;tole&quot; &quot;tol&quot;  &quot;tolu&quot; &quot;tomb&quot;
## [3531] &quot;tome&quot; &quot;toms&quot; &quot;tone&quot; &quot;tong&quot; &quot;tons&quot; &quot;tony&quot; &quot;took&quot; &quot;tool&quot; &quot;toom&quot; &quot;toon&quot;
## [3541] &quot;toot&quot; &quot;tope&quot; &quot;toph&quot; &quot;topi&quot; &quot;topo&quot; &quot;tops&quot; &quot;tora&quot; &quot;torc&quot; &quot;tore&quot; &quot;tori&quot;
## [3551] &quot;torn&quot; &quot;toro&quot; &quot;torr&quot; &quot;tors&quot; &quot;tort&quot; &quot;tory&quot; &quot;tosh&quot; &quot;toss&quot; &quot;tost&quot; &quot;tote&quot;
## [3561] &quot;tots&quot; &quot;tour&quot; &quot;tout&quot; &quot;town&quot; &quot;tows&quot; &quot;towy&quot; &quot;toyo&quot; &quot;toys&quot; &quot;trad&quot; &quot;tram&quot;
## [3571] &quot;trap&quot; &quot;tray&quot; &quot;tree&quot; &quot;tref&quot; &quot;trek&quot; &quot;tres&quot; &quot;tret&quot; &quot;trey&quot; &quot;trig&quot; &quot;trim&quot;
## [3581] &quot;trio&quot; &quot;trip&quot; &quot;trod&quot; &quot;trog&quot; &quot;trop&quot; &quot;trot&quot; &quot;trow&quot; &quot;troy&quot; &quot;true&quot; &quot;trug&quot;
## [3591] &quot;tsar&quot; &quot;tsks&quot; &quot;tuba&quot; &quot;tube&quot; &quot;tubs&quot; &quot;tuck&quot; &quot;tufa&quot; &quot;tuff&quot; &quot;tuft&quot; &quot;tugs&quot;
## [3601] &quot;tuis&quot; &quot;tule&quot; &quot;tump&quot; &quot;tuna&quot; &quot;tune&quot; &quot;tung&quot; &quot;tuns&quot; &quot;tups&quot; &quot;turd&quot; &quot;turf&quot;
## [3611] &quot;turk&quot; &quot;turn&quot; &quot;tush&quot; &quot;tusk&quot; &quot;tuts&quot; &quot;tutu&quot; &quot;twae&quot; &quot;twas&quot; &quot;twat&quot; &quot;twee&quot;
## [3621] &quot;twig&quot; &quot;twin&quot; &quot;twit&quot; &quot;twos&quot; &quot;tyee&quot; &quot;tyer&quot; &quot;tyes&quot; &quot;tyin&quot; &quot;tyke&quot; &quot;tyne&quot;
## [3631] &quot;type&quot; &quot;typo&quot; &quot;typp&quot; &quot;typy&quot; &quot;tyre&quot; &quot;tyro&quot; &quot;tzar&quot; &quot;udon&quot; &quot;udos&quot; &quot;ughs&quot;
## [3641] &quot;ugly&quot; &quot;ukes&quot; &quot;ulan&quot; &quot;ulna&quot; &quot;ulus&quot; &quot;ulva&quot; &quot;umbo&quot; &quot;umps&quot; &quot;unai&quot; &quot;unau&quot;
## [3651] &quot;unbe&quot; &quot;unci&quot; &quot;unco&quot; &quot;unde&quot; &quot;undo&quot; &quot;undy&quot; &quot;unit&quot; &quot;unto&quot; &quot;upas&quot; &quot;upby&quot;
## [3661] &quot;updo&quot; &quot;upon&quot; &quot;urbs&quot; &quot;urds&quot; &quot;urea&quot; &quot;urge&quot; &quot;uric&quot; &quot;urns&quot; &quot;urps&quot; &quot;ursa&quot;
## [3671] &quot;urus&quot; &quot;used&quot; &quot;user&quot; &quot;uses&quot; &quot;utas&quot; &quot;utes&quot; &quot;uvea&quot; &quot;vacs&quot; &quot;vagi&quot; &quot;vail&quot;
## [3681] &quot;vain&quot; &quot;vair&quot; &quot;vale&quot; &quot;vamp&quot; &quot;vane&quot; &quot;vang&quot; &quot;vans&quot; &quot;vara&quot; &quot;vars&quot; &quot;vary&quot;
## [3691] &quot;vasa&quot; &quot;vase&quot; &quot;vast&quot; &quot;vats&quot; &quot;vatu&quot; &quot;vaus&quot; &quot;vavs&quot; &quot;vaws&quot; &quot;veal&quot; &quot;veep&quot;
## [3701] &quot;veer&quot; &quot;vees&quot; &quot;veil&quot; &quot;vein&quot; &quot;vela&quot; &quot;veld&quot; &quot;vena&quot; &quot;vend&quot; &quot;vent&quot; &quot;vera&quot;
## [3711] &quot;verb&quot; &quot;vert&quot; &quot;very&quot; &quot;vest&quot; &quot;veto&quot; &quot;vets&quot; &quot;vext&quot; &quot;vial&quot; &quot;vibe&quot; &quot;vice&quot;
## [3721] &quot;vide&quot; &quot;vids&quot; &quot;vied&quot; &quot;vier&quot; &quot;vies&quot; &quot;view&quot; &quot;viga&quot; &quot;vigs&quot; &quot;vile&quot; &quot;vil&quot; 
## [3731] &quot;vims&quot; &quot;vina&quot; &quot;vine&quot; &quot;vino&quot; &quot;viny&quot; &quot;viol&quot; &quot;virl&quot; &quot;visa&quot; &quot;vise&quot; &quot;vita&quot;
## [3741] &quot;viva&quot; &quot;vive&quot; &quot;voes&quot; &quot;void&quot; &quot;vole&quot; &quot;volt&quot; &quot;vote&quot; &quot;vows&quot; &quot;vrow&quot; &quot;vugg&quot;
## [3751] &quot;vugh&quot; &quot;vugs&quot; &quot;wabs&quot; &quot;wack&quot; &quot;wade&quot; &quot;wadi&quot; &quot;wads&quot; &quot;wady&quot; &quot;waes&quot; &quot;waff&quot;
## [3761] &quot;waft&quot; &quot;wage&quot; &quot;wags&quot; &quot;waif&quot; &quot;wail&quot; &quot;wain&quot; &quot;wair&quot; &quot;wait&quot; &quot;wake&quot; &quot;wale&quot;
## [3771] &quot;walk&quot; &quot;wal&quot;  &quot;waly&quot; &quot;wame&quot; &quot;wand&quot; &quot;wane&quot; &quot;wank&quot; &quot;wans&quot; &quot;want&quot; &quot;wany&quot;
## [3781] &quot;waps&quot; &quot;ward&quot; &quot;ware&quot; &quot;wark&quot; &quot;warm&quot; &quot;warn&quot; &quot;warp&quot; &quot;wars&quot; &quot;wart&quot; &quot;wary&quot;
## [3791] &quot;wash&quot; &quot;wasp&quot; &quot;wast&quot; &quot;wats&quot; &quot;watt&quot; &quot;wauk&quot; &quot;waul&quot; &quot;waur&quot; &quot;wave&quot; &quot;wavy&quot;
## [3801] &quot;wawl&quot; &quot;waws&quot; &quot;waxy&quot; &quot;ways&quot; &quot;weak&quot; &quot;weal&quot; &quot;wean&quot; &quot;wear&quot; &quot;webs&quot; &quot;weds&quot;
## [3811] &quot;weed&quot; &quot;week&quot; &quot;weel&quot; &quot;ween&quot; &quot;weep&quot; &quot;weer&quot; &quot;wees&quot; &quot;weet&quot; &quot;weft&quot; &quot;weir&quot;
## [3821] &quot;weka&quot; &quot;weld&quot; &quot;wel&quot;  &quot;welt&quot; &quot;wend&quot; &quot;wens&quot; &quot;went&quot; &quot;wept&quot; &quot;were&quot; &quot;wert&quot;
## [3831] &quot;west&quot; &quot;wets&quot; &quot;wham&quot; &quot;whap&quot; &quot;what&quot; &quot;whee&quot; &quot;when&quot; &quot;whet&quot; &quot;whew&quot; &quot;whey&quot;
## [3841] &quot;whid&quot; &quot;whig&quot; &quot;whim&quot; &quot;whin&quot; &quot;whip&quot; &quot;whir&quot; &quot;whit&quot; &quot;whiz&quot; &quot;whoa&quot; &quot;whom&quot;
## [3851] &quot;whop&quot; &quot;whup&quot; &quot;whys&quot; &quot;wich&quot; &quot;wick&quot; &quot;wide&quot; &quot;wife&quot; &quot;wigs&quot; &quot;wild&quot; &quot;wile&quot;
## [3861] &quot;wil&quot;  &quot;wilt&quot; &quot;wily&quot; &quot;wimp&quot; &quot;wind&quot; &quot;wine&quot; &quot;wing&quot; &quot;wink&quot; &quot;wino&quot; &quot;wins&quot;
## [3871] &quot;winy&quot; &quot;wipe&quot; &quot;wire&quot; &quot;wiry&quot; &quot;wise&quot; &quot;wish&quot; &quot;wisp&quot; &quot;wiss&quot; &quot;wist&quot; &quot;wite&quot;
## [3881] &quot;with&quot; &quot;wits&quot; &quot;wive&quot; &quot;woad&quot; &quot;woes&quot; &quot;wogs&quot; &quot;woke&quot; &quot;woks&quot; &quot;wold&quot; &quot;wolf&quot;
## [3891] &quot;womb&quot; &quot;wonk&quot; &quot;wons&quot; &quot;wont&quot; &quot;wood&quot; &quot;woof&quot; &quot;wool&quot; &quot;woos&quot; &quot;wops&quot; &quot;word&quot;
## [3901] &quot;wore&quot; &quot;work&quot; &quot;worm&quot; &quot;worn&quot; &quot;wort&quot; &quot;wost&quot; &quot;wots&quot; &quot;wove&quot; &quot;wows&quot; &quot;wrap&quot;
## [3911] &quot;wren&quot; &quot;writ&quot; &quot;wuss&quot; &quot;wych&quot; &quot;wyes&quot; &quot;wyle&quot; &quot;wynd&quot; &quot;wynn&quot; &quot;wyns&quot; &quot;wyte&quot;
## [3921] &quot;xyst&quot; &quot;yack&quot; &quot;yaff&quot; &quot;yagi&quot; &quot;yags&quot; &quot;yaks&quot; &quot;yald&quot; &quot;yams&quot; &quot;yang&quot; &quot;yank&quot;
## [3931] &quot;yaps&quot; &quot;yard&quot; &quot;yare&quot; &quot;yarn&quot; &quot;yaud&quot; &quot;yaup&quot; &quot;yawl&quot; &quot;yawn&quot; &quot;yawp&quot; &quot;yaws&quot;
## [3941] &quot;yays&quot; &quot;yeah&quot; &quot;yean&quot; &quot;year&quot; &quot;yeas&quot; &quot;yech&quot; &quot;yegg&quot; &quot;yeld&quot; &quot;yelk&quot; &quot;yel&quot; 
## [3951] &quot;yelp&quot; &quot;yens&quot; &quot;yeps&quot; &quot;yerk&quot; &quot;yeti&quot; &quot;yett&quot; &quot;yeuk&quot; &quot;yews&quot; &quot;yids&quot; &quot;yil&quot; 
## [3961] &quot;yins&quot; &quot;yipe&quot; &quot;yips&quot; &quot;yird&quot; &quot;yirr&quot; &quot;ylem&quot; &quot;yobs&quot; &quot;yock&quot; &quot;yodh&quot; &quot;yods&quot;
## [3971] &quot;yoga&quot; &quot;yogh&quot; &quot;yogi&quot; &quot;yoke&quot; &quot;yoks&quot; &quot;yolk&quot; &quot;yond&quot; &quot;yoni&quot; &quot;yore&quot; &quot;your&quot;
## [3981] &quot;yous&quot; &quot;yowe&quot; &quot;yowl&quot; &quot;yows&quot; &quot;yuan&quot; &quot;yuca&quot; &quot;yuch&quot; &quot;yuck&quot; &quot;yuga&quot; &quot;yuks&quot;
## [3991] &quot;yule&quot; &quot;yups&quot; &quot;yurt&quot; &quot;yutz&quot; &quot;ywis&quot; &quot;zags&quot; &quot;zany&quot; &quot;zaps&quot; &quot;zarf&quot; &quot;zeal&quot;
## [4001] &quot;zebu&quot; &quot;zeds&quot; &quot;zees&quot; &quot;zein&quot; &quot;zeks&quot; &quot;zeps&quot; &quot;zerk&quot; &quot;zero&quot; &quot;zest&quot; &quot;zeta&quot;
## [4011] &quot;zigs&quot; &quot;zil&quot;  &quot;zinc&quot; &quot;zine&quot; &quot;zing&quot; &quot;zins&quot; &quot;zips&quot; &quot;ziti&quot; &quot;zits&quot; &quot;zoea&quot;
## [4021] &quot;zoic&quot; &quot;zona&quot; &quot;zone&quot; &quot;zonk&quot; &quot;zoom&quot; &quot;zoon&quot; &quot;zoos&quot; &quot;zori&quot; &quot;zouk&quot; &quot;zyme&quot;</code></pre>
<p><strong>Question 2</strong></p>
<pre class="r"><code>gsub(&quot;^g&quot;, &quot;G&quot;, words)</code></pre>
<pre><code>##    [1] &quot;aahs&quot; &quot;aals&quot; &quot;abas&quot; &quot;abba&quot; &quot;abbe&quot; &quot;abed&quot; &quot;abet&quot; &quot;able&quot; &quot;ably&quot; &quot;abos&quot;
##   [11] &quot;abri&quot; &quot;abut&quot; &quot;abye&quot; &quot;abys&quot; &quot;aced&quot; &quot;aces&quot; &quot;ache&quot; &quot;achy&quot; &quot;acid&quot; &quot;acme&quot;
##   [21] &quot;acne&quot; &quot;acre&quot; &quot;acta&quot; &quot;acts&quot; &quot;acyl&quot; &quot;adds&quot; &quot;adit&quot; &quot;ados&quot; &quot;adze&quot; &quot;aeon&quot;
##   [31] &quot;aero&quot; &quot;aery&quot; &quot;afar&quot; &quot;agar&quot; &quot;agas&quot; &quot;aged&quot; &quot;agee&quot; &quot;ager&quot; &quot;ages&quot; &quot;agha&quot;
##   [41] &quot;agin&quot; &quot;agio&quot; &quot;agly&quot; &quot;agma&quot; &quot;agog&quot; &quot;agon&quot; &quot;ague&quot; &quot;ahed&quot; &quot;ahem&quot; &quot;ahis&quot;
##   [51] &quot;ahoy&quot; &quot;aide&quot; &quot;aids&quot; &quot;ails&quot; &quot;aims&quot; &quot;ains&quot; &quot;airn&quot; &quot;airs&quot; &quot;airt&quot; &quot;airy&quot;
##   [61] &quot;aits&quot; &quot;ajar&quot; &quot;ajee&quot; &quot;akee&quot; &quot;akin&quot; &quot;alae&quot; &quot;alan&quot; &quot;alar&quot; &quot;alas&quot; &quot;alba&quot;
##   [71] &quot;albs&quot; &quot;alec&quot; &quot;alee&quot; &quot;alef&quot; &quot;ales&quot; &quot;alfa&quot; &quot;alga&quot; &quot;alif&quot; &quot;alit&quot; &quot;alky&quot;
##   [81] &quot;alls&quot; &quot;ally&quot; &quot;alma&quot; &quot;alme&quot; &quot;alms&quot; &quot;aloe&quot; &quot;alow&quot; &quot;alps&quot; &quot;also&quot; &quot;alto&quot;
##   [91] &quot;alts&quot; &quot;alum&quot; &quot;amah&quot; &quot;amas&quot; &quot;ambo&quot; &quot;amen&quot; &quot;amia&quot; &quot;amid&quot; &quot;amie&quot; &quot;amin&quot;
##  [101] &quot;amir&quot; &quot;amis&quot; &quot;ammo&quot; &quot;amok&quot; &quot;amps&quot; &quot;amus&quot; &quot;amyl&quot; &quot;anal&quot; &quot;anas&quot; &quot;ands&quot;
##  [111] &quot;anes&quot; &quot;anew&quot; &quot;anga&quot; &quot;anil&quot; &quot;anis&quot; &quot;ankh&quot; &quot;anna&quot; &quot;anoa&quot; &quot;anon&quot; &quot;ansa&quot;
##  [121] &quot;anta&quot; &quot;ante&quot; &quot;anti&quot; &quot;ants&quot; &quot;anus&quot; &quot;aped&quot; &quot;aper&quot; &quot;apes&quot; &quot;apex&quot; &quot;apod&quot;
##  [131] &quot;apos&quot; &quot;apps&quot; &quot;apse&quot; &quot;aqua&quot; &quot;arak&quot; &quot;arbs&quot; &quot;arch&quot; &quot;arco&quot; &quot;arcs&quot; &quot;area&quot;
##  [141] &quot;ares&quot; &quot;arfs&quot; &quot;aria&quot; &quot;arid&quot; &quot;aril&quot; &quot;arks&quot; &quot;arms&quot; &quot;army&quot; &quot;arse&quot; &quot;arts&quot;
##  [151] &quot;arty&quot; &quot;arum&quot; &quot;arvo&quot; &quot;aryl&quot; &quot;asci&quot; &quot;asea&quot; &quot;ashy&quot; &quot;asks&quot; &quot;asps&quot; &quot;atap&quot;
##  [161] &quot;ates&quot; &quot;atma&quot; &quot;atom&quot; &quot;atop&quot; &quot;auks&quot; &quot;auld&quot; &quot;aunt&quot; &quot;aura&quot; &quot;auto&quot; &quot;aver&quot;
##  [171] &quot;aves&quot; &quot;avid&quot; &quot;avos&quot; &quot;avow&quot; &quot;away&quot; &quot;awed&quot; &quot;awee&quot; &quot;awes&quot; &quot;awls&quot; &quot;awns&quot;
##  [181] &quot;awny&quot; &quot;awol&quot; &quot;awry&quot; &quot;axal&quot; &quot;axed&quot; &quot;axel&quot; &quot;axes&quot; &quot;axil&quot; &quot;axis&quot; &quot;axle&quot;
##  [191] &quot;axon&quot; &quot;ayah&quot; &quot;ayes&quot; &quot;ayin&quot; &quot;azan&quot; &quot;azon&quot; &quot;baal&quot; &quot;baas&quot; &quot;baba&quot; &quot;babe&quot;
##  [201] &quot;babu&quot; &quot;baby&quot; &quot;bach&quot; &quot;back&quot; &quot;bade&quot; &quot;bads&quot; &quot;baff&quot; &quot;bags&quot; &quot;baht&quot; &quot;bail&quot;
##  [211] &quot;bait&quot; &quot;bake&quot; &quot;bald&quot; &quot;bale&quot; &quot;balk&quot; &quot;ball&quot; &quot;balm&quot; &quot;bals&quot; &quot;bams&quot; &quot;band&quot;
##  [221] &quot;bane&quot; &quot;bang&quot; &quot;bani&quot; &quot;bank&quot; &quot;bans&quot; &quot;baps&quot; &quot;barb&quot; &quot;bard&quot; &quot;bare&quot; &quot;barf&quot;
##  [231] &quot;bark&quot; &quot;barm&quot; &quot;barn&quot; &quot;bars&quot; &quot;base&quot; &quot;bash&quot; &quot;bask&quot; &quot;bass&quot; &quot;bast&quot; &quot;bate&quot;
##  [241] &quot;bath&quot; &quot;bats&quot; &quot;batt&quot; &quot;baud&quot; &quot;bawd&quot; &quot;bawl&quot; &quot;bays&quot; &quot;bead&quot; &quot;beak&quot; &quot;beam&quot;
##  [251] &quot;bean&quot; &quot;bear&quot; &quot;beat&quot; &quot;beau&quot; &quot;beck&quot; &quot;beds&quot; &quot;bedu&quot; &quot;beef&quot; &quot;been&quot; &quot;beep&quot;
##  [261] &quot;beer&quot; &quot;bees&quot; &quot;beet&quot; &quot;begs&quot; &quot;bell&quot; &quot;bels&quot; &quot;belt&quot; &quot;bema&quot; &quot;bend&quot; &quot;bene&quot;
##  [271] &quot;bens&quot; &quot;bent&quot; &quot;berg&quot; &quot;berk&quot; &quot;berm&quot; &quot;best&quot; &quot;beta&quot; &quot;beth&quot; &quot;bets&quot; &quot;bevy&quot;
##  [281] &quot;beys&quot; &quot;bhut&quot; &quot;bias&quot; &quot;bibb&quot; &quot;bibs&quot; &quot;bice&quot; &quot;bide&quot; &quot;bidi&quot; &quot;bids&quot; &quot;bier&quot;
##  [291] &quot;biff&quot; &quot;bigs&quot; &quot;bike&quot; &quot;bile&quot; &quot;bilk&quot; &quot;bill&quot; &quot;bima&quot; &quot;bind&quot; &quot;bine&quot; &quot;bins&quot;
##  [301] &quot;bint&quot; &quot;biog&quot; &quot;bios&quot; &quot;bird&quot; &quot;birk&quot; &quot;birl&quot; &quot;biro&quot; &quot;birr&quot; &quot;bise&quot; &quot;bisk&quot;
##  [311] &quot;bite&quot; &quot;bits&quot; &quot;bitt&quot; &quot;bize&quot; &quot;blab&quot; &quot;blae&quot; &quot;blah&quot; &quot;blam&quot; &quot;blat&quot; &quot;blaw&quot;
##  [321] &quot;bleb&quot; &quot;bled&quot; &quot;blet&quot; &quot;blew&quot; &quot;blin&quot; &quot;blip&quot; &quot;blob&quot; &quot;bloc&quot; &quot;blog&quot; &quot;blot&quot;
##  [331] &quot;blow&quot; &quot;blub&quot; &quot;blue&quot; &quot;blur&quot; &quot;boar&quot; &quot;boas&quot; &quot;boat&quot; &quot;bobs&quot; &quot;bock&quot; &quot;bode&quot;
##  [341] &quot;bods&quot; &quot;body&quot; &quot;boff&quot; &quot;bogs&quot; &quot;bogy&quot; &quot;boho&quot; &quot;boil&quot; &quot;bola&quot; &quot;bold&quot; &quot;bole&quot;
##  [351] &quot;boll&quot; &quot;bolo&quot; &quot;bolt&quot; &quot;bomb&quot; &quot;bond&quot; &quot;bone&quot; &quot;bong&quot; &quot;bonk&quot; &quot;bony&quot; &quot;boob&quot;
##  [361] &quot;book&quot; &quot;boom&quot; &quot;boon&quot; &quot;boor&quot; &quot;boos&quot; &quot;boot&quot; &quot;bops&quot; &quot;bora&quot; &quot;bore&quot; &quot;bork&quot;
##  [371] &quot;born&quot; &quot;bort&quot; &quot;bosh&quot; &quot;bosk&quot; &quot;boss&quot; &quot;bota&quot; &quot;both&quot; &quot;bots&quot; &quot;bott&quot; &quot;bout&quot;
##  [381] &quot;bowl&quot; &quot;bows&quot; &quot;boxy&quot; &quot;boyo&quot; &quot;boys&quot; &quot;bozo&quot; &quot;brad&quot; &quot;brae&quot; &quot;brag&quot; &quot;bran&quot;
##  [391] &quot;bras&quot; &quot;brat&quot; &quot;braw&quot; &quot;bray&quot; &quot;bred&quot; &quot;bree&quot; &quot;bren&quot; &quot;brew&quot; &quot;brie&quot; &quot;brig&quot;
##  [401] &quot;brim&quot; &quot;brin&quot; &quot;brio&quot; &quot;bris&quot; &quot;brit&quot; &quot;broo&quot; &quot;bros&quot; &quot;brow&quot; &quot;brrr&quot; &quot;brut&quot;
##  [411] &quot;brux&quot; &quot;bubo&quot; &quot;bubs&quot; &quot;bubu&quot; &quot;buck&quot; &quot;buds&quot; &quot;buff&quot; &quot;bugs&quot; &quot;buhl&quot; &quot;buhr&quot;
##  [421] &quot;bulb&quot; &quot;bulk&quot; &quot;bull&quot; &quot;bumf&quot; &quot;bump&quot; &quot;bums&quot; &quot;buna&quot; &quot;bund&quot; &quot;bung&quot; &quot;bunk&quot;
##  [431] &quot;bunn&quot; &quot;buns&quot; &quot;bunt&quot; &quot;buoy&quot; &quot;bura&quot; &quot;burb&quot; &quot;burd&quot; &quot;burg&quot; &quot;burl&quot; &quot;burn&quot;
##  [441] &quot;burp&quot; &quot;burr&quot; &quot;burs&quot; &quot;bury&quot; &quot;bush&quot; &quot;busk&quot; &quot;buss&quot; &quot;bust&quot; &quot;busy&quot; &quot;bute&quot;
##  [451] &quot;buts&quot; &quot;butt&quot; &quot;buys&quot; &quot;buzz&quot; &quot;byes&quot; &quot;byre&quot; &quot;byrl&quot; &quot;byte&quot; &quot;cabs&quot; &quot;caca&quot;
##  [461] &quot;cade&quot; &quot;cadi&quot; &quot;cads&quot; &quot;cafe&quot; &quot;caff&quot; &quot;cage&quot; &quot;cagy&quot; &quot;caid&quot; &quot;cain&quot; &quot;cake&quot;
##  [471] &quot;caky&quot; &quot;calf&quot; &quot;calk&quot; &quot;call&quot; &quot;calm&quot; &quot;calo&quot; &quot;calx&quot; &quot;came&quot; &quot;camo&quot; &quot;camp&quot;
##  [481] &quot;cams&quot; &quot;cane&quot; &quot;cans&quot; &quot;cant&quot; &quot;cape&quot; &quot;caph&quot; &quot;capo&quot; &quot;caps&quot; &quot;carb&quot; &quot;card&quot;
##  [491] &quot;care&quot; &quot;cark&quot; &quot;carl&quot; &quot;carn&quot; &quot;carp&quot; &quot;carr&quot; &quot;cars&quot; &quot;cart&quot; &quot;casa&quot; &quot;case&quot;
##  [501] &quot;cash&quot; &quot;cask&quot; &quot;cast&quot; &quot;cate&quot; &quot;cats&quot; &quot;caul&quot; &quot;cave&quot; &quot;cavy&quot; &quot;caws&quot; &quot;cays&quot;
##  [511] &quot;ceca&quot; &quot;cede&quot; &quot;cedi&quot; &quot;cees&quot; &quot;ceil&quot; &quot;cell&quot; &quot;cels&quot; &quot;celt&quot; &quot;cent&quot; &quot;cepe&quot;
##  [521] &quot;ceps&quot; &quot;cere&quot; &quot;cero&quot; &quot;cess&quot; &quot;cete&quot; &quot;chad&quot; &quot;chai&quot; &quot;cham&quot; &quot;chao&quot; &quot;chap&quot;
##  [531] &quot;char&quot; &quot;chat&quot; &quot;chaw&quot; &quot;chay&quot; &quot;chef&quot; &quot;chew&quot; &quot;chez&quot; &quot;chia&quot; &quot;chic&quot; &quot;chid&quot;
##  [541] &quot;chin&quot; &quot;chip&quot; &quot;chis&quot; &quot;chit&quot; &quot;chon&quot; &quot;chop&quot; &quot;chow&quot; &quot;chub&quot; &quot;chug&quot; &quot;chum&quot;
##  [551] &quot;ciao&quot; &quot;cigs&quot; &quot;cine&quot; &quot;cion&quot; &quot;cire&quot; &quot;cist&quot; &quot;cite&quot; &quot;city&quot; &quot;clad&quot; &quot;clag&quot;
##  [561] &quot;clam&quot; &quot;clan&quot; &quot;clap&quot; &quot;claw&quot; &quot;clay&quot; &quot;clef&quot; &quot;clew&quot; &quot;clip&quot; &quot;clod&quot; &quot;clog&quot;
##  [571] &quot;clon&quot; &quot;clop&quot; &quot;clot&quot; &quot;cloy&quot; &quot;club&quot; &quot;clue&quot; &quot;coal&quot; &quot;coat&quot; &quot;coax&quot; &quot;cobb&quot;
##  [581] &quot;cobs&quot; &quot;coca&quot; &quot;cock&quot; &quot;coco&quot; &quot;coda&quot; &quot;code&quot; &quot;cods&quot; &quot;coed&quot; &quot;coff&quot; &quot;coft&quot;
##  [591] &quot;cogs&quot; &quot;coho&quot; &quot;coif&quot; &quot;coil&quot; &quot;coin&quot; &quot;coir&quot; &quot;coke&quot; &quot;coky&quot; &quot;cola&quot; &quot;cold&quot;
##  [601] &quot;cole&quot; &quot;cols&quot; &quot;colt&quot; &quot;coly&quot; &quot;coma&quot; &quot;comb&quot; &quot;come&quot; &quot;comp&quot; &quot;cone&quot; &quot;coni&quot;
##  [611] &quot;conk&quot; &quot;conn&quot; &quot;cons&quot; &quot;cony&quot; &quot;coof&quot; &quot;cook&quot; &quot;cool&quot; &quot;coon&quot; &quot;coop&quot; &quot;coos&quot;
##  [621] &quot;coot&quot; &quot;cope&quot; &quot;cops&quot; &quot;copy&quot; &quot;cord&quot; &quot;core&quot; &quot;corf&quot; &quot;cork&quot; &quot;corm&quot; &quot;corn&quot;
##  [631] &quot;cors&quot; &quot;cory&quot; &quot;cosh&quot; &quot;coss&quot; &quot;cost&quot; &quot;cosy&quot; &quot;cote&quot; &quot;cots&quot; &quot;coup&quot; &quot;cove&quot;
##  [641] &quot;cowl&quot; &quot;cows&quot; &quot;cowy&quot; &quot;coxa&quot; &quot;coys&quot; &quot;cozy&quot; &quot;crab&quot; &quot;crag&quot; &quot;cram&quot; &quot;crap&quot;
##  [651] &quot;craw&quot; &quot;cred&quot; &quot;crew&quot; &quot;crib&quot; &quot;cris&quot; &quot;crit&quot; &quot;croc&quot; &quot;crop&quot; &quot;crow&quot; &quot;crud&quot;
##  [661] &quot;crus&quot; &quot;crux&quot; &quot;cube&quot; &quot;cubs&quot; &quot;cuds&quot; &quot;cued&quot; &quot;cues&quot; &quot;cuff&quot; &quot;cuif&quot; &quot;cuke&quot;
##  [671] &quot;cull&quot; &quot;culm&quot; &quot;cult&quot; &quot;cunt&quot; &quot;cups&quot; &quot;curb&quot; &quot;curd&quot; &quot;cure&quot; &quot;curf&quot; &quot;curl&quot;
##  [681] &quot;curn&quot; &quot;curr&quot; &quot;curs&quot; &quot;curt&quot; &quot;cusk&quot; &quot;cusp&quot; &quot;cuss&quot; &quot;cute&quot; &quot;cuts&quot; &quot;cwms&quot;
##  [691] &quot;cyan&quot; &quot;cyma&quot; &quot;cyme&quot; &quot;cyst&quot; &quot;czar&quot; &quot;dabs&quot; &quot;dace&quot; &quot;dada&quot; &quot;dado&quot; &quot;dads&quot;
##  [701] &quot;daff&quot; &quot;daft&quot; &quot;dago&quot; &quot;dags&quot; &quot;dahl&quot; &quot;dahs&quot; &quot;dais&quot; &quot;daks&quot; &quot;dale&quot; &quot;dals&quot;
##  [711] &quot;dame&quot; &quot;damn&quot; &quot;damp&quot; &quot;dams&quot; &quot;dang&quot; &quot;dank&quot; &quot;dans&quot; &quot;daps&quot; &quot;darb&quot; &quot;dare&quot;
##  [721] &quot;dark&quot; &quot;darn&quot; &quot;dart&quot; &quot;dash&quot; &quot;data&quot; &quot;date&quot; &quot;dato&quot; &quot;daub&quot; &quot;daut&quot; &quot;davy&quot;
##  [731] &quot;dawk&quot; &quot;dawn&quot; &quot;daws&quot; &quot;dawt&quot; &quot;days&quot; &quot;daze&quot; &quot;dead&quot; &quot;deaf&quot; &quot;deal&quot; &quot;dean&quot;
##  [741] &quot;dear&quot; &quot;debs&quot; &quot;debt&quot; &quot;deck&quot; &quot;deco&quot; &quot;deed&quot; &quot;deem&quot; &quot;deep&quot; &quot;deer&quot; &quot;dees&quot;
##  [751] &quot;deet&quot; &quot;defi&quot; &quot;deft&quot; &quot;defy&quot; &quot;deil&quot; &quot;deke&quot; &quot;dele&quot; &quot;delf&quot; &quot;deli&quot; &quot;dell&quot;
##  [761] &quot;dels&quot; &quot;delt&quot; &quot;deme&quot; &quot;demo&quot; &quot;demy&quot; &quot;dene&quot; &quot;deni&quot; &quot;dens&quot; &quot;dent&quot; &quot;deny&quot;
##  [771] &quot;dere&quot; &quot;derm&quot; &quot;desk&quot; &quot;deva&quot; &quot;devs&quot; &quot;dews&quot; &quot;dewy&quot; &quot;dexy&quot; &quot;deys&quot; &quot;dhak&quot;
##  [781] &quot;dhal&quot; &quot;dhow&quot; &quot;dial&quot; &quot;dibs&quot; &quot;dice&quot; &quot;dick&quot; &quot;dido&quot; &quot;didy&quot; &quot;died&quot; &quot;diel&quot;
##  [791] &quot;dies&quot; &quot;diet&quot; &quot;diff&quot; &quot;difs&quot; &quot;digs&quot; &quot;dike&quot; &quot;dill&quot; &quot;dime&quot; &quot;dims&quot; &quot;dine&quot;
##  [801] &quot;ding&quot; &quot;dink&quot; &quot;dino&quot; &quot;dins&quot; &quot;dint&quot; &quot;diol&quot; &quot;dips&quot; &quot;dipt&quot; &quot;dire&quot; &quot;dirk&quot;
##  [811] &quot;dirl&quot; &quot;dirt&quot; &quot;disc&quot; &quot;dish&quot; &quot;disk&quot; &quot;diss&quot; &quot;dita&quot; &quot;dite&quot; &quot;dits&quot; &quot;ditz&quot;
##  [821] &quot;diva&quot; &quot;dive&quot; &quot;djin&quot; &quot;doat&quot; &quot;doby&quot; &quot;dock&quot; &quot;docs&quot; &quot;dodo&quot; &quot;doer&quot; &quot;does&quot;
##  [831] &quot;doff&quot; &quot;doge&quot; &quot;dogs&quot; &quot;dogy&quot; &quot;doit&quot; &quot;dojo&quot; &quot;dole&quot; &quot;doll&quot; &quot;dols&quot; &quot;dolt&quot;
##  [841] &quot;dome&quot; &quot;doms&quot; &quot;dona&quot; &quot;done&quot; &quot;dong&quot; &quot;dons&quot; &quot;doom&quot; &quot;door&quot; &quot;dopa&quot; &quot;dope&quot;
##  [851] &quot;dopy&quot; &quot;dore&quot; &quot;dork&quot; &quot;dorm&quot; &quot;dorp&quot; &quot;dorr&quot; &quot;dors&quot; &quot;dory&quot; &quot;dose&quot; &quot;doss&quot;
##  [861] &quot;dost&quot; &quot;dote&quot; &quot;doth&quot; &quot;dots&quot; &quot;doty&quot; &quot;doum&quot; &quot;dour&quot; &quot;doux&quot; &quot;dove&quot; &quot;down&quot;
##  [871] &quot;dows&quot; &quot;doxy&quot; &quot;doze&quot; &quot;dozy&quot; &quot;drab&quot; &quot;drag&quot; &quot;dram&quot; &quot;drat&quot; &quot;draw&quot; &quot;dray&quot;
##  [881] &quot;dree&quot; &quot;dreg&quot; &quot;drek&quot; &quot;drew&quot; &quot;drib&quot; &quot;drip&quot; &quot;drop&quot; &quot;drub&quot; &quot;drug&quot; &quot;drum&quot;
##  [891] &quot;drys&quot; &quot;duad&quot; &quot;dual&quot; &quot;dubs&quot; &quot;duce&quot; &quot;duci&quot; &quot;duck&quot; &quot;duct&quot; &quot;dude&quot; &quot;duds&quot;
##  [901] &quot;duel&quot; &quot;dues&quot; &quot;duet&quot; &quot;duff&quot; &quot;dugs&quot; &quot;duit&quot; &quot;duke&quot; &quot;dull&quot; &quot;duly&quot; &quot;duma&quot;
##  [911] &quot;dumb&quot; &quot;dump&quot; &quot;dune&quot; &quot;dung&quot; &quot;dunk&quot; &quot;duns&quot; &quot;dunt&quot; &quot;duos&quot; &quot;dupe&quot; &quot;dups&quot;
##  [921] &quot;dura&quot; &quot;dure&quot; &quot;durn&quot; &quot;duro&quot; &quot;durr&quot; &quot;dusk&quot; &quot;dust&quot; &quot;duty&quot; &quot;dyad&quot; &quot;dyed&quot;
##  [931] &quot;dyer&quot; &quot;dyes&quot; &quot;dyke&quot; &quot;dyne&quot; &quot;each&quot; &quot;earl&quot; &quot;earn&quot; &quot;ears&quot; &quot;ease&quot; &quot;east&quot;
##  [941] &quot;easy&quot; &quot;eath&quot; &quot;eats&quot; &quot;eaux&quot; &quot;eave&quot; &quot;ebbs&quot; &quot;ebon&quot; &quot;eche&quot; &quot;echo&quot; &quot;echt&quot;
##  [951] &quot;ecru&quot; &quot;ecus&quot; &quot;eddo&quot; &quot;eddy&quot; &quot;edge&quot; &quot;edgy&quot; &quot;edhs&quot; &quot;edit&quot; &quot;eels&quot; &quot;eely&quot;
##  [961] &quot;eery&quot; &quot;effs&quot; &quot;efts&quot; &quot;egad&quot; &quot;egal&quot; &quot;eger&quot; &quot;eggs&quot; &quot;eggy&quot; &quot;egis&quot; &quot;egos&quot;
##  [971] &quot;eide&quot; &quot;eked&quot; &quot;ekes&quot; &quot;elan&quot; &quot;elds&quot; &quot;elhi&quot; &quot;elks&quot; &quot;ells&quot; &quot;elms&quot; &quot;elmy&quot;
##  [981] &quot;else&quot; &quot;emes&quot; &quot;emeu&quot; &quot;emic&quot; &quot;emir&quot; &quot;emit&quot; &quot;emmy&quot; &quot;emus&quot; &quot;emyd&quot; &quot;ends&quot;
##  [991] &quot;engs&quot; &quot;enol&quot; &quot;enow&quot; &quot;enuf&quot; &quot;envy&quot; &quot;eons&quot; &quot;epee&quot; &quot;epha&quot; &quot;epic&quot; &quot;epos&quot;
## [1001] &quot;eras&quot; &quot;ergo&quot; &quot;ergs&quot; &quot;erne&quot; &quot;erns&quot; &quot;eros&quot; &quot;errs&quot; &quot;erst&quot; &quot;eses&quot; &quot;esne&quot;
## [1011] &quot;espy&quot; &quot;etas&quot; &quot;etch&quot; &quot;eths&quot; &quot;etic&quot; &quot;etna&quot; &quot;etui&quot; &quot;euro&quot; &quot;even&quot; &quot;ever&quot;
## [1021] &quot;eves&quot; &quot;evil&quot; &quot;ewer&quot; &quot;ewes&quot; &quot;exam&quot; &quot;exec&quot; &quot;exed&quot; &quot;exes&quot; &quot;exit&quot; &quot;exon&quot;
## [1031] &quot;expo&quot; &quot;eyas&quot; &quot;eyed&quot; &quot;eyen&quot; &quot;eyer&quot; &quot;eyes&quot; &quot;eyne&quot; &quot;eyra&quot; &quot;eyre&quot; &quot;eyry&quot;
## [1041] &quot;fabs&quot; &quot;face&quot; &quot;fact&quot; &quot;fade&quot; &quot;fado&quot; &quot;fads&quot; &quot;fags&quot; &quot;fail&quot; &quot;fain&quot; &quot;fair&quot;
## [1051] &quot;fake&quot; &quot;fall&quot; &quot;falx&quot; &quot;fame&quot; &quot;fane&quot; &quot;fang&quot; &quot;fano&quot; &quot;fans&quot; &quot;fard&quot; &quot;fare&quot;
## [1061] &quot;farl&quot; &quot;farm&quot; &quot;faro&quot; &quot;fart&quot; &quot;fash&quot; &quot;fast&quot; &quot;fate&quot; &quot;fats&quot; &quot;faun&quot; &quot;faux&quot;
## [1071] &quot;fava&quot; &quot;fave&quot; &quot;fawn&quot; &quot;fays&quot; &quot;faze&quot; &quot;feal&quot; &quot;fear&quot; &quot;feat&quot; &quot;feck&quot; &quot;feds&quot;
## [1081] &quot;feeb&quot; &quot;feed&quot; &quot;feel&quot; &quot;fees&quot; &quot;feet&quot; &quot;fehs&quot; &quot;fell&quot; &quot;felt&quot; &quot;feme&quot; &quot;fems&quot;
## [1091] &quot;fend&quot; &quot;fens&quot; &quot;feod&quot; &quot;fere&quot; &quot;fern&quot; &quot;fess&quot; &quot;fest&quot; &quot;feta&quot; &quot;fete&quot; &quot;fets&quot;
## [1101] &quot;feud&quot; &quot;feus&quot; &quot;fiar&quot; &quot;fiat&quot; &quot;fibs&quot; &quot;fice&quot; &quot;fico&quot; &quot;fido&quot; &quot;fids&quot; &quot;fief&quot;
## [1111] &quot;fife&quot; &quot;figs&quot; &quot;fila&quot; &quot;file&quot; &quot;fill&quot; &quot;film&quot; &quot;filo&quot; &quot;fils&quot; &quot;find&quot; &quot;fine&quot;
## [1121] &quot;fink&quot; &quot;fino&quot; &quot;fins&quot; &quot;fire&quot; &quot;firm&quot; &quot;firn&quot; &quot;firs&quot; &quot;fisc&quot; &quot;fish&quot; &quot;fist&quot;
## [1131] &quot;fits&quot; &quot;five&quot; &quot;fixt&quot; &quot;fizz&quot; &quot;flab&quot; &quot;flag&quot; &quot;flak&quot; &quot;flam&quot; &quot;flan&quot; &quot;flap&quot;
## [1141] &quot;flat&quot; &quot;flaw&quot; &quot;flax&quot; &quot;flay&quot; &quot;flea&quot; &quot;fled&quot; &quot;flee&quot; &quot;flew&quot; &quot;flex&quot; &quot;fley&quot;
## [1151] &quot;flic&quot; &quot;flip&quot; &quot;flir&quot; &quot;flit&quot; &quot;floc&quot; &quot;floe&quot; &quot;flog&quot; &quot;flop&quot; &quot;flow&quot; &quot;flub&quot;
## [1161] &quot;flue&quot; &quot;flus&quot; &quot;flux&quot; &quot;foal&quot; &quot;foam&quot; &quot;fobs&quot; &quot;foci&quot; &quot;foes&quot; &quot;fogs&quot; &quot;fogy&quot;
## [1171] &quot;fohn&quot; &quot;foil&quot; &quot;foin&quot; &quot;fold&quot; &quot;folk&quot; &quot;fond&quot; &quot;fons&quot; &quot;font&quot; &quot;food&quot; &quot;fool&quot;
## [1181] &quot;foot&quot; &quot;fops&quot; &quot;fora&quot; &quot;forb&quot; &quot;ford&quot; &quot;fore&quot; &quot;fork&quot; &quot;form&quot; &quot;fort&quot; &quot;foss&quot;
## [1191] &quot;foul&quot; &quot;four&quot; &quot;fowl&quot; &quot;foxy&quot; &quot;foys&quot; &quot;fozy&quot; &quot;frae&quot; &quot;frag&quot; &quot;frap&quot; &quot;frat&quot;
## [1201] &quot;fray&quot; &quot;free&quot; &quot;fret&quot; &quot;frig&quot; &quot;frit&quot; &quot;friz&quot; &quot;froe&quot; &quot;frog&quot; &quot;from&quot; &quot;frow&quot;
## [1211] &quot;frug&quot; &quot;fubs&quot; &quot;fuci&quot; &quot;fuck&quot; &quot;fuds&quot; &quot;fuel&quot; &quot;fugs&quot; &quot;fugu&quot; &quot;fuji&quot; &quot;full&quot;
## [1221] &quot;fume&quot; &quot;fumy&quot; &quot;fund&quot; &quot;funk&quot; &quot;funs&quot; &quot;furl&quot; &quot;furs&quot; &quot;fury&quot; &quot;fuse&quot; &quot;fuss&quot;
## [1231] &quot;futz&quot; &quot;fuze&quot; &quot;fuzz&quot; &quot;fyce&quot; &quot;fyke&quot; &quot;Gabs&quot; &quot;Gaby&quot; &quot;Gadi&quot; &quot;Gads&quot; &quot;Gaed&quot;
## [1241] &quot;Gaen&quot; &quot;Gaes&quot; &quot;Gaff&quot; &quot;Gaga&quot; &quot;Gage&quot; &quot;Gags&quot; &quot;Gain&quot; &quot;Gait&quot; &quot;Gala&quot; &quot;Gale&quot;
## [1251] &quot;Gall&quot; &quot;Gals&quot; &quot;Gama&quot; &quot;Gamb&quot; &quot;Game&quot; &quot;Gamp&quot; &quot;Gams&quot; &quot;Gamy&quot; &quot;Gane&quot; &quot;Gang&quot;
## [1261] &quot;Gaol&quot; &quot;Gape&quot; &quot;Gaps&quot; &quot;Gapy&quot; &quot;Garb&quot; &quot;Gars&quot; &quot;Gash&quot; &quot;Gasp&quot; &quot;Gast&quot; &quot;Gate&quot;
## [1271] &quot;Gats&quot; &quot;Gaud&quot; &quot;Gaum&quot; &quot;Gaun&quot; &quot;Gaur&quot; &quot;Gave&quot; &quot;Gawk&quot; &quot;Gawp&quot; &quot;Gays&quot; &quot;Gaze&quot;
## [1281] &quot;Gear&quot; &quot;Geck&quot; &quot;Geds&quot; &quot;Geed&quot; &quot;Geek&quot; &quot;Gees&quot; &quot;Geez&quot; &quot;Geld&quot; &quot;Gels&quot; &quot;Gelt&quot;
## [1291] &quot;Gems&quot; &quot;Gene&quot; &quot;Gens&quot; &quot;Gent&quot; &quot;Genu&quot; &quot;Germ&quot; &quot;Gest&quot; &quot;Geta&quot; &quot;Gets&quot; &quot;Geum&quot;
## [1301] &quot;Ghat&quot; &quot;Ghee&quot; &quot;Ghis&quot; &quot;Gibe&quot; &quot;Gibs&quot; &quot;Gids&quot; &quot;Gied&quot; &quot;Gien&quot; &quot;Gies&quot; &quot;Gift&quot;
## [1311] &quot;Giga&quot; &quot;Gigs&quot; &quot;Gild&quot; &quot;Gill&quot; &quot;Gilt&quot; &quot;Gimp&quot; &quot;Gink&quot; &quot;Gins&quot; &quot;Gips&quot; &quot;Gird&quot;
## [1321] &quot;Girl&quot; &quot;Girn&quot; &quot;Giro&quot; &quot;Girt&quot; &quot;Gist&quot; &quot;Gite&quot; &quot;Gits&quot; &quot;Give&quot; &quot;Glad&quot; &quot;Glam&quot;
## [1331] &quot;Gled&quot; &quot;Glee&quot; &quot;Gleg&quot; &quot;Glen&quot; &quot;Gley&quot; &quot;Glia&quot; &quot;Glib&quot; &quot;Glim&quot; &quot;Glob&quot; &quot;Glom&quot;
## [1341] &quot;Glop&quot; &quot;Glow&quot; &quot;Glue&quot; &quot;Glug&quot; &quot;Glum&quot; &quot;Glut&quot; &quot;Gnar&quot; &quot;Gnat&quot; &quot;Gnaw&quot; &quot;Gnus&quot;
## [1351] &quot;Goad&quot; &quot;Goal&quot; &quot;Goas&quot; &quot;Goat&quot; &quot;Gobo&quot; &quot;Gobs&quot; &quot;Goby&quot; &quot;Gods&quot; &quot;Goer&quot; &quot;Goes&quot;
## [1361] &quot;Gogo&quot; &quot;Gold&quot; &quot;Golf&quot; &quot;Gone&quot; &quot;Gong&quot; &quot;Good&quot; &quot;Goof&quot; &quot;Gook&quot; &quot;Goon&quot; &quot;Goop&quot;
## [1371] &quot;Goos&quot; &quot;Gore&quot; &quot;Gorm&quot; &quot;Gorp&quot; &quot;Gory&quot; &quot;Gosh&quot; &quot;Goth&quot; &quot;Gout&quot; &quot;Gowd&quot; &quot;Gowk&quot;
## [1381] &quot;Gown&quot; &quot;Goys&quot; &quot;Grab&quot; &quot;Grad&quot; &quot;Gram&quot; &quot;Gran&quot; &quot;Grat&quot; &quot;Gray&quot; &quot;Gree&quot; &quot;Grew&quot;
## [1391] &quot;Grey&quot; &quot;Grid&quot; &quot;Grig&quot; &quot;Grim&quot; &quot;Grin&quot; &quot;Grip&quot; &quot;Grit&quot; &quot;Grog&quot; &quot;Grok&quot; &quot;Grot&quot;
## [1401] &quot;Grow&quot; &quot;Grub&quot; &quot;Grue&quot; &quot;Grum&quot; &quot;Guan&quot; &quot;Guar&quot; &quot;Guck&quot; &quot;Gude&quot; &quot;Guff&quot; &quot;Guid&quot;
## [1411] &quot;Gulf&quot; &quot;Gull&quot; &quot;Gulp&quot; &quot;Guls&quot; &quot;Gums&quot; &quot;Gunk&quot; &quot;Guns&quot; &quot;Guru&quot; &quot;Gush&quot; &quot;Gust&quot;
## [1421] &quot;Guts&quot; &quot;Guvs&quot; &quot;Guys&quot; &quot;Gybe&quot; &quot;Gyms&quot; &quot;Gyps&quot; &quot;Gyre&quot; &quot;Gyri&quot; &quot;Gyro&quot; &quot;Gyve&quot;
## [1431] &quot;haaf&quot; &quot;haar&quot; &quot;habu&quot; &quot;hack&quot; &quot;hade&quot; &quot;hadj&quot; &quot;haed&quot; &quot;haem&quot; &quot;haen&quot; &quot;haes&quot;
## [1441] &quot;haet&quot; &quot;haft&quot; &quot;hags&quot; &quot;haha&quot; &quot;hahs&quot; &quot;haik&quot; &quot;hail&quot; &quot;hair&quot; &quot;haji&quot; &quot;hajj&quot;
## [1451] &quot;hake&quot; &quot;haku&quot; &quot;hale&quot; &quot;half&quot; &quot;hall&quot; &quot;halm&quot; &quot;halo&quot; &quot;halt&quot; &quot;hame&quot; &quot;hams&quot;
## [1461] &quot;hand&quot; &quot;hang&quot; &quot;hank&quot; &quot;hant&quot; &quot;haps&quot; &quot;hard&quot; &quot;hare&quot; &quot;hark&quot; &quot;harl&quot; &quot;harm&quot;
## [1471] &quot;harp&quot; &quot;hart&quot; &quot;hash&quot; &quot;hasp&quot; &quot;hast&quot; &quot;hate&quot; &quot;hath&quot; &quot;hats&quot; &quot;haul&quot; &quot;haut&quot;
## [1481] &quot;have&quot; &quot;hawk&quot; &quot;haws&quot; &quot;hays&quot; &quot;haze&quot; &quot;hazy&quot; &quot;head&quot; &quot;heal&quot; &quot;heap&quot; &quot;hear&quot;
## [1491] &quot;heat&quot; &quot;hebe&quot; &quot;heck&quot; &quot;heed&quot; &quot;heel&quot; &quot;heft&quot; &quot;hehs&quot; &quot;heil&quot; &quot;heir&quot; &quot;held&quot;
## [1501] &quot;hell&quot; &quot;helm&quot; &quot;helo&quot; &quot;help&quot; &quot;heme&quot; &quot;hemp&quot; &quot;hems&quot; &quot;hens&quot; &quot;hent&quot; &quot;herb&quot;
## [1511] &quot;herd&quot; &quot;here&quot; &quot;herl&quot; &quot;herm&quot; &quot;hern&quot; &quot;hero&quot; &quot;hers&quot; &quot;hest&quot; &quot;heth&quot; &quot;hets&quot;
## [1521] &quot;hewn&quot; &quot;hews&quot; &quot;hick&quot; &quot;hide&quot; &quot;hied&quot; &quot;hies&quot; &quot;high&quot; &quot;hike&quot; &quot;hila&quot; &quot;hili&quot;
## [1531] &quot;hill&quot; &quot;hilt&quot; &quot;hims&quot; &quot;hind&quot; &quot;hins&quot; &quot;hint&quot; &quot;hips&quot; &quot;hire&quot; &quot;hisn&quot; &quot;hiss&quot;
## [1541] &quot;hist&quot; &quot;hits&quot; &quot;hive&quot; &quot;hoar&quot; &quot;hoax&quot; &quot;hobo&quot; &quot;hobs&quot; &quot;hock&quot; &quot;hods&quot; &quot;hoed&quot;
## [1551] &quot;hoer&quot; &quot;hoes&quot; &quot;hogg&quot; &quot;hogs&quot; &quot;hoke&quot; &quot;hold&quot; &quot;hole&quot; &quot;holk&quot; &quot;holm&quot; &quot;holp&quot;
## [1561] &quot;hols&quot; &quot;holt&quot; &quot;holy&quot; &quot;home&quot; &quot;homo&quot; &quot;homy&quot; &quot;hone&quot; &quot;hong&quot; &quot;honk&quot; &quot;hons&quot;
## [1571] &quot;hood&quot; &quot;hoof&quot; &quot;hook&quot; &quot;hoop&quot; &quot;hoot&quot; &quot;hope&quot; &quot;hops&quot; &quot;hora&quot; &quot;horn&quot; &quot;hose&quot;
## [1581] &quot;host&quot; &quot;hots&quot; &quot;hour&quot; &quot;hove&quot; &quot;howe&quot; &quot;howf&quot; &quot;howk&quot; &quot;howl&quot; &quot;hows&quot; &quot;hoya&quot;
## [1591] &quot;hoys&quot; &quot;hubs&quot; &quot;huck&quot; &quot;hued&quot; &quot;hues&quot; &quot;huff&quot; &quot;huge&quot; &quot;hugs&quot; &quot;huic&quot; &quot;hula&quot;
## [1601] &quot;hulk&quot; &quot;hull&quot; &quot;hump&quot; &quot;hums&quot; &quot;hung&quot; &quot;hunh&quot; &quot;hunk&quot; &quot;huns&quot; &quot;hunt&quot; &quot;hurl&quot;
## [1611] &quot;hurt&quot; &quot;hush&quot; &quot;husk&quot; &quot;huts&quot; &quot;hwan&quot; &quot;hyla&quot; &quot;hymn&quot; &quot;hype&quot; &quot;hypo&quot; &quot;hyps&quot;
## [1621] &quot;hyte&quot; &quot;iamb&quot; &quot;ibex&quot; &quot;ibis&quot; &quot;iced&quot; &quot;ices&quot; &quot;ichs&quot; &quot;icky&quot; &quot;icon&quot; &quot;idea&quot;
## [1631] &quot;idem&quot; &quot;ides&quot; &quot;idle&quot; &quot;idly&quot; &quot;idol&quot; &quot;idyl&quot; &quot;iffy&quot; &quot;iggs&quot; &quot;iglu&quot; &quot;ikat&quot;
## [1641] &quot;ikon&quot; &quot;ilea&quot; &quot;ilex&quot; &quot;ilia&quot; &quot;ilka&quot; &quot;ilks&quot; &quot;ills&quot; &quot;illy&quot; &quot;imam&quot; &quot;imid&quot;
## [1651] &quot;immy&quot; &quot;impi&quot; &quot;imps&quot; &quot;inby&quot; &quot;inch&quot; &quot;info&quot; &quot;inia&quot; &quot;inks&quot; &quot;inky&quot; &quot;inly&quot;
## [1661] &quot;inns&quot; &quot;inro&quot; &quot;inti&quot; &quot;into&quot; &quot;ions&quot; &quot;iota&quot; &quot;ired&quot; &quot;ires&quot; &quot;irid&quot; &quot;iris&quot;
## [1671] &quot;irks&quot; &quot;iron&quot; &quot;isba&quot; &quot;isle&quot; &quot;isms&quot; &quot;itch&quot; &quot;item&quot; &quot;iwis&quot; &quot;ixia&quot; &quot;izar&quot;
## [1681] &quot;jabs&quot; &quot;jack&quot; &quot;jade&quot; &quot;jagg&quot; &quot;jags&quot; &quot;jail&quot; &quot;jake&quot; &quot;jamb&quot; &quot;jams&quot; &quot;jane&quot;
## [1691] &quot;jape&quot; &quot;jarl&quot; &quot;jars&quot; &quot;jato&quot; &quot;jauk&quot; &quot;jaup&quot; &quot;java&quot; &quot;jaws&quot; &quot;jays&quot; &quot;jazz&quot;
## [1701] &quot;jean&quot; &quot;jeed&quot; &quot;jeep&quot; &quot;jeer&quot; &quot;jees&quot; &quot;jeez&quot; &quot;jefe&quot; &quot;jehu&quot; &quot;jell&quot; &quot;jeon&quot;
## [1711] &quot;jerk&quot; &quot;jess&quot; &quot;jest&quot; &quot;jete&quot; &quot;jets&quot; &quot;jeux&quot; &quot;jews&quot; &quot;jiao&quot; &quot;jibb&quot; &quot;jibe&quot;
## [1721] &quot;jibs&quot; &quot;jiff&quot; &quot;jigs&quot; &quot;jill&quot; &quot;jilt&quot; &quot;jimp&quot; &quot;jink&quot; &quot;jinn&quot; &quot;jins&quot; &quot;jinx&quot;
## [1731] &quot;jism&quot; &quot;jive&quot; &quot;jivy&quot; &quot;jobs&quot; &quot;jock&quot; &quot;joes&quot; &quot;joey&quot; &quot;jogs&quot; &quot;john&quot; &quot;join&quot;
## [1741] &quot;joke&quot; &quot;joky&quot; &quot;jole&quot; &quot;jolt&quot; &quot;josh&quot; &quot;joss&quot; &quot;jota&quot; &quot;jots&quot; &quot;jouk&quot; &quot;jowl&quot;
## [1751] &quot;jows&quot; &quot;joys&quot; &quot;juba&quot; &quot;jube&quot; &quot;juco&quot; &quot;judo&quot; &quot;juga&quot; &quot;jugs&quot; &quot;juju&quot; &quot;juke&quot;
## [1761] &quot;juku&quot; &quot;jump&quot; &quot;junk&quot; &quot;jupe&quot; &quot;jura&quot; &quot;jury&quot; &quot;just&quot; &quot;jute&quot; &quot;juts&quot; &quot;kaas&quot;
## [1771] &quot;kabs&quot; &quot;kadi&quot; &quot;kaes&quot; &quot;kafs&quot; &quot;kagu&quot; &quot;kaif&quot; &quot;kail&quot; &quot;kain&quot; &quot;kaka&quot; &quot;kaki&quot;
## [1781] &quot;kale&quot; &quot;kame&quot; &quot;kami&quot; &quot;kana&quot; &quot;kane&quot; &quot;kaon&quot; &quot;kapa&quot; &quot;kaph&quot; &quot;karn&quot; &quot;kart&quot;
## [1791] &quot;kata&quot; &quot;kats&quot; &quot;kava&quot; &quot;kayo&quot; &quot;kays&quot; &quot;kbar&quot; &quot;keas&quot; &quot;keck&quot; &quot;keef&quot; &quot;keek&quot;
## [1801] &quot;keel&quot; &quot;keen&quot; &quot;keep&quot; &quot;keet&quot; &quot;kefs&quot; &quot;kegs&quot; &quot;keir&quot; &quot;kelp&quot; &quot;kelt&quot; &quot;kemp&quot;
## [1811] &quot;keno&quot; &quot;kens&quot; &quot;kent&quot; &quot;kepi&quot; &quot;keps&quot; &quot;kept&quot; &quot;kerb&quot; &quot;kerf&quot; &quot;kern&quot; &quot;keto&quot;
## [1821] &quot;keys&quot; &quot;khaf&quot; &quot;khan&quot; &quot;khat&quot; &quot;khet&quot; &quot;khis&quot; &quot;kibe&quot; &quot;kick&quot; &quot;kids&quot; &quot;kief&quot;
## [1831] &quot;kier&quot; &quot;kifs&quot; &quot;kike&quot; &quot;kill&quot; &quot;kiln&quot; &quot;kilo&quot; &quot;kilt&quot; &quot;kina&quot; &quot;kind&quot; &quot;kine&quot;
## [1841] &quot;king&quot; &quot;kink&quot; &quot;kino&quot; &quot;kins&quot; &quot;kips&quot; &quot;kirk&quot; &quot;kirn&quot; &quot;kirs&quot; &quot;kiss&quot; &quot;kist&quot;
## [1851] &quot;kite&quot; &quot;kith&quot; &quot;kits&quot; &quot;kiva&quot; &quot;kiwi&quot; &quot;klik&quot; &quot;knap&quot; &quot;knar&quot; &quot;knee&quot; &quot;knew&quot;
## [1861] &quot;knit&quot; &quot;knob&quot; &quot;knop&quot; &quot;knot&quot; &quot;know&quot; &quot;knur&quot; &quot;koan&quot; &quot;koas&quot; &quot;kobo&quot; &quot;kobs&quot;
## [1871] &quot;koel&quot; &quot;kohl&quot; &quot;kois&quot; &quot;koji&quot; &quot;kola&quot; &quot;kolo&quot; &quot;konk&quot; &quot;kook&quot; &quot;koph&quot; &quot;kops&quot;
## [1881] &quot;kora&quot; &quot;kore&quot; &quot;kors&quot; &quot;koss&quot; &quot;koto&quot; &quot;kris&quot; &quot;kudo&quot; &quot;kudu&quot; &quot;kues&quot; &quot;kufi&quot;
## [1891] &quot;kuna&quot; &quot;kune&quot; &quot;kuru&quot; &quot;kvas&quot; &quot;kyak&quot; &quot;kyar&quot; &quot;kyat&quot; &quot;kyes&quot; &quot;kyte&quot; &quot;labs&quot;
## [1901] &quot;lace&quot; &quot;lack&quot; &quot;lacs&quot; &quot;lacy&quot; &quot;lade&quot; &quot;lads&quot; &quot;lady&quot; &quot;lags&quot; &quot;laic&quot; &quot;laid&quot;
## [1911] &quot;lain&quot; &quot;lair&quot; &quot;lake&quot; &quot;lakh&quot; &quot;laky&quot; &quot;lall&quot; &quot;lama&quot; &quot;lamb&quot; &quot;lame&quot; &quot;lamp&quot;
## [1921] &quot;lams&quot; &quot;land&quot; &quot;lane&quot; &quot;lang&quot; &quot;lank&quot; &quot;laps&quot; &quot;lard&quot; &quot;lari&quot; &quot;lark&quot; &quot;lars&quot;
## [1931] &quot;lase&quot; &quot;lash&quot; &quot;lass&quot; &quot;last&quot; &quot;late&quot; &quot;lath&quot; &quot;lati&quot; &quot;lats&quot; &quot;latu&quot; &quot;laud&quot;
## [1941] &quot;lava&quot; &quot;lave&quot; &quot;lavs&quot; &quot;lawn&quot; &quot;laws&quot; &quot;lays&quot; &quot;laze&quot; &quot;lazy&quot; &quot;lead&quot; &quot;leaf&quot;
## [1951] &quot;leak&quot; &quot;leal&quot; &quot;lean&quot; &quot;leap&quot; &quot;lear&quot; &quot;leas&quot; &quot;lech&quot; &quot;leek&quot; &quot;leer&quot; &quot;lees&quot;
## [1961] &quot;leet&quot; &quot;left&quot; &quot;legs&quot; &quot;lehr&quot; &quot;leis&quot; &quot;leke&quot; &quot;leks&quot; &quot;leku&quot; &quot;lend&quot; &quot;leno&quot;
## [1971] &quot;lens&quot; &quot;lent&quot; &quot;lept&quot; &quot;less&quot; &quot;lest&quot; &quot;lets&quot; &quot;leud&quot; &quot;leva&quot; &quot;levo&quot; &quot;levy&quot;
## [1981] &quot;lewd&quot; &quot;leys&quot; &quot;liar&quot; &quot;libs&quot; &quot;lice&quot; &quot;lich&quot; &quot;lick&quot; &quot;lido&quot; &quot;lids&quot; &quot;lied&quot;
## [1991] &quot;lief&quot; &quot;lien&quot; &quot;lier&quot; &quot;lies&quot; &quot;lieu&quot; &quot;life&quot; &quot;lift&quot; &quot;like&quot; &quot;lilo&quot; &quot;lilt&quot;
## [2001] &quot;lily&quot; &quot;lima&quot; &quot;limb&quot; &quot;lime&quot; &quot;limn&quot; &quot;limo&quot; &quot;limp&quot; &quot;limy&quot; &quot;line&quot; &quot;ling&quot;
## [2011] &quot;link&quot; &quot;linn&quot; &quot;lino&quot; &quot;lins&quot; &quot;lint&quot; &quot;liny&quot; &quot;lion&quot; &quot;lipa&quot; &quot;lipe&quot; &quot;lips&quot;
## [2021] &quot;lira&quot; &quot;lire&quot; &quot;liri&quot; &quot;lisp&quot; &quot;list&quot; &quot;lite&quot; &quot;lits&quot; &quot;litu&quot; &quot;live&quot; &quot;load&quot;
## [2031] &quot;loaf&quot; &quot;loam&quot; &quot;loan&quot; &quot;lobe&quot; &quot;lobo&quot; &quot;lobs&quot; &quot;loca&quot; &quot;loch&quot; &quot;loci&quot; &quot;lock&quot;
## [2041] &quot;loco&quot; &quot;lode&quot; &quot;loft&quot; &quot;loge&quot; &quot;logo&quot; &quot;logs&quot; &quot;logy&quot; &quot;loid&quot; &quot;loin&quot; &quot;loll&quot;
## [2051] &quot;lone&quot; &quot;long&quot; &quot;loof&quot; &quot;look&quot; &quot;loom&quot; &quot;loon&quot; &quot;loop&quot; &quot;loos&quot; &quot;loot&quot; &quot;lope&quot;
## [2061] &quot;lops&quot; &quot;lord&quot; &quot;lore&quot; &quot;lorn&quot; &quot;lory&quot; &quot;lose&quot; &quot;loss&quot; &quot;lost&quot; &quot;lota&quot; &quot;loth&quot;
## [2071] &quot;loti&quot; &quot;lots&quot; &quot;loud&quot; &quot;loup&quot; &quot;lour&quot; &quot;lout&quot; &quot;love&quot; &quot;lowe&quot; &quot;lown&quot; &quot;lows&quot;
## [2081] &quot;luau&quot; &quot;lube&quot; &quot;luce&quot; &quot;luck&quot; &quot;lude&quot; &quot;lues&quot; &quot;luff&quot; &quot;luge&quot; &quot;lugs&quot; &quot;lull&quot;
## [2091] &quot;lulu&quot; &quot;luma&quot; &quot;lump&quot; &quot;lums&quot; &quot;luna&quot; &quot;lune&quot; &quot;lung&quot; &quot;lunk&quot; &quot;lunt&quot; &quot;luny&quot;
## [2101] &quot;lure&quot; &quot;lurk&quot; &quot;lush&quot; &quot;lust&quot; &quot;lute&quot; &quot;lutz&quot; &quot;luvs&quot; &quot;luxe&quot; &quot;lwei&quot; &quot;lych&quot;
## [2111] &quot;lyes&quot; &quot;lynx&quot; &quot;lyre&quot; &quot;lyse&quot; &quot;maar&quot; &quot;mabe&quot; &quot;mace&quot; &quot;mach&quot; &quot;mack&quot; &quot;macs&quot;
## [2121] &quot;made&quot; &quot;mads&quot; &quot;maes&quot; &quot;mage&quot; &quot;magi&quot; &quot;mags&quot; &quot;maid&quot; &quot;mail&quot; &quot;maim&quot; &quot;main&quot;
## [2131] &quot;mair&quot; &quot;make&quot; &quot;mako&quot; &quot;male&quot; &quot;mall&quot; &quot;malm&quot; &quot;malt&quot; &quot;mama&quot; &quot;mana&quot; &quot;mane&quot;
## [2141] &quot;mano&quot; &quot;mans&quot; &quot;many&quot; &quot;maps&quot; &quot;mara&quot; &quot;marc&quot; &quot;mare&quot; &quot;mark&quot; &quot;marl&quot; &quot;mars&quot;
## [2151] &quot;mart&quot; &quot;masa&quot; &quot;mash&quot; &quot;mask&quot; &quot;mass&quot; &quot;mast&quot; &quot;mate&quot; &quot;math&quot; &quot;mats&quot; &quot;matt&quot;
## [2161] &quot;maud&quot; &quot;maul&quot; &quot;maun&quot; &quot;maut&quot; &quot;mawn&quot; &quot;maws&quot; &quot;maxi&quot; &quot;maya&quot; &quot;mayo&quot; &quot;mays&quot;
## [2171] &quot;maze&quot; &quot;mazy&quot; &quot;mead&quot; &quot;meal&quot; &quot;mean&quot; &quot;meat&quot; &quot;meds&quot; &quot;meed&quot; &quot;meek&quot; &quot;meet&quot;
## [2181] &quot;mega&quot; &quot;megs&quot; &quot;meld&quot; &quot;mell&quot; &quot;mels&quot; &quot;melt&quot; &quot;meme&quot; &quot;memo&quot; &quot;mems&quot; &quot;mend&quot;
## [2191] &quot;meno&quot; &quot;menu&quot; &quot;meou&quot; &quot;meow&quot; &quot;merc&quot; &quot;mere&quot; &quot;merk&quot; &quot;merl&quot; &quot;mesa&quot; &quot;mesh&quot;
## [2201] &quot;mess&quot; &quot;meta&quot; &quot;mete&quot; &quot;meth&quot; &quot;mewl&quot; &quot;mews&quot; &quot;meze&quot; &quot;mhos&quot; &quot;mibs&quot; &quot;mica&quot;
## [2211] &quot;mice&quot; &quot;mick&quot; &quot;mics&quot; &quot;midi&quot; &quot;mids&quot; &quot;mien&quot; &quot;miff&quot; &quot;migg&quot; &quot;migs&quot; &quot;mike&quot;
## [2221] &quot;mild&quot; &quot;mile&quot; &quot;milk&quot; &quot;mill&quot; &quot;milo&quot; &quot;mils&quot; &quot;milt&quot; &quot;mime&quot; &quot;mina&quot; &quot;mind&quot;
## [2231] &quot;mine&quot; &quot;mini&quot; &quot;mink&quot; &quot;mint&quot; &quot;minx&quot; &quot;mips&quot; &quot;mire&quot; &quot;miri&quot; &quot;mirk&quot; &quot;mirs&quot;
## [2241] &quot;miry&quot; &quot;mise&quot; &quot;miso&quot; &quot;miss&quot; &quot;mist&quot; &quot;mite&quot; &quot;mitt&quot; &quot;mity&quot; &quot;mixt&quot; &quot;moan&quot;
## [2251] &quot;moas&quot; &quot;moat&quot; &quot;mobs&quot; &quot;mock&quot; &quot;mocs&quot; &quot;mode&quot; &quot;modi&quot; &quot;mods&quot; &quot;mogs&quot; &quot;moil&quot;
## [2261] &quot;mojo&quot; &quot;moke&quot; &quot;mola&quot; &quot;mold&quot; &quot;mole&quot; &quot;moll&quot; &quot;mols&quot; &quot;molt&quot; &quot;moly&quot; &quot;mome&quot;
## [2271] &quot;momi&quot; &quot;moms&quot; &quot;monk&quot; &quot;mono&quot; &quot;mons&quot; &quot;mony&quot; &quot;mood&quot; &quot;mool&quot; &quot;moon&quot; &quot;moor&quot;
## [2281] &quot;moos&quot; &quot;moot&quot; &quot;mope&quot; &quot;mops&quot; &quot;mopy&quot; &quot;mora&quot; &quot;more&quot; &quot;morn&quot; &quot;mors&quot; &quot;mort&quot;
## [2291] &quot;mosh&quot; &quot;mosk&quot; &quot;moss&quot; &quot;most&quot; &quot;mote&quot; &quot;moth&quot; &quot;mots&quot; &quot;mott&quot; &quot;moue&quot; &quot;move&quot;
## [2301] &quot;mown&quot; &quot;mows&quot; &quot;moxa&quot; &quot;mozo&quot; &quot;much&quot; &quot;muck&quot; &quot;muds&quot; &quot;muff&quot; &quot;mugg&quot; &quot;mugs&quot;
## [2311] &quot;mule&quot; &quot;mull&quot; &quot;mumm&quot; &quot;mump&quot; &quot;mums&quot; &quot;mumu&quot; &quot;muni&quot; &quot;muns&quot; &quot;muon&quot; &quot;mura&quot;
## [2321] &quot;mure&quot; &quot;murk&quot; &quot;murr&quot; &quot;muse&quot; &quot;mush&quot; &quot;musk&quot; &quot;muss&quot; &quot;must&quot; &quot;mute&quot; &quot;muts&quot;
## [2331] &quot;mutt&quot; &quot;mycs&quot; &quot;myna&quot; &quot;myth&quot; &quot;naan&quot; &quot;nabe&quot; &quot;nabs&quot; &quot;nada&quot; &quot;naff&quot; &quot;nags&quot;
## [2341] &quot;naif&quot; &quot;nail&quot; &quot;nala&quot; &quot;name&quot; &quot;nana&quot; &quot;nans&quot; &quot;naoi&quot; &quot;naos&quot; &quot;napa&quot; &quot;nape&quot;
## [2351] &quot;naps&quot; &quot;narc&quot; &quot;nard&quot; &quot;nark&quot; &quot;nary&quot; &quot;nave&quot; &quot;navy&quot; &quot;nays&quot; &quot;nazi&quot; &quot;neap&quot;
## [2361] &quot;near&quot; &quot;neat&quot; &quot;nebs&quot; &quot;neck&quot; &quot;need&quot; &quot;neem&quot; &quot;neep&quot; &quot;negs&quot; &quot;neif&quot; &quot;nema&quot;
## [2371] &quot;nene&quot; &quot;neon&quot; &quot;nerd&quot; &quot;ness&quot; &quot;nest&quot; &quot;nets&quot; &quot;nett&quot; &quot;neuk&quot; &quot;neum&quot; &quot;neve&quot;
## [2381] &quot;nevi&quot; &quot;news&quot; &quot;newt&quot; &quot;next&quot; &quot;nibs&quot; &quot;nice&quot; &quot;nick&quot; &quot;nide&quot; &quot;nidi&quot; &quot;nigh&quot;
## [2391] &quot;nill&quot; &quot;nils&quot; &quot;nims&quot; &quot;nine&quot; &quot;nipa&quot; &quot;nips&quot; &quot;nisi&quot; &quot;nite&quot; &quot;nits&quot; &quot;nixe&quot;
## [2401] &quot;nixy&quot; &quot;nobs&quot; &quot;nock&quot; &quot;node&quot; &quot;nodi&quot; &quot;nods&quot; &quot;noel&quot; &quot;noes&quot; &quot;nogg&quot; &quot;nogs&quot;
## [2411] &quot;noil&quot; &quot;noir&quot; &quot;nolo&quot; &quot;noma&quot; &quot;nome&quot; &quot;noms&quot; &quot;nona&quot; &quot;none&quot; &quot;nook&quot; &quot;noon&quot;
## [2421] &quot;nope&quot; &quot;nori&quot; &quot;norm&quot; &quot;nose&quot; &quot;nosh&quot; &quot;nosy&quot; &quot;nota&quot; &quot;note&quot; &quot;noun&quot; &quot;nous&quot;
## [2431] &quot;nova&quot; &quot;nows&quot; &quot;nowt&quot; &quot;nubs&quot; &quot;nude&quot; &quot;nuke&quot; &quot;null&quot; &quot;numb&quot; &quot;nuns&quot; &quot;nurd&quot;
## [2441] &quot;nurl&quot; &quot;nuts&quot; &quot;oafs&quot; &quot;oaks&quot; &quot;oaky&quot; &quot;oars&quot; &quot;oast&quot; &quot;oath&quot; &quot;oats&quot; &quot;obas&quot;
## [2451] &quot;obes&quot; &quot;obey&quot; &quot;obia&quot; &quot;obis&quot; &quot;obit&quot; &quot;oboe&quot; &quot;obol&quot; &quot;ocas&quot; &quot;odah&quot; &quot;odas&quot;
## [2461] &quot;odds&quot; &quot;odea&quot; &quot;odes&quot; &quot;odic&quot; &quot;odor&quot; &quot;odyl&quot; &quot;ofay&quot; &quot;offs&quot; &quot;ogam&quot; &quot;ogee&quot;
## [2471] &quot;ogle&quot; &quot;ogre&quot; &quot;ohed&quot; &quot;ohia&quot; &quot;ohms&quot; &quot;oils&quot; &quot;oily&quot; &quot;oink&quot; &quot;okas&quot; &quot;okay&quot;
## [2481] &quot;okeh&quot; &quot;okes&quot; &quot;okra&quot; &quot;olds&quot; &quot;oldy&quot; &quot;olea&quot; &quot;oleo&quot; &quot;oles&quot; &quot;olio&quot; &quot;olla&quot;
## [2491] &quot;omen&quot; &quot;omer&quot; &quot;omit&quot; &quot;once&quot; &quot;ones&quot; &quot;only&quot; &quot;onos&quot; &quot;onto&quot; &quot;onus&quot; &quot;onyx&quot;
## [2501] &quot;oohs&quot; &quot;oops&quot; &quot;oots&quot; &quot;ooze&quot; &quot;oozy&quot; &quot;opah&quot; &quot;opal&quot; &quot;oped&quot; &quot;open&quot; &quot;opes&quot;
## [2511] &quot;opts&quot; &quot;opus&quot; &quot;orad&quot; &quot;oral&quot; &quot;orbs&quot; &quot;orby&quot; &quot;orca&quot; &quot;orcs&quot; &quot;ordo&quot; &quot;ores&quot;
## [2521] &quot;orgy&quot; &quot;orle&quot; &quot;orra&quot; &quot;orts&quot; &quot;oryx&quot; &quot;orzo&quot; &quot;osar&quot; &quot;oses&quot; &quot;ossa&quot; &quot;otic&quot;
## [2531] &quot;otto&quot; &quot;ouch&quot; &quot;ouds&quot; &quot;ouph&quot; &quot;ours&quot; &quot;oust&quot; &quot;outs&quot; &quot;ouzo&quot; &quot;oval&quot; &quot;oven&quot;
## [2541] &quot;over&quot; &quot;ovum&quot; &quot;owed&quot; &quot;owes&quot; &quot;owls&quot; &quot;owns&quot; &quot;owse&quot; &quot;oxen&quot; &quot;oxes&quot; &quot;oxid&quot;
## [2551] &quot;oxim&quot; &quot;oyer&quot; &quot;oyes&quot; &quot;oyez&quot; &quot;paca&quot; &quot;pace&quot; &quot;pack&quot; &quot;pacs&quot; &quot;pact&quot; &quot;pacy&quot;
## [2561] &quot;padi&quot; &quot;pads&quot; &quot;page&quot; &quot;paid&quot; &quot;paik&quot; &quot;pail&quot; &quot;pain&quot; &quot;pair&quot; &quot;pale&quot; &quot;pall&quot;
## [2571] &quot;palm&quot; &quot;palp&quot; &quot;pals&quot; &quot;paly&quot; &quot;pams&quot; &quot;pane&quot; &quot;pang&quot; &quot;pans&quot; &quot;pant&quot; &quot;papa&quot;
## [2581] &quot;paps&quot; &quot;para&quot; &quot;pard&quot; &quot;pare&quot; &quot;park&quot; &quot;parr&quot; &quot;pars&quot; &quot;part&quot; &quot;pase&quot; &quot;pash&quot;
## [2591] &quot;pass&quot; &quot;past&quot; &quot;pate&quot; &quot;path&quot; &quot;pats&quot; &quot;paty&quot; &quot;pave&quot; &quot;pawl&quot; &quot;pawn&quot; &quot;paws&quot;
## [2601] &quot;pays&quot; &quot;peag&quot; &quot;peak&quot; &quot;peal&quot; &quot;pean&quot; &quot;pear&quot; &quot;peas&quot; &quot;peat&quot; &quot;pech&quot; &quot;peck&quot;
## [2611] &quot;pecs&quot; &quot;peds&quot; &quot;peed&quot; &quot;peek&quot; &quot;peel&quot; &quot;peen&quot; &quot;peep&quot; &quot;peer&quot; &quot;pees&quot; &quot;pegs&quot;
## [2621] &quot;pehs&quot; &quot;pein&quot; &quot;peke&quot; &quot;pele&quot; &quot;pelf&quot; &quot;pelt&quot; &quot;pend&quot; &quot;pens&quot; &quot;pent&quot; &quot;peon&quot;
## [2631] &quot;pepo&quot; &quot;peps&quot; &quot;pere&quot; &quot;peri&quot; &quot;perk&quot; &quot;perm&quot; &quot;perp&quot; &quot;pert&quot; &quot;perv&quot; &quot;peso&quot;
## [2641] &quot;pest&quot; &quot;pets&quot; &quot;pews&quot; &quot;pfft&quot; &quot;pfui&quot; &quot;phat&quot; &quot;phew&quot; &quot;phis&quot; &quot;phiz&quot; &quot;phon&quot;
## [2651] &quot;phot&quot; &quot;phut&quot; &quot;pial&quot; &quot;pian&quot; &quot;pias&quot; &quot;pica&quot; &quot;pice&quot; &quot;pick&quot; &quot;pics&quot; &quot;pied&quot;
## [2661] &quot;pier&quot; &quot;pies&quot; &quot;pigs&quot; &quot;pika&quot; &quot;pike&quot; &quot;piki&quot; &quot;pile&quot; &quot;pili&quot; &quot;pill&quot; &quot;pily&quot;
## [2671] &quot;pima&quot; &quot;pimp&quot; &quot;pina&quot; &quot;pine&quot; &quot;ping&quot; &quot;pink&quot; &quot;pins&quot; &quot;pint&quot; &quot;piny&quot; &quot;pion&quot;
## [2681] &quot;pipe&quot; &quot;pips&quot; &quot;pipy&quot; &quot;pirn&quot; &quot;pish&quot; &quot;piso&quot; &quot;piss&quot; &quot;pita&quot; &quot;pith&quot; &quot;pits&quot;
## [2691] &quot;pity&quot; &quot;pixy&quot; &quot;plan&quot; &quot;plat&quot; &quot;play&quot; &quot;plea&quot; &quot;pleb&quot; &quot;pled&quot; &quot;plew&quot; &quot;plex&quot;
## [2701] &quot;plie&quot; &quot;plod&quot; &quot;plop&quot; &quot;plot&quot; &quot;plow&quot; &quot;ploy&quot; &quot;plug&quot; &quot;plum&quot; &quot;plus&quot; &quot;pock&quot;
## [2711] &quot;poco&quot; &quot;pods&quot; &quot;poem&quot; &quot;poet&quot; &quot;pogy&quot; &quot;pois&quot; &quot;poke&quot; &quot;poky&quot; &quot;pole&quot; &quot;poll&quot;
## [2721] &quot;polo&quot; &quot;pols&quot; &quot;poly&quot; &quot;pome&quot; &quot;pomo&quot; &quot;pomp&quot; &quot;poms&quot; &quot;pond&quot; &quot;pone&quot; &quot;pong&quot;
## [2731] &quot;pons&quot; &quot;pony&quot; &quot;pood&quot; &quot;poof&quot; &quot;pooh&quot; &quot;pool&quot; &quot;poon&quot; &quot;poop&quot; &quot;poor&quot; &quot;poos&quot;
## [2741] &quot;pope&quot; &quot;pops&quot; &quot;pore&quot; &quot;pork&quot; &quot;porn&quot; &quot;port&quot; &quot;pose&quot; &quot;posh&quot; &quot;post&quot; &quot;posy&quot;
## [2751] &quot;pots&quot; &quot;pouf&quot; &quot;pour&quot; &quot;pout&quot; &quot;pows&quot; &quot;poxy&quot; &quot;pram&quot; &quot;prao&quot; &quot;prat&quot; &quot;prau&quot;
## [2761] &quot;pray&quot; &quot;pree&quot; &quot;prep&quot; &quot;prex&quot; &quot;prey&quot; &quot;prez&quot; &quot;prig&quot; &quot;prim&quot; &quot;proa&quot; &quot;prod&quot;
## [2771] &quot;prof&quot; &quot;prog&quot; &quot;prom&quot; &quot;prop&quot; &quot;pros&quot; &quot;prow&quot; &quot;psis&quot; &quot;psst&quot; &quot;ptui&quot; &quot;pubs&quot;
## [2781] &quot;puce&quot; &quot;puck&quot; &quot;puds&quot; &quot;puff&quot; &quot;pugh&quot; &quot;pugs&quot; &quot;puja&quot; &quot;puke&quot; &quot;pula&quot; &quot;pule&quot;
## [2791] &quot;puli&quot; &quot;pull&quot; &quot;pulp&quot; &quot;puls&quot; &quot;puma&quot; &quot;pump&quot; &quot;puna&quot; &quot;pung&quot; &quot;punk&quot; &quot;puns&quot;
## [2801] &quot;punt&quot; &quot;puny&quot; &quot;pupa&quot; &quot;pups&quot; &quot;pupu&quot; &quot;pure&quot; &quot;puri&quot; &quot;purl&quot; &quot;purr&quot; &quot;purs&quot;
## [2811] &quot;push&quot; &quot;puss&quot; &quot;puts&quot; &quot;putt&quot; &quot;putz&quot; &quot;pyas&quot; &quot;pyes&quot; &quot;pyic&quot; &quot;pyin&quot; &quot;pyre&quot;
## [2821] &quot;pyro&quot; &quot;qadi&quot; &quot;qaid&quot; &quot;qats&quot; &quot;qoph&quot; &quot;quad&quot; &quot;quag&quot; &quot;quai&quot; &quot;quay&quot; &quot;quey&quot;
## [2831] &quot;quid&quot; &quot;quin&quot; &quot;quip&quot; &quot;quit&quot; &quot;quiz&quot; &quot;quod&quot; &quot;race&quot; &quot;rack&quot; &quot;racy&quot; &quot;rads&quot;
## [2841] &quot;raff&quot; &quot;raft&quot; &quot;raga&quot; &quot;rage&quot; &quot;ragg&quot; &quot;ragi&quot; &quot;rags&quot; &quot;raia&quot; &quot;raid&quot; &quot;rail&quot;
## [2851] &quot;rain&quot; &quot;rais&quot; &quot;raja&quot; &quot;rake&quot; &quot;raki&quot; &quot;raku&quot; &quot;rale&quot; &quot;rami&quot; &quot;ramp&quot; &quot;rams&quot;
## [2861] &quot;rand&quot; &quot;rang&quot; &quot;rani&quot; &quot;rank&quot; &quot;rant&quot; &quot;rape&quot; &quot;raps&quot; &quot;rapt&quot; &quot;rare&quot; &quot;rase&quot;
## [2871] &quot;rash&quot; &quot;rasp&quot; &quot;rate&quot; &quot;rath&quot; &quot;rato&quot; &quot;rats&quot; &quot;rave&quot; &quot;raws&quot; &quot;raya&quot; &quot;rays&quot;
## [2881] &quot;raze&quot; &quot;razz&quot; &quot;read&quot; &quot;real&quot; &quot;ream&quot; &quot;reap&quot; &quot;rear&quot; &quot;rebs&quot; &quot;reck&quot; &quot;recs&quot;
## [2891] &quot;redd&quot; &quot;rede&quot; &quot;redo&quot; &quot;reds&quot; &quot;reed&quot; &quot;reef&quot; &quot;reek&quot; &quot;reel&quot; &quot;rees&quot; &quot;refs&quot;
## [2901] &quot;reft&quot; &quot;regs&quot; &quot;reif&quot; &quot;rein&quot; &quot;reis&quot; &quot;rely&quot; &quot;rems&quot; &quot;rend&quot; &quot;rent&quot; &quot;repo&quot;
## [2911] &quot;repp&quot; &quot;reps&quot; &quot;resh&quot; &quot;rest&quot; &quot;rete&quot; &quot;rets&quot; &quot;revs&quot; &quot;rhea&quot; &quot;rhos&quot; &quot;rhus&quot;
## [2921] &quot;rial&quot; &quot;rias&quot; &quot;ribs&quot; &quot;rice&quot; &quot;rich&quot; &quot;rick&quot; &quot;ride&quot; &quot;rids&quot; &quot;riel&quot; &quot;rife&quot;
## [2931] &quot;riff&quot; &quot;rifs&quot; &quot;rift&quot; &quot;rigs&quot; &quot;rile&quot; &quot;rill&quot; &quot;rime&quot; &quot;rims&quot; &quot;rimy&quot; &quot;rind&quot;
## [2941] &quot;ring&quot; &quot;rink&quot; &quot;rins&quot; &quot;riot&quot; &quot;ripe&quot; &quot;rips&quot; &quot;rise&quot; &quot;risk&quot; &quot;rite&quot; &quot;ritz&quot;
## [2951] &quot;rive&quot; &quot;road&quot; &quot;roam&quot; &quot;roan&quot; &quot;roar&quot; &quot;robe&quot; &quot;robs&quot; &quot;rock&quot; &quot;rocs&quot; &quot;rode&quot;
## [2961] &quot;rods&quot; &quot;roes&quot; &quot;roil&quot; &quot;role&quot; &quot;rolf&quot; &quot;roll&quot; &quot;romp&quot; &quot;roms&quot; &quot;rood&quot; &quot;roof&quot;
## [2971] &quot;rook&quot; &quot;room&quot; &quot;root&quot; &quot;rope&quot; &quot;ropy&quot; &quot;rose&quot; &quot;rosy&quot; &quot;rota&quot; &quot;rote&quot; &quot;roti&quot;
## [2981] &quot;rotl&quot; &quot;roto&quot; &quot;rots&quot; &quot;roue&quot; &quot;roup&quot; &quot;rout&quot; &quot;roux&quot; &quot;rove&quot; &quot;rows&quot; &quot;rube&quot;
## [2991] &quot;rubs&quot; &quot;ruby&quot; &quot;ruck&quot; &quot;rudd&quot; &quot;rude&quot; &quot;rued&quot; &quot;ruer&quot; &quot;rues&quot; &quot;ruff&quot; &quot;ruga&quot;
## [3001] &quot;rugs&quot; &quot;ruin&quot; &quot;rule&quot; &quot;ruly&quot; &quot;rump&quot; &quot;rums&quot; &quot;rune&quot; &quot;rung&quot; &quot;runs&quot; &quot;runt&quot;
## [3011] &quot;ruse&quot; &quot;rush&quot; &quot;rusk&quot; &quot;rust&quot; &quot;ruth&quot; &quot;ruts&quot; &quot;ryas&quot; &quot;ryes&quot; &quot;ryke&quot; &quot;rynd&quot;
## [3021] &quot;ryot&quot; &quot;sabe&quot; &quot;sabs&quot; &quot;sack&quot; &quot;sacs&quot; &quot;sade&quot; &quot;sadi&quot; &quot;safe&quot; &quot;saga&quot; &quot;sage&quot;
## [3031] &quot;sago&quot; &quot;sags&quot; &quot;sagy&quot; &quot;said&quot; &quot;sail&quot; &quot;sain&quot; &quot;sake&quot; &quot;saki&quot; &quot;sale&quot; &quot;sall&quot;
## [3041] &quot;salp&quot; &quot;sals&quot; &quot;salt&quot; &quot;same&quot; &quot;samp&quot; &quot;sand&quot; &quot;sane&quot; &quot;sang&quot; &quot;sank&quot; &quot;sans&quot;
## [3051] &quot;saps&quot; &quot;sard&quot; &quot;sari&quot; &quot;sark&quot; &quot;sash&quot; &quot;sass&quot; &quot;sate&quot; &quot;sati&quot; &quot;saul&quot; &quot;save&quot;
## [3061] &quot;sawn&quot; &quot;saws&quot; &quot;says&quot; &quot;scab&quot; &quot;scad&quot; &quot;scag&quot; &quot;scam&quot; &quot;scan&quot; &quot;scar&quot; &quot;scat&quot;
## [3071] &quot;scop&quot; &quot;scot&quot; &quot;scow&quot; &quot;scry&quot; &quot;scud&quot; &quot;scum&quot; &quot;scup&quot; &quot;scut&quot; &quot;seal&quot; &quot;seam&quot;
## [3081] &quot;sear&quot; &quot;seas&quot; &quot;seat&quot; &quot;secs&quot; &quot;sect&quot; &quot;seed&quot; &quot;seek&quot; &quot;seel&quot; &quot;seem&quot; &quot;seen&quot;
## [3091] &quot;seep&quot; &quot;seer&quot; &quot;sees&quot; &quot;sego&quot; &quot;segs&quot; &quot;seif&quot; &quot;seis&quot; &quot;self&quot; &quot;sell&quot; &quot;sels&quot;
## [3101] &quot;seme&quot; &quot;semi&quot; &quot;send&quot; &quot;sene&quot; &quot;sent&quot; &quot;sept&quot; &quot;sera&quot; &quot;sere&quot; &quot;serf&quot; &quot;sers&quot;
## [3111] &quot;seta&quot; &quot;sets&quot; &quot;sett&quot; &quot;sewn&quot; &quot;sews&quot; &quot;sext&quot; &quot;sexy&quot; &quot;shad&quot; &quot;shag&quot; &quot;shah&quot;
## [3121] &quot;sham&quot; &quot;shat&quot; &quot;shaw&quot; &quot;shay&quot; &quot;shea&quot; &quot;shed&quot; &quot;shes&quot; &quot;shew&quot; &quot;shim&quot; &quot;shin&quot;
## [3131] &quot;ship&quot; &quot;shit&quot; &quot;shiv&quot; &quot;shmo&quot; &quot;shod&quot; &quot;shoe&quot; &quot;shog&quot; &quot;shoo&quot; &quot;shop&quot; &quot;shot&quot;
## [3141] &quot;show&quot; &quot;shri&quot; &quot;shul&quot; &quot;shun&quot; &quot;shut&quot; &quot;shwa&quot; &quot;sial&quot; &quot;sibb&quot; &quot;sibs&quot; &quot;sice&quot;
## [3151] &quot;sick&quot; &quot;sics&quot; &quot;side&quot; &quot;sidh&quot; &quot;sift&quot; &quot;sigh&quot; &quot;sign&quot; &quot;sika&quot; &quot;sike&quot; &quot;sild&quot;
## [3161] &quot;silk&quot; &quot;sill&quot; &quot;silo&quot; &quot;silt&quot; &quot;sima&quot; &quot;simp&quot; &quot;sims&quot; &quot;sine&quot; &quot;sing&quot; &quot;sinh&quot;
## [3171] &quot;sink&quot; &quot;sins&quot; &quot;sipe&quot; &quot;sips&quot; &quot;sire&quot; &quot;sirs&quot; &quot;site&quot; &quot;sith&quot; &quot;sits&quot; &quot;size&quot;
## [3181] &quot;sizy&quot; &quot;skag&quot; &quot;skas&quot; &quot;skat&quot; &quot;skee&quot; &quot;skeg&quot; &quot;skep&quot; &quot;skew&quot; &quot;skid&quot; &quot;skim&quot;
## [3191] &quot;skin&quot; &quot;skip&quot; &quot;skis&quot; &quot;skit&quot; &quot;skua&quot; &quot;slab&quot; &quot;slag&quot; &quot;slam&quot; &quot;slap&quot; &quot;slat&quot;
## [3201] &quot;slaw&quot; &quot;slay&quot; &quot;sled&quot; &quot;slew&quot; &quot;slid&quot; &quot;slim&quot; &quot;slip&quot; &quot;slit&quot; &quot;slob&quot; &quot;sloe&quot;
## [3211] &quot;slog&quot; &quot;slop&quot; &quot;slot&quot; &quot;slow&quot; &quot;slub&quot; &quot;slue&quot; &quot;slug&quot; &quot;slum&quot; &quot;slur&quot; &quot;slut&quot;
## [3221] &quot;smew&quot; &quot;smit&quot; &quot;smog&quot; &quot;smug&quot; &quot;smut&quot; &quot;snag&quot; &quot;snap&quot; &quot;snaw&quot; &quot;sned&quot; &quot;snib&quot;
## [3231] &quot;snip&quot; &quot;snit&quot; &quot;snob&quot; &quot;snog&quot; &quot;snot&quot; &quot;snow&quot; &quot;snub&quot; &quot;snug&quot; &quot;snye&quot; &quot;soak&quot;
## [3241] &quot;soap&quot; &quot;soar&quot; &quot;soba&quot; &quot;sobs&quot; &quot;soca&quot; &quot;sock&quot; &quot;soda&quot; &quot;sods&quot; &quot;sofa&quot; &quot;soft&quot;
## [3251] &quot;soil&quot; &quot;soja&quot; &quot;soke&quot; &quot;sola&quot; &quot;sold&quot; &quot;sole&quot; &quot;soli&quot; &quot;solo&quot; &quot;sols&quot; &quot;soma&quot;
## [3261] &quot;some&quot; &quot;soms&quot; &quot;sone&quot; &quot;song&quot; &quot;sons&quot; &quot;sook&quot; &quot;soon&quot; &quot;soot&quot; &quot;soph&quot; &quot;sops&quot;
## [3271] &quot;sora&quot; &quot;sorb&quot; &quot;sord&quot; &quot;sore&quot; &quot;sori&quot; &quot;sorn&quot; &quot;sort&quot; &quot;soth&quot; &quot;sots&quot; &quot;souk&quot;
## [3281] &quot;soul&quot; &quot;soup&quot; &quot;sour&quot; &quot;sous&quot; &quot;sown&quot; &quot;sows&quot; &quot;soya&quot; &quot;soys&quot; &quot;spae&quot; &quot;spam&quot;
## [3291] &quot;span&quot; &quot;spar&quot; &quot;spas&quot; &quot;spat&quot; &quot;spay&quot; &quot;spaz&quot; &quot;spec&quot; &quot;sped&quot; &quot;spew&quot; &quot;spic&quot;
## [3301] &quot;spik&quot; &quot;spin&quot; &quot;spit&quot; &quot;spiv&quot; &quot;spot&quot; &quot;spry&quot; &quot;spud&quot; &quot;spue&quot; &quot;spun&quot; &quot;spur&quot;
## [3311] &quot;sris&quot; &quot;stab&quot; &quot;stag&quot; &quot;star&quot; &quot;stat&quot; &quot;staw&quot; &quot;stay&quot; &quot;stem&quot; &quot;step&quot; &quot;stet&quot;
## [3321] &quot;stew&quot; &quot;stey&quot; &quot;stir&quot; &quot;stoa&quot; &quot;stob&quot; &quot;stop&quot; &quot;stot&quot; &quot;stow&quot; &quot;stub&quot; &quot;stud&quot;
## [3331] &quot;stum&quot; &quot;stun&quot; &quot;stye&quot; &quot;suba&quot; &quot;subs&quot; &quot;such&quot; &quot;suck&quot; &quot;sudd&quot; &quot;suds&quot; &quot;sued&quot;
## [3341] &quot;suer&quot; &quot;sues&quot; &quot;suet&quot; &quot;sugh&quot; &quot;suit&quot; &quot;suks&quot; &quot;sulk&quot; &quot;sulu&quot; &quot;sumo&quot; &quot;sump&quot;
## [3351] &quot;sums&quot; &quot;sung&quot; &quot;sunk&quot; &quot;sunn&quot; &quot;suns&quot; &quot;supe&quot; &quot;sups&quot; &quot;suqs&quot; &quot;sura&quot; &quot;surd&quot;
## [3361] &quot;sure&quot; &quot;surf&quot; &quot;suss&quot; &quot;swab&quot; &quot;swag&quot; &quot;swam&quot; &quot;swan&quot; &quot;swap&quot; &quot;swat&quot; &quot;sway&quot;
## [3371] &quot;swig&quot; &quot;swim&quot; &quot;swob&quot; &quot;swop&quot; &quot;swot&quot; &quot;swum&quot; &quot;sybo&quot; &quot;syce&quot; &quot;syke&quot; &quot;syli&quot;
## [3381] &quot;sync&quot; &quot;syne&quot; &quot;syph&quot; &quot;tabs&quot; &quot;tabu&quot; &quot;tace&quot; &quot;tach&quot; &quot;tack&quot; &quot;taco&quot; &quot;tact&quot;
## [3391] &quot;tads&quot; &quot;tael&quot; &quot;tags&quot; &quot;tahr&quot; &quot;tail&quot; &quot;tain&quot; &quot;taka&quot; &quot;take&quot; &quot;tala&quot; &quot;talc&quot;
## [3401] &quot;tale&quot; &quot;tali&quot; &quot;talk&quot; &quot;tall&quot; &quot;tame&quot; &quot;tamp&quot; &quot;tams&quot; &quot;tang&quot; &quot;tank&quot; &quot;tans&quot;
## [3411] &quot;taos&quot; &quot;tapa&quot; &quot;tape&quot; &quot;taps&quot; &quot;tare&quot; &quot;tarn&quot; &quot;taro&quot; &quot;tarp&quot; &quot;tars&quot; &quot;tart&quot;
## [3421] &quot;task&quot; &quot;tass&quot; &quot;tate&quot; &quot;tats&quot; &quot;taus&quot; &quot;taut&quot; &quot;tavs&quot; &quot;taws&quot; &quot;taxa&quot; &quot;taxi&quot;
## [3431] &quot;teak&quot; &quot;teal&quot; &quot;team&quot; &quot;tear&quot; &quot;teas&quot; &quot;teat&quot; &quot;tech&quot; &quot;teds&quot; &quot;teed&quot; &quot;teel&quot;
## [3441] &quot;teem&quot; &quot;teen&quot; &quot;tees&quot; &quot;teff&quot; &quot;tegg&quot; &quot;tegs&quot; &quot;tela&quot; &quot;tele&quot; &quot;tell&quot; &quot;tels&quot;
## [3451] &quot;temp&quot; &quot;tend&quot; &quot;tens&quot; &quot;tent&quot; &quot;tepa&quot; &quot;term&quot; &quot;tern&quot; &quot;test&quot; &quot;teth&quot; &quot;tets&quot;
## [3461] &quot;tews&quot; &quot;text&quot; &quot;thae&quot; &quot;than&quot; &quot;that&quot; &quot;thaw&quot; &quot;thee&quot; &quot;them&quot; &quot;then&quot; &quot;thew&quot;
## [3471] &quot;they&quot; &quot;thin&quot; &quot;thio&quot; &quot;thir&quot; &quot;this&quot; &quot;thou&quot; &quot;thro&quot; &quot;thru&quot; &quot;thud&quot; &quot;thug&quot;
## [3481] &quot;thus&quot; &quot;tick&quot; &quot;tics&quot; &quot;tide&quot; &quot;tidy&quot; &quot;tied&quot; &quot;tier&quot; &quot;ties&quot; &quot;tiff&quot; &quot;tike&quot;
## [3491] &quot;tiki&quot; &quot;tile&quot; &quot;till&quot; &quot;tils&quot; &quot;tilt&quot; &quot;time&quot; &quot;tine&quot; &quot;ting&quot; &quot;tins&quot; &quot;tint&quot;
## [3501] &quot;tiny&quot; &quot;tipi&quot; &quot;tips&quot; &quot;tire&quot; &quot;tirl&quot; &quot;tiro&quot; &quot;titi&quot; &quot;tits&quot; &quot;tivy&quot; &quot;toad&quot;
## [3511] &quot;toby&quot; &quot;tods&quot; &quot;tody&quot; &quot;toea&quot; &quot;toed&quot; &quot;toes&quot; &quot;toff&quot; &quot;toft&quot; &quot;tofu&quot; &quot;toga&quot;
## [3521] &quot;togs&quot; &quot;toil&quot; &quot;toit&quot; &quot;toke&quot; &quot;tola&quot; &quot;told&quot; &quot;tole&quot; &quot;toll&quot; &quot;tolu&quot; &quot;tomb&quot;
## [3531] &quot;tome&quot; &quot;toms&quot; &quot;tone&quot; &quot;tong&quot; &quot;tons&quot; &quot;tony&quot; &quot;took&quot; &quot;tool&quot; &quot;toom&quot; &quot;toon&quot;
## [3541] &quot;toot&quot; &quot;tope&quot; &quot;toph&quot; &quot;topi&quot; &quot;topo&quot; &quot;tops&quot; &quot;tora&quot; &quot;torc&quot; &quot;tore&quot; &quot;tori&quot;
## [3551] &quot;torn&quot; &quot;toro&quot; &quot;torr&quot; &quot;tors&quot; &quot;tort&quot; &quot;tory&quot; &quot;tosh&quot; &quot;toss&quot; &quot;tost&quot; &quot;tote&quot;
## [3561] &quot;tots&quot; &quot;tour&quot; &quot;tout&quot; &quot;town&quot; &quot;tows&quot; &quot;towy&quot; &quot;toyo&quot; &quot;toys&quot; &quot;trad&quot; &quot;tram&quot;
## [3571] &quot;trap&quot; &quot;tray&quot; &quot;tree&quot; &quot;tref&quot; &quot;trek&quot; &quot;tres&quot; &quot;tret&quot; &quot;trey&quot; &quot;trig&quot; &quot;trim&quot;
## [3581] &quot;trio&quot; &quot;trip&quot; &quot;trod&quot; &quot;trog&quot; &quot;trop&quot; &quot;trot&quot; &quot;trow&quot; &quot;troy&quot; &quot;true&quot; &quot;trug&quot;
## [3591] &quot;tsar&quot; &quot;tsks&quot; &quot;tuba&quot; &quot;tube&quot; &quot;tubs&quot; &quot;tuck&quot; &quot;tufa&quot; &quot;tuff&quot; &quot;tuft&quot; &quot;tugs&quot;
## [3601] &quot;tuis&quot; &quot;tule&quot; &quot;tump&quot; &quot;tuna&quot; &quot;tune&quot; &quot;tung&quot; &quot;tuns&quot; &quot;tups&quot; &quot;turd&quot; &quot;turf&quot;
## [3611] &quot;turk&quot; &quot;turn&quot; &quot;tush&quot; &quot;tusk&quot; &quot;tuts&quot; &quot;tutu&quot; &quot;twae&quot; &quot;twas&quot; &quot;twat&quot; &quot;twee&quot;
## [3621] &quot;twig&quot; &quot;twin&quot; &quot;twit&quot; &quot;twos&quot; &quot;tyee&quot; &quot;tyer&quot; &quot;tyes&quot; &quot;tyin&quot; &quot;tyke&quot; &quot;tyne&quot;
## [3631] &quot;type&quot; &quot;typo&quot; &quot;typp&quot; &quot;typy&quot; &quot;tyre&quot; &quot;tyro&quot; &quot;tzar&quot; &quot;udon&quot; &quot;udos&quot; &quot;ughs&quot;
## [3641] &quot;ugly&quot; &quot;ukes&quot; &quot;ulan&quot; &quot;ulna&quot; &quot;ulus&quot; &quot;ulva&quot; &quot;umbo&quot; &quot;umps&quot; &quot;unai&quot; &quot;unau&quot;
## [3651] &quot;unbe&quot; &quot;unci&quot; &quot;unco&quot; &quot;unde&quot; &quot;undo&quot; &quot;undy&quot; &quot;unit&quot; &quot;unto&quot; &quot;upas&quot; &quot;upby&quot;
## [3661] &quot;updo&quot; &quot;upon&quot; &quot;urbs&quot; &quot;urds&quot; &quot;urea&quot; &quot;urge&quot; &quot;uric&quot; &quot;urns&quot; &quot;urps&quot; &quot;ursa&quot;
## [3671] &quot;urus&quot; &quot;used&quot; &quot;user&quot; &quot;uses&quot; &quot;utas&quot; &quot;utes&quot; &quot;uvea&quot; &quot;vacs&quot; &quot;vagi&quot; &quot;vail&quot;
## [3681] &quot;vain&quot; &quot;vair&quot; &quot;vale&quot; &quot;vamp&quot; &quot;vane&quot; &quot;vang&quot; &quot;vans&quot; &quot;vara&quot; &quot;vars&quot; &quot;vary&quot;
## [3691] &quot;vasa&quot; &quot;vase&quot; &quot;vast&quot; &quot;vats&quot; &quot;vatu&quot; &quot;vaus&quot; &quot;vavs&quot; &quot;vaws&quot; &quot;veal&quot; &quot;veep&quot;
## [3701] &quot;veer&quot; &quot;vees&quot; &quot;veil&quot; &quot;vein&quot; &quot;vela&quot; &quot;veld&quot; &quot;vena&quot; &quot;vend&quot; &quot;vent&quot; &quot;vera&quot;
## [3711] &quot;verb&quot; &quot;vert&quot; &quot;very&quot; &quot;vest&quot; &quot;veto&quot; &quot;vets&quot; &quot;vext&quot; &quot;vial&quot; &quot;vibe&quot; &quot;vice&quot;
## [3721] &quot;vide&quot; &quot;vids&quot; &quot;vied&quot; &quot;vier&quot; &quot;vies&quot; &quot;view&quot; &quot;viga&quot; &quot;vigs&quot; &quot;vile&quot; &quot;vill&quot;
## [3731] &quot;vims&quot; &quot;vina&quot; &quot;vine&quot; &quot;vino&quot; &quot;viny&quot; &quot;viol&quot; &quot;virl&quot; &quot;visa&quot; &quot;vise&quot; &quot;vita&quot;
## [3741] &quot;viva&quot; &quot;vive&quot; &quot;voes&quot; &quot;void&quot; &quot;vole&quot; &quot;volt&quot; &quot;vote&quot; &quot;vows&quot; &quot;vrow&quot; &quot;vugg&quot;
## [3751] &quot;vugh&quot; &quot;vugs&quot; &quot;wabs&quot; &quot;wack&quot; &quot;wade&quot; &quot;wadi&quot; &quot;wads&quot; &quot;wady&quot; &quot;waes&quot; &quot;waff&quot;
## [3761] &quot;waft&quot; &quot;wage&quot; &quot;wags&quot; &quot;waif&quot; &quot;wail&quot; &quot;wain&quot; &quot;wair&quot; &quot;wait&quot; &quot;wake&quot; &quot;wale&quot;
## [3771] &quot;walk&quot; &quot;wall&quot; &quot;waly&quot; &quot;wame&quot; &quot;wand&quot; &quot;wane&quot; &quot;wank&quot; &quot;wans&quot; &quot;want&quot; &quot;wany&quot;
## [3781] &quot;waps&quot; &quot;ward&quot; &quot;ware&quot; &quot;wark&quot; &quot;warm&quot; &quot;warn&quot; &quot;warp&quot; &quot;wars&quot; &quot;wart&quot; &quot;wary&quot;
## [3791] &quot;wash&quot; &quot;wasp&quot; &quot;wast&quot; &quot;wats&quot; &quot;watt&quot; &quot;wauk&quot; &quot;waul&quot; &quot;waur&quot; &quot;wave&quot; &quot;wavy&quot;
## [3801] &quot;wawl&quot; &quot;waws&quot; &quot;waxy&quot; &quot;ways&quot; &quot;weak&quot; &quot;weal&quot; &quot;wean&quot; &quot;wear&quot; &quot;webs&quot; &quot;weds&quot;
## [3811] &quot;weed&quot; &quot;week&quot; &quot;weel&quot; &quot;ween&quot; &quot;weep&quot; &quot;weer&quot; &quot;wees&quot; &quot;weet&quot; &quot;weft&quot; &quot;weir&quot;
## [3821] &quot;weka&quot; &quot;weld&quot; &quot;well&quot; &quot;welt&quot; &quot;wend&quot; &quot;wens&quot; &quot;went&quot; &quot;wept&quot; &quot;were&quot; &quot;wert&quot;
## [3831] &quot;west&quot; &quot;wets&quot; &quot;wham&quot; &quot;whap&quot; &quot;what&quot; &quot;whee&quot; &quot;when&quot; &quot;whet&quot; &quot;whew&quot; &quot;whey&quot;
## [3841] &quot;whid&quot; &quot;whig&quot; &quot;whim&quot; &quot;whin&quot; &quot;whip&quot; &quot;whir&quot; &quot;whit&quot; &quot;whiz&quot; &quot;whoa&quot; &quot;whom&quot;
## [3851] &quot;whop&quot; &quot;whup&quot; &quot;whys&quot; &quot;wich&quot; &quot;wick&quot; &quot;wide&quot; &quot;wife&quot; &quot;wigs&quot; &quot;wild&quot; &quot;wile&quot;
## [3861] &quot;will&quot; &quot;wilt&quot; &quot;wily&quot; &quot;wimp&quot; &quot;wind&quot; &quot;wine&quot; &quot;wing&quot; &quot;wink&quot; &quot;wino&quot; &quot;wins&quot;
## [3871] &quot;winy&quot; &quot;wipe&quot; &quot;wire&quot; &quot;wiry&quot; &quot;wise&quot; &quot;wish&quot; &quot;wisp&quot; &quot;wiss&quot; &quot;wist&quot; &quot;wite&quot;
## [3881] &quot;with&quot; &quot;wits&quot; &quot;wive&quot; &quot;woad&quot; &quot;woes&quot; &quot;wogs&quot; &quot;woke&quot; &quot;woks&quot; &quot;wold&quot; &quot;wolf&quot;
## [3891] &quot;womb&quot; &quot;wonk&quot; &quot;wons&quot; &quot;wont&quot; &quot;wood&quot; &quot;woof&quot; &quot;wool&quot; &quot;woos&quot; &quot;wops&quot; &quot;word&quot;
## [3901] &quot;wore&quot; &quot;work&quot; &quot;worm&quot; &quot;worn&quot; &quot;wort&quot; &quot;wost&quot; &quot;wots&quot; &quot;wove&quot; &quot;wows&quot; &quot;wrap&quot;
## [3911] &quot;wren&quot; &quot;writ&quot; &quot;wuss&quot; &quot;wych&quot; &quot;wyes&quot; &quot;wyle&quot; &quot;wynd&quot; &quot;wynn&quot; &quot;wyns&quot; &quot;wyte&quot;
## [3921] &quot;xyst&quot; &quot;yack&quot; &quot;yaff&quot; &quot;yagi&quot; &quot;yags&quot; &quot;yaks&quot; &quot;yald&quot; &quot;yams&quot; &quot;yang&quot; &quot;yank&quot;
## [3931] &quot;yaps&quot; &quot;yard&quot; &quot;yare&quot; &quot;yarn&quot; &quot;yaud&quot; &quot;yaup&quot; &quot;yawl&quot; &quot;yawn&quot; &quot;yawp&quot; &quot;yaws&quot;
## [3941] &quot;yays&quot; &quot;yeah&quot; &quot;yean&quot; &quot;year&quot; &quot;yeas&quot; &quot;yech&quot; &quot;yegg&quot; &quot;yeld&quot; &quot;yelk&quot; &quot;yell&quot;
## [3951] &quot;yelp&quot; &quot;yens&quot; &quot;yeps&quot; &quot;yerk&quot; &quot;yeti&quot; &quot;yett&quot; &quot;yeuk&quot; &quot;yews&quot; &quot;yids&quot; &quot;yill&quot;
## [3961] &quot;yins&quot; &quot;yipe&quot; &quot;yips&quot; &quot;yird&quot; &quot;yirr&quot; &quot;ylem&quot; &quot;yobs&quot; &quot;yock&quot; &quot;yodh&quot; &quot;yods&quot;
## [3971] &quot;yoga&quot; &quot;yogh&quot; &quot;yogi&quot; &quot;yoke&quot; &quot;yoks&quot; &quot;yolk&quot; &quot;yond&quot; &quot;yoni&quot; &quot;yore&quot; &quot;your&quot;
## [3981] &quot;yous&quot; &quot;yowe&quot; &quot;yowl&quot; &quot;yows&quot; &quot;yuan&quot; &quot;yuca&quot; &quot;yuch&quot; &quot;yuck&quot; &quot;yuga&quot; &quot;yuks&quot;
## [3991] &quot;yule&quot; &quot;yups&quot; &quot;yurt&quot; &quot;yutz&quot; &quot;ywis&quot; &quot;zags&quot; &quot;zany&quot; &quot;zaps&quot; &quot;zarf&quot; &quot;zeal&quot;
## [4001] &quot;zebu&quot; &quot;zeds&quot; &quot;zees&quot; &quot;zein&quot; &quot;zeks&quot; &quot;zeps&quot; &quot;zerk&quot; &quot;zero&quot; &quot;zest&quot; &quot;zeta&quot;
## [4011] &quot;zigs&quot; &quot;zill&quot; &quot;zinc&quot; &quot;zine&quot; &quot;zing&quot; &quot;zins&quot; &quot;zips&quot; &quot;ziti&quot; &quot;zits&quot; &quot;zoea&quot;
## [4021] &quot;zoic&quot; &quot;zona&quot; &quot;zone&quot; &quot;zonk&quot; &quot;zoom&quot; &quot;zoon&quot; &quot;zoos&quot; &quot;zori&quot; &quot;zouk&quot; &quot;zyme&quot;</code></pre>
<p><strong>Question 3</strong></p>
<pre class="r"><code>letter &lt;- gsub(&quot;([A-Za-z])([A-Za-z])([A-Za-z])([A-Za-z])&quot;, &quot;\\1&quot;, words)</code></pre>
<p><strong>Question 4</strong></p>
<pre class="r"><code>table(letter)</code></pre>
<pre><code>## letter
##   a   b   c   d   e   f   g   h   i   j   k   l   m   n   o   p   q   r   s   t 
## 196 262 237 239 106 195 195 191  59  89 130 215 220 108 112 267  15 185 362 254 
##   u   v   w   x   y   z 
##  40  75 168   1  74  35</code></pre>
<pre class="r"><code>sort(table(letter))</code></pre>
<pre><code>## letter
##   x   q   z   u   i   y   v   j   e   n   o   k   w   r   h   f   g   a   l   m 
##   1  15  35  40  59  74  75  89 106 108 112 130 168 185 191 195 195 196 215 220 
##   c   d   t   b   p   s 
## 237 239 254 262 267 362</code></pre>
<p>S is the most common starting letter</p>
</div>
<div id="problem-set-6-1" class="section level3">
<h3>Problem Set 6</h3>
<pre class="r"><code># load library for working with SQL databases
library(sqldf)
library(lubridate)

# packages for creating maps
library(leaflet)
library(ggmap)
library(hexbin)

#set up the database 
setwd(&quot;/Users/briannafisher/Dropbox/CRIM 4002/Hotspot Map Assignment&quot;)
a &lt;- read.table(&quot;incidents_part1_part2_2020.csv&quot;,
                sep=&quot;,&quot;,nrows=30000,header=TRUE)
tail(a)</code></pre>
<pre><code>##                                                 the_geom cartodb_id
## 29995 0101000020E6100000B271711252C152C0AC391F22DE0B4440    2649802
## 29996 0101000020E61000008538BD280DC852C062644D55EFFC4340    2649803
## 29997 0101000020E6100000786B0D63DACA52C0BF6B860AC4F94340    2649804
## 29998 0101000020E6100000EE7E2E7D1CCA52C01E2EBD26B9014440    2649805
## 29999 0101000020E61000006A4330D4C2CA52C0EF4F2D4B89FF4340    2649806
## 30000 0101000020E6100000934EC9DEF7C852C0F044F749C1054440    2649807
##                                     the_geom_webmercator objectid dc_dist psa
## 29995 0101000020110F0000B982A6B386DB5FC1369CB92F109D5241  2638024       7   2
## 29996 0101000020110F00006761E089F5E65FC136C698C67F8C5241  2638025      26   3
## 29997 0101000020110F0000D75378D2B7EB5FC19F17C8C9FC885241  2638026       9   1
## 29998 0101000020110F00003F25EB4275EA5FC143130AB7CE915241  2638027      39   2
## 29999 0101000020110F00004ADA70CE8FEB5FC1024337F7618F5241  2638028      39   3
## 30000 0101000020110F0000C5F4123884E85FC1A4FEA68447965241  2638029      35   1
##        dispatch_date_time dispatch_date dispatch_time hour_       dc_key
## 29995 2020-01-30 17:56:00    2020-01-30      17:56:00    17 202007002816
## 29996 2020-09-15 12:03:00    2020-09-15      12:03:00    12 202026034508
## 29997 2020-07-29 08:40:00    2020-07-29      08:40:00     8 202009025781
## 29998 2020-08-17 00:36:00    2020-08-17      00:36:00     0 202039050148
## 29999 2020-01-08 12:01:00    2020-01-08      12:01:00    12 202039002016
## 30000 2020-02-12 20:32:00    2020-02-12      20:32:00    20 202035013255
##                location_block ucr_general             text_general_code
## 29995  11000 BLOCK RENNARD ST         400 Aggravated Assault No Firearm
## 29996  2500 BLOCK E NORRIS ST         500          Burglary Residential
## 29997  1700 BLOCK CHESTNUT ST         500      Burglary Non-Residential
## 29998    1800 BLOCK W PIKE ST         400 Aggravated Assault No Firearm
## 29999 2700 BLOCK N CROSKEY ST         400    Aggravated Assault Firearm
## 30000   6000 BLOCK N CAMAC ST         500          Burglary Residential
##         point_x  point_y      lat       lng
## 29995 -75.02063 40.09272 40.09272 -75.02063
## 29996 -75.12580 39.97605 39.97605 -75.12580
## 29997 -75.16958 39.95130 39.95130 -75.16958
## 29998 -75.15799 40.01346 40.01346 -75.15799
## 29999 -75.16814 39.99638 39.99638 -75.16814
## 30000 -75.14013 40.04496 40.04496 -75.14013</code></pre>
<pre class="r"><code>sure.you.want.to.rebuild.database &lt;- TRUE
if(sure.you.want.to.rebuild.database) # run once to set up the database
{
  # connect to or create a new SQlite database
  con &lt;- dbConnect(SQLite(), dbname=&quot;phillycrimenew.db&quot;)
  
  # how is SQLite planning on storing the data?
  variabletypes &lt;- dbDataType(con, a)
  
  # remove a crime table if it already exists
  if(dbExistsTable(con, &quot;crime&quot;)) dbRemoveTable(con, &quot;crime&quot;)
  # import the cleaned data file into RSQLite
  dbWriteTable(con, &quot;crime&quot;,
               &quot;/Users/briannafisher/Dropbox/CRIM 4002/Hotspot Map Assignment/incidents_part1_part2_2020.csv&quot;,
               row.names=FALSE,
               header=TRUE,
               field.types=variabletypes,
               sep=&quot;,&quot;) #&quot; RSQLite doesn&#39;t handle commas in quotes
  dbListFields(con,&quot;crime&quot;)
  dbDisconnect(con)
}

#connect to the database 
con &lt;- dbConnect(SQLite(), dbname=&quot;phillycrimenew.db&quot;)
dbListFields(con,&quot;crime&quot;)</code></pre>
<pre><code>##  [1] &quot;the_geom&quot;             &quot;cartodb_id&quot;           &quot;the_geom_webmercator&quot;
##  [4] &quot;objectid&quot;             &quot;dc_dist&quot;              &quot;psa&quot;                 
##  [7] &quot;dispatch_date_time&quot;   &quot;dispatch_date&quot;        &quot;dispatch_time&quot;       
## [10] &quot;hour_&quot;                &quot;dc_key&quot;               &quot;location_block&quot;      
## [13] &quot;ucr_general&quot;          &quot;text_general_code&quot;    &quot;point_x&quot;             
## [16] &quot;point_y&quot;              &quot;lat&quot;                  &quot;lng&quot;</code></pre>
<pre class="r"><code>#create the map 
res &lt;- dbSendQuery(con, &quot;
                   SELECT lat,lng,text_general_code,ucr_general
                   FROM crime;&quot;)
a &lt;- dbFetch(res, n = -1)
dbClearResult(res)

a$lat &lt;- as.numeric(a$lat)
a$lng &lt;- as.numeric(a$lng)

#create baseline of map with lat and long
philly.map &lt;- ggmap(get_map(c(-75.25, 39.93, -75.18, 39.98),
                             scale=&quot;auto&quot;,source=&quot;stamen&quot;))
philly.map</code></pre>
<p><img src="portfolio2_files/figure-html/unnamed-chunk-187-1.png" width="672" /></p>
<pre class="r"><code>#add points to the map
map.points &lt;- philly.map +
                  geom_point(aes(x=lng,y=lat), data=a,
                    alpha=0.5, color=&quot;darkred&quot;, size = 1)
map.points</code></pre>
<p><img src="portfolio2_files/figure-html/unnamed-chunk-187-2.png" width="672" /></p>
<pre class="r"><code>#look at crime type and ucr code
res &lt;- dbSendQuery(con, &quot;
                   SELECT DISTINCT text_general_code, ucr_general
                   FROM crime
                   GROUP BY text_general_code, ucr_general&quot;)
dbFetch(res, n = -1)</code></pre>
<pre><code>##                          text_general_code ucr_general
## 1               Aggravated Assault Firearm         400
## 2            Aggravated Assault No Firearm         400
## 3                       All Other Offenses        2600
## 4                                    Arson         900
## 5                 Burglary Non-Residential         500
## 6                     Burglary Residential         500
## 7              DRIVING UNDER THE INFLUENCE        2100
## 8                       Disorderly Conduct        2400
## 9                             Embezzlement        1200
## 10              Forgery and Counterfeiting        1000
## 11                                   Fraud        1100
## 12                     Gambling Violations        1900
## 13                     Homicide - Criminal         100
## 14                    Homicide - Criminal          100
## 15                   Liquor Law Violations        2200
## 16                     Motor Vehicle Theft         700
## 17          Narcotic / Drug Law Violations        1800
## 18    Offenses Against Family and Children        2000
## 19                          Other Assaults         800
## 20 Other Sex Offenses (Not Commercialized)        1700
## 21    Prostitution and Commercialized Vice        1600
## 22                      Public Drunkenness        2300
## 23                                    Rape         200
## 24               Receiving Stolen Property        1300
## 25                         Robbery Firearm         300
## 26                      Robbery No Firearm         300
## 27                      Theft from Vehicle         600
## 28                                  Thefts         600
## 29                      Vagrancy/Loitering        2500
## 30             Vandalism/Criminal Mischief        1400
## 31                       Weapon Violations        1500</code></pre>
<pre class="r"><code>dbClearResult(res)</code></pre>
<pre class="r"><code>#subset for violent crimes 
#400 - aggravated assault with a firearm, 400 - aggravated assault with no firearm, 
#100 - homicide (criminal), 200 - rape, 300 - robbery with a firearm, 300 - robbery without a firearm 

res &lt;- dbSendQuery(con, &quot;
                   SELECT lat,lng,ucr_general
                   FROM crime
                   WHERE ucr_general=&#39;400&#39; OR ucr_general=&#39;100&#39; OR ucr_general=&#39;200&#39; OR 
                   ucr_general=&#39;300&#39;&quot;)
b &lt;- dbFetch(res, n = -1)
dbClearResult(res)

b$lat &lt;- as.numeric(b$lat)
b$lng &lt;- as.numeric(b$lng)

#add points to the map
violent.points &lt;- philly.map +
                      geom_point(aes(x=lng,y=lat), data=b,
                         alpha=0.5, color=&quot;darkred&quot;, size = 1)
violent.points</code></pre>
<p><img src="portfolio2_files/figure-html/unnamed-chunk-188-1.png" width="672" /></p>
<pre class="r"><code>#subset for each violent crime

#homicide
res &lt;- dbSendQuery(con, &quot;
                   SELECT lat,lng,ucr_general
                   FROM crime
                   WHERE ucr_general=&#39;100&#39;&quot;)
homicide &lt;- dbFetch(res, n = -1)
dbClearResult(res)

homicide$color &lt;- &quot;Homicide&quot;

#rape
res &lt;- dbSendQuery(con, &quot;
                   SELECT lat,lng,ucr_general
                   FROM crime
                   WHERE ucr_general=&#39;200&#39;&quot;)
rape &lt;- dbFetch(res, n = -1)
dbClearResult(res)

rape$color &lt;- &quot;Rape&quot;

#robbery
res &lt;- dbSendQuery(con, &quot;
                   SELECT lat,lng,ucr_general
                   FROM crime
                   WHERE ucr_general=&#39;300&#39;&quot;)
robbery &lt;- dbFetch(res, n = -1)
dbClearResult(res)

robbery$color &lt;- &quot;Robbery&quot;

#aggravated assault
res &lt;- dbSendQuery(con, &quot;
                   SELECT lat,lng,ucr_general
                   FROM crime
                   WHERE ucr_general=&#39;400&#39;&quot;)
agg.assault &lt;- dbFetch(res, n = -1)
dbClearResult(res)

agg.assault$lat &lt;- as.numeric(agg.assault$lat)
agg.assault$lng &lt;- as.numeric(agg.assault$lng)

agg.assault$color &lt;- &quot;Aggravated Assault&quot;

#add all violent crimes to the map
violent.points.color &lt;- philly.map +
                           geom_point(aes(x=lng,y=lat, fill = color), data=homicide,
                                alpha=0.5, color=&quot;darkred&quot;, size = 1) +
                          geom_point(aes(x=lng,y=lat, fill = color), data=rape,
                                alpha=0.5, color=&quot;blue&quot;, size = 1) +
                          geom_point(aes(x=lng,y=lat, fill = color), data=robbery,
                                alpha=0.5, color=&quot;yellow&quot;, size = 1) +
                          geom_point(aes(x=lng,y=lat, fill = color), data=agg.assault,
                                alpha=0.5, color=&quot;hotpink&quot;, size = 1) +
                          ggtitle(&quot;Violent Crimes in West Philadelphia in 2020&quot;) +
                          xlab(&quot;Longitude&quot;) +
                          ylab(&quot;Latitude&quot;) 

#add a legend to the plot
cols &lt;- c(&quot;Homicide&quot;=&quot;darkred&quot;, &#39;Rape&#39;=&#39;blue&#39;, &#39;Robbery&#39;=&#39;yellow&#39;, &#39;Aggravated Assault&#39;=&#39;hotpink&#39;)

violent.points.color +
  scale_colour_manual(name=&quot;Type of Crime&quot;,values=cols) +
  scale_fill_manual(name = &quot;Type of Crime&quot;, values = cols,
                  labels = c(&#39;Homicide&#39;, &#39;Rape&#39;, &#39;Robbery&#39;, &#39;Aggravated Assault&#39;)) +
  guides(color = guide_legend(override.aes = list(color = cols))) </code></pre>
<p><img src="portfolio2_files/figure-html/unnamed-chunk-188-2.png" width="672" /></p>
</div>
<div id="problem-set-7" class="section level3">
<h3>Problem Set 7</h3>
<p>In order to not crash Github, I am using the dataset I made as a result of webscrapping the box office website.</p>
<pre class="r"><code>#load in movie and box office data
setwd(&quot;/Users/briannafisher/Dropbox/CRIM 4002/&quot;)
load(&quot;11.3/movie revenue.RData&quot;)
load(&quot;Regular Exp and Webscraping Assignment/boxoffice.RData&quot;)

library(kableExtra)
library(dplyr)
library(ggpubr)
library(ggplot2)
library(lubridate)</code></pre>
<pre class="r"><code>#subset for the first day
moviedataDay1 &lt;- subset(movie.data, date == &quot;2010-01-01&quot;)
boxofficeDay1 &lt;- subset(boxoffice.data, date == &quot;2010-01-01&quot;)

#compare tables for the numbers.com and box office data for one day
table1 &lt;- moviedataDay1 %&gt;% 
            kbl %&gt;% 
            kable_classic()

table2 &lt;- boxofficeDay1 %&gt;% 
            kbl %&gt;% 
            kable_classic()</code></pre>
<p>Looking at the names of the movies, in the numbers.com data names that are too long are replaced with “…” instead of the rest of the title. In the box office data, this is not done and all of the movie names are complete.</p>
<pre class="r"><code>#look at changes over a month

#numbers.com
moviedataMonth &lt;- movie.data[movie.data$date &gt;= &quot;2010-01-01&quot; &amp; movie.data$date &lt;= &quot;2010-01-31&quot;, ]

numbers.line &lt;- ggplot(data=moviedataMonth, aes(x=movie, y=gross, group=movie)) +
                    geom_line(aes(color=movie))+
                      geom_point(aes(color=movie))

#box office
boxofficedataMonth &lt;- boxoffice.data[boxoffice.data$date &gt;= &quot;2010-01-01&quot; &amp; boxoffice.data$date &lt;= &quot;2010-01-31&quot;, ]

boxoffice.line &lt;- ggplot(data=boxofficedataMonth, aes(x=movie, y=gross, group=movie)) +
                       geom_line(aes(color=movie))+
                          geom_point(aes(color=movie))

combined &lt;- ggarrange(numbers.line, boxoffice.line,
                        labels = c(&quot;Number.com&quot;, &quot;Box Office&quot;),
                         ncol = 1, nrow = 2)</code></pre>
<p>It looks like the change in movie gross over the month of January 2010 for both the numbers.com and box office data are the same. However, you can see in the list of movies that they are not the same</p>
<pre class="r"><code>#I want to compare the number of movies per month
movie.month &lt;- aggregate(gross~movie, data = moviedataMonth, FUN = sum)
boxoffice.month &lt;- aggregate(gross~movie, data = boxofficedataMonth, FUN = sum)

#plot numbers.com
movie.month.plot &lt;- ggplot(data= movie.month, aes(x = reorder(movie, gross), 
                                                y = gross, fill = reorder(movie, gross))) +
  geom_bar(stat= &quot;identity&quot;) +
  xlab(&quot;&quot;) +
  ylab(&quot;Movie Gross&quot;) +
  ggtitle(&quot;January 2010 on Numbers.Com&quot;) +
  scale_fill_discrete(name = &quot;Movie Name&quot;) +
  theme(axis.text.x= element_blank(),
        axis.ticks.x=element_blank())

#plot box office
boxoffice.month.plot &lt;- ggplot(data= boxoffice.month, aes(x = reorder(movie, gross), 
                                                  y = gross, fill = reorder(movie, gross))) +
  geom_bar(stat= &quot;identity&quot;) +
  xlab(&quot;&quot;) +
  ylab(&quot;Movie Gross&quot;) +
  ggtitle(&quot;January 2010 on Box Office&quot;) +
  scale_fill_discrete(name = &quot;Movie Name&quot;) +
  theme(axis.text.x= element_blank(),
        axis.ticks.x=element_blank())

combined.month &lt;- ggarrange(movie.month.plot, boxoffice.month.plot,
                      ncol = 1, nrow = 2)

nrow(boxoffice.month)</code></pre>
<pre><code>## [1] 67</code></pre>
<pre class="r"><code>nrow(movie.month)</code></pre>
<pre><code>## [1] 96</code></pre>
<p>While the aggregations look about the same for both websites, there are 29 more movies included in the numbers.com data for the month of January 2010 than are included in the box office data. It looks like there are missing movies in the box office data, not just duplicates or mistakes in the numbers.com data. While the box office data has nicer formatted movie names, I think that it is more important to have all of the data and that we should use the numbers.com data set for our comparison with crime.</p>
</div>
<div id="problem-set-7-1" class="section level3">
<h3>Problem Set 7</h3>
<pre class="r"><code># to restart working with the data without having to rerun everything
library(lubridate)
library(sf)
library(leaflet)
library(jsonlite)
library(crayon)
setwd(&quot;/Users/briannafisher/Dropbox/CRIM 4002/11.8&quot;)
load(&quot;PPD OIS final.RData&quot;)
PPDmap &lt;- st_read(&quot;Boundaries_PSA-shp 2&quot;)</code></pre>
<pre><code>## Reading layer `1d53400f-66f7-45b3-86fe-6aca8d7c3b5b2020329-1-lutzgd.vpipe&#39; from data source `/Users/briannafisher/Dropbox/CRIM 4002/11.8/Boundaries_PSA-shp 2&#39; 
##   using driver `ESRI Shapefile&#39;
## Simple feature collection with 66 features and 10 fields
## Geometry type: POLYGON
## Dimension:     XY
## Bounding box:  xmin: -75.28031 ymin: 39.86701 xmax: -74.95575 ymax: 40.13793
## Geodetic CRS:  WGS 84</code></pre>
<pre class="r"><code># Search for hospitals
ois$hospital &lt;- &quot;fill in&quot;

#look for Presby
i &lt;- grep(&quot;Presb&quot;,ois$text)
cat(gsub(&quot;Presb&quot;, bgYellow$black$bold(&quot;Presb&quot;), ois$text[i]),
    sep=&quot;\n\n&quot;)</code></pre>
<pre><code>## June 4, 2022
## 400 South Street
## On Saturday, June 4, 2022, at approximately 11:31 PM, Officer #1, along with another Officer, was in full uniform, assigned to a foot beat detail on South Street. The Officers were in the area of 200 South Street and heard several gunshots coming from the area of 400 South Street. The Officers proceeded to the area from where the gunshots were emanating and observed several civilians suffering from gunshot wounds lying on the sidewalk and on the street. As the officers began rendering first aid, Officer #1 observed an unknown black male on the southwest corner of South and American Streets firing a handgun into a large crowd. Officer #1 drew his weapon and fired several times in the direction of the unknown male. The unknown male dropped his handgun on the sidewalk and ran southbound on 600 American Street. The male was lost in the area.
## It is unknown whether Officer #1 struck the male.
## There were no injuries to police.
## This Officer-Involved Shooting occurred concurrently, and in response to, a Mass Casualty Shooting Incident that took place at the above date, time, and locations.
## The OISI Unit and the Homicide Unit are conducting a joint investigation.
## As per protocol, the discharging officer (Officer #1) has been placed on administrative duty pending the outcome of the OISI and Internal Affairs investigations.
## The Mass Casualty Incident (MCI) is under investigation by the Philadelphia Police Department’s Homicide Unit.
## The individuals listed below were injured as a result of the MCI.
## Decedent #1: 34/B/M Pronounced at 12:05 AM at Presbyterian Hospital.
## Decedent #2: 27/B/F Pronounced at 11:49 PM at Jefferson Hospital.
## Decedent #3: 22/B/M, Pronounced at 11:49 PM at Jefferson Hospital.
## Shooting Victim #1: 23/B/M. Shot multiple times about the torso area. Critical condition.
## Shooting Victim #2: 18/B/M. Shot one time in the right hand.
## Shooting Victim #3: 18/B/M. Shot one time in his left buttocks.
## Shooting Victim #4: 20/B/M. Shot one time in his left forearm.
## Shooting Victim #5: 17/B/M. Shot one time right chest area.
## Shooting Victim #6: 69/W/M. Shot one time in his left calf area.
## Shooting Victim #7: 43/B/M. Shot one time right ankle.
## Shooting Victim #8: 17/B/F. Shot one time in her left leg.
## Shooting Victim #9: 19/B/F. Shot one time in her left leg.
## Shooting Victim #10: 20/B/M. Shot one time in his left shoulder.
## Shooting Victim #11: 17/B/F. Shot one time left shoulder.
## Non-shooting victim #1: 49/B/F. Victim struck by shattered glass
## 
## 20xx South Beechwood Street
## On Tuesday, February 15, 2022, at approximately 3:45 PM, 1st District Police Officer #1 and Officers #2, #3, and #4, in full uniform and operating marked patrol vehicles, all responded to a radio call for a person with a weapon on the 20xx block of South Beechwood Street.
## Upon arrival, the officers met with the witness (outside of the residence) who informed the officers that her son, a 36/W/M, was inside their residence, armed with a knife. The witness added that her sister, a 72/W/F, was in the residence as well.
## When the officers entered the residence, they observed the offender on the second floor of the property, armed with a knife. The officers attempted to establish a dialogue with him, but were unable to convince him to drop the knife and walk downstairs.
## The offender then entered the front bedroom where they heard a commotion. Officer #4 instructed Officers #2 and Officer #3 to position themselves in the hallway and stairwell, armed with their Tasers. Officer #4 instructed Officer #1 to enter the middle bedroom and attempt to gain access to the front bedroom through an adjoining door. When Officer #1 opened the adjoining bedroom door, he observed the offender armed with a knife in his right hand. At that point, Officer #1 discharged his Taser. The offender then stabbed the victim in the back. Officer #2 made entry through the front bedroom door and observed the offender stabbing the victim on the bed as well as Officer #1 utilizing his Taser with no effect. At that point, Officer #2 deployed his Taser, but it did not stop the offender from continuing to stab the victim. Officer #1 then discharged his firearm, striking the offender in his torso (right side)
## Police transported the victim and offender to Presbyterian Hospital where they were both pronounced.
## The offender’s knife was recovered in the front bedroom.
## 
## 27xx Brown Street
## On Monday 1-31-2022, at approximately 4:55 PM, Officer #1 and Officer #2 and were in full uniform operating a marked patrol car when they responded to a radio call for a “Person with a Gun” on the 2700 block of Brown Street, in front of the bar.
## Upon arriving at the location, the Officers stopped on to the corner of 27th and Brown Streets and exited their vehicle. The Officers observed a 38/H/M, on the northwest corner, in front of the bar holding a black handgun. Both Officers ordered the male several times to drop the gun; however, the male ignored the officers’ verbal commands and pointed his weapon in the direction of the officers. Both Officers discharged their weapons, striking the male one time in his upper left leg area, near his groin.
## The male fell to the ground and dropped the gun. Officer #1 was able to secure the male’s gun at that time.
## Philadelphia Fire Department Medics arrived on location and transported the male to Presbyterian Hospital where he was listed in stable condition.
## There were no injuries to Police or Civilians.
## Both officers have been placed on administrative duty pending the outcome of the OISI and Internal Affairs Bureau Investigation findings.
## 
## On 10-26-21, at approximately 3:04PM, Officers #1 and #2 in full uniform and marked patrol cars responded to the 5700 block of Overbrook Avenue for a report of a disturbance. Officer #1 arrived on location and encountered the offender, armed with a hand held pickaxe and a hammer inside of the location. During this encounter, the offender approached Officer #1, armed with the weapons in each hand, as he neared the front door. Officer #1 ordered the offender to drop his weapons. However, the offender ignored the officers’ verbal commands. At that point, Officer #1 deployed his ECW, which struck the offender, who in turn fell to the floor inside of the residence. Officer #1, Officer #2 (who at this time had arrived on location), and several civilians ran away from the offender towards the driveway. As the offender neared Officer #1, the offender struck him in the head with the hammer. Officer #1 fell and the offender, still armed, stood over Officer #1. At that point, both officers discharged their firearms, fatally wounding him.
## During the incident, Officer #1 sustained a gunshot to the right knee and a wound to the head (from the hammer). That officer was treated at Presbyterian Hospital. Officer #2 was uninjured.
## The offender was transported to Lankenau Hospital where he was pronounced deceased at 3:29PM.
## The incident was captured on the officers BWCs.
## 
## ﻿Philadelphia Police Officer Involved Shooting
## 35xx Wharton Street
## PS20-31
## On 11-27-20 at 7:58 PM, officers responded to a shooting at 15xx S. Taney Terrace where, a Black male was shot and later pronounced deceased at 8:23 PM at Presbyterian Hospital. Information was developed from witnesses on scene in reference to the identity of the alleged shooter, including name and address. Based on that information, Officers #1 and #2, in full uniform and marked patrol vehicle went to 35xx Wharton Street. Officer #3 was also in full uniform and in a marked patrol vehicle, was already on location and observed a blue minivan parked in the side driveway that was observed fleeing the homicide scene. Officers #1 and #2 went to the rear of 35xx Wharton Street for rear containment. Officer #1 and #2 observed a black male standing in the side doorway of that property. Officer #1 attempted to communicate with the male. The male stated, “You looking for me?”, then discharged his firearm at Officers #1 and #2. Officer #3 was positioned in the side driveway towards the front of property, observed the black male, shooting at the officers. In response, Officer #3 discharged his weapon, missing the male. At that point, the male retreated into the property and officers secured the location and declared a barricaded.  SWAT personnel attempted to establish an open line of communication with the male for over an hour without success.  
## SWAT officers made entry and located the decedent, a Black male, towards the rear of the property, 1st floor kitchen with an apparent gunshot wound to the head. SWAT cleared the rest of the property with negative results. A firearm was located next to Scott’s body. Philadelphia Fire Department Medics pronounced Scott at the scene.
## There were no other reported injuries to police or civilians.
## 
## ﻿Philadelphia Police Officer Involved Shooting
## 61xx Locust Street
## PS20-29
## On 10-26-2020, at approximately 3:50 PM, Police Officers #1 and #2 were operating a marked patrol vehicle, in full uniform, responded to a radio call for a “Person screaming/armed with a knife” at 61xx Locust Street. Upon arrival, the officers encountered a black male exiting the front door of 61xx Locust Street, walking off of the front porch, holding a knife in his right hand. The officers immediately began to back step away from the male, ordering him to drop the knife, while drawing their weapons. The male continued to advance towards the officers with the knife, while the officers continued to order the male to drop the knife. The officers backed away to the opposite side of the street and around a parked auto, all the while giving verbal commands to stop and drop the knife.  
## Note:  A review of BWC footage revealed that the officers ordered the male approximately 12 times to drop the knife during the incident.
## The male’s mother and brother attempted to intervene, by pushing/grabbing the male in the middle of the street and sidewalk without success.  The male walked between two parked cars and entered into the street, stuttered-stepped towards the officers, with knife still in hand, then walked towards them.  In response, both officers discharged their weapons (13 rounds total), fatally wounding the male.  
## The male was transported and later pronounced at Presbyterian Hospital at 4:06 PM. 
## Recovered at the scene was a kitchen style steak knife, approximately 10 inches (silver blade with a black handle).  
## The incident is depicted on the discharging officers’ BWCs. 
## There were no other reported injuries to police or civilians.
## 
## ﻿OIS # 19-04
## On March 6, 2019, at approximately 6:50 PM, uniformed officers operating a marked patrol vehicle in the 18th district responded to a radio call for “a person with a weapon/report of a stabbing” at 49xx Hazel Avenue.  Upon arrival, the officers exited their patrol car and observed a male emerge from behind a large bush in front of 49xx Hazel Avenue, while wielding a knife in his hand. Both officers drew their firearms and ordered the male to drop the knife, as the officers were backing away. They ordered the male to drop the knife several times while continuing to back away.  The male did not drop the knife and continued to advance towards the officers.  In response, one of the officers discharged his firearm, striking the male in the chest.  The male fell to the ground and was placed in custody by police.  
## The male was transported to Presbyterian Hospital by police and listed in critical, but stable condition. There were no other known injuries in connection with this incident. 
## A black handled steak knife with a 5’ blade was recovered at the scene.
## *** Information posted in the original summary reflects a preliminary understanding of what occurred at the time of the incident. This information is posted shortly after the incident and may be updated as the investigation leads to new information. The District Attorney’s Office is provided all the information from the PPD’s investigation prior to their charging decision.
## 
## ﻿OIS# 18-02
## On Monday, January 29th, 2018, at approximately 7:36AM, an off-duty detective in plainclothes was driving his personal vehicle westbound on the 1300 block of Bigler Street when he observed a male chasing a second male on foot. The detective stopped his vehicle and the male being chased (male #1) stated that the other male (male #2) had just struck a pedestrian with his vehicle and was attempting to flee the scene. The detective exited his vehicle, drew his firearm, and identified himself to male #2 as a police officer. The offender began punching and wrestling with the detective and the detective discharged his firearm multiple times, striking the offender. The offender was admitted to Presbyterian Hospital and was pronounced deceased at 10:15AM.
## The detective was treated and released at Methodist Hospital for abrasions and contusions to his head and left shoulder. The pedestrian was treated and released at Jefferson Hospital for abrasions and contusions to his leg, torso, and head.  No other injuries were reported in connection with this incident.
## *** Information posted in the original summary reflects a preliminary understanding of what occurred at the time of the incident. This information is posted shortly after the incident and may be updated as the investigation leads to new information. The DA’s Office is provided all the information from the PPD’s investigation prior to their charging decision.
## 
## ﻿OIS# 17-13 
## On Friday, May 12, 2017, at approximately 2:42 AM, 12th District uniformed officers responded to a radio call for a male violating a Protection From Abuse (PFA) order inside a residence on the 1200 block of south 51 street. The offender was inside the 2nd floor front bedroom. A female complainant stated the male might be armed with a knife.  The male refused officers’ direction to open the door and come out of the room. Officer number one forced the door open, and the offender, armed with a ten-inch knife, moved towards the officers. Officer number two deployed his ECW (Taser), contacting the offender, momentarily causing him to fall onto the bed. The offender stood up and while still holding the knife, moved towards the officers.  Officer number one discharged his service weapon, striking the offender in the torso. The offender was transported to Penn Presbyterian Medical Center where he was pronounced deceased.
## There were no other injuries as a result of this incident.  A knife was recovered at the scene.
## *** Information posted in the original summary reflects a preliminary understanding of what occurred at the time of the incident. This information is posted shortly after the incident and may be updated as the investigation leads to new information. The DA’s Office is provided all the information from the PPD’s investigation prior to their charging decision.
## 
## ﻿OIS# 17-30
## On Saturday, November 11, 2017, at approximately 1:43 AM, three uniformed 17th District officers responded to a disturbance at a property in the 1200 block of south 29th Street. While attempting to quell the dispute between two male residents of the property, one of the male’s produced a folding knife. One officer drew his firearm, and two officers drew their ECW’s (Taser) and told the male to drop the knife. The male moved towards one officer and lunged at the officer with his knife. The officer discharged one round striking the male in the chest. The male was admitted to Presbyterian Hospital in critical condition. The knife was recovered from the male.
## *** Information posted in the original summary reflects a preliminary understanding of what occurred at the time of the incident. This information is posted shortly after the incident and may be updated as the investigation leads to new information. The DA’s Office is provided all the information from the PPD’s investigation prior to their charging decision.
## 
## ﻿OIS# 17-36
## On Tuesday, December 26, 2017, at approximately 9:40 AM, three plainclothes 18th District officers pursued a vehicle bearing a license plate of a vehicle that was stolen in a gunpoint robbery at 3:00AM that day.  The operator fit the description of the offender in the 3AM robbery and in a second gunpoint robbery that occurred at 9:00AM at a local business. The stolen vehicle crashed into an occupied vehicle at 49th and Walnut Streets, and the three plainclothes officers approached the stolen vehicle. One of the officers approached the driver’s side of the vehicle with his weapon drawn and opened the driver’s door. The male operator refused commands to show his hands and reached towards his waistband.  The officer positioned at the open driver’s door discharged one round striking the male in the chest. The male was admitted to Presbyterian Hospital in critical condition. No firearm was recovered from the male or the vehicle. The male was positively identified by both robbery victims.
## No other injuries were reported in connection with this incident.   
## *** Information posted in the original summary reflects a preliminary understanding of what occurred at the time of the incident. This information is posted shortly after the incident and may be updated as the investigation leads to new information. The DA’s Office is provided all the information from the PPD’s investigation prior to their charging decision.
## 
## ﻿PS# 16-01
## 1/07/16
## On Thursday, January 7, 2016, at approximately 11:41 P.M., a uniformed officer in a marked police vehicle was traveling north in the 300 block of S. 60th Street, when he observed a male approaching his vehicle near the intersection of 60th and Spruce Streets.  The male was armed with a firearm.  Without warning, the offender discharged the firearm, striking the officer as he remained seated inside his police vehicle.  The offender advanced to the driver’s door of the police vehicle and leaned in through the shattered window, still discharging his firearm at the officer.  The offender then fled on foot, but continued to discharge his weapon at the officer. The officer exited his police vehicle and returned fire striking the offender.  The offender was apprehended by responding officers in the 5900 block of Delancey Street. 
## The officer was transported to Penn-Presbyterian Hospital where he was admitted.
## The offender was transported to the Hospital of the University of Pennsylvania for treatment.
## The offender’s firearm, a Glock, 9MM, semi-automatic pistol, which had been reported stolen, was recovered empty, with the slide locked to the rear, at the scene.
## There were no other injuries as a result of this firearm discharge. 
##   *** Information posted in the original summary reflects a preliminary understanding of what occurred at the time of the incident. This information is posted shortly after the incident and may be updated as the investigation leads to new information. The DA’s Office is provided all the information from the PPD’s investigation prior to their charging decision.
## Summary chart: https://drive.google.com/open?id=0B9DvDlV7ezcqWlptNDZ0Ny1IWUk
## Ps# 16-01 summary: https://drive.google.com/open?id=0B9DvDlV7ezcqdTNtQXd6T3M1ZVk
## 
## ﻿PS# 16-11
## 4/17/16
## On Sunday, April 17, 2016, at approximately 8:52 P.M., uniformed officers in a marked police vehicle were waved down in the 5900 block of Market Street by a female complainant of a robbery. The complainant told the officers that she was sitting in her parked Dodge Durango, in the unit block of south Salford Street, when two unknown males ordered her out of the vehicle, point of gun.  The female exited her vehicle and ran to the 5900 block of Market Street, where she alerted the officers. The officers drove to the unit block of S. Salford Street and observed the offenders in the Durango. Offender #1 exited the vehicle and fled south on S. Salford Street, with officer #1 in pursuit, in the police vehicle.  Officer #2 exited the police vehicle and approached offender #2, who was seated in the passenger side of the Durango.  
## As officer #2 approached the Durango, offender #2 exited the vehicle, and became involved in a physical struggle with officer #2.  During the struggle offender #2 discharged a gun striking officer #2 in the left leg. Offender #2 then fled north on N. Salford Street, at which time officer #2 discharged his weapon, missing the offender.   Offender #2 was lost in the area.
## Officer #1 returned to his partner and subsequently transported him to Penn-Presbyterian Hospital, where he was admitted. 
## Offender #1 was detained by civilians at 60th and Market Streets and ultimately turned over to responding officers.   
## Minutes before this incident, the same two offenders committed a point of gun robbery of a male complainant in the 5900 block of Market Street. The offenders took the male complainant’s car keys and mistakenly believed the Durango belonged to him.   
## There are no other known injuries at this time.
## Offender #2 was subsequently identified and apprehended in the 1200 block of N. Alden Street on 4/18/16. Arresting officers recovered a 9 MM pistol from the offender.  
## *** Information posted in the original summary reflects a preliminary understanding of what occurred at the time of the incident. This information is posted shortly after the incident and may be updated as the investigation leads to new information. The DA’s Office is provided all the information from the PPD’s investigation prior to their charging decision.
## 
## ﻿PS#16-12
## 5/03/16
## On Tuesday, May 3, 2016, at approximately 11:14 P.M., uniformed police officers in a marked police vehicle, while on patrol, heard gunshots coming from a rear alley, between the 5300 block of Lindbergh Boulevard and the 5300 block of Grays Avenue. The officers entered the alley and observed a male standing on the rear deck of a property in the 5300 block of Grays Avenue, holding a gun in his hand. The officers ordered the offender to drop the gun. The offender ignored the officers’ commands and discharged the weapon one time at the officers. In response, one of the officers discharged his firearm, striking the offender. The offender fled into the rear of a property in the 5300 block of Grays Avenue. The officers entered the property and observed the offender lying on the kitchen floor.  The officers then observed a second male flee the property, through the front door.  The second male was apprehended in the 5300 block of Grays Avenue.  
## The offender’s firearm, a .22 caliber, semi-automatic pistol, loaded with four live rounds was recovered on the front porch of a property in the 5300 block of Grays Avenue.  
## The offender was transported to Penn-Presbyterian Hospital for treatment.
## There were no other reported injuries as a result of this police firearm discharge incident.
##   *** Information posted in the original summary reflects a preliminary understanding of what occurred at the time of the incident. This information is posted shortly after the incident and may be updated as the investigation leads to new information. The DA’s Office is provided all the information from the PPD’s investigation prior to their charging decision.
## 
## ﻿PS#16-13
## 5/04/16
## On Wednesday May 4, 2016, at approximately 12:58 A.M., on-duty officers, in plainclothes, and an unmarked police vehicle, responded to a Police Radio assignment to investigate a Dodge Caravan acting suspicious, in the area of 6300 Overbrook Avenue. The officers observed the vehicle being operated by a male, circling the block.  The officers requested a marked police vehicle to assist them.  A uniformed officer, in a marked police vehicle, responded, and pulled behind the Dodge Caravan in the 6300 block of Overbrook Avenue, and activated his emergency equipment.  At the same time, the officers in the unmarked police vehicle stopped in front of the Dodge Caravan.  Both officers exited the unmarked police vehicle and ordered the male operator to turn the engine off.
## The offender accelerated his vehicle forward in the direction of one of the officers, who drew his weapon, and discharged it, striking the offender. The offender’s vehicle continued forward into the 6200 block of Overbrook Avenue, where it crashed into several parked unattended vehicles. The offender was transported to Penn-Presbyterian Hospital, where he was pronounced deceased. 
## There were no other reported injuries as a result of the firearm discharge.   
## No weapon was recovered.
##  *** Information posted in the original summary reflects a preliminary understanding of what occurred at the time of the incident. This information is posted shortly after the incident and may be updated as the investigation leads to new information. The DA’s Office is provided all the information from the PPD’s investigation prior to their charging decision.
## 
## ﻿PS#16-29
## 9/09/16
## On Friday, September 9, 2016, at approximately 4:43 P.M., uniformed officers, in a marked police vehicle, responded to a Police Radio assignment of a “Person screaming” inside a property in the 200 block of Millick Street.  Upon their arrival, a female opened the door of the property and informed the officers that a male had assaulted a second female inside the property.  Simultaneously, the male emerged from the kitchen and began firing a weapon at the officers.  One of the rounds fired by the offender struck the female at the door.  In response, both officers discharged their weapons, striking the offender, as he retreated into the property.  
## A barricaded person was declared and the SWAT Unit was called to the scene.  The offender was ultimately apprehended inside the property by SWAT officers.    
## The offender’s firearm, a .380 caliber semi-automatic pistol, loaded with 1 live round, was recovered at the scene.
## The offender and the female who was struck by the offender’s gunfire were both transported to Penn-Presbyterian Hospital for treatment.   
## There were no other injuries as a result of this incident.
## *** Information posted in the original summary reflects a preliminary understanding of what occurred at the time of the incident. This information is posted shortly after the incident and may be updated as the investigation leads to new information. The DA’s Office is provided all the information from the PPD’s investigation prior to their charging decision.
## 
## ﻿PS#16-30
## 9/16/16
## On Friday, September 16, 2016, at approximately 11:18 P.M., a uniformed sergeant in a marked police vehicle was seated in her parked vehicle in the 5100 block of Sansom Street, when a male approached and without warning, began to discharge a firearm, striking the sergeant, as she remained seated in her vehicle. The offender then began walking east on Sansom Street, stopping at a lounge/bar in the 5100 block of Sansom Street, where he discharged his firearm into the lounge/bar, striking a female employee and a male security guard. The offender continued walking east on Sansom Street to the 4900 block, where he discharged his firearm into an occupied parked vehicle, striking one female and one male occupant.
## Responding uniformed officers, in marked police vehicles, along with an officer from the University of Pennsylvania police force, located the offender in an alleyway in the rear of the 4800 blocks of Sansom and Walnut Streets. While in the 4800 block of Sansom Street the offender discharged his firearm, striking the University of Pennsylvania Officer as well as a marked police vehicle. Four Officers (one of whom was the University of Pennsylvania Officer) discharged their firearms, striking the offender.  The offender fell to the ground and dropped his firearm.  Fire Rescue responded and pronounced the offender deceased. 
## The offender’s firearm, a 9MM, semi-automatic pistol, with an obliterated serial number, loaded with 14 live rounds, was recovered at the scene. There were three empty magazines from the offender’s firearm recovered throughout the scene.  
## The sergeant, the University of Pennsylvania Officer, along with the four civilians who were all struck by gunfire, were transported to Penn-Presbyterian Hospital for treatment.
## The female from the parked vehicle was later pronounced deceased at Penn-Presbyterian Hospital.
## *** Information posted in the original summary reflects a preliminary understanding of what occurred at the time of the incident. This information is posted shortly after the incident and may be updated as the investigation leads to new information. The DA’s Office is provided all the information from the PPD’s investigation prior to their charging decision.
## 
## ﻿PS#16-32
## 9/28/16
## On Wednesday, September 9, 2016, at approximately 7:10 P.M., uniformed and plainclothes officers, in both marked and unmarked police vehicles, responded to a Police Radio assignment of a “Person screaming, someone shot”, in the 6200 block of Hazel Avenue.  Upon their arrival, the officers encountered two juvenile males with multiple stab wounds and a juvenile female who had been choked  by a male relative.  The offender was identified as the father of the female and one of the males and appeared to be under the influence of narcotics. 
## Officers surveyed the area and received information that the offender may be at a property in the 700 block of Cobbs Creek Parkway.  Upon arrival at that location, the officers observed the offender exit the property with his right hand in his pocket.  The officers gave the offender commands to show his hands, but he did not comply. At one point, the offender abruptly removed his right hand from his pocket, holding an object that appeared to the officers to be a handgun. 
## In response, the officers discharged their weapons, striking the offender.  The offender was transported to Penn-Presbyterian Hospital, where he was pronounced deceased.  
## No weapon was recovered from the offender or his immediate area; however, a cellular telephone was recovered from the ground near the offender.
## Two additional victims were located inside the property in the 700 block of Cobbs Creek Parkway.  The victims indicated that the offender cut one of their throats and punched the other multiple times in the face.  The victims were transported to Penn-Presbyterian Hospital and Mercy Hospital, respectively, for treatment.
## A switchblade type knife and a steak knife were recovered from the properties.
## There were no other injuries as a result of this incident.  
## *** Information posted in the original summary reflects a preliminary understanding of what occurred at the time of the incident. This information is posted shortly after the incident and may be updated as the investigation leads to new information. The DA’s Office is provided all the information from the PPD’s investigation prior to their charging decision.
## 
## ﻿PS# 16-35
## 10/19/16
## On Saturday, October 22, 2016, at approximately 4:10 A.M., uniformed officers, in a marked police vehicle, were responding to a Police Radio assignment of a disturbance in the 600 block of N. 56th Street.  As the officers approached the intersection of 56th Street and Haverford Avenue, they heard gunshots and saw muzzle flashes coming from a driveway in the 5500 block of Haverford Avenue. The officers stopped, exited their vehicle, and approached the driveway. As the officers approached, a male ran north on 56th Street.  Officer number one pursued the male on foot and apprehended him in the 500 block N. 56th Street.  A second male exited the driver side door of a nearby black Toyota Corolla and walked toward Officer number two. Officer number two ordered the male to stop.  The male reached toward his waistband.  In response, Officer number two discharged his firearm, striking the offender. A third male was also apprehended outside of the Toyota.  A fourth male fled from the scene on foot and was not identified.
## The offender was transported to Penn-Presbyterian Hospital for treatment.
## No weapon was recovered; however, fifteen fired cartridge casings were recovered at the scene. 
## There were no other injuries as a result of this incident.
## *** Information posted in the original summary reflects a preliminary understanding of what occurred at the time of the incident. This information is posted shortly after the incident and may be updated as the investigation leads to new information. The DA’s Office is provided all the information from the PPD’s investigation prior to their charging decision.</code></pre>
<pre class="r"><code>cat(paste(ois$id[i], collapse=&#39;&quot;,&quot;&#39;))</code></pre>
<pre><code>## 22-15&quot;,&quot;22-07&quot;,&quot;22-03&quot;,&quot;21-15&quot;,&quot;20-31&quot;,&quot;20-29&quot;,&quot;19-04&quot;,&quot;18-02&quot;,&quot;17-13&quot;,&quot;17-30&quot;,&quot;17-36&quot;,&quot;16-01&quot;,&quot;16-11&quot;,&quot;16-12&quot;,&quot;16-13&quot;,&quot;16-29&quot;,&quot;16-30&quot;,&quot;16-32&quot;,&quot;16-35</code></pre>
<pre class="r"><code>ois$hospital[ois$id %in% c(&quot;22-07&quot;,&quot;22-03&quot;,&quot;20-29&quot;,&quot;19-04&quot;,&quot;18-02&quot;,&quot;17-13&quot;,
                           &quot;17-30&quot;,&quot;17-36&quot;,&quot;16-12&quot;,&quot;16-13&quot;,&quot;16-29&quot;,&quot;16-32&quot;,
                           &quot;16-35&quot;)] &lt;- &quot;Presby&quot;

#look for Hospital of the University of Pennsylvania
i &lt;- grep(&quot;Hospital of the University of Pennsylvania&quot;,ois$text)
cat(gsub(&quot;Hospital of the University of Pennsylvania&quot;, 
         bgYellow$black$bold(&quot;Hospital of the University of Pennsylvania&quot;), 
         ois$text[i]),
    sep=&quot;\n\n&quot;)</code></pre>
<pre><code>## ﻿PS# 16-01
## 1/07/16
## On Thursday, January 7, 2016, at approximately 11:41 P.M., a uniformed officer in a marked police vehicle was traveling north in the 300 block of S. 60th Street, when he observed a male approaching his vehicle near the intersection of 60th and Spruce Streets.  The male was armed with a firearm.  Without warning, the offender discharged the firearm, striking the officer as he remained seated inside his police vehicle.  The offender advanced to the driver’s door of the police vehicle and leaned in through the shattered window, still discharging his firearm at the officer.  The offender then fled on foot, but continued to discharge his weapon at the officer. The officer exited his police vehicle and returned fire striking the offender.  The offender was apprehended by responding officers in the 5900 block of Delancey Street. 
## The officer was transported to Penn-Presbyterian Hospital where he was admitted.
## The offender was transported to the Hospital of the University of Pennsylvania for treatment.
## The offender’s firearm, a Glock, 9MM, semi-automatic pistol, which had been reported stolen, was recovered empty, with the slide locked to the rear, at the scene.
## There were no other injuries as a result of this firearm discharge. 
##   *** Information posted in the original summary reflects a preliminary understanding of what occurred at the time of the incident. This information is posted shortly after the incident and may be updated as the investigation leads to new information. The DA’s Office is provided all the information from the PPD’s investigation prior to their charging decision.
## Summary chart: https://drive.google.com/open?id=0B9DvDlV7ezcqWlptNDZ0Ny1IWUk
## Ps# 16-01 summary: https://drive.google.com/open?id=0B9DvDlV7ezcqdTNtQXd6T3M1ZVk</code></pre>
<pre class="r"><code>cat(paste(ois$id[i], collapse=&#39;&quot;,&quot;&#39;))</code></pre>
<pre><code>## 16-01</code></pre>
<pre class="r"><code>ois$hospital[ois$id %in% c(&quot;16-01&quot;)] &lt;- &quot;HUP&quot;

#look for Temple Hospital
i &lt;- grep(&quot;Temple Hospital&quot;,ois$text)
cat(gsub(&quot;Temple Hospital&quot;, 
         bgYellow$black$bold(&quot;Temple Hospital&quot;), 
         ois$text[i]),
    sep=&quot;\n\n&quot;)</code></pre>
<pre><code>## 22xx West Hunting Park Avenue
## On Wednesday, May 11, 2022, at approximately 9:19 AM, a 39th District officer (Officer “A”*) working inside the 39th District Operations Room observed a black male wearing a mask standing at the window. Officer “A” approached the window and asked, “How can I help you?” The male began to speak and because of his mask, Officer “A” could not hear what he was saying. The male stated to the officer, “Come outside, I need to talk to you.” Officer “A” opened the door, slightly, and the male grabbed the door handle and pulled open the door. The male lunged at Officer “A” with a screwdriver in the area of his face and chest. Officer “A” grabbed the male’s arm and pulled him into the operations room and both fell to the ground. While Officer “A” was lying on his back, the male attempted several times to stab him. The male stabbed Officer “A” in the right side of the back of the head.
## The Discharging Officer, Officer #1, was in full uniform working inside of the 39th District Operations room. Officer #1 observed a male come into the Operations Room and begin to Officer “A”. The male was holding a weapon in his right hand, swinging several times at Officer “A”. Officer #1 drew her weapon and discharged one time at the male, striking him in the torso.
## The male’s weapon (screwdriver) was recovered at the scene.
## The injured officer, Officer “A”, was transported to Temple Hospital by police. He was listed in stable condition and was treated and released.
## The male was transported to Temple Hospital by police and taken to the operating room. He was listed in critical but stable condition.
## The investigation is active and ongoing with the Officer-Involved Shooting Investigation Unit.
## Officer #1, the Discharging Officer, has been placed on administrative duty pending the outcome of the Internal Affairs investigation.
## *The lettered Officer (Officer “A”) in this OIS denotes an Officer who was involved in the incident but did not discharge their weapon. The numbered Officer (Officer #1) denotes the discharging Officer.
## 
## 47xx Leiper Street
## On 4/6/2022, at approximately 7:00 PM, two 15th District officers were travelling along 4700 Penn St. in their marked vehicle when they heard 8-9 gunshots near their location. The officers saw a Black male with a black hooded sweatshirt running down the 1600 block of Arrott Street. The officers exited their vehicle and engaged the male in a foot pursuit. The officers relayed to police radio that they were involved in a foot pursuit and notified radio that they were coming up 4700 Penn Street. Once they got to Arrott Street, one of the officers lost sight of the male but his partner indicated that he “ran into the building over here.” Passers-by also pointed the location out to the officers and stated “He ran into there! In that house!” indicating 4701 Leiper Street. The officers notified police radio and informed them that a male was barricaded inside that location. The officers remained on location keeping an eye on the building. They could hear movement in the location and at one point, the same male they had chased had started to exit the side door of the structure, and upon seeing them, slammed the door and returned to the home. The officers noted that the male was no longer wearing the hooded sweatshirt.
## Additional officers arrived on location to the barricade incident. A short time later, officers heard gunshots coming from above inside of the residence at 4701 Leiper Street. A responding supervisor told the group of officers to remain in cover, as this was an active shooter situation. At some point, a request was made over police radio for long-gun trained officers to assist. A SEPTA Officer arrived at the location with a long-gun. The SEPTA Police Officer was at 1400 Arrott Street attempting to take cover behind a patrol vehicle, and while doing so, he was struck in the stomach area by gunfire. Responding officers transported him to Temple Hospital where he was listed critical but stable condition after receiving surgery for a GSW to the abdomen.
## During this incident, additional officers who arrived on location discharged their firearms at the offender who was positioned on the second floor near the windows, armed with a firearm.
## The crime scene was processed and inside investigators observed a Black male, face-up, with an apparent GSW to his head. In addition, these investigators observed a black semi-automatic handgun near his right shoulder in the 2nd floor front bedroom of 4701 Leiper Street.
## Responding officers initially believed the GSW to the head was self-inflicted, due to preliminary evidence observed.
## The decedent’s body was removed from the scene and transported to the Medical Examiner’s Office.
## An autopsy of the decedent was completed on 4/7/22 by the Philadelphia Medical Examiner’s Office.
## As part of the ongoing investigation, it is currently believed that the decedent’s GSW to the head was not self-inflicted, and was caused by shots fired from discharging officers at some point during the exchange of gunfire between the decedent and discharging officers.
## Note: During the course of this incident, officers came upon two gunshot victims &amp;#8211; female victim #1 sustained a graze wound to her right upper hip area and female victim #2 who sustained a perforating gunshot wound to her buttocks. These victims were transported to Temple Hospital and were placed in stable condition.
## A third gunshot victim – a male &amp;#8211; walked into Jefferson-Frankford Hospital with 2 GSWs to the neck area. He was transported to Jefferson-Torresdale where he was intubated. Upon further investigation, it is believed that this male was involved in a physical altercation with the offender, and while walking away, the offender fired at him – striking him as well as the two female victims.
## Offender/Decedent: 18/B/M.
## Offender’s weapon: Polymer 80 Privately Made Firearm (PMF – aka “Ghost Gun”) 9MM semi-auto pistol.
## Victim #1: 52/F: GSW to right upper hip area
## Victim #2: 42/F: GSW to buttocks
## Victim #3: 33/M: Two GSWs to neck
## Victim #4: 28/M SEPTA PD P/O Injuries: GSW to abdomen
## Discharging Officer #1: 15th District P/O 45/W/M
## Discharging Officer #2: 15th District P/O 36/W/M
## Discharging Officer #3: 25th District P/O 27/B/M
## Discharging Officer #4: 25th District P/O 31/W/M
## Discharging Officer#5: 24th District P/O 30/W/M
## Discharging Officer #6: 2nd District P/O 37/W/M
## Discharging Officer #7: 15th District P/O 33/H/M
## The Investigation is active and ongoing with the Officer-Involved Shooting Investigation Unit.
## All discharging officers have been placed on administrative duty pending the outcome of the Internal Affairs investigation.
## 
## 100 West Lehigh Avenue 
## On Friday, February 11, 2022 at approximately 12:37pm, members of the Philadelphia Police Department’s SWAT Unit were at 1xx West Lehigh Avenue to execute a search warrant. The search warrant was to search for a 35/H/M wanted for parole violations.
## Police Officers #1 and #2, from the Philadelphia Police Department’s SWAT Unit, knocked and announced “POLICE WITH A WARRANT” and breached the front door. Police Officers #3, #4, #5, also assigned to SWAT, were assigned as the 3rd floor entry team. Officer #3, equipped with a ballistic shield, assigned to be first in line, ascended the stairs and made his way to the 3rd floor apartment door. Officer #3 put his shield to the door and called up the “breacher”. Officer #4 used a breaching shotgun on the door lock and deadbolt, discharging three (3) rounds on the lock with negative results for breaching the lock. At that point, Officer #3 called for a ram. Officer #3 bladed his body, in order to make room for Officer #4 to strike the door with a “ram”. At that point, Officer #3, facing the apartment wall, still positioned in the stairwell, heard “pops” emanating from inside the 3rd floor apartment. Officer #3 noted that the “pops” were very light, because he had his headset on. Officer #3 then heard two additional “pops”, then a third “pop”, followed by the sensation of a “sting” in his chest. He observed a hole in the wall and drywall dust on his shoulder. Additionally, he observed a hole through the 3rd floor apartment door. Officer #3 informed his team, via SWAT Band, that he was shot. At that point, Officer #3 exited the property. SWAT Unit personnel transported Police Officer #3 to Temple Hospital where he received treatment by medical staff. The bullet did not penetrate his ballistic vest. Police Officer #3 sustained a “red mark” to his chest, from where the bullet stuck his vest.
## Police Officer #6 and #7, also assigned to SWAT, were positioned in the rear of the property. Police Officer #6 and Police Officer #7 observed a male, later positively identified as the male wanted for parole violations, exit the 3rd floor rear window, jumping down to the 2nd floor’s rooftop. Police Officer #6 stated, “Gun! DROP THE GUN!” The male then pointed his firearm at Police Officer #6. Police Officer #6 discharged his weapon at the male, missing him, who then discarded his weapon on another adjacent rooftop. The magazine dislodged from the firearm’s magazine well and landed on the ground, behind the property.
## Police Officer #4 made his way to the 2nd floor and climbed through the window and onto the roof. He turned the corner and observed the male, but could not see his hands. Police Officer #4 ordered the male to “show his hands.” However, the male did not comply. A brief struggle ensued and the male was eventually placed in handcuffs. The male complained of pain to his ankle. Police transported the male to AEMC where he received treatment for his injured ankle.
## The male’s firearm, a Glock 17, 9MM, semi-automatic handgun, was recovered with one (1) live round in the chamber, the magazine had ten (10) live 9MM rounds inside.
## Note: The firearm is in stolen status, stolen from Upper Darby, Pa.
## The discharging officer, Officer #6, has been placed on administrative duty pending the outcome of the Internal Affairs Bureau and Officer-Involved Shooting Investigations Unit investigations.
## 
## ﻿PHILADELPHIA POLICE OFFICER INVOLVED SHOOTING
## 33xx Emerald Street
## PS20-34
## On Friday, 12-25-2020, at approximately 12:22 AM, Officer #1 and Officer #2 were operating a marked patrol wagon, in full uniform, when a radio call for a disturbance/fight on the highway at 33xx Emerald Street was broadcast. While police were attempting to diffuse the disturbance, additional family members exited their residences and formed a large crowd on the sidewalk and in the middle of the street. The parties involved began to escalate the situation by pushing and throwing punches at each other. The Offender, a 43-year-old Hispanic male, removed a handgun from his right rear waistband and discharged his weapon, striking Victim #1, a 15-year-old Hispanic male, and Victim #2, a 17-year-old Hispanic male both in the neck. Officer #1 and Officer #2 then drew their weapons and discharged, striking the Offender in the torso. Officer #1 was able to recover the weapon from the Offender’s hand. 
## Police transported all three individuals to Temple Hospital. 
## The Offender was pronounced at the hospital. 
## Victim #1 was also pronounced at the hospital. 
## Victim #2 is being treated and is currently listed in stable condition. 
## There were no other reported injuries to police or civilians. 
## The Offender’s weapon, a 9MM Smith &amp;amp; Wesson is stolen out of Virginia. 
## The investigation is still active and ongoing.
## 
## PHILADELPHIA POLICE OFFICER INVOLVED SHOOTING
## 47xx Rorer Street
## PS20-33
## On Wednesday, 12-9-2020, at approximately 10:54 AM, Officer #1 and Officer #2, operating a
## marked patrol vehicle and in full uniform, responded to a radio call for a person armed with a
## knife at 47xx Rorer St. Upon arrival, the officers encountered the defendant, a Hispanic male, on
## the top landing of the stairs, armed with a knife. When the male began descending down the
## steps towards the officers, the officers immediately began to back away from the male while
## ordering him to drop the knife.
## Officer #1, not equipped with a Taser, drew his firearm and ordered the defendant to stop and
## drop the knife. Officer #2 drew his Taser and ordered the male several times to drop the knife.
## When the defendant kept advancing towards the officers, Officer #2 discharged his Taser,
## striking the male center mass with no effect. The defendant then began to charge in the direction
## of Officer #1 while holding a 10-inch knife in his right hand.
## Backup officers, Officer #3 and Officer #4 operating a marked patrol vehicle, in full uniform,
## responded to the original person with a weapon call and assist officer. Upon arrival, the officers
## observed the defendant, armed with a large knife, walking towards Officer #1 and Officer #2.
## Officer #3 was shouting, “Drop the knife” and heard a Taser being deployed, striking the male
## with no effect. The defendant, still armed with the knife, continued in the direction of Officer #1,
## causing Officer #3 to discharge his Taser, again striking the male with no effect.
## The defendant continued charging at Officer #1. Officer #1 retreated, running backwards for 225
## feet, in the middle of the street and gave approximately (13) thirteen commands to “drop the
## knife”.  Officer #3 was running along the west sidewalk and deployed his Taser, a second time,
## striking the male on his left side with no effect. Officer #1 fired his weapon (2) two times and
## paused shouting for the male to stop. When the defendant continued to advance towards Officer
## #1, Officer #1 fired a third time, striking the male in the chest. Officer #1 kicked the knife away
## from the defendant and the male was taken into custody.
## The male was transported to Temple Hospital by police and is listed in critical condition.
## There were no other reported injuries to police or civilians.
## The investigation is still active and ongoing. Attempts are being made to identify the defendant.
## 
## ﻿OIS 19-23
## 11/21/19
## On November 21, 2019, at approximately 9:58 am, two uniformed 15th District officers responded to a radio call of a person with a gun at 4100 Comly Street.  While surveying the area, from their patrol car, they received information from Police Radio that the person, a male was on a SEPTA bus, traveling south in the 5900 block of Torresdale Avenue.  
## The officers saw the bus and positioned their police car in front of the bus, stopping it.  The officers boarded the front of the bus and saw a male, armed with a gun, positioned near the rear door, pointing a firearm in their direction.  The male told the officers to get off the bus.  The officers retreated to the front door and exited. As the officers sought cover, the male moved to the rear exit door, extended his arm out of the door and fired his gun at the officers, missing them.  He fired the gun again at the officers again as he exited the.  The officers then discharged their firearms striking the male multiple times. The male turned and ran towards the rear of the bus and pointed and fired his gun at a third officer who had arrived on the scene, striking the third officer in the arm. The male ran to the sidewalk, collapsed and was transported to Temple Hospital in critical condition.  The male’s .22 caliber weapon was recovered at the scene. The officer who was shot was treated at Jefferson-Torresdale Hospital and released. 
## *** Information posted in the original summary reflects a preliminary understanding of what occurred at the time of the incident. This information is posted shortly after the incident and may be updated as the investigation leads to new information. The District Attorney’s Office is provided all the information from the PPD’s investigation prior to their charging decision.
## 
## ﻿OIS 18-28
## At approximately 8:47 AM on December 5, 2018, a uniformed officer assigned to the 24th District, operating a marked patrol vehicle, responded to a radio call for a “Fight on the Highway” on the 3500 block of Belgrade Street.  Upon arrival, the officer observed several civilians saying, “get him” while pointing at 35xx Belgrade Street. The officer observed a woman in the doorway of a residence on the block pushing a male, out of the doorway, while shouting, “Get Out of my House!” The officer observed the male push past woman and enter her residence. The woman stated she did not know the male and did not give him permission to enter her residence. The officer entered the house and observed the male in the kitchen with his right hand concealed behind his back near the kitchen counter. The officer drew his Electronic Control Weapon (ECW – commonly referred to as a taser) and ordered the male to show his hands several times.  However, he did not comply.  He instead advanced towards the officer, who then activated his ECW, which failed to deploy.  The male continued to advance towards the officer, yielding a knife.  The officer dropped his ECW, drew his firearm, and discharged one round, striking the male in his chest. 
## The male was transported to Temple Hospital and was pronounced deceased at 9:16 AM.  No other injuries were reported in connection with this incident.
## A black handled, 7-inch steak knife was recovered at the scene.
## *** Information posted in the original summary reflects a preliminary understanding of what occurred at the time of the incident. This information is posted shortly after the incident and may be updated as the investigation leads to new information. The District Attorney’s Office is provided all the information from the PPD’s investigation prior to their charging decision.
## 
## ﻿PS#16-19
## 5/31/16
## On Tuesday, May 31, 2016, at approximately 11:15 PM, an off-duty officer in civilian attire was operating his motorcycle northbound in the 3400 block of North Broad Street.  The officer proceeded through the intersection at Tioga Street, at which time a green Chevy Monte Carlo, traveling south in the 3500 block of North Broad Street turned left turn in front of him, causing him to collide with the vehicle. At the point of impact, the officer was thrown from his motorcycle and landed on the highway.  At that point, the operator of the Monte Carlo attempted to flee the scene, but was blocked by the motorcycle. The officer approached the driver’s door and identified himself as a police officer.  The operator dislodged the vehicle from the motorcycle and began to drag the officer.  While being dragged by the vehicle, the officer observed the offender reach for a firearm in the vehicle.  In response, the officer discharged his weapon, missing the offender.    
## The officer was treated and subsequently released from Temple Hospital  
## There were no other known injuries as a result of this incident.
## No weapon was recovered.
## *** Information posted in the original summary reflects a preliminary understanding of what occurred at the time of the incident. This information is posted shortly after the incident and may be updated as the investigation leads to new information. The DA’s Office is provided all the information from the PPD’s investigation prior to their charging decision.</code></pre>
<pre class="r"><code>cat(paste(ois$id[i], collapse=&#39;&quot;,&quot;&#39;))</code></pre>
<pre><code>## 22-14&quot;,&quot;22-10&quot;,&quot;22-06&quot;,&quot;20-34&quot;,&quot;20-33&quot;,&quot;19-23&quot;,&quot;18-28&quot;,&quot;16-19</code></pre>
<pre class="r"><code>ois[ois$id == &quot;22-14&quot;,] </code></pre>
<pre><code>## Simple feature collection with 1 feature and 10 fields
## Geometry type: POINT
## Dimension:     XY
## Bounding box:  xmin: -75.16457 ymin: 40.0109 xmax: -75.16457 ymax: 40.0109
## Geodetic CRS:  WGS 84
##      id                                        location       date
## 4 22-14 2200 West Hunting Park Avenue, Philadelphia, PA 2022-05-11
##                                        url
## 4 https://ois.sites.phillypolice.com/22-14
##                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   text
## 4 22xx West Hunting Park Avenue\nOn Wednesday, May 11, 2022, at approximately 9:19 AM, a 39th District officer (Officer “A”*) working inside the 39th District Operations Room observed a black male wearing a mask standing at the window. Officer “A” approached the window and asked, “How can I help you?” The male began to speak and because of his mask, Officer “A” could not hear what he was saying. The male stated to the officer, “Come outside, I need to talk to you.” Officer “A” opened the door, slightly, and the male grabbed the door handle and pulled open the door. The male lunged at Officer “A” with a screwdriver in the area of his face and chest. Officer “A” grabbed the male’s arm and pulled him into the operations room and both fell to the ground. While Officer “A” was lying on his back, the male attempted several times to stab him. The male stabbed Officer “A” in the right side of the back of the head.\nThe Discharging Officer, Officer #1, was in full uniform working inside of the 39th District Operations room. Officer #1 observed a male come into the Operations Room and begin to Officer “A”. The male was holding a weapon in his right hand, swinging several times at Officer “A”. Officer #1 drew her weapon and discharged one time at the male, striking him in the torso.\nThe male’s weapon (screwdriver) was recovered at the scene.\nThe injured officer, Officer “A”, was transported to Temple Hospital by police. He was listed in stable condition and was treated and released.\nThe male was transported to Temple Hospital by police and taken to the operating room. He was listed in critical but stable condition.\nThe investigation is active and ongoing with the Officer-Involved Shooting Investigation Unit.\nOfficer #1, the Discharging Officer, has been placed on administrative duty pending the outcome of the Internal Affairs investigation.\n*The lettered Officer (Officer “A”) in this OIS denotes an Officer who was involved in the incident but did not discharge their weapon. The numbered Officer (Officer #1) denotes the discharging Officer.
##                                                    addrmatch score
## 4 2200 W Hunting Park Ave, Philadelphia, Pennsylvania, 19140   100
##        addrtype scoreCol                  geometry hospital
## 4 StreetAddress     blue POINT (-75.16457 40.0109)  fill in</code></pre>
<pre class="r"><code>ois[ois$id == &quot;22-10&quot;,]</code></pre>
<pre><code>## Simple feature collection with 1 feature and 10 fields
## Geometry type: POINT
## Dimension:     XY
## Bounding box:  xmin: -75.08632 ymin: 40.01798 xmax: -75.08632 ymax: 40.01798
## Geodetic CRS:  WGS 84
##      id                             location       date
## 5 22-10 4700 Leiper Street, Philadelphia, PA 2022-04-07
##                                        url
## 5 https://ois.sites.phillypolice.com/22-10
##                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    text
## 5 47xx Leiper Street\nOn 4/6/2022, at approximately 7:00 PM, two 15th District officers were travelling along 4700 Penn St. in their marked vehicle when they heard 8-9 gunshots near their location. The officers saw a Black male with a black hooded sweatshirt running down the 1600 block of Arrott Street. The officers exited their vehicle and engaged the male in a foot pursuit. The officers relayed to police radio that they were involved in a foot pursuit and notified radio that they were coming up 4700 Penn Street. Once they got to Arrott Street, one of the officers lost sight of the male but his partner indicated that he “ran into the building over here.” Passers-by also pointed the location out to the officers and stated “He ran into there! In that house!” indicating 4701 Leiper Street. The officers notified police radio and informed them that a male was barricaded inside that location. The officers remained on location keeping an eye on the building. They could hear movement in the location and at one point, the same male they had chased had started to exit the side door of the structure, and upon seeing them, slammed the door and returned to the home. The officers noted that the male was no longer wearing the hooded sweatshirt.\nAdditional officers arrived on location to the barricade incident. A short time later, officers heard gunshots coming from above inside of the residence at 4701 Leiper Street. A responding supervisor told the group of officers to remain in cover, as this was an active shooter situation. At some point, a request was made over police radio for long-gun trained officers to assist. A SEPTA Officer arrived at the location with a long-gun. The SEPTA Police Officer was at 1400 Arrott Street attempting to take cover behind a patrol vehicle, and while doing so, he was struck in the stomach area by gunfire. Responding officers transported him to Temple Hospital where he was listed critical but stable condition after receiving surgery for a GSW to the abdomen.\nDuring this incident, additional officers who arrived on location discharged their firearms at the offender who was positioned on the second floor near the windows, armed with a firearm.\nThe crime scene was processed and inside investigators observed a Black male, face-up, with an apparent GSW to his head. In addition, these investigators observed a black semi-automatic handgun near his right shoulder in the 2nd floor front bedroom of 4701 Leiper Street.\nResponding officers initially believed the GSW to the head was self-inflicted, due to preliminary evidence observed.\nThe decedent’s body was removed from the scene and transported to the Medical Examiner’s Office.\nAn autopsy of the decedent was completed on 4/7/22 by the Philadelphia Medical Examiner’s Office.\nAs part of the ongoing investigation, it is currently believed that the decedent’s GSW to the head was not self-inflicted, and was caused by shots fired from discharging officers at some point during the exchange of gunfire between the decedent and discharging officers.\nNote: During the course of this incident, officers came upon two gunshot victims &amp;#8211; female victim #1 sustained a graze wound to her right upper hip area and female victim #2 who sustained a perforating gunshot wound to her buttocks. These victims were transported to Temple Hospital and were placed in stable condition.\nA third gunshot victim – a male &amp;#8211; walked into Jefferson-Frankford Hospital with 2 GSWs to the neck area. He was transported to Jefferson-Torresdale where he was intubated. Upon further investigation, it is believed that this male was involved in a physical altercation with the offender, and while walking away, the offender fired at him – striking him as well as the two female victims.\nOffender/Decedent: 18/B/M.\nOffender’s weapon: Polymer 80 Privately Made Firearm (PMF – aka “Ghost Gun”) 9MM semi-auto pistol.\nVictim #1: 52/F: GSW to right upper hip area\nVictim #2: 42/F: GSW to buttocks\nVictim #3: 33/M: Two GSWs to neck\nVictim #4: 28/M SEPTA PD P/O Injuries: GSW to abdomen\nDischarging Officer #1: 15th District P/O 45/W/M\nDischarging Officer #2: 15th District P/O 36/W/M\nDischarging Officer #3: 25th District P/O 27/B/M\nDischarging Officer #4: 25th District P/O 31/W/M\nDischarging Officer#5: 24th District P/O 30/W/M\nDischarging Officer #6: 2nd District P/O 37/W/M\nDischarging Officer #7: 15th District P/O 33/H/M\nThe Investigation is active and ongoing with the Officer-Involved Shooting Investigation Unit.\nAll discharging officers have been placed on administrative duty pending the outcome of the Internal Affairs investigation.
##                                           addrmatch score      addrtype
## 5 4700 Leiper St, Philadelphia, Pennsylvania, 19124   100 StreetAddress
##   scoreCol                   geometry hospital
## 5     blue POINT (-75.08632 40.01798)  fill in</code></pre>
<pre class="r"><code>ois[ois$id == &quot;22-06&quot;,]</code></pre>
<pre><code>## Simple feature collection with 1 feature and 10 fields
## Geometry type: POINT
## Dimension:     XY
## Bounding box:  xmin: -75.13111 ymin: 39.99066 xmax: -75.13111 ymax: 39.99066
## Geodetic CRS:  WGS 84
##      id                                 location       date
## 9 22-06 100 West Lehigh Avenue, Philadelphia, PA 2022-02-11
##                                        url
## 9 https://ois.sites.phillypolice.com/22-06
##                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          text
## 9 100 West Lehigh Avenue \nOn Friday, February 11, 2022 at approximately 12:37pm, members of the Philadelphia Police Department’s SWAT Unit were at 1xx West Lehigh Avenue to execute a search warrant. The search warrant was to search for a 35/H/M wanted for parole violations.\nPolice Officers #1 and #2, from the Philadelphia Police Department’s SWAT Unit, knocked and announced “POLICE WITH A WARRANT” and breached the front door. Police Officers #3, #4, #5, also assigned to SWAT, were assigned as the 3rd floor entry team. Officer #3, equipped with a ballistic shield, assigned to be first in line, ascended the stairs and made his way to the 3rd floor apartment door. Officer #3 put his shield to the door and called up the “breacher”. Officer #4 used a breaching shotgun on the door lock and deadbolt, discharging three (3) rounds on the lock with negative results for breaching the lock. At that point, Officer #3 called for a ram. Officer #3 bladed his body, in order to make room for Officer #4 to strike the door with a “ram”. At that point, Officer #3, facing the apartment wall, still positioned in the stairwell, heard “pops” emanating from inside the 3rd floor apartment. Officer #3 noted that the “pops” were very light, because he had his headset on. Officer #3 then heard two additional “pops”, then a third “pop”, followed by the sensation of a “sting” in his chest. He observed a hole in the wall and drywall dust on his shoulder. Additionally, he observed a hole through the 3rd floor apartment door. Officer #3 informed his team, via SWAT Band, that he was shot. At that point, Officer #3 exited the property. SWAT Unit personnel transported Police Officer #3 to Temple Hospital where he received treatment by medical staff. The bullet did not penetrate his ballistic vest. Police Officer #3 sustained a “red mark” to his chest, from where the bullet stuck his vest.\nPolice Officer #6 and #7, also assigned to SWAT, were positioned in the rear of the property. Police Officer #6 and Police Officer #7 observed a male, later positively identified as the male wanted for parole violations, exit the 3rd floor rear window, jumping down to the 2nd floor’s rooftop. Police Officer #6 stated, “Gun! DROP THE GUN!” The male then pointed his firearm at Police Officer #6. Police Officer #6 discharged his weapon at the male, missing him, who then discarded his weapon on another adjacent rooftop. The magazine dislodged from the firearm’s magazine well and landed on the ground, behind the property.\nPolice Officer #4 made his way to the 2nd floor and climbed through the window and onto the roof. He turned the corner and observed the male, but could not see his hands. Police Officer #4 ordered the male to “show his hands.” However, the male did not comply. A brief struggle ensued and the male was eventually placed in handcuffs. The male complained of pain to his ankle. Police transported the male to AEMC where he received treatment for his injured ankle.\nThe male’s firearm, a Glock 17, 9MM, semi-automatic handgun, was recovered with one (1) live round in the chamber, the magazine had ten (10) live 9MM rounds inside.\nNote: The firearm is in stolen status, stolen from Upper Darby, Pa.\nThe discharging officer, Officer #6, has been placed on administrative duty pending the outcome of the Internal Affairs Bureau and Officer-Involved Shooting Investigations Unit investigations.
##                                             addrmatch score     addrtype
## 9 100 W Lehigh Ave, Philadelphia, Pennsylvania, 19133   100 PointAddress
##   scoreCol                   geometry hospital
## 9     blue POINT (-75.13111 39.99066)  fill in</code></pre>
<pre class="r"><code>ois$hospital[ois$id %in% c(&quot;16-19&quot;, &quot;18-28&quot;, &quot;19-23&quot;, &quot;20-33&quot;, &quot;20-34&quot;,
                           &quot;22-14&quot;, &quot;22-05&quot;, &quot;21-10&quot;, &quot;16-40&quot;, &quot;16-43&quot;,
                           &quot;15-09&quot;, &quot;20-30&quot;, &quot;19-13&quot;, &quot;19-14&quot;, &quot;19-20&quot;,
                           &quot;18-01&quot;, &quot;18-28&quot;, &quot;17-19&quot;, &quot;17-22&quot;, &quot;17-23&quot;,
                           &quot;17-25&quot;, &quot;17-17&quot;, &quot;16-07&quot;, &quot;16-28&quot;, &quot;16-37&quot;)] &lt;- &quot;Temple Hospital&quot;


#look for Jefferson Hospital
i &lt;- grep(&quot;Jefferson Hospital&quot;,ois$text)
cat(gsub(&quot;Jefferson Hospital&quot;, 
         bgYellow$black$bold(&quot;Jefferson Hospital&quot;), 
         ois$text[i]),
    sep=&quot;\n\n&quot;)</code></pre>
<pre><code>## 1300 Chancellor Street
## On Saturday, September 11, 2022, Officer #1 and his partner, Officer #2, along with Officer #3 were working the nightclub detail, in plainclothes and operating unmarked units. The officers observed a disturbance involving several males at the corner of 13th and Chancellor Street and announced that they were police with their badges displayed around their neck. The crowd began to walk west on Chancellor Street from 12th Street still pushing and shoving. Two of the males stopped in the middle of Chancellor Street, facing one another and began shoving each other. Officer #2 and Officer #3 attempted to intervene by stepping in between the two males. The two males began to push back at Officers #2 and #3, while the crowd joined in pushing the officers.
## One of the males, Offender #1 23/M, punched Officer #2 in the face/lip area. Officers #2 and #3 attempted to arrest the offender but were unsuccessful, due to the hostile crowd pushing the officers back. Officer #2 and Officer #3 observed the offender armed with a silver handgun pointing the gun it in their direction. Officer #2 yelled “gun” and drew his weapon, ordering the offender to drop the gun, twice. Officer #2 yelled to Officer #1 that the offender had a gun. Officer #1 was standing behind the offender as he was turning around, with the offender pointing the gun at Officer #1. Officer #1 discharged his weapon one time as the offender was running on Chancellor Street with the gun. The offender ran through the parking lot, in a southwesterly direction towards Locust Street. Officer #1 discharged his weapon several times in the parking lot, as he was ordering the offender to drop the gun. The offender then fled west on the 1300 block of Locust Street where he dropped the firearm, which was later recovered by police.
## The offender was apprehended at Broad and Locust Streets. He was transported to Jefferson Hospital by police with a gunshot wound to his left shoulder. The offender was taken into surgery in critical condition.
## The offender’s 9mm firearm was loaded with 15 rounds.
## 
## June 4, 2022
## 400 South Street
## On Saturday, June 4, 2022, at approximately 11:31 PM, Officer #1, along with another Officer, was in full uniform, assigned to a foot beat detail on South Street. The Officers were in the area of 200 South Street and heard several gunshots coming from the area of 400 South Street. The Officers proceeded to the area from where the gunshots were emanating and observed several civilians suffering from gunshot wounds lying on the sidewalk and on the street. As the officers began rendering first aid, Officer #1 observed an unknown black male on the southwest corner of South and American Streets firing a handgun into a large crowd. Officer #1 drew his weapon and fired several times in the direction of the unknown male. The unknown male dropped his handgun on the sidewalk and ran southbound on 600 American Street. The male was lost in the area.
## It is unknown whether Officer #1 struck the male.
## There were no injuries to police.
## This Officer-Involved Shooting occurred concurrently, and in response to, a Mass Casualty Shooting Incident that took place at the above date, time, and locations.
## The OISI Unit and the Homicide Unit are conducting a joint investigation.
## As per protocol, the discharging officer (Officer #1) has been placed on administrative duty pending the outcome of the OISI and Internal Affairs investigations.
## The Mass Casualty Incident (MCI) is under investigation by the Philadelphia Police Department’s Homicide Unit.
## The individuals listed below were injured as a result of the MCI.
## Decedent #1: 34/B/M Pronounced at 12:05 AM at Presbyterian Hospital.
## Decedent #2: 27/B/F Pronounced at 11:49 PM at Jefferson Hospital.
## Decedent #3: 22/B/M, Pronounced at 11:49 PM at Jefferson Hospital.
## Shooting Victim #1: 23/B/M. Shot multiple times about the torso area. Critical condition.
## Shooting Victim #2: 18/B/M. Shot one time in the right hand.
## Shooting Victim #3: 18/B/M. Shot one time in his left buttocks.
## Shooting Victim #4: 20/B/M. Shot one time in his left forearm.
## Shooting Victim #5: 17/B/M. Shot one time right chest area.
## Shooting Victim #6: 69/W/M. Shot one time in his left calf area.
## Shooting Victim #7: 43/B/M. Shot one time right ankle.
## Shooting Victim #8: 17/B/F. Shot one time in her left leg.
## Shooting Victim #9: 19/B/F. Shot one time in her left leg.
## Shooting Victim #10: 20/B/M. Shot one time in his left shoulder.
## Shooting Victim #11: 17/B/F. Shot one time left shoulder.
## Non-shooting victim #1: 49/B/F. Victim struck by shattered glass
## 
## On 10-4-2021, at approximately 1:29AM, 16th District Officers (Officer #1, Officer #2, Officer #3, and Officer #4), in full uniform and operating marked patrol vehicles, responded to the 4100 block of Parkside Avenue for multiple calls for gunshots. While surveying the area for the gunshots, the officers heard the gunfire. In addition, civilians directed the officers in the direction of where they believed the gunshots emanated from. While in the rear of a schoolyard at 3800 Lansdowne Drive, Officers observed the offender, 55/B/M, discharging a rifle. The officers ordered the offender to “drop the gun” several times; however, the offender ignored their verbal commands and discharged his rifle towards police. In response, the officers discharged their weapons, striking the offender in his right and left collarbone area. During the exchange of gunfire, Officer #1 sustained a GSW to his right arm. Officer #2 sustained a graze wound to the nose area.
## Note: The offender was wearing a bulletproof vest at the time of his arrest.
## An AR style rifle, .40 caliber handgun, multiple magazines, and multiple FCCs were recovered at the scene.
## It is believed that the male was also involved at a homicide at Jefferson Hospital, just prior to the police involved shooting.
## Both the Homicide Unit and the OISI Unit coordinated their investigations.
## 
## ﻿On Saturday, May 9, 2020, an off-duty Police Officer, was in plainclothes, visiting a friend in the 2500 block of south 7th Street. While inside the location, the Officer heard breaking glass and observed a male outside, knocking over recycling bins. The male began throwing the trash and glass bottles along the sidewalk. While standing in the front doorway, the Officer saw the male walk north bound and knock over another recycling bin. The Officer exited the location and shouted for him to stop throwing the trash and get off the block. The male pulled out a pair of scissors and started coming towards the Officer.  The Officer identified himself and ordered the male to drop the scissors. The male began swinging the scissors at the officer.  The Officer drew his off-duty weapon and discharged it, striking the male several times, stopping the males attack.  
## The scissors were recovered at the scene.
## The male sustained Gunshot Wounds to the left arm, abdomen, and groin area. He was taken by PFD Medic to Jefferson Hospital for treatment and was listed in critical, but stable condition.
## No further injuries were reported in connection with this incident.  
## *** Information posted in the original summary reflects a preliminary understanding of what occurred at the time of the incident. This information is posted shortly after the incident and may be updated as the investigation leads to new information. The District Attorney’s Office is provided all the information from the PPD’s investigation prior to their charging decision.
## 
## ﻿OIS# 18-02
## On Monday, January 29th, 2018, at approximately 7:36AM, an off-duty detective in plainclothes was driving his personal vehicle westbound on the 1300 block of Bigler Street when he observed a male chasing a second male on foot. The detective stopped his vehicle and the male being chased (male #1) stated that the other male (male #2) had just struck a pedestrian with his vehicle and was attempting to flee the scene. The detective exited his vehicle, drew his firearm, and identified himself to male #2 as a police officer. The offender began punching and wrestling with the detective and the detective discharged his firearm multiple times, striking the offender. The offender was admitted to Presbyterian Hospital and was pronounced deceased at 10:15AM.
## The detective was treated and released at Methodist Hospital for abrasions and contusions to his head and left shoulder. The pedestrian was treated and released at Jefferson Hospital for abrasions and contusions to his leg, torso, and head.  No other injuries were reported in connection with this incident.
## *** Information posted in the original summary reflects a preliminary understanding of what occurred at the time of the incident. This information is posted shortly after the incident and may be updated as the investigation leads to new information. The DA’s Office is provided all the information from the PPD’s investigation prior to their charging decision.</code></pre>
<pre class="r"><code>cat(paste(ois$id[i], collapse=&#39;&quot;,&quot;&#39;))</code></pre>
<pre><code>## 22-24&quot;,&quot;22-15&quot;,&quot;21-14&quot;,&quot;20-15&quot;,&quot;18-02</code></pre>
<pre class="r"><code>ois[ois$date == &quot;2020-05-09&quot;,] </code></pre>
<pre><code>## Simple feature collection with 1 feature and 10 fields
## Geometry type: POINT
## Dimension:     XY
## Bounding box:  xmin: -75.15967 ymin: 39.91684 xmax: -75.15967 ymax: 39.91684
## Geodetic CRS:  WGS 84
##       id                                location       date
## 32 20-15 2550 south 7th Street, Philadelphia, PA 2020-05-09
##                                         url
## 32 https://ois.sites.phillypolice.com/20-15
##                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           text
## 32 ﻿On Saturday, May 9, 2020, an off-duty Police Officer, was in plainclothes, visiting a friend in the 2500 block of south 7th Street. While inside the location, the Officer heard breaking glass and observed a male outside, knocking over recycling bins. The male began throwing the trash and glass bottles along the sidewalk. While standing in the front doorway, the Officer saw the male walk north bound and knock over another recycling bin. The Officer exited the location and shouted for him to stop throwing the trash and get off the block. The male pulled out a pair of scissors and started coming towards the Officer.  The Officer identified himself and ordered the male to drop the scissors. The male began swinging the scissors at the officer.  The Officer drew his off-duty weapon and discharged it, striking the male several times, stopping the males attack.  \nThe scissors were recovered at the scene.\nThe male sustained Gunshot Wounds to the left arm, abdomen, and groin area. He was taken by PFD Medic to Jefferson Hospital for treatment and was listed in critical, but stable condition.\nNo further injuries were reported in connection with this incident.  \n*** Information posted in the original summary reflects a preliminary understanding of what occurred at the time of the incident. This information is posted shortly after the incident and may be updated as the investigation leads to new information. The District Attorney’s Office is provided all the information from the PPD’s investigation prior to their charging decision.
##                                           addrmatch score     addrtype scoreCol
## 32 2550 S 7th St, Philadelphia, Pennsylvania, 19148   100 PointAddress     blue
##                      geometry hospital
## 32 POINT (-75.15967 39.91684)  fill in</code></pre>
<pre class="r"><code>ois[ois$location == &quot;1300 Chancellor Street, Philadelphia, PA&quot;,] </code></pre>
<pre><code>## Simple feature collection with 1 feature and 10 fields
## Geometry type: POINT
## Dimension:     XY
## Bounding box:  xmin: -75.16231 ymin: 39.94845 xmax: -75.16231 ymax: 39.94845
## Geodetic CRS:  WGS 84
##      id                                 location       date
## 1 22-24 1300 Chancellor Street, Philadelphia, PA 2022-09-11
##                                        url
## 1 https://ois.sites.phillypolice.com/22-24
##                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     text
## 1 1300 Chancellor Street\nOn Saturday, September 11, 2022, Officer #1 and his partner, Officer #2, along with Officer #3 were working the nightclub detail, in plainclothes and operating unmarked units. The officers observed a disturbance involving several males at the corner of 13th and Chancellor Street and announced that they were police with their badges displayed around their neck. The crowd began to walk west on Chancellor Street from 12th Street still pushing and shoving. Two of the males stopped in the middle of Chancellor Street, facing one another and began shoving each other. Officer #2 and Officer #3 attempted to intervene by stepping in between the two males. The two males began to push back at Officers #2 and #3, while the crowd joined in pushing the officers.\nOne of the males, Offender #1 23/M, punched Officer #2 in the face/lip area. Officers #2 and #3 attempted to arrest the offender but were unsuccessful, due to the hostile crowd pushing the officers back. Officer #2 and Officer #3 observed the offender armed with a silver handgun pointing the gun it in their direction. Officer #2 yelled “gun” and drew his weapon, ordering the offender to drop the gun, twice. Officer #2 yelled to Officer #1 that the offender had a gun. Officer #1 was standing behind the offender as he was turning around, with the offender pointing the gun at Officer #1. Officer #1 discharged his weapon one time as the offender was running on Chancellor Street with the gun. The offender ran through the parking lot, in a southwesterly direction towards Locust Street. Officer #1 discharged his weapon several times in the parking lot, as he was ordering the offender to drop the gun. The offender then fled west on the 1300 block of Locust Street where he dropped the firearm, which was later recovered by police.\nThe offender was apprehended at Broad and Locust Streets. He was transported to Jefferson Hospital by police with a gunshot wound to his left shoulder. The offender was taken into surgery in critical condition.\nThe offender’s 9mm firearm was loaded with 15 rounds.
##                                               addrmatch score      addrtype
## 1 1300 Chancellor St, Philadelphia, Pennsylvania, 19107   100 StreetAddress
##   scoreCol                   geometry hospital
## 1     blue POINT (-75.16231 39.94845)  fill in</code></pre>
<pre class="r"><code>ois$hospital[ois$id %in% c(&quot;20-15&quot;, &quot;22-24&quot;)] &lt;- &quot;Jefferson Hospital&quot;

#look for Jefferson-Frankford Hospital
i &lt;- grep(&quot;Jefferson-Frankford&quot;,ois$text)
cat(gsub(&quot;Jefferson-Frankford&quot;, 
         bgYellow$black$bold(&quot;Jefferson-Frankford&quot;), 
         ois$text[i]),
    sep=&quot;\n\n&quot;)</code></pre>
<pre><code>## 47xx Leiper Street
## On 4/6/2022, at approximately 7:00 PM, two 15th District officers were travelling along 4700 Penn St. in their marked vehicle when they heard 8-9 gunshots near their location. The officers saw a Black male with a black hooded sweatshirt running down the 1600 block of Arrott Street. The officers exited their vehicle and engaged the male in a foot pursuit. The officers relayed to police radio that they were involved in a foot pursuit and notified radio that they were coming up 4700 Penn Street. Once they got to Arrott Street, one of the officers lost sight of the male but his partner indicated that he “ran into the building over here.” Passers-by also pointed the location out to the officers and stated “He ran into there! In that house!” indicating 4701 Leiper Street. The officers notified police radio and informed them that a male was barricaded inside that location. The officers remained on location keeping an eye on the building. They could hear movement in the location and at one point, the same male they had chased had started to exit the side door of the structure, and upon seeing them, slammed the door and returned to the home. The officers noted that the male was no longer wearing the hooded sweatshirt.
## Additional officers arrived on location to the barricade incident. A short time later, officers heard gunshots coming from above inside of the residence at 4701 Leiper Street. A responding supervisor told the group of officers to remain in cover, as this was an active shooter situation. At some point, a request was made over police radio for long-gun trained officers to assist. A SEPTA Officer arrived at the location with a long-gun. The SEPTA Police Officer was at 1400 Arrott Street attempting to take cover behind a patrol vehicle, and while doing so, he was struck in the stomach area by gunfire. Responding officers transported him to Temple Hospital where he was listed critical but stable condition after receiving surgery for a GSW to the abdomen.
## During this incident, additional officers who arrived on location discharged their firearms at the offender who was positioned on the second floor near the windows, armed with a firearm.
## The crime scene was processed and inside investigators observed a Black male, face-up, with an apparent GSW to his head. In addition, these investigators observed a black semi-automatic handgun near his right shoulder in the 2nd floor front bedroom of 4701 Leiper Street.
## Responding officers initially believed the GSW to the head was self-inflicted, due to preliminary evidence observed.
## The decedent’s body was removed from the scene and transported to the Medical Examiner’s Office.
## An autopsy of the decedent was completed on 4/7/22 by the Philadelphia Medical Examiner’s Office.
## As part of the ongoing investigation, it is currently believed that the decedent’s GSW to the head was not self-inflicted, and was caused by shots fired from discharging officers at some point during the exchange of gunfire between the decedent and discharging officers.
## Note: During the course of this incident, officers came upon two gunshot victims &amp;#8211; female victim #1 sustained a graze wound to her right upper hip area and female victim #2 who sustained a perforating gunshot wound to her buttocks. These victims were transported to Temple Hospital and were placed in stable condition.
## A third gunshot victim – a male &amp;#8211; walked into Jefferson-Frankford Hospital with 2 GSWs to the neck area. He was transported to Jefferson-Torresdale where he was intubated. Upon further investigation, it is believed that this male was involved in a physical altercation with the offender, and while walking away, the offender fired at him – striking him as well as the two female victims.
## Offender/Decedent: 18/B/M.
## Offender’s weapon: Polymer 80 Privately Made Firearm (PMF – aka “Ghost Gun”) 9MM semi-auto pistol.
## Victim #1: 52/F: GSW to right upper hip area
## Victim #2: 42/F: GSW to buttocks
## Victim #3: 33/M: Two GSWs to neck
## Victim #4: 28/M SEPTA PD P/O Injuries: GSW to abdomen
## Discharging Officer #1: 15th District P/O 45/W/M
## Discharging Officer #2: 15th District P/O 36/W/M
## Discharging Officer #3: 25th District P/O 27/B/M
## Discharging Officer #4: 25th District P/O 31/W/M
## Discharging Officer#5: 24th District P/O 30/W/M
## Discharging Officer #6: 2nd District P/O 37/W/M
## Discharging Officer #7: 15th District P/O 33/H/M
## The Investigation is active and ongoing with the Officer-Involved Shooting Investigation Unit.
## All discharging officers have been placed on administrative duty pending the outcome of the Internal Affairs investigation.
## 
## ﻿PHILADELPHIA POLICE OFFICER INVOLVED SHOOTING
## 35xx Kyle Road
## PS20-32
## On Monday, November 30, 2020, approximately 8:39 PM, two officers in full uniform, operating marked patrol vehicles responded to the 8th Police District headquarters in reference to a domestic dispute at 35xx Kyle Road. The complaint was against a white male who changed the locks to the property.
## The officers drove over to the property on Kyle Road with the three complainants who were filing the report. The white female suspect opened the door and let the officers and complainants into the property. Once inside the property, the male suspect, who was in the kitchen armed with a shotgun, pointed the shotgun at the officers and complainants and shouted for them to leave. At that point both of the officers and all three of the complainants exited the home. The two police officers then notified Police Radio of an armed suspect. A barricade was declared and SWAT officers were called to take the location.
## After attempting to communicate with the suspects for over an hour, officers were ordered to perform a hard knock and then breach the front door. It was at that point that the discharging SWAT officer observed the female suspect holding a shotgun at waist level, and pointing it in the direction of the SWAT officer. The discharging SWAT officer alerted the other officers on scene that the female had a shotgun. The male suspect, who was positioned behind the female suspect, fired one shot at the breaching SWAT officers. It was at this point that the discharging SWAT officer discharged his M400 rifle one time into the female suspect’s abdomen. The discharging SWAT officer tactically retreated from the female suspect and the female suspect retreated back into the property.
## SWAT officers were able to enter the property through the rear and make contact with the male suspect. The suspect was suffering from a self-inflicted gunshot wound to the head. Officers located the female suspect within the home and both she and the male suspect were transported to Jefferson-Frankford hospital. Both are listed in critical condition.
## Multiple firearms were recovered from the property during the execution of a search warrant for the residence</code></pre>
<pre class="r"><code>cat(paste(ois$id[i], collapse=&#39;&quot;,&quot;&#39;))</code></pre>
<pre><code>## 22-10&quot;,&quot;20-32</code></pre>
<pre class="r"><code>ois$hospital[ois$id %in% c(&quot;20-32&quot;)] &lt;- &quot;Jefferson-Frankford&quot;

#look for Jefferson-Torresdale Hospital
i &lt;- grep(&quot;Jefferson-Torresdale&quot;,ois$text)
cat(gsub(&quot;Jefferson-Torresdale&quot;, 
         bgYellow$black$bold(&quot;Jefferson-Torresdale&quot;), 
         ois$text[i]),
    sep=&quot;\n\n&quot;)</code></pre>
<pre><code>## 47xx Leiper Street
## On 4/6/2022, at approximately 7:00 PM, two 15th District officers were travelling along 4700 Penn St. in their marked vehicle when they heard 8-9 gunshots near their location. The officers saw a Black male with a black hooded sweatshirt running down the 1600 block of Arrott Street. The officers exited their vehicle and engaged the male in a foot pursuit. The officers relayed to police radio that they were involved in a foot pursuit and notified radio that they were coming up 4700 Penn Street. Once they got to Arrott Street, one of the officers lost sight of the male but his partner indicated that he “ran into the building over here.” Passers-by also pointed the location out to the officers and stated “He ran into there! In that house!” indicating 4701 Leiper Street. The officers notified police radio and informed them that a male was barricaded inside that location. The officers remained on location keeping an eye on the building. They could hear movement in the location and at one point, the same male they had chased had started to exit the side door of the structure, and upon seeing them, slammed the door and returned to the home. The officers noted that the male was no longer wearing the hooded sweatshirt.
## Additional officers arrived on location to the barricade incident. A short time later, officers heard gunshots coming from above inside of the residence at 4701 Leiper Street. A responding supervisor told the group of officers to remain in cover, as this was an active shooter situation. At some point, a request was made over police radio for long-gun trained officers to assist. A SEPTA Officer arrived at the location with a long-gun. The SEPTA Police Officer was at 1400 Arrott Street attempting to take cover behind a patrol vehicle, and while doing so, he was struck in the stomach area by gunfire. Responding officers transported him to Temple Hospital where he was listed critical but stable condition after receiving surgery for a GSW to the abdomen.
## During this incident, additional officers who arrived on location discharged their firearms at the offender who was positioned on the second floor near the windows, armed with a firearm.
## The crime scene was processed and inside investigators observed a Black male, face-up, with an apparent GSW to his head. In addition, these investigators observed a black semi-automatic handgun near his right shoulder in the 2nd floor front bedroom of 4701 Leiper Street.
## Responding officers initially believed the GSW to the head was self-inflicted, due to preliminary evidence observed.
## The decedent’s body was removed from the scene and transported to the Medical Examiner’s Office.
## An autopsy of the decedent was completed on 4/7/22 by the Philadelphia Medical Examiner’s Office.
## As part of the ongoing investigation, it is currently believed that the decedent’s GSW to the head was not self-inflicted, and was caused by shots fired from discharging officers at some point during the exchange of gunfire between the decedent and discharging officers.
## Note: During the course of this incident, officers came upon two gunshot victims &amp;#8211; female victim #1 sustained a graze wound to her right upper hip area and female victim #2 who sustained a perforating gunshot wound to her buttocks. These victims were transported to Temple Hospital and were placed in stable condition.
## A third gunshot victim – a male &amp;#8211; walked into Jefferson-Frankford Hospital with 2 GSWs to the neck area. He was transported to Jefferson-Torresdale where he was intubated. Upon further investigation, it is believed that this male was involved in a physical altercation with the offender, and while walking away, the offender fired at him – striking him as well as the two female victims.
## Offender/Decedent: 18/B/M.
## Offender’s weapon: Polymer 80 Privately Made Firearm (PMF – aka “Ghost Gun”) 9MM semi-auto pistol.
## Victim #1: 52/F: GSW to right upper hip area
## Victim #2: 42/F: GSW to buttocks
## Victim #3: 33/M: Two GSWs to neck
## Victim #4: 28/M SEPTA PD P/O Injuries: GSW to abdomen
## Discharging Officer #1: 15th District P/O 45/W/M
## Discharging Officer #2: 15th District P/O 36/W/M
## Discharging Officer #3: 25th District P/O 27/B/M
## Discharging Officer #4: 25th District P/O 31/W/M
## Discharging Officer#5: 24th District P/O 30/W/M
## Discharging Officer #6: 2nd District P/O 37/W/M
## Discharging Officer #7: 15th District P/O 33/H/M
## The Investigation is active and ongoing with the Officer-Involved Shooting Investigation Unit.
## All discharging officers have been placed on administrative duty pending the outcome of the Internal Affairs investigation.
## 
## ﻿On Friday, February 28, 2020, two uniformed officers in an Emergency Patrol Wagon responded to a call for service at the Roosevelt Inn in the 7600 block of Roosevelt Blvd.  As they pulled into the parking lot, they observed a man in boxer shorts who was yelling near medics, climb into the driver’s seat in medic unit and try to drive away. The Officers and Fire Department personnel tried to stop the male and prevent him from leaving. A struggle ensued inside the medic unit and the male was able to place the vehicle in reverse, striking the police wagon and almost striking Officer 2 while. Officer 1, positioned at the driver’s side door, loudly ordering the driver to “Get Out.”  The male then drove the medic unit in the direction of Officer 1.  Officer 1 drew his weapon and discharged, striking the male, through the driver’s door.  The man continued driving, fleeing south bound on Roosevelt Boulevard.  
## A slow pursuit of the stolen medic unit lasted for more than an hour before it ended in the 2700 block of Tolbut Street, where after a brief struggle and ECW deployment, the fleeing man was arrested.  He had sustained gunshot wounds to his legs and was transported to Jefferson-Torresdale Hospital. He underwent emergency surgery and was listed in stable condition.  
## An officer, who complained of pain in his ribs, back, neck, knee and hand was taken to Nazareth Hospital where he was treated and released.  No other injuries were reported in connection with this incident. 
## During the pursuit, the medic vehicle struck an occupied civilian, three unoccupied police vehicles, and rolled over State Police Spike Strips which flattened the medic unit tires. 
## *** Information posted in the original summary reflects a preliminary understanding of what occurred at the time of the incident. This information is posted shortly after the incident and may be updated as the investigation leads to new information. The District Attorney’s Office is provided all the information from the PPD’s investigation prior to their charging decision.
## 
## ﻿OIS 19-23
## 11/21/19
## On November 21, 2019, at approximately 9:58 am, two uniformed 15th District officers responded to a radio call of a person with a gun at 4100 Comly Street.  While surveying the area, from their patrol car, they received information from Police Radio that the person, a male was on a SEPTA bus, traveling south in the 5900 block of Torresdale Avenue.  
## The officers saw the bus and positioned their police car in front of the bus, stopping it.  The officers boarded the front of the bus and saw a male, armed with a gun, positioned near the rear door, pointing a firearm in their direction.  The male told the officers to get off the bus.  The officers retreated to the front door and exited. As the officers sought cover, the male moved to the rear exit door, extended his arm out of the door and fired his gun at the officers, missing them.  He fired the gun again at the officers again as he exited the.  The officers then discharged their firearms striking the male multiple times. The male turned and ran towards the rear of the bus and pointed and fired his gun at a third officer who had arrived on the scene, striking the third officer in the arm. The male ran to the sidewalk, collapsed and was transported to Temple Hospital in critical condition.  The male’s .22 caliber weapon was recovered at the scene. The officer who was shot was treated at Jefferson-Torresdale Hospital and released. 
## *** Information posted in the original summary reflects a preliminary understanding of what occurred at the time of the incident. This information is posted shortly after the incident and may be updated as the investigation leads to new information. The District Attorney’s Office is provided all the information from the PPD’s investigation prior to their charging decision.</code></pre>
<pre class="r"><code>cat(paste(ois$id[i], collapse=&#39;&quot;,&quot;&#39;))</code></pre>
<pre><code>## 22-10&quot;,&quot;20-08&quot;,&quot;19-23</code></pre>
<pre class="r"><code>ois$hospital[ois$id %in% c(&quot;20-08&quot;, &quot;16-34&quot;)] &lt;- &quot;Jefferson-Torresdale&quot;

#look for Einstein Hospital
i &lt;- grep(&quot;Einstein Hospital&quot;,ois$text)
cat(gsub(&quot;Einstein Hospital&quot;, 
         bgYellow$black$bold(&quot;Einstein Hospital&quot;), 
         ois$text[i]),
    sep=&quot;\n\n&quot;)</code></pre>
<pre><code>## 5xx E. Brinton Street
## On Saturday, September 10, 2022, at approximately 8:04 AM, Officer #1 and her partner Officer #2, along with Officer #3 and his partner, Officer #4 were operating marked patrol units and in full uniform, responded to a radio call for a person with a gun on the 6300 block of Chew Avenue.
## Upon arrival, the officers were informed that the offender had entered an apartment at that location and threated several victims. The offender was armed with a black handgun. The offender fired his gun one time and missed a 43/F. The offender fled the scene and took the victim’s cell phone and watch.
## The victim left the apartment and returned some time later. The offender, who returned to the location began chasing the victim and her daughter through the complex courtyard with a black handgun. Officers went into the victim’s apartment, but the male was not on location.
## Police developed information that the offender was on the 500 block of East Brinton Street. When Officer #1 opened the door, Officer #2 observed the offender pointing a gun in the direction of the officers. Both Officers discharged their weapons numerous times, striking the offender one time in the right buttocks. The offender’s 9mm handgun was recovered.
## The offender was transported to Einstein Hospital by police. He was treated and released.
## There were no injuries to police.</code></pre>
<pre class="r"><code>cat(paste(ois$id[i], collapse=&#39;&quot;,&quot;&#39;))</code></pre>
<pre><code>## 22-22</code></pre>
<pre class="r"><code>ois$hospital[ois$id %in% c(&quot;22-22&quot;, &quot;21-06&quot;, &quot;21-04&quot;, &quot;16-42&quot;, &quot;20-26&quot;,
                           &quot;17-03&quot;, &quot;17-37&quot;, &quot;16-10&quot;, &quot;16-33&quot;)] &lt;- &quot;Einstein Hospital&quot;

#look for Lankenau Hospital
i &lt;- grep(&quot;Lankenau Hospital&quot;,ois$text)
cat(gsub(&quot;Lankenau Hospital&quot;, 
         bgYellow$black$bold(&quot;Lankenau Hospital&quot;), 
         ois$text[i]),
    sep=&quot;\n\n&quot;)</code></pre>
<pre><code>## On 10-26-21, at approximately 3:04PM, Officers #1 and #2 in full uniform and marked patrol cars responded to the 5700 block of Overbrook Avenue for a report of a disturbance. Officer #1 arrived on location and encountered the offender, armed with a hand held pickaxe and a hammer inside of the location. During this encounter, the offender approached Officer #1, armed with the weapons in each hand, as he neared the front door. Officer #1 ordered the offender to drop his weapons. However, the offender ignored the officers’ verbal commands. At that point, Officer #1 deployed his ECW, which struck the offender, who in turn fell to the floor inside of the residence. Officer #1, Officer #2 (who at this time had arrived on location), and several civilians ran away from the offender towards the driveway. As the offender neared Officer #1, the offender struck him in the head with the hammer. Officer #1 fell and the offender, still armed, stood over Officer #1. At that point, both officers discharged their firearms, fatally wounding him.
## During the incident, Officer #1 sustained a gunshot to the right knee and a wound to the head (from the hammer). That officer was treated at Presbyterian Hospital. Officer #2 was uninjured.
## The offender was transported to Lankenau Hospital where he was pronounced deceased at 3:29PM.
## The incident was captured on the officers BWCs.</code></pre>
<pre class="r"><code>cat(paste(ois$id[i], collapse=&#39;&quot;,&quot;&#39;))</code></pre>
<pre><code>## 21-15</code></pre>
<pre class="r"><code>ois$hospital[ois$id %in% c(&quot;21-15&quot;)] &lt;- &quot;Lankenau Hospital&quot;

#look for Episcopal Hospital
i &lt;- grep(&quot;Episcopal Hospital&quot;,ois$text)
cat(gsub(&quot;Episcopal Hospital&quot;, 
         bgYellow$black$bold(&quot;Episcopal Hospital&quot;), 
         ois$text[i]),
    sep=&quot;\n\n&quot;)</code></pre>
<pre><code>## ﻿PS#16-03
## 2/04/16
## On Thursday, February 4, 2016, at approximately 7:32 P.M., a uniformed police officer in a marked police vehicle, was patrolling in the Greenmont Cemetery in the 4300 block of N. Front Street when he heard multiple gunshots coming from inside the cemetery. The officer observed a blue Saturn traveling through the cemetery at a high rate of speed.  The officer notified Police Radio of the situation.  The officer then observed the Saturn drive toward the Front Street exit of the cemetery where a second police vehicle attempted to stop the Saturn.  The Saturn drove past the second police vehicle and fled north on Front Street with both police vehicles now in pursuit.  At the intersection of Loudon and “D” Streets, the Saturn stuck a moving vehicle, followed by a parked vehicle.  The Saturn initially stopped after striking the parked vehicle.  Officers from the second police vehicle stopped their vehicle in front of the Saturn and exited the vehicle. Two passengers from the Saturn exited the vehicle and fled on foot.  The male driver of the Saturn then put his vehicle in reverse and struck a police vehicle, which was behind it.  The Saturn then began to drive forward.  One of the officers from the second police vehicle moved to the side of the Saturn and believing that the vehicle was driving toward his partner discharged his weapon two times, striking the driver door of the Saturn.  The Saturn then struck the open passenger door of the second police vehicle, where it ultimately came to rest.  Two offenders were removed from the Saturn and taken into custody.  The two offenders that had fled on foot were also taken into custody.  One police officer deployed his ECW on one of the offenders that had fled the scene, after the offender charged at the officer.
## One of the offenders in the vehicle was wanted on an arrest warrant and for probation violations.  A second offender was also wanted for probation violations.
## The two wanted offenders were transported to Episcopal Hospital for minor injuries.   
## There were no injuries as a result of the police firearm discharge.
## The offender’s firearm, a 9MM, semi-automatic pistol, loaded with seven live rounds was recovered from inside the Saturn.
## *** Information posted in the original summary reflects a preliminary understanding of what occurred at the time of the incident. This information is posted shortly after the incident and may be updated as the investigation leads to new information. The DA’s Office is provided all the information from the PPD’s investigation prior to their charging decision.</code></pre>
<pre class="r"><code>cat(paste(ois$id[i], collapse=&#39;&quot;,&quot;&#39;))</code></pre>
<pre><code>## 16-03</code></pre>
<pre class="r"><code>ois$hospital[ois$id %in% c(&quot;16-03&quot;)] &lt;- &quot;Episcopal Hospital&quot;


#people who died at the scene / were not injured / did not specify the hospital
ois$hospital[ois$id %in% c(&quot;22-10&quot;, &quot;22-06&quot;, &quot;22-15&quot;, &quot;21-14&quot;, &quot;20-23&quot;,
                           &quot;22-09&quot;, &quot;22-08&quot;, &quot;22-04&quot;, &quot;22-01&quot;, &quot;21-12&quot;,
                           &quot;21-09&quot;, &quot;15-02&quot;, &quot;15-06&quot;, &quot;15-10&quot;, &quot;15-12&quot;,
                           &quot;20-31&quot;, &quot;20-07&quot;, &quot;20-20&quot;, &quot;20-24&quot;, &quot;19-06&quot;,
                           &quot;19-09&quot;, &quot;19-11&quot;, &quot;19-21&quot;, &quot;18-08&quot;, &quot;18-12&quot;,
                           &quot;18-19&quot;, &quot;18-25&quot;, &quot;18-27&quot;, &quot;17-20&quot;, &quot;17-28&quot;,
                           &quot;20-09&quot;, &quot;20-12&quot;, &quot;18-16&quot;, &quot;18-17&quot;, &quot;18-22&quot;,
                           &quot;18-26&quot;, &quot;16-02&quot;, &quot;16-11&quot;, &quot;16-16&quot;, &quot;16-18&quot;,
                           &quot;16-30&quot;, &quot;16-38&quot;)] &lt;- &quot;NA&quot;

#make sure all of the hospitals are there
sum(table(ois$hospital)) #+42 NA&#39;s</code></pre>
<pre><code>## [1] 96</code></pre>
<pre class="r"><code>#get the coordinates for each hospital
hospitals &lt;- textConnection(
  &quot;hospital;address;lon;lat
Presby;51 N 39th St, Philadelphia, PA 19104;-75.19880;39.95887
HUP;3400 Spruce St, Philadelphia, PA 19104;-75.19361;39.94999
Temple;3401 N Broad St, Philadelphia, PA 19140;-75.150819;40.005273
Jefferson;111 S 11th St, Philadelphia, PA 19107;-75.158308;39.949733
Jefferson-Frankford;4900 Frankford Ave, Philadelphia, PA 19124;-75.081505;40.019822
Jefferson-Torresdale;10800 Knights Rd, Philadelphia, PA 19114;-74.982773;40.071286
Einstein;5501 Old York Rd, Philadelphia, PA  19141;-75.142147;40.036707
Lankenau;100 E Lancaster Ave, Wynnewood, PA  19096;-75.261515;39.987894
Episcopal;100 E Lehigh Ave, Philadelphia, PA  19125;-75.128937;39.990027&quot;)
hospitals &lt;- read.table(hospitals, sep=&quot;;&quot;, header=TRUE)

#if you use the geocode function instead of adding coordinates
# a &lt;- lapply(hospitals$address, geocodeARCGIS)
# hospitals$lon &lt;- sapply(a, function(x) x$candidates$location$x[1])
# hospitals$lat &lt;- sapply(a, function(x) x$candidates$location$y[1])

#create colors for each hospital
#hospitals$col &lt;- hcl.colors(nrow(hospitals), &quot;Blue-Red 3)</code></pre>
<pre class="r"><code># convert to sf object
hospitals &lt;- st_as_sf(hospitals,    
                      coords=c(&quot;lon&quot;,&quot;lat&quot;),
                      crs=4326)

#plot the locations of each hospital
plot(st_geometry(PPDmap))
plot(st_geometry(hospitals), add=TRUE, pch=19, col=&quot;blue&quot;)

#add a label
#text(st_coordinates(hospitals), labels = substring(hospitals$hospital,1,2))

#plot the officer involved shootings that resulted in a hospital visit
ois.hospital &lt;- subset(ois, ois$hospital!=&quot;NA&quot;)
plot(st_geometry(ois.hospital), add=TRUE, pch=19, col=&quot;hotpink&quot;)</code></pre>
<p><img src="portfolio2_files/figure-html/unnamed-chunk-195-1.png" width="672" /></p>
<pre class="r"><code>#calculate the distance from each shooting to the hospitals
dist &lt;- st_distance(ois.hospital, hospitals)

#add column to find which hospital is closest
ois.hospital$closest &lt;- NA
for(i in 1:nrow(ois.hospital))
{
  
  results &lt;- which.min(dist[i,])
  
  if (results == 1) {
    ois.hospital$closest[i] &lt;- &quot;Presby&quot;
  } else if (results == 2) {
    ois.hospital$closest[i] &lt;- &quot;HUP&quot;
  } else if (results == 3) {
    ois.hospital$closest[i] &lt;- &quot;Temple Hospital&quot;
  } else if (results == 4) {
    ois.hospital$closest[i] &lt;- &quot;Jefferson Hospital&quot;
  } else if (results == 5) {
    ois.hospital$closest[i] &lt;- &quot;Jefferson-Frankford Hospital&quot;
  } else if (results == 6) {
    ois.hospital$closest[i] &lt;- &quot;Jefferson-Torresdale Hospital&quot;
  } else if (results == 7) {
    ois.hospital$closest[i] &lt;- &quot;Einstein Hospital&quot;  
  } else if (results == 8) {
    ois.hospital$closest[i] &lt;- &quot;Lankenau Hospital&quot;
  } else if (results == 9) {
    ois.hospital$closest[i] &lt;- &quot;Episcopal Hospital&quot;  
  } else {
    cat(&quot;Skipping\n&quot;)
  }
}

#another way to do this
# iclosest &lt;- apply(dist, 1, which.min)
# table(actual=hospitals$hospital[i],
#  closest=hospitals$hospital[iclosest])
# 100*mean(i==iclosest)


#add column to see whether they were taken to the closest hospital
ois.hospital$yes.closest &lt;- NA
for(i in 1:nrow(ois.hospital))
{
  if (ois.hospital$hospital[i] == ois.hospital$closest[i]) {
    ois.hospital$yes.closest[i] &lt;- 1
  } else {
    ois.hospital$yes.closest[i] &lt;- 0
  }
}</code></pre>
<pre class="r"><code>#calculate in what percentage of PPD shootings do PPD officers transport the individuals 
#they shoot to the nearest hospital?

(sum(ois.hospital$yes.closest == 1))/54</code></pre>
<pre><code>## [1] 0.4444444</code></pre>
<p>In 44% of PPD shootings PPD officers transport the individuals they shoot to the nearest hospitals.</p>
</div>
<div id="final-exam" class="section level3">
<h3>Final Exam</h3>
<p><strong>1. Setup the data, load the libraries, and inspect the data</strong></p>
<p><strong>a. Load <code>finaldata2022.RData</code> file and the <code>lubridate</code> and <code>sf</code> packages. <code>finaldata2022.RData</code> contains two R objects: <code>stops</code> is a data frame with all traffic stops made in Nashville in 2017 and 2018. <code>precincts</code> is a geographic object describing the Nashville Police Precincts. (2 points)</strong></p>
<pre class="r"><code>setwd(&quot;/Users/briannafisher/Dropbox/Github/BriannaFisher/&quot;)
load(&quot;data/finaldata2022.RData&quot;)

library(lubridate)
library(sf)</code></pre>
<p><strong>b. Show the first 2 lines of the <code>stops</code> dataset. (2 points)</strong></p>
<pre class="r"><code>stops[1:2,]</code></pre>
<pre><code>##        raw_row_number officer_id       date     time
## 847594        2637161 da31f1d69d 2017-01-01 00:04:00
## 847595        2637160 1386d24b69 2017-01-01 00:04:00
##                                                      location      lat
## 847594 EDMONDSON PIKE &amp; HUNTINGTON PKWY, NASHVILLE, TN, 37211 36.05226
## 847595       GALLATIN AVE &amp; SEYMOUR AVE, NASHVILLE, TN, 37206 36.18565
##              lng stop_precinct zone subject_age subject_sex subject_race
## 847594 -86.74311             8  835          18        male        white
## 847595 -86.74756             2  227          61        male        white
##        raw_suspect_ethnicity                violation arrest_made outcome
## 847594                     N         safety violation       FALSE warning
## 847595                     N moving traffic violation       FALSE warning
##        contraband_drugs contraband_weapons
## 847594               NA                 NA
## 847595               NA                 NA</code></pre>
<p><strong>c. Write code that outputs the column names of the <code>stops</code> dataset. For the stop recorded in row 150, report the <code>violation</code> for which the driver was stopped and the <code>outcome</code> of the stop. (3 points)</strong></p>
<pre class="r"><code>names(stops)</code></pre>
<pre><code>##  [1] &quot;raw_row_number&quot;        &quot;officer_id&quot;            &quot;date&quot;                 
##  [4] &quot;time&quot;                  &quot;location&quot;              &quot;lat&quot;                  
##  [7] &quot;lng&quot;                   &quot;stop_precinct&quot;         &quot;zone&quot;                 
## [10] &quot;subject_age&quot;           &quot;subject_sex&quot;           &quot;subject_race&quot;         
## [13] &quot;raw_suspect_ethnicity&quot; &quot;violation&quot;             &quot;arrest_made&quot;          
## [16] &quot;outcome&quot;               &quot;contraband_drugs&quot;      &quot;contraband_weapons&quot;</code></pre>
<pre class="r"><code>stops[150, c(&quot;violation&quot;, &quot;outcome&quot;)]</code></pre>
<pre><code>##               violation outcome
## 847743 safety violation warning</code></pre>
<p>For row 150, the violation was a safety violation and the outcome was a warning.</p>
<p><strong>d. How many rows and columns are there in the <code>stops</code> dataset? (2 points)</strong></p>
<pre class="r"><code>nrow(stops)</code></pre>
<pre><code>## [1] 449782</code></pre>
<pre class="r"><code>ncol(stops)</code></pre>
<pre><code>## [1] 18</code></pre>
<pre class="r"><code>dim(stops)</code></pre>
<pre><code>## [1] 449782     18</code></pre>
<p>There are 449782 rows and 18 columns in the dataset.</p>
<p><strong>e. There is a single individual who was arrested (<code>arrest_made</code>) after a stop for “child restraint” (<code>violation</code>). Write code that displays the sex, age, and race of this individual. (2 points)</strong></p>
<pre class="r"><code>with(stops, subject_sex[arrest_made == TRUE &amp; violation == &quot;child restraint&quot;])</code></pre>
<pre><code>##  [1] NA       NA       NA       NA       NA       NA       NA       &quot;female&quot;
##  [9] NA       NA       NA       NA       NA       NA       NA       NA      
## [17] NA       NA       NA       NA       NA       NA       NA       NA      
## [25] NA       NA       NA       NA       NA       NA       NA       NA      
## [33] NA       NA       NA       NA       NA       NA       NA       NA      
## [41] NA       NA       NA       NA       NA       NA       NA       NA      
## [49] NA       NA       NA       NA       NA       NA       NA       NA      
## [57] NA       NA       NA       NA       NA       NA       NA       NA      
## [65] NA       NA       NA       NA       NA       NA       NA       NA      
## [73] NA       NA       NA       NA       NA       NA       NA       NA      
## [81] NA       NA       NA       NA       NA       NA       NA</code></pre>
<pre class="r"><code>with(stops, subject_age[arrest_made == TRUE &amp; violation == &quot;child restraint&quot;])</code></pre>
<pre><code>##  [1] NA NA NA NA NA NA NA 61 NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
## [26] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
## [51] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA
## [76] NA NA NA NA NA NA NA NA NA NA NA NA</code></pre>
<pre class="r"><code>with(stops, subject_race[arrest_made == TRUE &amp; violation == &quot;child restraint&quot;])</code></pre>
<pre><code>##  [1] NA      NA      NA      NA      NA      NA      NA      &quot;black&quot; NA     
## [10] NA      NA      NA      NA      NA      NA      NA      NA      NA     
## [19] NA      NA      NA      NA      NA      NA      NA      NA      NA     
## [28] NA      NA      NA      NA      NA      NA      NA      NA      NA     
## [37] NA      NA      NA      NA      NA      NA      NA      NA      NA     
## [46] NA      NA      NA      NA      NA      NA      NA      NA      NA     
## [55] NA      NA      NA      NA      NA      NA      NA      NA      NA     
## [64] NA      NA      NA      NA      NA      NA      NA      NA      NA     
## [73] NA      NA      NA      NA      NA      NA      NA      NA      NA     
## [82] NA      NA      NA      NA      NA      NA</code></pre>
<p>The individual who was arrested for a child restraint violation is a 61 year old Black female.</p>
<p><strong>2. Fix Data Errors, Work with Time Variables and Create a New Dataset</strong></p>
<p><strong>a. Use the appropriate <code>lubridate</code> functions to transform <code>date</code> into a properly formatted and stored date object. Also, create a new variable in the <code>stops</code> data frame called <code>year</code> for the year in which a stop was made. (2 points)</strong></p>
<pre class="r"><code>stops$date &lt;- ymd(stops$date)
is(stops$date) #check that it worked</code></pre>
<pre><code>## [1] &quot;Date&quot;     &quot;oldClass&quot;</code></pre>
<pre class="r"><code>stops$year &lt;- year(stops$date)
is(stops$year)</code></pre>
<pre><code>## [1] &quot;numeric&quot;      &quot;vector&quot;       &quot;index&quot;        &quot;replValue&quot;    &quot;numLike&quot;     
## [6] &quot;number&quot;       &quot;atomicVector&quot; &quot;replValueSp&quot;</code></pre>
<pre class="r"><code>table(stops$year)</code></pre>
<pre><code>## 
##   2017   2018 
## 245565 204217</code></pre>
<p><strong>b. Create a new data frame called <code>stops_underage</code> that only contains stops from 2018 of underage drivers (younger than 16). (2 points)</strong></p>
<pre class="r"><code>stops_underage &lt;- subset(stops, year == 2018 &amp; subject_age &lt; 16)
table(stops_underage$subject_age)</code></pre>
<pre><code>## 
## 10 11 12 13 14 15 
##  1  1  2  3 11 66</code></pre>
<pre class="r"><code>table(stops_underage$year)</code></pre>
<pre><code>## 
## 2018 
##   84</code></pre>
<p><strong>c. In your <code>stops_underage</code> dataset, how old was the youngest stopped driver in 2018? How many drivers stopped were (strictly) younger than 14? (2 points)</strong></p>
<pre class="r"><code>table(stops_underage$subject_age)</code></pre>
<pre><code>## 
## 10 11 12 13 14 15 
##  1  1  2  3 11 66</code></pre>
<p>The youngest driver that was stopped in 2018 was 10 years old.</p>
<pre class="r"><code>sum(stops_underage$subject_age == 10)+sum(stops_underage$subject_age == 11)+
  sum(stops_underage$subject_age == 12)+sum(stops_underage$subject_age == 13)</code></pre>
<pre><code>## [1] 7</code></pre>
<pre class="r"><code>1+1+2+3 #or add up the table responses</code></pre>
<pre><code>## [1] 7</code></pre>
<p>7 drivers were stopped that were younger than 14.</p>
<p><strong>d. What percent of all stop locations in the full <code>stop</code> dataset include the words <code>MURFEESBORO PIKE</code>? (Hint: You might want to use <code>grepl()</code>.) (4 points)</strong></p>
<pre class="r"><code>sum(grepl(&quot;MURFREESBORO PIKE&quot;, stops$location))</code></pre>
<pre><code>## [1] 28555</code></pre>
<pre class="r"><code>(28555/449782)*100</code></pre>
<pre><code>## [1] 6.348631</code></pre>
<p>6.35% of the stop locations include the words Murfreesboro Pike</p>
<p><strong>e. Drop all stops for which no time was recorded in the dataset. (2 points)</strong></p>
<pre class="r"><code>sum(is.na(stops$time))</code></pre>
<pre><code>## [1] 479</code></pre>
<pre class="r"><code>stops &lt;- subset(stops, stops$time != is.na(stops$time))</code></pre>
<p><strong>f. Count the number of stops that were recorded to occur <em>exactly</em> on the hour or at half past the hour. (e.g. …, 09:30:00, 10:00:00, 10:30:00, …). (Hint: consider using <code>grep()</code>) (4 points)</strong></p>
<pre class="r"><code>sum(table(grep(&quot;[0-9]\\:(0)(0)\\:(0)(0)|[0-9]\\:(3)(0)\\:(0)(0)&quot;, stops$time, value=TRUE)))</code></pre>
<pre><code>## [1] 19159</code></pre>
<p>There were 19159 stops recorded to occur exactly on the hour or at half past the hour.</p>
<p><strong>g. Create a new column called <code>hour_of_stop</code> that lists the hour in which a stop was made. In what hour of the day do officers make the least stops? (4 points)</strong></p>
<pre class="r"><code>stops$time &lt;- hms(stops$time)
stops$hour_of_stop &lt;- hour(stops$time)

sort(table(stops$hour_of_stop))</code></pre>
<pre><code>## 
##     6     4     3     5     2    14     1    18     7    11    19    15    22 
##  7749  8077  8876 10951 11678 13484 15577 16857 17315 18157 18716 19589 20202 
##    17     0    16    20    13     8    21    12     9    10    23 
## 20218 21897 22323 22873 23288 24134 24213 24585 25364 25852 27328</code></pre>
<p>Officers make the least amount of stops at 6 am.</p>
<p><strong>h. Create a new variable called <code>drugs_or_weapons</code> that equals 1 if <code>contraband_weapons</code> or <code>contraband_drugs</code> is <code>TRUE</code> and equals 0 otherwise. For each stop <code>outcome</code>, calculate the percentage of stops in which either drugs or weapons were found. For which value of <code>outcome</code> do the police most frequently find contraband (weapons or drugs)? (Hint: Use <code>aggregate()</code>) (5 points)</strong></p>
<pre class="r"><code>stops$drugs_or_weapons &lt;- 0
stops$drugs_or_weapons[stops$contraband_drugs == &quot;TRUE&quot; | stops$contraband_weapons == &quot;TRUE&quot;] &lt;- 1

aggregate(drugs_or_weapons~outcome, stops, mean)</code></pre>
<pre><code>##    outcome drugs_or_weapons
## 1   arrest      0.172234099
## 2 citation      0.021978328
## 3  warning      0.000455192</code></pre>
<p>Police most frequently find contraband when the outcome of the stop is an arrest.</p>
<p><strong>i. For each <code>stop_precinct</code>, how many unique zones are there? (Hint: <code>function(x) length(unique(x))</code> will give you the number of unique values… consider combining with <code>aggregate()</code>) (3 points)</strong></p>
<pre class="r"><code>length(unique(stops$stop_precinct))</code></pre>
<pre><code>## [1] 9</code></pre>
<pre class="r"><code>table(stops$zone)</code></pre>
<pre><code>## 
##   111   113   115   117   121   123   125   211   213   215   217   221   223 
## 11519 12528  5609  5894  9336  8056  8035  9393  6331  5334  5473  7752  8750 
##   225   227   311   313   315   317   321   323   325   331   333   335   411 
##  9378 17432  5942  7038  8791  5395  9786 12366  4632  6187  9833  2586  4452 
##   413   415   421   423   425   511   513   515   517    52   521   523   525 
##  8400  1905  8581  6613 11200  6870  9025 10875  6309     4  9086  8932  5654 
##   531   533   535   611   613   615   617   621   623   625   627   711   713 
##  9820  5181  4580  5248  6306  4122  4184  5926  3093  3908  2221  5085  3231 
##   715   721   723   725   727   811   813   815   821   823   825   831   833 
##  5988  5351  5538  3769  4201  6943  5904  4134 11175  7798  6204  6765  4960 
##   835 
##  5723</code></pre>
<pre class="r"><code>aggregate(zone~stop_precinct, stops, unique)</code></pre>
<pre><code>##   stop_precinct                                                 zone
## 1             1                    117, 121, 113, 125, 111, 123, 115
## 2             2               227, 213, 211, 215, 225, 221, 223, 217
## 3             3     333, 321, 323, 325, 315, 311, 335, 313, 317, 331
## 4             4                         413, 411, 423, 421, 425, 415
## 5             5 531, 521, 515, 523, 513, 525, 533, 517, 535, 511, 52
## 6             6               617, 625, 615, 623, 621, 627, 611, 613
## 7             7                    727, 721, 723, 715, 711, 725, 713
## 8             8          835, 831, 825, 813, 811, 823, 821, 815, 833</code></pre>
<p>For precinct 1, there are 7 unique zones. For precinct 2, there are 8 unique zones. For precinct 3, there are 10 unique zones. For precinct 4, there are 6 unique zones. For precinct 5, there are 11 unique zones. For precinct 6, there are 8 unique zones. For precinct 7, there are 7 unique zones. For precinct 8, there are 9 unique zones.</p>
<p><strong>j. Calculate the number of stops in 2018 by month of stop and type of <code>violation</code>. (4 points)</strong></p>
<pre class="r"><code>stops$month &lt;- month(stops$date)
aggregate(raw_row_number~violation+month, subset(stops, year == 2018), length)</code></pre>
<pre><code>##                      violation month raw_row_number
## 1              child restraint     1              1
## 2           investigative stop     1            286
## 3     moving traffic violation     1          11249
## 4            parking violation     1             32
## 5                 registration     1           2881
## 6             safety violation     1           2642
## 7           seatbelt violation     1            537
## 8  vehicle equipment violation     1           7555
## 9              child restraint     2              3
## 10          investigative stop     2            258
## 11    moving traffic violation     2           9708
## 12           parking violation     2             57
## 13                registration     2           2115
## 14            safety violation     2           2063
## 15          seatbelt violation     2            340
## 16 vehicle equipment violation     2           5947
## 17             child restraint     3              5
## 18          investigative stop     3            322
## 19    moving traffic violation     3          10972
## 20           parking violation     3             29
## 21                registration     3           2441
## 22            safety violation     3           2231
## 23          seatbelt violation     3            466
## 24 vehicle equipment violation     3           6253
## 25          investigative stop     4            264
## 26    moving traffic violation     4          10793
## 27           parking violation     4             25
## 28                registration     4           2334
## 29            safety violation     4           1664
## 30          seatbelt violation     4            579
## 31 vehicle equipment violation     4           5324
## 32             child restraint     5              2
## 33          investigative stop     5            223
## 34    moving traffic violation     5           9441
## 35           parking violation     5             36
## 36                registration     5           2055
## 37            safety violation     5           1342
## 38          seatbelt violation     5            403
## 39 vehicle equipment violation     5           4513
## 40             child restraint     6              4
## 41          investigative stop     6            216
## 42    moving traffic violation     6           8802
## 43           parking violation     6             35
## 44                registration     6           2071
## 45            safety violation     6           1235
## 46          seatbelt violation     6            332
## 47 vehicle equipment violation     6           4228
## 48             child restraint     7              3
## 49          investigative stop     7            223
## 50    moving traffic violation     7           9110
## 51           parking violation     7             22
## 52                registration     7           2053
## 53            safety violation     7           1338
## 54          seatbelt violation     7            429
## 55 vehicle equipment violation     7           4321
## 56             child restraint     8              8
## 57          investigative stop     8            237
## 58    moving traffic violation     8           9178
## 59           parking violation     8             21
## 60                registration     8           2151
## 61            safety violation     8           1452
## 62          seatbelt violation     8            570
## 63 vehicle equipment violation     8           4293
## 64             child restraint     9              9
## 65          investigative stop     9            174
## 66    moving traffic violation     9           7307
## 67           parking violation     9             42
## 68                registration     9           1841
## 69            safety violation     9           1303
## 70          seatbelt violation     9            319
## 71 vehicle equipment violation     9           3698
## 72             child restraint    10              1
## 73          investigative stop    10            165
## 74    moving traffic violation    10           7003
## 75           parking violation    10             32
## 76                registration    10           1573
## 77            safety violation    10           1191
## 78          seatbelt violation    10            252
## 79 vehicle equipment violation    10           3485
## 80          investigative stop    11            139
## 81    moving traffic violation    11           5477
## 82           parking violation    11             12
## 83                registration    11           1214
## 84            safety violation    11            922
## 85          seatbelt violation    11            141
## 86 vehicle equipment violation    11           2401
## 87             child restraint    12              2
## 88          investigative stop    12             82
## 89    moving traffic violation    12           3101
## 90           parking violation    12              4
## 91                registration    12            492
## 92            safety violation    12            277
## 93          seatbelt violation    12             33
## 94 vehicle equipment violation    12            703</code></pre>
<p><strong>3. Examine the behavior of Officer ffd40c04a1</strong></p>
<p><strong>a. Create a new dataframe called <code>officer1</code> that contains all stops made by officer with <code>officer_id</code> ffd40c04a1. (2 points).</strong></p>
<pre class="r"><code>officer1 &lt;- subset(stops, officer_id == &quot;ffd40c04a1&quot;)</code></pre>
<p><strong>b. How many days passed between the first day on which this officer made a stop, and the last day on which this officer made a stop? (Hint: Use <code>difftime()</code> to calculate the number of days.) (5 points)</strong></p>
<pre class="r"><code>difftime(max(officer1$date),
          min(officer1$date),
          units = &quot;days&quot;)</code></pre>
<pre><code>## Time difference of 703 days</code></pre>
<pre class="r"><code>range(officer1$date)</code></pre>
<pre><code>## [1] &quot;2017-01-03&quot; &quot;2018-12-07&quot;</code></pre>
<pre class="r"><code>difftime(&quot;2018-12-07&quot;,
         &quot;2017-01-03&quot;,
         units = &quot;days&quot;)</code></pre>
<pre><code>## Time difference of 703 days</code></pre>
<p>703 days passed between the first day on which this officer made a stop and the last day.</p>
<p><strong>c. On what day did Officer ffd40c04a1 make the most stops? What do you notice about the location of the stops that this officer made on this day? (4 points)</strong></p>
<pre class="r"><code>sort(table(officer1$date))</code></pre>
<pre><code>## 
## 2017-01-03 2017-01-05 2017-01-14 2017-01-27 2017-02-10 2017-02-17 2017-02-23 
##          1          1          1          1          1          1          1 
## 2017-03-04 2017-03-17 2017-03-21 2017-03-29 2017-03-30 2017-04-13 2017-05-12 
##          1          1          1          1          1          1          1 
## 2017-05-17 2017-05-23 2017-06-22 2017-06-30 2017-07-25 2017-07-28 2017-07-29 
##          1          1          1          1          1          1          1 
## 2017-08-15 2017-09-14 2017-09-26 2017-12-23 2018-01-02 2018-01-08 2018-01-19 
##          1          1          1          1          1          1          1 
## 2018-01-24 2018-02-02 2018-02-06 2018-02-09 2018-02-19 2018-03-05 2018-03-14 
##          1          1          1          1          1          1          1 
## 2018-03-16 2018-03-21 2018-03-26 2018-04-09 2018-04-10 2018-04-18 2018-04-20 
##          1          1          1          1          1          1          1 
## 2018-04-25 2018-05-07 2018-05-16 2018-05-18 2018-06-06 2018-06-08 2018-06-12 
##          1          1          1          1          1          1          1 
## 2018-06-19 2018-06-20 2018-06-26 2018-07-31 2018-08-03 2018-08-07 2018-08-09 
##          1          1          1          1          1          1          1 
## 2018-08-23 2018-08-27 2018-08-28 2018-09-06 2018-09-12 2018-09-17 2018-10-03 
##          1          1          1          1          1          1          1 
## 2018-10-16 2018-11-08 2018-11-29 2018-12-07 2017-01-04 2017-01-19 2017-02-09 
##          1          1          1          1          2          2          2 
## 2017-02-16 2017-02-20 2017-02-21 2017-03-03 2017-04-11 2017-05-18 2017-05-27 
##          2          2          2          2          2          2          2 
## 2017-06-01 2017-06-06 2017-07-24 2017-09-13 2017-09-21 2017-12-01 2017-12-14 
##          2          2          2          2          2          2          2 
## 2017-12-15 2017-12-21 2018-01-04 2018-01-23 2018-01-26 2018-02-01 2018-03-13 
##          2          2          2          2          2          2          2 
## 2018-03-15 2018-07-10 2018-08-30 2018-09-16 2017-01-11 2017-01-12 2017-01-18 
##          2          2          2          2          3          3          3 
## 2017-01-26 2017-02-15 2017-03-25 2017-04-05 2017-04-28 2017-05-22 2017-09-09 
##          3          3          3          3          3          3          3 
## 2018-04-03 2018-06-25 2018-06-28 2018-07-26 2018-07-27 2018-11-11 2018-03-12 
##          3          3          3          3          3          3          4 
## 2018-04-05 2018-04-07 2018-04-12 2018-05-04 2018-06-13 2018-06-14 2018-07-13 
##          4          4          4          4          4          4          4 
## 2018-09-11 2017-08-30 2017-05-30 2018-06-09 2018-06-10 
##          4          5          6          6          9</code></pre>
<pre class="r"><code>officer1[officer1$date == &quot;2018-06-10&quot;,]</code></pre>
<pre><code>##         raw_row_number officer_id       date       time
## 1205782        2995882 ffd40c04a1 2018-06-10 15H 33M 0S
## 1205783        2995883 ffd40c04a1 2018-06-10 15H 34M 0S
## 1205872        2995972 ffd40c04a1 2018-06-10 21H 25M 0S
## 1205873        2995973 ffd40c04a1 2018-06-10 21H 26M 0S
## 1205874        2995974 ffd40c04a1 2018-06-10 21H 28M 0S
## 1205875        2995975 ffd40c04a1 2018-06-10 21H 29M 0S
## 1205879        2995979 ffd40c04a1 2018-06-10 21H 31M 0S
## 1205881        2995981 ffd40c04a1 2018-06-10 21H 33M 0S
## 1205883        2995983 ffd40c04a1 2018-06-10 21H 35M 0S
##                                            location      lat       lng
## 1205782 S 2ND ST &amp; SHELBY AVE, NASHVILLE, TN, 37213 36.16483 -86.76798
## 1205783 S 2ND ST &amp; SHELBY AVE, NASHVILLE, TN, 37213 36.16483 -86.76798
## 1205872 S 2ND ST &amp; SHELBY AVE, NASHVILLE, TN, 37213 36.16483 -86.76798
## 1205873 S 2ND ST &amp; SHELBY AVE, NASHVILLE, TN, 37213 36.16483 -86.76798
## 1205874 S 2ND ST &amp; SHELBY AVE, NASHVILLE, TN, 37213 36.16483 -86.76798
## 1205875 S 2ND ST &amp; SHELBY AVE, NASHVILLE, TN, 37213 36.16483 -86.76798
## 1205879 S 2ND ST &amp; SHELBY AVE, NASHVILLE, TN, 37213 36.16483 -86.76798
## 1205881 S 2ND ST &amp; SHELBY AVE, NASHVILLE, TN, 37213 36.16483 -86.76798
## 1205883 S 2ND ST &amp; SHELBY AVE, NASHVILLE, TN, 37213 36.16483 -86.76798
##         stop_precinct zone subject_age subject_sex subject_race
## 1205782             4  413          28        male        black
## 1205783             4  413          21        male        white
## 1205872             4  413          38        male        white
## 1205873             4  413          41      female        white
## 1205874             4  413          43      female     hispanic
## 1205875             4  413          39        male        black
## 1205879             4  413          29        male        black
## 1205881             4  413          45        male        black
## 1205883             4  413          58      female        black
##         raw_suspect_ethnicity                violation arrest_made  outcome
## 1205782                     N moving traffic violation       FALSE citation
## 1205783                     N moving traffic violation       FALSE citation
## 1205872                     N moving traffic violation       FALSE citation
## 1205873                     N moving traffic violation       FALSE citation
## 1205874                     N moving traffic violation       FALSE citation
## 1205875                     N moving traffic violation       FALSE citation
## 1205879                     N moving traffic violation       FALSE citation
## 1205881                     N moving traffic violation       FALSE citation
## 1205883                     N moving traffic violation       FALSE citation
##         contraband_drugs contraband_weapons year hour_of_stop drugs_or_weapons
## 1205782               NA                 NA 2018           15                0
## 1205783               NA                 NA 2018           15                0
## 1205872               NA                 NA 2018           21                0
## 1205873               NA                 NA 2018           21                0
## 1205874               NA                 NA 2018           21                0
## 1205875               NA                 NA 2018           21                0
## 1205879               NA                 NA 2018           21                0
## 1205881               NA                 NA 2018           21                0
## 1205883               NA                 NA 2018           21                0
##         month
## 1205782     6
## 1205783     6
## 1205872     6
## 1205873     6
## 1205874     6
## 1205875     6
## 1205879     6
## 1205881     6
## 1205883     6</code></pre>
<p>Officer ffd40c04a1 made the most stops of 06/10/2018. The location for all of these stops on this day is the same place.</p>
<p><strong>d. Create <code>arrestDates</code> to be the collection of dates on which Officer ffd40c04a1 made an arrest. For each of the dates in <code>arrestDates</code>, count how many stops the officer made. (4 points)</strong></p>
<pre class="r"><code>arrestDates &lt;- subset(officer1, arrest_made == &quot;TRUE&quot;)

officer1[officer1$date == &quot;2017-01-11&quot;,] #3</code></pre>
<pre><code>##        raw_row_number officer_id       date       time
## 854820        2644392 ffd40c04a1 2017-01-11 10H 20M 0S
## 854916        2644488 ffd40c04a1 2017-01-11 13H 10M 0S
## 854987        2644558 ffd40c04a1 2017-01-11  15H 7M 0S
##                                                     location      lat       lng
## 854820 DR D B TODD JR BLVD &amp; SCOVEL ST, NASHVILLE, TN, 37208 36.17049 -86.80704
## 854916        22ND AVE N &amp; BUCHANAN ST, NASHVILLE, TN, 37208 36.18016 -86.81314
## 854987            16TH AVE N &amp; CLAY ST, NASHVILLE, TN, 37208 36.18289 -86.81117
##        stop_precinct zone subject_age subject_sex subject_race
## 854820             6  613          36      female        black
## 854916             6  613          25        male        black
## 854987             6  611          45        male        black
##        raw_suspect_ethnicity                   violation arrest_made outcome
## 854820                     N vehicle equipment violation       FALSE warning
## 854916                     N vehicle equipment violation       FALSE warning
## 854987                     N vehicle equipment violation        TRUE  arrest
##        contraband_drugs contraband_weapons year hour_of_stop drugs_or_weapons
## 854820               NA                 NA 2017           10                0
## 854916               NA                 NA 2017           13                0
## 854987            FALSE              FALSE 2017           15                0
##        month
## 854820     1
## 854916     1
## 854987     1</code></pre>
<pre class="r"><code>officer1[officer1$date == &quot;2017-04-05&quot;,] #3</code></pre>
<pre><code>##        raw_row_number officer_id       date      time
## 917018        2706690 ffd40c04a1 2017-04-05 7H 48M 0S
## 917164        2706836 ffd40c04a1 2017-04-05 10H 5M 0S
## 917315        2706988 ffd40c04a1 2017-04-05 13H 3M 0S
##                                                       location      lat
## 917018          21ST AVE N &amp; BUCHANAN ST, NASHVILLE, TN, 37208 36.18012
## 917164 DR D B TODD JR BLVD &amp; SEIFRIED ST, NASHVILLE, TN, 37208 36.18209
## 917315            27TH AVE N &amp; HERMAN ST, NASHVILLE, TN, 37208 36.16189
##              lng stop_precinct zone subject_age subject_sex subject_race
## 917018 -86.81183             6  613          34        male        black
## 917164 -86.81201             6  611          41      female        black
## 917315 -86.81778             6  615          21      female        black
##        raw_suspect_ethnicity                   violation arrest_made outcome
## 917018                     N vehicle equipment violation       FALSE warning
## 917164                     N vehicle equipment violation       FALSE warning
## 917315                     N    moving traffic violation        TRUE  arrest
##        contraband_drugs contraband_weapons year hour_of_stop drugs_or_weapons
## 917018               NA                 NA 2017            7                0
## 917164               NA                 NA 2017           10                0
## 917315            FALSE              FALSE 2017           13                0
##        month
## 917018     4
## 917164     4
## 917315     4</code></pre>
<pre class="r"><code>officer1[officer1$date == &quot;2017-06-22&quot;,] #1</code></pre>
<pre><code>##        raw_row_number officer_id       date       time
## 970946        2760688 ffd40c04a1 2017-06-22 18H 39M 0S
##                                            location      lat       lng
## 970946 24TH AVE N &amp; ALBION ST, NASHVILLE, TN, 37208 36.16564 -86.81215
##        stop_precinct zone subject_age subject_sex subject_race
## 970946             6  615          26        male        black
##        raw_suspect_ethnicity          violation arrest_made outcome
## 970946                     N seatbelt violation        TRUE  arrest
##        contraband_drugs contraband_weapons year hour_of_stop drugs_or_weapons
## 970946             TRUE              FALSE 2017           18                1
##        month
## 970946     6</code></pre>
<pre class="r"><code>officer1[officer1$date == &quot;2018-01-04&quot;,] #2</code></pre>
<pre><code>##         raw_row_number officer_id       date       time
## 1095778        2885714 ffd40c04a1 2018-01-04  8H 23M 0S
## 1095959        2885896 ffd40c04a1 2018-01-04 11H 31M 0S
##                                                   location      lat       lng
## 1095778 ED TEMPLE BLVD &amp; W HEIMAN ST, NASHVILLE, TN, 37209 36.16966 -86.82132
## 1095959  UNDERWOOD ST &amp; UNDERWOOD ST, NASHVILLE, TN, 37208       NA        NA
##         stop_precinct zone subject_age subject_sex subject_race
## 1095778             6  613          44      female        black
## 1095959             6  613          23      female        white
##         raw_suspect_ethnicity                   violation arrest_made outcome
## 1095778                     N vehicle equipment violation       FALSE warning
## 1095959                     N    moving traffic violation        TRUE  arrest
##         contraband_drugs contraband_weapons year hour_of_stop drugs_or_weapons
## 1095778               NA                 NA 2018            8                0
## 1095959            FALSE              FALSE 2018           11                0
##         month
## 1095778     1
## 1095959     1</code></pre>
<pre class="r"><code>officer1[officer1$date == &quot;2018-01-19&quot;,] #1</code></pre>
<pre><code>##         raw_row_number officer_id       date      time
## 1106757        2896721 ffd40c04a1 2018-01-19 8H 28M 0S
##                                           location      lat       lng
## 1106757 16TH AVE N &amp; CLAY ST, NASHVILLE, TN, 37208 36.18289 -86.81117
##         stop_precinct zone subject_age subject_sex subject_race
## 1106757             6  611          55        male        black
##         raw_suspect_ethnicity                violation arrest_made outcome
## 1106757                     N moving traffic violation        TRUE  arrest
##         contraband_drugs contraband_weapons year hour_of_stop drugs_or_weapons
## 1106757            FALSE              FALSE 2018            8                0
##         month
## 1106757     1</code></pre>
<pre class="r"><code>officer1[officer1$date == &quot;2018-02-01&quot;,] #2</code></pre>
<pre><code>##         raw_row_number officer_id       date       time
## 1118795        2908770 ffd40c04a1 2018-02-01   8H 3M 0S
## 1119136        2909111 ffd40c04a1 2018-02-01 13H 41M 0S
##                                                      location      lat
## 1118795 ASHLAND CITY HWY &amp; HYDESDALE LN, NASHVILLE, TN, 37218 36.20662
## 1119136        11TH AVE N &amp; COCKRILL ST, NASHVILLE, TN, 37208 36.17704
##               lng stop_precinct zone subject_age subject_sex subject_race
## 1118795 -86.85575             6  625          55      female        black
## 1119136 -86.80215             6  613          41        male        black
##         raw_suspect_ethnicity                violation arrest_made  outcome
## 1118795                     N moving traffic violation       FALSE citation
## 1119136                     N       investigative stop        TRUE   arrest
##         contraband_drugs contraband_weapons year hour_of_stop drugs_or_weapons
## 1118795               NA                 NA 2018            8                0
## 1119136             TRUE              FALSE 2018           13                1
##         month
## 1118795     2
## 1119136     2</code></pre>
<pre class="r"><code>officer1[officer1$date == &quot;2018-03-05&quot;,] #1</code></pre>
<pre><code>##         raw_row_number officer_id       date      time
## 1141783        2931783 ffd40c04a1 2018-03-05 7H 38M 0S
##                                                         location      lat
## 1141783 DR D B TODD JR BLVD &amp; UNDERWOOD ST, NASHVILLE, TN, 37208 36.17336
##               lng stop_precinct zone subject_age subject_sex subject_race
## 1141783 -86.80825             6  613          58        male        white
##         raw_suspect_ethnicity          violation arrest_made outcome
## 1141783                     N investigative stop        TRUE  arrest
##         contraband_drugs contraband_weapons year hour_of_stop drugs_or_weapons
## 1141783            FALSE              FALSE 2018            7                0
##         month
## 1141783     3</code></pre>
<pre class="r"><code>officer1[officer1$date == &quot;2018-03-26&quot;,] #1</code></pre>
<pre><code>##         raw_row_number officer_id       date      time
## 1158102        2948115 ffd40c04a1 2018-03-26 11H 7M 0S
##                                             location      lat       lng
## 1158102 28TH AVE N &amp; HERMAN ST, NASHVILLE, TN, 37209 36.16165 -86.81925
##         stop_precinct zone subject_age subject_sex subject_race
## 1158102             6  615          22        male        black
##         raw_suspect_ethnicity                   violation arrest_made outcome
## 1158102                     N vehicle equipment violation        TRUE  arrest
##         contraband_drugs contraband_weapons year hour_of_stop drugs_or_weapons
## 1158102            FALSE              FALSE 2018           11                0
##         month
## 1158102     3</code></pre>
<pre class="r"><code>officer1[officer1$date == &quot;2018-04-10&quot;,] #1</code></pre>
<pre><code>##         raw_row_number officer_id       date      time
## 1169181        2959205 ffd40c04a1 2018-04-10 16H 3M 0S
##                                              location     lat       lng
## 1169181 16TH AVE N &amp; CENTURY ST, NASHVILLE, TN, 37208 36.1786 -86.80835
##         stop_precinct zone subject_age subject_sex subject_race
## 1169181             6  613          49        male        black
##         raw_suspect_ethnicity                   violation arrest_made outcome
## 1169181                     N vehicle equipment violation        TRUE  arrest
##         contraband_drugs contraband_weapons year hour_of_stop drugs_or_weapons
## 1169181            FALSE              FALSE 2018           16                0
##         month
## 1169181     4</code></pre>
<pre class="r"><code>officer1[officer1$date == &quot;2018-06-20&quot;,] #1</code></pre>
<pre><code>##         raw_row_number officer_id       date      time
## 1211612        3001722 ffd40c04a1 2018-06-20 9H 33M 0S
##                                             location      lat       lng
## 1211612 1410 BRICK CHURCH PIKE, NASHVILLE, TN, 37207 36.20515 -86.77844
##         stop_precinct zone subject_age subject_sex subject_race
## 1211612             6  621          49        male        black
##         raw_suspect_ethnicity          violation arrest_made outcome
## 1211612                     N investigative stop        TRUE  arrest
##         contraband_drugs contraband_weapons year hour_of_stop drugs_or_weapons
## 1211612            FALSE              FALSE 2018            9                0
##         month
## 1211612     6</code></pre>
<p><strong>e. Create a function called <code>last_stop_arrest()</code> that takes in a date and returns <code>TRUE</code> if the officer made an arrest during their last stop on the given day, and <code>FALSE</code> otherwise. Use your function <code>last_stop_arrest()</code> to check if the last stop on <code>"2017-01-11"</code> involved an arrest. <code>last_stop_arrest("2017-01-11")</code> should give you a value of <code>TRUE</code> or <code>FALSE</code>. (6 points)</strong></p>
<pre class="r"><code>last_stop_arrest &lt;- function(x)
{
  if (isTRUE(max(officer1$time[x])) ==
      isTRUE(officer1$arrest_made[x] == &quot;TRUE&quot;)) {
    return( TRUE )
  } else {
    return( FALSE )
  }
}

last_stop_arrest(&quot;2017-01-11&quot;)</code></pre>
<pre><code>## [1] TRUE</code></pre>
<p>2017-01-11 did involve an arrest.</p>
<p><strong>f. Make a barplot counting the number of Officer ffd40c04a1’s stops by <code>outcome</code>. Label both the x and y axis and name the graph. (5 points)</strong></p>
<pre class="r"><code>data &lt;- aggregate(raw_row_number~outcome, officer1, length)

barplot(data$raw_row_number, names.arg = data$outcome, ylab = &quot;Number of Stops&quot;,
        xlab = &quot;Outcome&quot;, main = &quot;Officer ffd40c04a1&#39;s Stops by Outcome&quot;)</code></pre>
<p><img src="portfolio2_files/figure-html/unnamed-chunk-219-1.png" width="672" /></p>
<p><strong>4. Work with geographic data</strong></p>
<p><strong>a. Plot the Nashville Police Precincts (2 points)</strong></p>
<pre class="r"><code>plot(st_geometry(precincts))</code></pre>
<p><img src="portfolio2_files/figure-html/unnamed-chunk-220-1.png" width="672" /></p>
<p><strong>b. Plot <code>precincts</code> and add the precinct names as labels. Use <code>st_centroid()</code> and <code>st_coordinates()</code> to retrieve the coordinates of the centers of precincts and <code>text()</code> to add the labels. Make sure the names are small enough that they do not overlap each other. (Ignore warnings of “st_centroid assumes attributes are constant over geometries of x”) (6 points)</strong></p>
<pre class="r"><code>plot(st_geometry(precincts))
labs &lt;- with(precincts, paste0(precincts$precinct))
text(st_coordinates(st_centroid(precincts)),
     labels=labs, col=&quot;hotpink&quot;, cex = 0.5)</code></pre>
<p><img src="portfolio2_files/figure-html/unnamed-chunk-221-1.png" width="672" /></p>
<p><strong>c. Make a data frame called <code>arrests</code> containing only stops resulting in arrests, eliminating all observations with missing latitude or longitude. (3 points)</strong></p>
<pre class="r"><code>arrests &lt;- subset(stops, arrest_made == &quot;TRUE&quot; &amp; lat != is.na(lat) &amp; lng != is.na(lng))</code></pre>
<p><strong>d. Convert <code>arrests</code> into an <code>sf</code> spatial object called <code>arrests_sf</code>. You need to specify the correct values for <code>coords</code> and <code>crs</code>. Then make sure your new <code>arrests_sf</code> has the same CRS as <code>precincts</code>, transforming if necessary. (5 points)</strong></p>
<pre class="r"><code>arrests_sf &lt;- st_as_sf(arrests,
                     coords=c(&quot;lng&quot;,&quot;lat&quot;),
                     crs=4326)

st_crs(precincts)</code></pre>
<pre><code>## Coordinate Reference System:
##   User input: WGS84(DD) 
##   wkt:
## GEOGCRS[&quot;WGS84(DD)&quot;,
##     DATUM[&quot;WGS84&quot;,
##         ELLIPSOID[&quot;WGS84&quot;,6378137,298.257223563,
##             LENGTHUNIT[&quot;metre&quot;,1,
##                 ID[&quot;EPSG&quot;,9001]]]],
##     PRIMEM[&quot;Greenwich&quot;,0,
##         ANGLEUNIT[&quot;degree&quot;,0.0174532925199433]],
##     CS[ellipsoidal,2],
##         AXIS[&quot;geodetic longitude&quot;,east,
##             ORDER[1],
##             ANGLEUNIT[&quot;degree&quot;,0.0174532925199433]],
##         AXIS[&quot;geodetic latitude&quot;,north,
##             ORDER[2],
##             ANGLEUNIT[&quot;degree&quot;,0.0174532925199433]]]</code></pre>
<pre class="r"><code>arrests_sf &lt;- st_transform(arrests_sf, st_crs(precincts))</code></pre>
<p><strong>e. Plot the police precincts and plot all arrest locations. Color the districts in grey and arrests in red. Additionally, for arrests set arguments <code>pch=20</code> and <code>cex=0.3</code>. By looking at the map, are there any arrests outside the city boundaries? (5 points)</strong></p>
<pre class="r"><code>plot(st_geometry(precincts), col = &quot;grey&quot;)
plot(st_geometry(arrests_sf), add = TRUE, col = &quot;red&quot;, pch = 20, cex = 0.3)</code></pre>
<p><img src="portfolio2_files/figure-html/unnamed-chunk-224-1.png" width="672" /> By looking at the map, there looks like there is one arrest outside of city boundaries in the top right hand corner.</p>
<p><strong>f. Use <code>st_join()</code> to determine in which precinct each arrest occurred. To do so, note the <code>precincts</code> map object has a column called <code>precinct</code>. Use <code>st_join()</code> to merge <code>arrests_sf</code> with <code>precincts[,"precinct"]</code> making a new object called <code>arrests_precincts</code>. (3 points)</strong></p>
<pre class="r"><code>arrests_precincts &lt;- st_join(arrests_sf, precincts[,&quot;precinct&quot;])</code></pre>
<p><strong>g. <code>stop_precinct</code> reports the precinct in which the officer reported the stop occurred. Of the arrests the officer reported occurred in precinct 4 (which is the CENTRAL precinct), how many of the arrests had coordinates that were not in the CENTRAL precinct? (2 points)</strong></p>
<pre class="r"><code>precinct4 &lt;- subset(arrests_precincts, stop_precinct == 4)
central &lt;- subset(precincts, precinct == &quot;CENTRAL&quot;)

i &lt;- st_intersects(precinct4, central)
precinct4$incentral &lt;- lengths(i) &gt; 0

table(precinct4$incentral)</code></pre>
<pre><code>## 
## FALSE  TRUE 
##    10   362</code></pre>
<p>There are 10 arrests that had coordinates that were not in the central precinct</p>
<p><strong>h. Plot just the CENTRAL precinct. Color the precinct in grey and arrests in red. Plot a blue triangle (<code>pch=17</code>) for the one individual whose race is “unknown”. Make the blue triangle bigger than the red dots so that it is easier to see. (6 points)</strong></p>
<pre class="r"><code>plot(st_geometry(subset(precincts, precinct == &quot;CENTRAL&quot;)), col = &quot;grey&quot;)
plot(st_geometry(subset(arrests_precincts, precinct == &quot;CENTRAL&quot;)), 
     col = &quot;red&quot;, add = TRUE, pch = 20, cex = 0.3)
plot(st_geometry(subset(arrests_precincts, precinct == &quot;CENTRAL&quot; &amp; subject_race == &quot;unknown&quot;)), 
     col = &quot;blue&quot;, add = TRUE, pch = 17, cex = 1)</code></pre>
<p><img src="portfolio2_files/figure-html/unnamed-chunk-227-1.png" width="672" /></p>
<p><strong>i. For each precinct, compute the percentage of arrests for which contraband drugs are found. Color precincts with drug recovery rates between 0-15% <code>white</code>, 15%-20% <code>orange</code>, and over 20% <code>red</code>. (8 points)</strong></p>
<pre class="r"><code>drug.data &lt;- aggregate(drugs_or_weapons~precinct, arrests_precincts, mean)

i &lt;- match(precincts$precinct, drug.data$precinct)
precincts$drugs_or_weapons &lt;- drug.data$drugs_or_weapons[i]

plot(st_geometry(precincts), col = &quot;grey&quot;)
plot(st_geometry(subset(precincts, precinct == &quot;CENTRAL&quot;)), col = &quot;orange&quot;, add = TRUE)
plot(st_geometry(subset(precincts, precinct == &quot;EAST&quot;)), col = &quot;white&quot;, add = TRUE)
plot(st_geometry(subset(precincts, precinct == &quot;HERMITAGE&quot;)), col = &quot;white&quot;, add = TRUE)
plot(st_geometry(subset(precincts, precinct == &quot;MADISON&quot;)), col = &quot;orange&quot;, add = TRUE)
plot(st_geometry(subset(precincts, precinct == &quot;MIDTOWN-HILLS&quot;)), col = &quot;red&quot;, add = TRUE)
plot(st_geometry(subset(precincts, precinct == &quot;NORTH&quot;)), col = &quot;red&quot;, add = TRUE)
plot(st_geometry(subset(precincts, precinct == &quot;SOUTH&quot;)), col = &quot;orange&quot;, add = TRUE)
plot(st_geometry(subset(precincts, precinct == &quot;WEST&quot;)), col = &quot;orange&quot;, add = TRUE)</code></pre>
<p><img src="portfolio2_files/figure-html/unnamed-chunk-228-1.png" width="672" /></p>
</div>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3,h4",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
