---
title: "Here is some of my work in R Studio!"
output:
  html_document:
    toc: true
    toc_float: true
    collapsed: false
    number_sections: false
    toc_depth: 4
    #code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(message=FALSE,warning=FALSE, cache=TRUE)
```

# Portfolio {.tabset}

## Introduction to Data Science

<h2>Introduction to Data Science</h2>

### Problem Set 1

__Question 1a__
```{r} 
state <- c(1, 2, 3, 4, 5)
pop <- c(12.80, 19.45, 3.56, 0.97, 8.88)
cases <- c(139623, 439238, 52095, 17857, 196337)
```
The first vector, state, is created using the concatenate function to combine the five states within the data set (state 1, 2, 3, 4, and 5). The second vector, pop, is created using the concatenate function to combine the populations for those five states (12.80, 19.45, 3.56, 0.97, 8.88). The third vector, cases, is created using the concatenate function to combine the numbers of cases for the five states within the data set (139623, 439238, 52095, 17857, 196337). Now, these three vectors store all of the data on COVID-19 for five northeastern states as provided within the data table. 

__Question 1b__
```{r} 
ne.covid <- cbind(state, pop, cases)
ne.covid
```
The object ne.covid was created by combining the three columns (state, population, cases) from the data set into a matrix. The function cbind was implemented and assigned to ne.covid. Once created, running ne.covid displays the same data table but in R.

__Question 1c__
```{r} 
mean(ne.covid[,2])
median(ne.covid[,2])
max(ne.covid[,2])
min(ne.covid[,2])
```
The mean of the second column of ne.covid is 9.132, the median is 8.88, the maximum is 19.45, and the minimum is 0.97.

__Question 1d__
```{r} 
mean(ne.covid[,3])
median(ne.covid[,3])
max(ne.covid[,3])
min(ne.covid[,3])
```
The mean of the third column of ne.covid is 169030, the median is 139623, the maximum is 439238, and the minimum is 17857.

__Question 1e__
```{r} 
#creating a vector for state population in thousands
pop.in.1000s <- pop*1000

#creating a vector for covid-19 cases per 1000 residenrs
cases.per.1000 <- cases /pop.in.1000s
```
The vector cases.per.1000 is created by assigning the result of the cases divided by 1000 to the vector. This vector represents the number of COVID-19 cases in each state per 1000 residents.

__Question 1f__
```{r} 
state_chr <- c("PA", "NY", "CT", "DE", "NJ")

plot(y=cases.per.1000, x=pop, xlab = "Population in Millions", ylab = "Cases per 1000 Residents", main = "COVID-19 in the Northeast", type = "n")

plot(y=cases.per.1000, x=pop, xlab = "Population in Millions", ylab = "Cases per 1000 Residents", main = "COVID-19 in the Northeast", text(x = pop, y = cases.per.1000, labels = state_chr))
```
The scatterplot “COVID-19 in the Northeast” was created by using the plot function. Within the plot, y is designated as cases.per.1000, x is designated as population in millisons, the x-axis is labeled population with the xlab function, and the y-axis is labeled Cases per 1000 Residents with the ylab function. The title is created with the main function, and is labeled COVID-19 in the Northeast. The states are assigned to their corresponding dot on the scatterplot with the text function.

__Question 1g__
```{r} 
#adding cases.per.1000 and state_chr as columns to the ne.covid matrix
ne.covid <- cbind(ne.covid, cases.per.1000, state_chr)

#subsetting to identify the state most affected by COVID 19
ne.covid[ne.covid[, "cases.per.1000"] == max(cases.per.1000), c("state_chr", "cases.per.1000")]

#subsetting to identify the state least affected by COVID 19
ne.covid[ne.covid[, "cases.per.1000"] == min(cases.per.1000), c("state_chr", "cases.per.1000")]
```
New York has been the most affected by COVID-19, with around 22.58 cases per 1000 residents. Pennsylvania has been the least affceted by COVID-19, with about 10.91 cases per 1000 residents.

__Question 1h__
If I could get one more piece of information about COVID-19 to describe how affected each of these states are, it would be the death rates. The death rates would signify the level of impact COVID-19 had on the states, as some people within the cases category may be asymptomatic or have mild symptoms and are okay now. 

__Question 2a__
```{r} 
load("/Users/briannafisher/Dropbox/Github/BriannaFisher/data/2019MLBTeamsData.Rdata")
bb$avgattpergame <- as.numeric(bb$home.attendance/bb$games.played)
median(bb$avgattpergame)
max(bb$avgattpergame)
min(bb$avgattpergame)
```
Because there are an even number of teams, no singular team had the median average attendance of 14055.35 but the two in the middle were the Washington Nationals (with a median average attendance of 13949.27) and the Minnesota Twins (with a median average attendance of 14161.43). The team with the maximum average attendance per game was the Los Angeles Dodgers, with a maximum of 24532.77. The team with the minimum average attendance per game was the Miami Marlins, with a minimum of 5008.037.

__Question 2b__
```{r} 
bb$teambattavg <- as.numeric(bb$hits/bb$at.bats)
median(bb$teambattavg)
max(bb$teambattavg)
min(bb$teambattavg)
```
Because there are an even number of teams, no singular team had the median team batting average of 0.2492307 but the two in the middle were the Oakland Athletics (with a median team batting average of 0.2488761) and the Cleveland Indians (with a median team batting average of 0.2495853). The team with the maximum batting average is the Houston Astros with a maximum of 0.2740068. The team with the minimum batting average is the Toronto Blue Jays with a minimum of 0.2364828.

__Question 2c__
```{r} 
plot(y=bb$avgattpergame, x=bb$teambattavg, xlab = "Team Batting Average", 
     ylab = "Average Attendance Per Game", main = "MLB 2019 Data")
```
The graph looks very spread out, with the dots in seemingly randomly places. It is fairly nonlinear with no clear direction or association. The graph tells you that there is no relationship between team skill and attendance.

__Question 2d__
```{r} 
bb$runs.pitch <- as.numeric(bb$opponent.runs/bb$outs.pitched)
plot(y=bb$avgattpergame, x=bb$runs.pitch, xlab = "Opponent Runs per Outs Pitched", 
     ylab = "Average Attendance Per Game", main = "MLB 2019 Data 2")
```
The graph looks like the lower the opponent runs per outs pitched, the higher the average attendance per game. The same is for the opposite, the lower the average attendance per game, the higher the opponent runs per outs pitched. There are some outliers, though, that do not fit the pattern. This tells you that while there is not a linear relationship between team skill and attendance, there is an association between the two. 

__Question 2e__
```{r} 
bb$teamwinper <- as.numeric(bb$wins/bb$games.played)
plot(y=bb$teamwinper, x=bb$teambattavg, xlab = "Team Batting Average", 
     ylab = "Team Winning Percentage", main = "MLB 2019 Data 3")
```
The graph looks more linear than the other two, with team winning percentage increasing as team batting average increases. This tells you that there is a positive relationship between team batting average and team winning percentage.

__Question 2 Bonus__
```{r} 
prediction <- lm(formula = teamwinper ~ teambattavg, data = bb)
plot(bb$teamwinper ~ bb$teambattavg, xlab = "Team Batting Average", 
     ylab = "Team Winning Percentage", main = "MLB 2019 Data 3")
abline(prediction)
```
To make a better prediction of a team’s winning percentage, the least squares regression line can be calculated and plotted in order to show where the predicted values would lie. This line is used to predict the value of y, or team winning percentage, for any value of x, or team batting average.

__Question 3a__
```{r} 
recentgrads <- read.csv("/Users/briannafisher/Dropbox/Github/BriannaFisher/data/recentgrads.csv", header = TRUE, na="NA")
ncol(recentgrads)
nrow(recentgrads)
```
There are 15 columns and 173 rows in the “recentgrads” data set. The unit of analysis of the data is major, as the data focuses on the jobs college graduates received depending on their major. 

__Question 3b__
```{r} 
table(recentgrads$Major_category)
```
There are 16 different major categories that the data are divided into. The engineering category has the most majors, with 29 different majors.  

__Question 3c__
```{r} 
sum(recentgrads$Women, na.rm = T)
percentwomen <- sum(recentgrads$Women, na.rm = T)/sum(recentgrads$Total, na.rm = T)
percentwomen * 100
```
There are 3,895,228 women included in the dataset. 57.52% of the people in the dataset are women.

__Question 3d__
```{r} 
recentgrads$womengrads <- as.numeric(recentgrads$Women/recentgrads$Total)
order(recentgrads$womengrads, na.last = T)
recentgrads[74,]
order(recentgrads$womengrads, na.last = F)
recentgrads[165,]
```
The major that had the highest percentage of women graduates is education, with a percentage of 96.90%. The major that had the lowest percentage of women graduates is military technologies, with a percentage if 0%. 

__Question 4__
Random sampling is such a vital component of survey research because it ensures that there is no bias within the sample. If people were chosen to take a survey, the surveyor could have picked specific people who they know will prove their hypothesis and therefore discredit the validity and accuracy of the survey. Random sampling also ensures that the results are representative of the entire population, which is why a sample of 1500 people is enough to learn about the whole US population. If the sample is completely random, then we can be confident that a sample of only 1500 people will include people who represent all different backgrounds and interests within the country.   


### Problem Set 2

__Question 1a__
```{r} 
load("/Users/briannafisher/Dropbox/Github/BriannaFisher/data/exitpoll2016.RData")
require(tidyverse)
exit.untouched <- exit

#The unit of observation is people, and the dataset had more than one row for every observation.
#Because there are two rows for each observation, using the spread function will condense each repeated row into one. Since the favorable candidate and favorable rating variables are the ones repeated, they are used to create the new columns
exit <- spread(exit,
                 key = favorable.cand,
                 value = favorable.rating)
head(exit)

#Using the recode function, the values of 1 and 2 can be replaced for favorable and unfavorable
attributes(exit.untouched$favorable.rating)

exit$clinton <- recode(exit$clinton, "1" = "Favorable", "2" = "Unfavorable")
exit$trump <- recode(exit$trump, "1" = "Favorable", "2" = "Unfavorable")
```

__Question 1b__
```{r} 
#the gather function brings responses that are spread over multiple columns into one. The recode function
#changes the data from numeric values (0/1) that don't make sense
exit <- gather(exit,
                 key = "educ", 
                 value = "val",
               starts_with("educ."))

exit$educ <- recode(exit$educ, "educ.hs" = "hs", "educ.somecoll" = "some college", 
                    "educ.bach" = "bachelors", "educ.postgrad" = "postgrad")

#Since all unknown values are coded as 99 (using attributes checks this), I can recode those values to NA
attributes(exit.untouched$educ.hs)
attributes(exit.untouched$educ.somecoll)
attributes(exit.untouched$educ.bach)
attributes(exit.untouched$educ.postgrad)

exit[exit$educ == "99"] <- NA

exit$val <- NULL

#Could have also changed the names by reshaping the education data
exit$educ[exit$educ == "educ.hs"] <- "hs"
exit$educ[exit$educ == "educ.somecoll"] <- "some college"
exit$educ[exit$educ == "educ.bach"] <- "bachelors"
exit$educ[exit$educ == "educ.postgrad"] <- "postgrad"
```

__Question 1c__
```{r} 
#The separate function splits the sex.age.race column into three separate columns
exit <- separate(exit,
         col = "sex.age.race",
         into = c("sex","age","race"), sep = " ")

#Converting the columns to factors and then replacing the missing/unknown values with NA cleans the data
exit$age = as.factor(exit$age)
summary(exit$age)
exit$age[which(exit$age == "-999")] = NA
summary(exit$age)

exit$sex = as.factor(exit$sex)
summary(exit$sex)
exit$sex[which(exit$sex == "unknown")] = NA
summary(exit$sex)

#The race values are already coded as NA for missing, but could have done this 
exit$race = as.factor(exit$race)
summary(exit$race)
exit$race[which(exit$race == "NA")] = NA
summary(exit$race)
```

__Question 1d__
```{r} 
#the new varible third.party is created by recoding everything as NA and then recoding each value to the 
#new value. Using NULL removes the variable from the data set
attributes(exit.untouched$PRSPA16)

exit$third.party <- "NA"
exit$third.party[exit$PRSPA16 == 1] <- "0"
exit$third.party[exit$PRSPA16 == 2] <- "0"
exit$third.party[exit$PRSPA16 == 3] <- "1"
exit$third.party[exit$PRSPA16 == 4] <- "1"
exit$third.party[exit$PRSPA16 == 9] <- "1"

exit$PRSPA16 <- NULL
```

__Question 1e__
```{r} 
#the as.numeric function converts the married variable into a dummy variable, coding 1 for married and 
#0 for not married
attributes(exit.untouched$married) #tells us that 1 is yes and 2 is no

exit$married <- as.numeric(exit$married==1)
```

__Question 1f__
```{r} 
#the factor function recodes the PHIL3 and partyid variables into meaningful labels 
attributes(exit.untouched$PHIL3)

exit$PHIL3 <- factor(exit$PHIL3, labels = c("Liberal", "Moderate", "Conservative"))

attributes(exit.untouched$partyid)

exit$partyid <- factor(exit$partyid, labels = c("Democrat", "Republican", "Independent",
                                                "Something Else"))
```

__Question 1g__
```{r} 
#I split the age variable into the different groups and then also made the partyid ordinal so that they can be compared. From there I made them into a table, and then did the frequencies of the results. Lastly, I added together all of the values in the table to make sure that they are equal to 1. 
exit$Age.group <- "NA"
exit$Age.group[exit$age == "18-29"] <- 1
exit$Age.group[exit$age == "30-44"] <- 2
exit$Age.group[exit$age == "45-65"] <- 3
exit$Age.group[exit$age == "65+"] <- 4

exit$ID <- "NA"
exit$ID[exit$partyid == "Republican"] <- 5
exit$ID[exit$partyid == "Democrat"] <- 6
exit$ID[exit$partyid == "Independent"] <- 7
exit$ID[exit$partyid == "Something Else"] <- 8

mytable <- table(exit$Age.group, exit$ID)
prop.table(mytable)
sum(prop.table(mytable))
```
Comparing the frequencies of the age group and ID variables, there is a 6.97% chance of people in the age group of 18-29 being democratic and a 5.68% chance of people being 18-29 and republican. The values are lower for independents and ‘something else,’ with a 0.64% chance of someone 18-29 being independent and a 0.88% chance of someone being 18-29 and something else. This is fairly expected, as young people are more likely to be democratic than any other party. Another interesting observation is that there is the same 15.32% chance of someone being 45-65 years old and either a republican or democrat. The 45-65-year-old age group also has the highest chance of being independent (5.21%) and something else (1.25%) than any other group. This may be explained by the fact that middle aged and older people are more likely to watch the news and therefore align with a particular political party, or because this age group has particularly high voter turnout and therefore need to be registered to a party to participate.  

__Question 2a__
```{r} 
library(rio)
UNICEF_untouched <- rio::import("/Users/briannafisher/Dropbox/Github/BriannaFisher/data/unicefdata.xlsx")

UNICEF <- UNICEF_untouched

#Problems with the data:
#1. Columns are named with numbers
#2. Column names are in the actual columns
#3. Have dashes and x's within the data
```

__Question 2b__
```{r} 
#The names function renames the columns with the names in the first row, and then the first two rows can be deleted. Using rownames will renumber the rows so that it does not start at 3.
names(UNICEF) <- lapply(UNICEF[1, ], as.character)
UNICEF = UNICEF[-1,] 
UNICEF = UNICEF[-1,] 
row.names(UNICEF) <- 1:nrow(UNICEF)
```

__Question 2c__
```{r} 
#rowmeans tells us the mean value of each row in the data set. The rows that have "1" as their mean 
#are blank and should be removed. The -c function lets you drop rows or 
#columns from the data set
rowMeans(is.na(UNICEF))
which(rowMeans(is.na(UNICEF)) == 1)

UNICEF <- UNICEF[,-c(12,14)]
UNICEF <- UNICEF[-c(198),]
row.names(UNICEF) <- 1:nrow(UNICEF)
UNICEF <- UNICEF[-c(209),]
row.names(UNICEF) <- 1:nrow(UNICEF)

#Now, the dataset has 12 columns and 216 rows. (When I take out the summary indicators on 2. h.,
#the dataset has 12 columns and 215 rows).
```

__Question 2d__
```{r} 
#The rename function changes the names of the columns so that they are more manageable
attributes(UNICEF)
library(dplyr)

UNICEF <- rename(UNICEF, c("Countries" = "Countries and areas", 
                 "U5MR.1990" = "Under-5 mortality rate (U5MR) (1990)",
                 "U5MR.2015" = "Under-5 mortality rate (U5MR) 2015",
                 "U5MR.Male" = "U5MR (male)", "U5MR.Female" = "U5MR (female)", 
                 "Total.Pop" = "Total population (thousands)",
                 "Annual.Births" = "Annual no. of births (thousands)",
                 "GNI.Per.Capita" = "GNI per capita (US$)", 
                 "Neonatal.Mortality.Rate" = "Neonatal  mortality  rate",
                 "Life.Expect.Birth" = "Life expectancy at birth (years)",
                 "Total.Adult.Lit.Rate" = "Total adult literacy rate          (%)",
                 "Primary.School.Net.Enrollment.Ratio" = "Primary school net enrolment ratio      (%)"))
```

__Question 2e__
```{r} 
which(UNICEF$Countries == "Notes:")

UNICEF <- UNICEF[-c(209:216),]
```

__Question 2f__
```{r} 
#This recodes all values of - in the dataset to NA
UNICEF[UNICEF == "-"] <- NA

#This converts the columns to be numeric and replaces the letters with NAs
UNICEF[,2:12] <- as.numeric(as.character(unlist(UNICEF[,2:12])))
```


__Question 2g__
```{r} 
#Subsetting the data creates a new dataset with only the wanted obeservations.
summary.indicators <- subset(UNICEF[199:208,])
UNICEF <- UNICEF[-c(198:208),]

#Now, the UNICEF dataset has 197 rows and the summary indicators dataset has 10 rows.
```

__Question 2h__
```{r} 
#to find the change in mortality rate from 1990 to 2015, the two can be subtracted (any countries with apositive value had an increase in mortality rate)
change.mortality <- (UNICEF$U5MR.2015)-(UNICEF$U5MR.1990)
print(change.mortality)
```
Three countries had a mortality rate that increased over this 25-year period. The countries are Dominica, Lesotho, and Niue. 

### Problem Set 3

__Question 1a__
```{r}
library(rio)
library(tidyr)
library(dplyr)
library(plyr)

#the rio package reads in the data from excel
mont_untouched <- rio::import("/Users/briannafisher/Dropbox/Github/BriannaFisher/data/2018-General-Montgomery.xls")
mont <- mont_untouched
dekalb <- read.csv("/Users/briannafisher/Dropbox/Github/BriannaFisher/data/dekalb-cleaned.csv")

#first, dim is used to see how many columns are coded as precincts. Then the gather function is used to 
#put all of the precincts in one column
dim(mont)
mont <- gather(mont, key = "precinct", value = "votes", 4:54)

#Using !grepl, I can remove the columns with the over and under votes and the number of registered voters and 
#ballots cast in each precinct
mont <- mont[!grepl("Over Votes", mont$Candidate),]
mont <- mont[!grepl("Under Votes", mont$Candidate),]
mont <- mont[!grepl("REGISTERED VOTERS", mont$`Contest Title`),]
mont <- mont[!grepl("BALLOTS CAST", mont$`Contest Title`),]
row.names(mont) <- 1:nrow(mont)

#na.omit is used to remove the rows with missing vote data
mont <- na.omit(mont)

#the rename function recodes the column names
attributes(mont)
mont <- plyr::rename(mont, "office" = "Contest Title", "party" = "Party",
               "candidate" = "Candidate")

#the recode function is used to clean the values within the party variable
unique(mont$party)
mont$party <- recode(mont$party, "DEM" = "Democrat", "REP" = "Republican", "NON" = "No party",
               "IND" = "Independent")

#you can create new variables for the state and county
mont$state <- "Alabama"
mont$county <- "Montgomery"

#the "c" function reorders the columns
mont <- mont[, c(6, 7, 4, 1, 3, 2, 5)]
```

__Question 1b__
```{r} 
#1. b. You can use a for loop to find the total number of votes in each office 

#first create vectors with what you want to loop over
office <- unique(mont$office)
office

precinct <- unique(mont$precinct)
precinct

#create a matrix to store the results of the loop
office.precinct <- matrix(NA, nrow=length(precinct), ncol=length(office))

#loop over the votes for the precincts and offices
for(j in 1: length(office)){
  
  for(i in 1:length(precinct)){
    office.precinct[i,j] <-  sum(mont$votes[mont$precinct==precinct[i] & mont$office==office[j]], 
                                 na.rm=T)
  }
  
}

#you can use the max function to find the maximum number of votes in one precinct/office
#combination
max(office.precinct)

#which will tell you the exact row / column of the office / precinct
which(office.precinct == max(office.precinct), arr.ind = T)

#I can subset from my vectors to find the names of the combination
office[3]
precinct[23]
```
The office-precinct combination that had the highest number of votes is the 305 F precinct and Governor office with 4675 votes.

__Question 1c__
```{r} 
#You can first find the mean since this is the statistic we want
mean(mont$votes[mont$party=="Democrat" & mont$office=="GOVERNOR"],na.rm=T)
mean(mont$votes[mont$party=="Republican" & mont$office=="GOVERNOR"],na.rm=T)

#you can then use a t test to find out if either means are statistically significant
diff.test <- t.test(mont$votes[mont$party=="Democrat" & mont$office=="GOVERNOR"],
                    mont$votes[mont$party=="Republican" & mont$office=="GOVERNOR"])

diff.test
```
The average number of votes for the Democratic candidate for Governor was 955. The average number of votes for the Republican candidate for Governor was 559. These two numbers are statistically distinguishable from one another. If the average number of votes for the Democratic and Republican candidates for Governor is the same, we would expect to see a difference in the means 0.44% of the time. Since the p-value (0.0044) is so low, we can reject the null hypothesis. There is significant statistical evidence to support that the two means are statistically distinguishable from each other.

__Question 2a__
```{r} 
# You can use the sample function to simulate fliping a coin
dodgers.win.prob <- c(1,1,1,1,1,1,0,0,0,0)

sample(dodgers.win.prob, size = 7, replace = TRUE) #output: 0 0 1 1 1 0 1

dodgers <- sum(sample(dodgers.win.prob, size = 7, replace = TRUE))
```
In my simulation, the Dodgers won a majority of the games (actually four exactly), therefore winning the world series.

__Question 2b__
```{r} 
#first create an empty vector to put the results
dodgers.wins <- rep(NA, 10000)

#Then you can use a for loop to simulate the same 7-game world series 10,000 times
for(i in 1:10000){
  dodgers.wins[i]<- sum(sample(dodgers.win.prob, size = 7, replace = TRUE))
  
}

#you can create a probability table of the results
prob.dodgers.wins <- prop.table(table(dodgers.wins))
print(prob.dodgers.wins)

#to find the proportion of times the Dodgers won 4 or more games, you can sum the results
sum(prob.dodgers.wins[5:8])
```
The Dodgers win four or more games 71.33% of the time.

__Question 2c__
```{r} 
#You can use sequence to make a vector with every second game
odd.games <- seq(7, 151, by = 2)
dodgers.win.95 <- rep(NA, length(odd.games))

#you can use a double for loop to find the wins for the length of the series
for(j in 1:length(odd.games)){
  for(i in 1:10000){
    dodgers.wins[i]<- sum(sample(dodgers.win.prob, size = odd.games[j], replace = TRUE))
    
  }
  dodgers.win.95[j]<- prop.table(table(dodgers.wins >= (odd.games[j]/2)))["TRUE"]
}

print(dodgers.win.95)

#you can use the plot function to make a graph of the proportion of times the better team
# wins and the series length
plot(x = odd.games, y = dodgers.win.95, xlab = "Series Length", ylab = 
"Proportion of Times the Better Team Wins", main = "Simulated World Series Wins")
abline(h=0.95)
```
The series would have to be around 67 games in order for the better team to win 95% of the 10,000 simulated world series games. 

__Question 2d__
Given the current series length, we cannot reject the null hypothesis that the better team should win 50% of the time. Because the standard is that better team should win 95% of the time, our value of 71.33% is statistically insignificant when they only play seven games.


### Problem Set 5

__Question 1a__
```{r} 
fem <- read.csv("/Users/briannafisher/Dropbox/Github/BriannaFisher/data/washington_replication_data.csv")

#You can use the dim full get the number of members in Congress since each row corresponds to a member
dim(fem)

#you can use the sum function to add the number of females and divide it by the total number of members to
#get the proportion of females in Congress
sum(fem$female)/435

#doing this gets the same answer
mean(fem$female, na.rm = T)

#you can use the sum function to add the number of republicans (when party = 2) and divide it by the 
#total number of members to get the proportion of females in Congress
sum(fem$party==2)/435

#doing this gets the same answer
mean(fem$party == 2, na.rm = T)

#you can create logical variables for democrats and women in order to find the proportions
fem$women <- fem$female == 1
fem$democrat <- fem$party == 1
mean(fem$women[fem$democrat], na.rm = T)

#you can do the same thing for republicans
fem$rep <- fem$party == 2
mean(fem$women[fem$rep], na.rm = T)
```
There are 435 members of Congress in the dataset. 11.03% of the representations are women. 52.41% of the representatives are republicans. 16.50% of democrats are women. 6.14% of republicans are women.

__Question 1b__
```{r} 
#you can use the summary function to find the summary statistics of the AAUW variable
summary(fem$aauw)

#you can use the table function to see how many legislators have each score
table(fem$aauw)

#you can create logical variables for democrats and people who have a score of 100 in order to 
#find the proportions
fem$dem.100 <- fem$aauw == 100
sum(fem$women[fem$dem.100], na.rm = T)

#you can create logical variables for democrats and people who have a score of 0 in order to 
#find the proportions
fem$dem.0 <- fem$aauw == 0
sum(fem$women[fem$dem.0], na.rm = T)
```
The mean of the AAUW’s legislative score variable is 47.31, the median is 38, the minimum is 0, and the maximum is 100. 135 legislators have a score of 0, while 112 legislators have a score of 100. 30 democrats have a score of 100, while 5 have a score of 0.

__Question 1c__
```{r} 
#you can use the linear model function to run a regression, and the summary function to display the output
reg1 <- lm(aauw ~ female, data=fem)
summary(reg1)
```
The coefficient for the intercept (legislative support for feminist issues) is 43.765 and the coefficient for the legislator’s gender (whether or not they are female) is 32.11. Women are more likely to support feminist issues than men by 32.11 points, on average. When the legislator is male (when the female variable equals zero), the average legislative support for feminist issues is 43.765 points.

__Question 1d__
```{r} 
#you can create a republican variable by subsetting for the people who responded 2 to the party question
fem$republican <- NA
fem$republican[fem$party == 1] <- 0
fem$republican[fem$party == 2] <- 1
fem$republican[fem$party == 3] <- 0

#you can use the linear model function to run a regression, and the summary function to display the output
reg2 <- lm(aauw ~ female + republican, data=fem)
summary(reg2)
```
The coefficient for the intercept (legislative support for feminist issues) is 84.072, the coefficient for the legislator’s gender (whether or not they are female) is 13.063, and the coefficient for the legislator being republican is -72.891. When the legislator is male and a democrat (or independent), the average legislative support for feminist issues is 84.072. Women are more likely to support feminist issues than men by 13.063 points, on average, when holding republicans fixed. Republicans are less likely to support feminist issues than Democrats or Independents by 72.891 points, on average, when holding women fixed.

__Question 1e__
```{r} 
#you can use the linear model function to run a regression, and the summary function to display the output
reg3 <- lm(aauw ~ female + demvote, data=fem)
summary(reg3)

#this tells you the change when you increase democratic vote share by 10 percentage points
216.619/10
```
Holding gender fixed, the AAUW score increases by 21.662 points when you increase the Democratic vote share by 10 percentage points.

__Question 1f__
```{r} 
#you can create separte variables for the different religions
#none coded
fem$rel.none <- NA
fem$rel.none[fem$rgroup == 0] <- 1
fem$rel.none[fem$rgroup == 1] <- 0
fem$rel.none[fem$rgroup == 2] <- 0
fem$rel.none[fem$rgroup == 3] <- 0
fem$rel.none[fem$rgroup == 4] <- 0

#protestant
fem$rel.prot <- NA
fem$rel.prot[fem$rgroup == 0] <- 0
fem$rel.prot[fem$rgroup == 1] <- 1
fem$rel.prot[fem$rgroup == 2] <- 0
fem$rel.prot[fem$rgroup == 3] <- 0
fem$rel.prot[fem$rgroup == 4] <- 0

#catholic/orthodox
fem$rel.cath <- NA
fem$rel.cath[fem$rgroup == 0] <- 0
fem$rel.cath[fem$rgroup == 1] <- 0
fem$rel.cath[fem$rgroup == 2] <- 1
fem$rel.cath[fem$rgroup == 3] <- 0
fem$rel.cath[fem$rgroup == 4] <- 0

#christian
fem$rel.chris <- NA
fem$rel.chris[fem$rgroup == 0] <- 0
fem$rel.chris[fem$rgroup == 1] <- 0
fem$rel.chris[fem$rgroup == 2] <- 0
fem$rel.chris[fem$rgroup == 3] <- 1
fem$rel.chris[fem$rgroup == 4] <- 0

#jewish
fem$rel.jew <- NA
fem$rel.jew[fem$rgroup == 0] <- 0
fem$rel.jew[fem$rgroup == 1] <- 0
fem$rel.jew[fem$rgroup == 2] <- 0
fem$rel.jew[fem$rgroup == 3] <- 0
fem$rel.jew[fem$rgroup == 4] <- 1

#you can use the linear model function to run a regression, and the summary function to display the output
reg4 <- lm(aauw ~ female + demvote + rel.prot + rel.cath + rel.chris + rel.jew, data=fem)
summary(reg4)

#this tells you the change when you increase democratic vote share by 10 percentage points
201.269/10
```
When the legislator is male, has no religion, and has a 0 for the democratic vote share, the average legislative support for feminist issues is 17.924. When holding religion and democratic vote share fixed, women are more likely to support feminist issues than men by 17.924 points. When holding religion and sex fixed, the democratic vote share increases by 20.1269 points. When holding sex, democratic vote share, Catholics, Christians, and Jews fixed, legislators who are Protestant are less likely than those who have no religion to support feminist issues by 35.144 points. When holding sex, democratic vote share, Protestants, Christians, and Jews fixed, legislators who are Catholic are less likely than those who have no religion to support feminist issues by 31.692 points. When holding sex, democratic vote share, Catholics, Protestants, and Jews fixed, legislators who are Christian are less likely than those who have no religion to support feminist issues by 39.369 points. When holding sex, democratic vote share, Catholics, Christians, and Protestants fixed, legislators who are Jewish are less likely than those who have no religion to support feminist issues by 7.602 points.

### Problem Set 6

```{r, echo=FALSE, results=FALSE} 
load("/Users/briannafisher/Dropbox/Github/BriannaFisher/data/ANESData.Rdata")
anes.untouched <- anes
library(tidyverse)

#I subsetted the original data to only the varibales that I want
anes <- subset(anes, select = c(V161010e, V162079, V161002, V161019, V161021, V161021a, V161082,
                                V161083, V161126, V161129, V161151x, V161215, V161217, V161267, V161268, 
                                V161270, V161310x, V161324, V161361x)) 

#I renamed thew categories so that all of the variables were descriptive
anes <- rename(anes, c("state.abbr" = "V161010e", "therm.Trump" = 'V162079', "sex" = "V161002", "party" = "V161019", "vote.prim" = "V161021", "cand.prim" = 'V161021a', 'approve.job' =  'V161082', 'approve.econ' = 'V161083', "lib.scale.self" = "V161126", "lib.scale.rep" = "V161129", "vote.reason" = "V161151x", "trust.govt" = "V161215", "waste.tax" = "V161217", "age" = "V161267", "marital.stat" = "V161268", "educ" =  "V161270", "race" = "V161310x", "kids.house" =  "V161324", "income" = "V161361x"))

#creating a variable for sex
anes$female <- NA
anes$female[anes$sex == "1"] <- 0
anes$female[anes$sex == "2"] <- 1

anes$male <- NA
anes$male[anes$sex == "1"] <- 1
anes$male[anes$sex == "2"] <- 0

#creating a variable for approval of how the economy was handled 
anes$econ.approve <- NA
anes$econ.approve[anes$approve.econ == "1"] <- 1
anes$econ.approve[anes$approve.econ == "2"] <- 0

anes$econ.disapprove <- NA
anes$econ.disapprove[anes$approve.econ == "1"] <- 0
anes$econ.disapprove[anes$approve.econ == "2"] <- 1

#coding a variable for party
anes$democrat <- NA
anes$democrat[anes$party == "1"] <- 1
anes$democrat[anes$party == "2"] <- 0
anes$democrat[anes$party == "4"] <- 0

anes$republican <- NA
anes$republican[anes$party == "1"] <- 0
anes$republican[anes$party == "2"] <- 1
anes$republican[anes$party == "4"] <- 0

anes$none.ind <- NA
anes$none.ind[anes$party == "1"] <- 0
anes$none.ind[anes$party == "2"] <- 0
anes$none.ind[anes$party == "4"] <- 1

#creating variables for age groups
table(anes$age)

#creating a variable for 18-29
anes$age.1829 <- 0
anes$age.1829[anes$age >= 18 & anes$age <= 29] <- 1

#creating a variable for 30-49
anes$age.3049 <- 0
anes$age.3049[anes$age >= 30 & anes$age <= 49] <- 1

#creating a variable for 50-64
anes$age.5064 <- 0
anes$age.5064[anes$age >= 50 & anes$age <= 64] <- 1

#creating a variable for 65-90
anes$age.6581 <- 0
anes$age.6581[anes$age >= 65 & anes$age <= 90] <- 1
```

Because of the importance of the economy during an election and the different platforms on taxes and spending by both the Democratic and Republican parties, as well as the large difference between the average feeling thermometer score in regard to approval of the economy, I chose to model how a respondent feels about how the President (Barack Obama) is handling the economy to help explain why people like Donald Trump. 
```{r, echo=FALSE} 
#plotting average feeling thermometer score in regards to approval of the economy
mean.approve <- mean(anes$therm.Trump[anes$econ.approve==1], na.rm = T)
mean.disapprove <- mean(anes$therm.Trump[anes$econ.disapprove==1], na.rm = T)

df <- data.frame(mean.val=c(24.85, 58.14),
                 Legend=c("Approve", "Disapprove"))

#plotting average sentence length and representation type
mean.approve <- ggplot(df, aes(x = Legend, y = mean.val, fill= Legend)) +
  geom_bar(stat="identity") +
  geom_text(aes(label=mean.val), vjust=-0.3, size=5) +
  scale_fill_manual(values = c("dodgerblue1", "red")) +
  xlab("Whether or not the respondent approves of how the President is handling the economy") +
  ylab("Average Trump Feeling Thermometer Score in Degrees") +
  ggtitle("Average Feeling Thermometer Score in regards to Approval of the Economy") +
  scale_y_continuous(limits = c(0, 60)) +
  theme_bw() 
mean.approve

ggsave(filename = "mean.approve.png", 
       plot = mean.approve,
       width = 10, 
       height = 5)
```
After running a bivariate regression between these two variables, I found that people who approved of how Obama was handling the economy were less likely to like Trump by 33 points than someone who disapproved of how the economy was handled. I also found that the average support for Trump when someone does not approve of how the economy was handled by Obama was 58 points.

```{r, echo=FALSE, results=FALSE} 
#running a regression between the Trump feeling thermometer and approval of how the President is 
#handling the economy 
reg1 <- lm(therm.Trump ~ econ.approve, data=anes)
summary(reg1)

#creating a table for the results
library(stargazer)
stargazer(reg1, omit.stat = c("f","adj.rsq","ser","ll","aic","bic"), 
          title="Trump Feeling Thermometer and Approval of President Handling the Economy", 
          model.names = FALSE, 
          covariate.labels = c("Approval of Handling the Economy", "Intercept"),
          type="text", out="/Users/briannafisher/Dropbox/PSCI107/Figures/Final.txt")
```

When controlling for party, sex, and age, people who approved of how Obama was handling the economy were still less likely to like Trump, but now by 21 points. Also similar to the bivariate regression, when someone was over 65 years old, male, republican, and disapproved of how Obama was handling the economy, the average support for Trump was 73 points. When holding sex and age fixed, democrats were less likely to like Trump than republicans by 23 points, while independents were less likely to like Trump than republicans by 15 points. When holding party and sex fixed, people who were aged 30 to 49 were less likely to like Trump than people aged 65 and older by 14 points. I did not see any significant difference in support for Trump between males and females, between people aged 18 to 29 and people aged 65 and older, and between people aged 50 to 64 and people aged 65 and older.

```{r, echo=FALSE, results=FALSE} 
#running a regression between the Trump feeling thermometer and approval of how the President is 
#handling the economy with controls
reg2 <- lm(therm.Trump ~ econ.approve + democrat + none.ind + female + age.1829 +age.3049 +age.5064, 
           data=anes)
summary(reg2)

#creating a table for the results
stargazer(reg2, omit.stat = c("f","adj.rsq","ser","ll","aic","bic"), 
          title="Trump Feeling Thermometer and Approval of President Handling the Economy with Controls", 
          model.names = FALSE, 
          covariate.labels = c("Approval of Handling the Economy", "Democrat", "None/Independent",
                               "Female", "Age 18-29", "Age 30-49", "Age 50-64","Intercept"),
          type="text", out="/Users/briannafisher/Dropbox/PSCI107/Figures/Final.txt")
```

Both of the results for how the economy was being handled by Obama from the regressions are statistically significant, with p-values less than 0.01, meaning that we can reject the null hypothesis that approval of how Obama was handling the economy would not impact whether or not people like Trump. 


### Final - Public Defender Representation Leads to Longer Prison Sentences
```{r, echo=FALSE, results=FALSE} 
library(foreign)
drunk <- read.dta("/Users/briannafisher/Dropbox/Github/BriannaFisher/data/drunk.dta")
library(tidyverse)
library(plyr)
library(stargazer)

#I subsetted the original data to only the varibales that I want
drunk.1 <- subset(drunk, select = c(V1, V2, V5, V6, V7, V8, V9, V11, V12, V13, V14, V15, V16, V17, V18, V20, 
                                    V21, V37, V62)) 

#I renamed thew categories so that all of the variables were descriptive
drunk.1 <- rename(drunk.1, c("V1" = "record.num", "V2" = "ID", "V5" = "representation", "V6" = 
                               "div.sent", "V7" = "month.sent", "V8" = "day.sent", "V9" = "year.sent", "V11" =
                               "DWI", "V12" = "sec.DWI", "V13" = "BAC.10", "V14" = "careless.driv", 
                             "V15" = "revoke.lic", "V16" = "no.ID", "V17" = "move.viol", "V18" = 
                               "vehicle.char", "V20" = "sent.length", "V21" = "fine", "V37" = "birth.year", "V62" =
                               "sex"))

#creating an age variable
drunk.1$age <- drunk.1$birth.year + 1900
drunk.1$age <- 1982 - drunk.1$age

#creating variables for age groups
table(drunk.1$age)

#creating a variable for 18-29
drunk.1$age.1829 <- 0
drunk.1$age.1829[drunk.1$age >= 18 & drunk.1$age <= 29] <- 1

#creating a variable for 30-49
drunk.1$age.3049 <- 0
drunk.1$age.3049[drunk.1$age >= 30 & drunk.1$age <= 49] <- 1

#creating a variable for 50-64
drunk.1$age.5064 <- 0
drunk.1$age.5064[drunk.1$age >= 50 & drunk.1$age <= 64] <- 1

#creating a variable for 65-81
drunk.1$age.6581 <- 0
drunk.1$age.6581[drunk.1$age >= 65 & drunk.1$age <= 81] <- 1

#creating dummy variables for male and female
attributes(drunk.1$sex)

drunk.1$female <- NA
drunk.1$female[drunk.1$sex == "MALE"] <- 0
drunk.1$female[drunk.1$sex == "FEMALE"] <- 1

drunk.1$male <- NA
drunk.1$male[drunk.1$sex == "MALE"] <- 1
drunk.1$male[drunk.1$sex == "FEMALE"] <- 0

#creating a dummy variable for whether or not someone was charged and convicted
attributes(drunk.1$DWI)

drunk.1$charge.conv <- NA
drunk.1$charge.conv[drunk.1$DWI == "NO CHARGE, NO CONVICTION"] <- 0
drunk.1$charge.conv[drunk.1$DWI == "CONVICTED ON AMENDED CHARGE"] <- 0
drunk.1$charge.conv[drunk.1$DWI == "CHARGE, BUT NO CONVICTION"] <- 0
drunk.1$charge.conv[drunk.1$DWI == "CHARGED AND CONVICTION"] <- 1

#creating a dummy variable for type of representation
attributes(drunk.1$representation)

table(drunk.1$representation)

drunk.1$pro.se <- NA
drunk.1$pro.se[drunk.1$representation == "PRO SE"] <- 1
drunk.1$pro.se[drunk.1$representation == "PUBLIC DEFENDER"] <- 0
drunk.1$pro.se[drunk.1$representation == "PRIVATE ATTORNEY"] <- 0

drunk.1$pd <- NA
drunk.1$pd[drunk.1$representation == "PRO SE"] <- 0
drunk.1$pd[drunk.1$representation == "PUBLIC DEFENDER"] <- 1
drunk.1$pd[drunk.1$representation == "PRIVATE ATTORNEY"] <- 0

drunk.1$priv.att <- NA
drunk.1$priv.att[drunk.1$representation == "PRO SE"] <- 0
drunk.1$priv.att[drunk.1$representation == "PUBLIC DEFENDER"] <- 0
drunk.1$priv.att[drunk.1$representation == "PRIVATE ATTORNEY"] <- 1

#creating a dummy variable for whether or not they had a second DUI
attributes(drunk.1$sec.DWI)

drunk.1$sec.charge <- NA
drunk.1$sec.charge[drunk.1$sec.DWI == "NO CHARGE, NO CONVICTION"] <- 0
drunk.1$sec.charge[drunk.1$sec.DWI == "CONVICTED ON AMENDED CHARGE"] <- 1
drunk.1$sec.charge[drunk.1$sec.DWI == "CHARGE, BUT NO CONVICTION"] <- 1
drunk.1$sec.charge[drunk.1$sec.DWI == "CHARGED AND CONVICTION"] <- 1

#creating a dummy variable for whether or not their BAC was above 0.10
attributes(drunk.1$BAC.10)

drunk.1$yes.BAC <- NA
drunk.1$yes.BAC[drunk.1$BAC.10 == "NO CHARGE, NO CONVICTION"] <- 0
drunk.1$yes.BAC[drunk.1$BAC.10 == "CONVICTED ON AMENDED CHARGE"] <- 0
drunk.1$yes.BAC[drunk.1$BAC.10 == "CHARGE, BUT NO CONVICTION"] <- 0
drunk.1$yes.BAC[drunk.1$BAC.10 == "CHARGED AND CONVICTION"] <- 1

#creating a continuous variable for representation type
drunk.1$rep1 <- NA
drunk.1$rep1[drunk.1$representation == "PRO SE"] <- 1
drunk.1$rep1[drunk.1$representation == "PUBLIC DEFENDER"] <- 2
drunk.1$rep1[drunk.1$representation == "PRIVATE ATTORNEY"] <- 3

drunk.1$rep2 <- NA
drunk.1$rep2[drunk.1$representation == "PRO SE"] <- 1
drunk.1$rep2[drunk.1$representation == "PUBLIC DEFENDER"] <- 2
drunk.1$rep2[drunk.1$representation == "PRIVATE ATTORNEY"] <- 3

#I made the rep variable a factor variable and renamed the columns
drunk.1$rep1 <- factor(drunk.1$rep1)
levels(drunk.1$rep1) <- c("1"="PRO SE", "2"="PUBLIC DEFENDER", "3"="PRIVATE ATTORNEY")
```

Public defenders make up the backbone of our society. They guarantee the right to representation, a fair trial, and above all else, the ability to have someone with real, legal knowledge stand up for you in court. 

The Sixth amendment guarantees everyone the right to counsel in all criminal prosecutions; however, public defenders are underpaid and overworked, as well as have little time to prepare for each case. 
In effect, the Sixth amendment was created to make sure that everybody has an adequate defense regardless of the severity of the crime, their ability to pay, or any other circumstance that could interfere with a fair trial. When public defenders do not have the time or resources to properly craft a defense, it uncovers a systemic crack within the Justice System: is the Sixth amendment actually more detrimental to a defendant than helpful, rendering this guarantee essentially useless?

This idea can be studied by looking at whether or not court appointed counsel has a larger impact on sentence length than other representation types. After analyzing data  from official court records for defendants convicted and sentenced to serve time in jail and those convicted and sentenced to pay a fine for Driving While Intoxicated in Minnesota in 1982, the answer is yes, a defendant represented by a public defender is more likely to have a longer prison sentence than someone represented by a private attorney or someone that represented themselves.

```{r, echo=FALSE, results=FALSE} 
#looking at whether type of representation or BAC over 0.10 has a greater impact on sentence length
reg1 <- lm(sent.length ~ pro.se + priv.att + age.1829 + age.3049 +age.5064 + female, 
           data=drunk.1)
summary(reg1)

#making a table with the regression results
stargazer(reg1, omit.stat = c("f","adj.rsq","ser","ll","aic","bic"), 
          title="Factors for Sentence Length", 
          model.names = FALSE, 
          covariate.labels = c("Pro Se", "Private Attorney",
                               "Age 18-29", "Age 30-49", "Age 50-64", "Female", 
                               "Intercept"),
          type="text", out="/Users/briannafisher/Dropbox/PSCI107/Figures/Final.txt")
```

```{r, echo=FALSE} 
#calculating the mean sentence length for each representation type
mean.prose <- mean(drunk.1$sent.length[drunk.1$rep1=="PRO SE"])
mean.pd <- mean(drunk.1$sent.length[drunk.1$rep1=="PUBLIC DEFENDER"])
mean.privatt <- mean(drunk.1$sent.length[drunk.1$rep1=="PRIVATE ATTORNEY"])
mean.bac <- mean(drunk.1$sent.length[drunk.1$yes.BAC==1])

df <- data.frame(mean.val=c(3.15, 9.90, 3.15),
                 Legend=c("PRO SE", "PUBLIC DEFENDER", "PRIVATE ATTORNEY"))

#plotting average sentence length and representation type
mean.bar <- ggplot(df, aes(x = Legend, y = mean.val, fill= Legend)) +
    geom_bar(stat="identity") +
    geom_text(aes(label=mean.val), vjust=-0.3, size=5) +
    scale_fill_manual(values = c("deeppink2", "khaki1", "deepskyblue")) +
    xlab("Representation Type") +
    ylab("Average Sentence Length in Days") +
    ggtitle("Average Sentence Length per Attorney") +
    scale_y_continuous(limits = c(0, 10.5)) +
    theme_bw() 
mean.bar

ggsave(filename = "mean.bar.png", 
       plot = mean.bar,
       width = 10, 
       height = 5)
```

On average, people represented by public defenders spend almost 10 days in prison. However, those represented by private attorneys or pro se (those that represented themselves), spend as little as 3.15 days in prison.

To model this further, I examined the relationship between representing yourself in court and being represented by a public defender or private attorney, as well as controlling for age and sex (since females are less likely than males to be convicted of Driving While Intoxicated and people over 65 are less likely to be driving). 

```{r, echo=FALSE} 
#creating a plot for the regression coefficients
install.packages("broom.mixed")
library(broom.mixed)
install.packages("ggstance")
library(ggstance)
install.packages("jtools")
library(jtools)
regression <- plot_summs(reg1, scale = TRUE, colors = "deeppink2", 
                         coefs = c("Pro Se" = "pro.se", "Private Attorney" = "priv.att", 
                                  "Age 18-29" = "age.1829", 
              "Age 30-49" = "age.3049", "Age 50-64" = "age.5064", "Female" = "female"),
           title = "Regression Coefficients on Sentence Length")
regression <- regression + ggtitle("How much longer would your average sentence length be?") +
  xlab("Additional Days")
regression

ggsave(filename = "regression.png", 
       plot = regression,
       width = 12, 
       height = 5)
```

When a defendant was male, older than 65 years old, and represented by a public defender, their average sentence length for Driving While Intoxicated was 9.67 days. However, when holding sex and age fixed, having a private attorney as representation is associated with a 7 day decrease in sentence length. 
Seven fewer days in prison for the same crime because someone was fortunate enough to be represented by a private attorney rather than a public defender clearly indicates that there are foundational problems that need to be investigated within public defender offices as a whole. 

After looking at the data, I also thought that it was unusual that so many people were not only representing themselves, but also receiving lessor sentences than people represented by public defenders. Originally, I thought that people who represent themselves might have less serious cases, and therefore get shorter sentences regardless of representation. However, people who represent themselves were actually more likely to have a blood alcohol content over 0.10 (with 0.08 being the legal limit) than those represented by public defenders and private attorneys, as well as be convicted of a second charge of Driving While Intoxicated. This could possibly be caused by whether or not Minnesota public defender offices have less resources than other areas and public defenders are more accustomed to receiving longer sentences for their defendants, but I would need more research and data in order to determine the actual cause.  

This leads to the question, why is the Sixth amendment failing so many defendants?

Public defender offices act more like factories, where cases come in the front door and go out the back within the same breath. Each case gets a formulaic defense that is applied within the couple of minutes that public defenders have to review it before acting as representation in court. There is a focus on brevity and completeness, rather than a fair and personalized defense for each individual.

This has, in turn, led to the increased implementation of plea deals, which help to alleviate the number of trials carried out by prosecutors but are used in place of putting in the time and resources to thoroughly review a case. As a result, prisoners are carrying out sentences that are almost always too long for the crime committed but act as a result of an insufficient plea deal. 

The crutch of using a plea deal could be a factor in the additional seven days spent in prison by someone represented by a public defender. This highlights the disparity between being able to afford better representation and invoking one’s right to counsel, which should hold up to the “adequate” standard set by the Constitution. 

This is clearly a flaw within the American Justice System, but what can be done to fix this?

First, and perhaps most importantly, public defender offices need to have an increase in funding so that they can complete their jobs more effectively. Second, public defender offices should create subdivisions within each office based upon certain infractions and categories within the Justice System. When an office assigns their attorneys to a case based upon their preferential and desired division, the lawyer is more inclined to become passionate and have greater knowledge in the case. 

Additional research needs to be completed within other areas of the law to determine if this pattern carries over to crimes other than Driving While Intoxicated. If so, the entire premise of public defender offices needs to be evaluated in order to ensure that the Sixth amendment is effective and can be used as a support to defendants, rather than a detriment to them. 

Anyone put on trial deserves, and is required by law, to have an attentive and interested lawyer to defend them. When lawyers take on too many cases, they ultimately contribute to the decline in effectiveness of the Sixth amendment and legal system as a whole. If a legal system cannot act effectively, there is no way to guarantee that justice will guide the decisions of prosecutors and defenders alike.

## Statistical Methods for Political Science

<h2>Statistical Methods for Political Science</h2>

### Midterm

```{r, echo=FALSE, results=FALSE} 
library(foreign)
library(dplyr)
library(stargazer)
library(Hmisc)
library(weights)

Kaiser <- read.dta("/Users/briannafisher/Dropbox/Github/BriannaFisher/data/KaiserFamilyFoundationPoll.DTA", convert.factors = T)
head(Kaiser)
```

__Theory__

As COVID-19 started to worsen throughout the country, there was a stark difference in the way that Democratic versus Republican government officials handled the outbreak. States with Republican governors quickly ended stay at home orders and reopened nonessential businesses, while states with Democratic governors saw extensive statewide lockdowns and stricter rules about going out in public. These two ideals were met with both support and criticism from higher ranking government officials, such as praise by the President for reopening states and criticism from Democratic congressmen who supported a lockdown. These differing views on how to handle the virus were also seen at the local level, with everyday citizens sharing the same ideas about social distancing practices depending on their ideology. Similarly, the support from higher ranking government officials for one practice over the other influenced how people followed protocol. 

I theorize that people who identify as liberal are more likely to socially distance than those who identify as conservative. States with a majority of people who identify as liberal have Democratic governors and state governments, so these areas already had lengthy stay at home orders and strict rules in place to limit the virus. People in these states mostly agreed with their government’s policies and were already used to social distancing and quarantining when the states reopened. States with a majority of people who identify as conservative, however, have Republican governments that emphasized keeping businesses and schools open. Florida and Texas, for example, saw crowded beaches and malls all summer while New York, and especially New York City, had quiet streets and closed restaurants. The reasons why people with different ideologies followed different social distancing practices also has to do with the core beliefs of those ideologies. Conservatives heavily value the economy, so it was expected for conservative governments to not order mandatory lockdowns in order for nonessential businesses to stay open. Liberals, however, generally believe in government action to solve problems and protect its citizens, so following lockdown orders and strictly social distancing was expected. I hypothesize that ideological views caused liberals to socially distance more than conservatives.

__Empirical Tests__

Based on my theory, I hypothesize that people who identify as liberal were less likely to partake in everyday activities (such as shopping for food, medicine, or essential household items, visiting close friends or family, going to work, using public transportation, and dining at a restaurant) than people who identify as conservative. A maintained assumption for this theory is that all of these activities have the same level of importance to each person. Shopping for food, medicine, or essential household items is necessary for people to survive, while dining at a restaurant depends on the person’s comfort level. This would cause me to expect that the percentage of people who were liberal and went shopping for those items is similar to the percentage of people who were conservative and went shopping for those items, while the other activities would vary depending on how greatly that person needed to complete them. 

Additionally, I hypothesize that people who approve of Trump were more likely to partake in these activities than people who don’t approve of Trump. A maintained assumption of this is that people who approve of Trump therefore value his opinion and will follow his example (such as not socially distancing). However, some people may not take his opinion into consideration when deciding whether or not to participate in these activities. Also, people who approve of Trump mostly identify as conservative, while those who do not identify as liberal. Thus, I would expect the same as before that people who are liberal were less likely to partake in these activities then people who are conservative. 

__Variable Coding__
```{r, echo=FALSE, results=FALSE}
#visiting close family or friends
Kaiser$AA2 <- 0
Kaiser$AA2[Kaiser$Q18B == "Not at all"] = 1

#going to work
Kaiser$AA3 <- 0
Kaiser$AA3[Kaiser$Q18C == "Not at all"] = 1

#using public transit
Kaiser$AA4 <- 0
Kaiser$AA4[Kaiser$Q18D == "Not at all"] = 1

#dining at a restaurant
Kaiser$AA5 <- 0
Kaiser$AA5[Kaiser$Q18E == "Not at all"] = 1

#whether or not they did not go to work, visit family or friends, use public transit, and
#dine at a restaurant
Kaiser$Abstained.activities <- 0
Kaiser$Abstained.activities[Kaiser$AA2 == 1 & Kaiser$AA3 == 1  & 
                               Kaiser$AA4 == 1 & Kaiser$AA5 == 1] = 1

table(Kaiser$Abstained.activities)
```

```{r, echo=FALSE, results=FALSE}
#creating a variable for conservative ideology  
Kaiser$Conservative <- NA
Kaiser$Conservative[Kaiser$ideology == "Liberal"] = 0
Kaiser$Conservative[Kaiser$ideology == "Conservative"] = 1
Kaiser$Conservative[Kaiser$ideology == "Moderate"] = 0
Kaiser$Conservative[Kaiser$ideology == "Don't Know"] = 0
Kaiser$Conservative[Kaiser$ideology == "Refused"] = 0

#creating a variable for moderate ideology  
Kaiser$Moderate <- NA
Kaiser$Moderate[Kaiser$ideology == "Liberal"] = 0
Kaiser$Moderate[Kaiser$ideology == "Conservative"] = 0
Kaiser$Moderate[Kaiser$ideology == "Moderate"] = 1
Kaiser$Moderate[Kaiser$ideology == "Don't Know"] = 0
Kaiser$Moderate[Kaiser$ideology == "Refused"] = 0
```
In order to test my theory and hypothesis, I use data from a study completed by the Kaiser Family Foundation. The study was completed from June 8, 2020 to June 14, 2020, and focuses on the perception of health, race, and COVID-19 in the United States. 
 
My dependent variable is constructed using a combination of four everyday activities that people abstained from. In question 18 of the survey, the respondents were asked how often they (18A) shop for food, medicine, or essential items, (18B) visit close friends or family, (18C) go to work, (18D) use public transit, and (18E) dine at a restaurant. The respondents had four response options: 1) “4 times or more”, 2)” 2-3 times”, 3) “1 time”, or 4) “Not at all.” Because shopping for food, medicine, or essential items was necessary for everybody, no matter their ideology, to continue during the pandemic, my dependent variable is a combination between questions 18B, 18C, 18D, and 18E. Also, since I am looking at whether or not people abstained from these activities, I only focus on whether or not the respondent said 4, or not at all, to any of the four options. My dependent variable is coded as a dummy variable that equals 1 if the respondent abstained from any of the four activities (visiting close family or friends, going to work, using public transit, or dining in a restaurant) and 0 if they participated in any of these activities at least once. A measurement assumption for this variable is that I am measuring social distancing as a whole by only four activities, when in reality people could be going out in public for a variety of reasons that do not match up with the variable. 

My key independent variables are two dummy variables coded for whether or not someone is conservative or moderate. The “Conservative” dummy variable is coded as 1 if the respondent answered the ideology question as conservative and 0 if they responded as liberal, moderate, don’t know, or refused. The “Moderate” dummy variable is coded as 1 if the respondent the ideology question as moderate and 0 if they responded as liberal, conservative, don’t know, or refused. Both variables are coded as missing if someone did not answer the question. A measurement assumption for this variable is that people only conform to these specific ideologies, when in reality ideology is measured on more of a spectrum. 

__Control Variables__
```{r, echo=FALSE, results=FALSE}
##creating a variable for Trump approval (people who strongly or somewhat disapprove Trump are the excluded group)

# creating a variable for people who strongly or somewhat approve
Kaiser$trump.approve <- NA
Kaiser$trump.approve[Kaiser$trumpapp == "Strongly approve"] = 1
Kaiser$trump.approve[Kaiser$trumpapp == "Somewhat approve"] = 1
Kaiser$trump.approve[Kaiser$trumpapp == "Somewhat disapprove"] = 0
Kaiser$trump.approve[Kaiser$trumpapp == "Strongly disapprove"] = 0
Kaiser$trump.approve[Kaiser$trumpapp == "Don't Know"] = 0
Kaiser$trump.approve[Kaiser$trumpapp == "Refused"] = 0
```

```{r, echo=FALSE, results=FALSE}
##creating a variable for age (18-29 are the excluded group)

#creating a variable for 18-29
Kaiser$age.1829 <- 0
Kaiser$age.1829[Kaiser$age >= 18 & Kaiser$age <= 29] <- 1
Kaiser$age.1829[Kaiser$age == 99] <- NA

#creating a variable for 30-49
Kaiser$age.3049 <- 0
Kaiser$age.3049[Kaiser$age >= 30 & Kaiser$age <= 49] <- 1
Kaiser$age.3049[Kaiser$age == 99] <- NA

#creating a variable for 50-64
Kaiser$age.5064 <- 0
Kaiser$age.5064[Kaiser$age >= 50 & Kaiser$age <= 64] <- 1
Kaiser$age.5064[Kaiser$age == 99] <- NA
```

```{r, echo=FALSE, results=FALSE}
##creating a variable for race (white people are the excluded group)
attributes(Kaiser$race)
Kaiser$minority <- NA
Kaiser$minority[Kaiser$race == "White"] = 0
Kaiser$minority[Kaiser$race == "Black or African-American"] = 1
Kaiser$minority[Kaiser$race == "Asain"] = 1
Kaiser$minority[Kaiser$race == "Other or mixed race"] = 1
Kaiser$minority[Kaiser$race == "Don't Know"] = 0
Kaiser$minority[Kaiser$race == "Refused"] = 0
```
One control variable when analyzing the relationship between ideology and social distancing is whether or not someone approves of Trump. Because Trump is in such a large position of power and has control over the narrative of the virus, people look up to him to determine how they should act. When Trump does not socially distance or wear a mask, normal people see this as a sign that they should not either. I coded this variable (trump.approve) as a dummy variable that equals one if someone strongly or somewhat approves of Trump and 0 if they somewhat disapprove, strongly disapprove, don’t know, ore refused. I would expect someone who is liberal to somewhat or strongly disapprove of Trump, and therefore made it my excluded group.

Another control variable when analyzing the relationship between ideology and social distancing is a person’s age. I expect people over the age of 65 to social distance more, as the elderly are at a higher risk for catching the virus than those that are younger. As a result, I made people 65 years old to 97 years old my excluded group. I created dummy variables for each age group (18-29, 30-49, 50-64), with that specific group being coded as 1 and the other responses being coded as 0.

A third control variable is a person’s race. On average, people who are White are more likely to be liberal than people of another race. The biggest block of the Democratic vote, for example, has shifted to white liberals from African Americans. Because of this, I excluded people who identify as White from my regression. I created a dummy variable to represent minority groups, with 1 being for people who responded that they were Black or African American, Asian, other or mixed race, don’t know, or refused and 0 for people who responded that they were White.

__Descriptive Statistics__
```{r, echo=FALSE}
subKaiser <- subset(Kaiser, select = c(Abstained.activities, Conservative, Moderate, trump.approve, age.1829, age.3049, age.5064, minority), na.rm = T)

stargazer(subKaiser, type = "text", title="Table 1: Descriptive Statistics on Ideology and Social Distancing", summary.stat = c("n", "mean", "sd", "min", "max"),
          covariate.labels= c("Abstained from Activities",
                              "Conservatie Ideology", "Moderate Ideology",
                              "Trump Approval", "Age 18-29", "Age 35-49", "Age 50-64", 
                              "Minority"),
          out="/Users/briannafisher/Dropbox/PSCI338/Midterm/Kaiser.txt") 
```
Table 1 presents descriptive statistics for my dependent variable, independent variables, and control variables. The table depicts the number of observations, mean, standard deviation, minimum, and maximum values for the following variables: Abstained From Activities, Conservative Ideology, Moderate Ideology, Trump Approval, Age 18-29, Age 35-49, Age 64, and Minorities. 

__Results__
```{r, echo=FALSE, results=FALSE}
#plot for conservatives
plotdata <- aggregate(Kaiser$Abstained.activities, by=list(Kaiser$Conservative), FUN=mean)
plotdata
colnames(plotdata) <- c("Conservative or Not", "Mean Number of Abstained Activities")
levels(plotdata$`Conservative or Not`) <- c("yes", "no")
barplot(plotdata$`Mean Number of Abstained Activities`, names = plotdata$`Conservative or Not`, xlab = "Conservative: Yes = 1, No = 0", ylab = "Average Number of Abstained from Activities", main = "Figure 1: Abstained From Acitvities and Conservative", ylim = c(0, 0.5), col=c("gray10","gray50"))
postscript("/Users/briannafisher/Dropbox/PSCI338/Midterm/Plot1.eps")
```
Figure 1 shows, as I predicted, that conservatives were less likely to socially distance than liberals or moderates. The “0” block represents people who responded to the survey as liberal, moderate, don’t know, or other, and is about 0.8 units higher than the conservative, or “1”, block.

```{r, echo=FALSE, results=FALSE}
# Baseline analysis of whether ideology is related to social distancing
baseline <- lm(Abstained.activities ~ Conservative + Moderate, data = subKaiser)
summary(baseline)
```

```{r, echo=FALSE, results=FALSE}
# Full analysis of whether ideology is related to social distancing with control variables
full <- lm(Abstained.activities ~ Conservative + Moderate + trump.approve + age.1829  + age.3049 + age.5064 + minority, data = subKaiser)
summary(full)
```

```{r, echo=FALSE, results=FALSE}
# Restricts dataset to only liberals 
libdata <- subset(subKaiser, subset = Conservative + Moderate == 0)

#Full analysis for just liberals
full.lib <- lm(Abstained.activities ~ trump.approve + age.1829  + age.3049 + age.5064 + minority, data = libdata)
summary(full.lib)

prop.table(table(libdata$trump.approve))
```

```{r, echo=FALSE}
stargazer(baseline, full, full.lib, omit.stat = c("f","adj.rsq","ser","ll","aic","bic"), 
          title="Table 2: Correlation of Abstained From Activities During COVID-19", 
          model.names = FALSE, 
          column.labels = c("Ideology","All", "Liberals"),
          covariate.labels = c("Conservative", "Moderate","Trump Approval",
                               "Age 18-29", "Age 30-49", "Age 50-64", "Minority Groups", "Constant"), type="text", out="/Users/briannafisher/Dropbox/PSCI338/Midterm/Correlation.txt")
```
Table 2 presents a regression analysis for three subsets, all regressed on the dependent variable of abstained activities. The first column represents just the independent variable of ideology, for both conservatives and moderates. The average number of activities liberals abstained from was 0.26 units, while conservatives were 0.08 units less likely to abstain from any activities. This provides evidence for my hypothesis, as liberals were more likely to socially distance than those who identify as conservative. Moderates were 0.006 units less likely to abstain from any activities than liberals, which was also expected as moderates fall between liberals and conservatives on the ideology spectrum and subsequently should have fallen in the middle of the regression.

The second column in the regression includes all of the control variables that I used to test my theory. The average number of activities liberals abstained from activities was 0.437 units, while conservatives were 0.073 unites less likely to abstain from activities, holding fixed Trump approval, minority status, and age. This coefficient most likely increased because it now included my excluded groups of liberals, people who are white, people who are 65 years old and older, and people who do not approve of Trump. Theoretically, all of these categories would lead to increased social distancing, which is seen when the coefficient changes. The coefficient on Trump Approval indicates that people who support Trump are an additional 0.049 units less likely to abstain from any activities than people who do not support Trump. This was expected, since people who approve of Trump are likely to follow his behavior of not social distancing. Additionally, the coefficients on all three age groups (18-29, 20-49, 50-64) are negative, indicating that they are less likely to social distance than people who are aged 65 years old and older. This result was expected, as people who are younger are both at less of a risk of the virus and do not take the virus as seriously as those who are older. Finally, the coefficient on the minority groups variable indicates that people who identify as a minority are 0.022 units more likely to social distance than those that identify as White. Originally, I had hypothesized that people who identify as White would socially distance more since they make up the largest demographic of liberals. However, this result indicates that people who make up a minority group are more likely to socially distance than those who are White.

Similarly, to the second column, column three shows the same general patterns for the coefficients of the age and minority group variables. However, among liberals, people who approve of Trump are 0.091 units more likely to socially distance than liberals who do not approve of Trump. This result was not expected, as I would think that people who approve of Trump (who promotes not social distancing) would be less likely than people who do not approve of Trump (liberals especially) to socially distance. When looking at the data though, only 14.45% of liberals approve of Trump, while 85.55% disapprove (out of 357 observations). This makes it clear that the result is just unusual and there was little data to work with. 

__Conclusion__
I was able to find evidence that people who identify as liberal are more likely to socially distance than those who identify as conservative. Because social distancing is such a broad topic, I would have wanted to have more information on the extent to which people social distanced (for example visiting family or friends while staying six feet apart and wearing a mask versus going inside of someone else’s house). This most likely would have changed the respondent’s attitude towards social distancing, as going inside of another person’s house does not adhere to the “definition” of social distancing set forth by the CDC. As a control variable, I would have wanted to look at the type of job a respondent has. If a respondent has a job where they are deemed an essential worker, then they would have had to respond yes to the “Did you go to work” (18C) question even if it was involuntary. I would have also wanted to look at a respondent’s religion. If a respondent goes to church twice a week, for example, then they might have a more relaxed attitude on social distancing if they were still going throughout the pandemic. 

If I was able to look at these variables as well, I would expect the regression coefficient to increase. The majority of people in the country were not deemed essential workers, so I would expect more people to socially distance than the proportion of those who had to go to work. I would also expect the coefficient to increase in regard to religion because when the survey was taken in June, most places of worship were closed due to the pandemic. This would have caused more people to social distance if they were not able to practice their religion in person.  

In regard to measurement error, it worries me that ideology is measured by only three choices. I would have wanted to have a more continuous variable to measure ideology, rather than just three options. In today’s political climate, there are numerous divisions within each political party and ideology separating one person’s view of being liberal or conservative from another. Right now, my study only analyzes ideology as if it is cut and dry, when in reality there are many different options to the question. This might have made respondents more open to answering the question if they had more options, especially if they responded as they don’t know.


### Final

__Introduction__

The process of scientific jury selection was first applied to a major case in the Harrisburg Seven trial in 1972. During the trial, social scientists used demographical information of the jurors to identify whether or not they would be biased towards a conviction and subsequently to serve on the jury. Ever since this case, prosecutors and defense attorneys alike have become accustomed to considering demographics – such as race, age, sex, economic background, marital status, religion, and relationship with the law – when picking a jury. During the voir dire process, lawyers have the opportunity to use peremptory and causal challenges in order to dismiss jurors that would not maintain fairness when listening to the case. A challenge for cause occurs when a lawyer removes someone for a legal reason (these are unlimited during a trial). A peremptory challenge occurs when a lawyer removes someone without a reason or explanation, but cannot be on the basis of race, ethnicity, or sex (the number is limited by the statute being tried). Increasingly, lawyers have been using these challenges in a subtle (in order to remain legal) way to achieve a jury that is more likely to either side in favor or against the defendant, depending on whether it is the prosecution or defense. According to the Equal Justice Initiative’s 2010 report on illegal racial discrimination in jury selection, 8 out of 10 African Americans in Houston County, Alabama that qualified for jury service have been struck by prosecutors from death penalty cases. It was also reported that in Jefferson Parish, Louisiana, there is no effective African American representation on the jury in 80 percent of criminal trials. This idea of deciding a case before presenting evidence just based upon racial biases and stereotypes seems like it should be a significant problem in the evaluation of trials and within the criminal justice system as a whole. This led me to the question “Are jurors more sympathetic to defendants of the same race?” and to my hypothesis that “juries in which at least 50% of the jurors are the same race as the defendant are more likely to side in favor of the defendant.”

In order to test my hypothesis, I analyzed data on four courthouses (Bronx County Supreme Court in New York, Los Angeles County Superior Court in California, Maricopa County Superior Court in Arizona, and District of Columbia Superior Court in Washington, DC). I ran a baseline regression between whether or not the defendant had at least one conviction and the proportion of the jury whose members are less than 50% racially similar to the defendant, as well as a controlled regression including victim believability, defendant sympathy, if the crime was a misdemeanor, and if the victim was not white. For both regressions, I found that the defendant was more likely to be convicted when the jury was less than 50% racially similar to the defendant than when the jury was at least 50% racially similar to the defendant, providing evidence for my hypothesis. 

__Theory and Previous Literature__

While completing preliminary research, two sources emerged as predominantly important for this paper. In Professor of Law at Washington University School of Law Peter A. Joy’s 2015 paper for the Northwestern University Law Review entitled “Race Matters in Jury Selection,” he analyzed a study conducted by Samuel Sommers and Phoebe Ellsworth on implicit bias during the voir dire process. During the study, one group of mock jurors received a questionnaire about their racial attitudes and racial biases in the legal system while the other group was asked questions that disregarded race as a whole. According to Joy, the purpose of the questions was “not to identify racial bias in particular jurors, but rather to cause prospective jurors to think about their attitudes toward race to help jurors consciously guard against implicit bias.” The study found that both White and African American jurors were less likely to convict African American defendants after being asked the race-related questions during the voir dire, as well as that all-White juries were more likely to convict African American defendants than White defendants (Joy 2015). Ideally, all jurors would be asked these race-based questions in the real world during their voir dire in order to spark introspection and make themselves aware of any biases they may hold. However, race-relevant questions are only allowed during capital punishment cases, and the inclusion of a race-relevant voir dire is up to the discretion of the trial judge in all other cases. Originally, I planned on studying multiple demographics and how they impacted a juror’s decision on the defendant’s sentence as a whole. However, after this explanatory research, this paper became the foundation of my theory: implicit racial bias impacts jury decision making.

Similarly, in Justin D. Levinson (Associate Professor of Law at the University of Hawaii), Huajian Cai (Professor at the Key Laboratory of Mental Health and Institute of Psychology for the Chinese Academy of Sciences), and Danielle Young’s (member of the Department of Psychology at the University of Hawaii) research paper for the Ohio State Journal of Criminal Law entitled “Guilty By Implicit Racial Bias: The Guilty/Not Guilty Implicit Association Test,” they completed a study on how the Implicit Association Test (IAT) can be used in a legal setting. The study had participants (67 jury eligible students from the University of Hawaii) complete multiple tasks in order to measure racial beliefs and preferences. The first test was a Guilty/Not Guilty IAT test developed as a race IAT with “the attribute concepts of Guilty and Not Guilty and target concepts of Black and White” (Levinson 2010). The second test was a Pleasant/Unpleasant IAT test also developed as a race IAT to evaluate the concepts of Pleasant and Unpleasant with the target concepts of Black and White. The participants were also given the Modern Racism Scale, which has a series of questions in regard to racial beliefs, a feeling thermometer, which evaluates explicit racial preferences, and finally a robbery evidence evaluation task, which asked participants to decide whether a defendant was guilty or not guilty in a mock trial. The study found that participants in the Guilty/Not Guilty IAT displayed a “significant association between Black and Guilty compared to White and Guilty” and that participants in the Pleasant/Unpleasant IAT displayed a “significant association between Black and Unpleasant compared to White and Unpleasant” (Levinson 2010). Ultimately, Levinson, Cai, and Young were able to conclude that people are more likely to perceive black people as guilty, and that the implicit associations led to “predicted judgments of the probative value of evidence” (Levinson 2010). This study was crucial to the refinement of my theory and hypothesis, as it is such a significant problem that some trials are already decided before hearing any evidence, completely violating the “fair trial” requirement set forth by the Constitution. 

After reviewing this previous literature, I have decided to focus on the proportion of jurors whose race matches the race of the defendant and whether or not that impacts their trial outcome. I have also decided to look at jury sympathy for the victim and defendant, as the second study proves the prominence of implicit biases when making decisions in regard to trial outcome. My research will add a unique perspective to this literature as I will be analyzing data from four different courthouses, all of which are located in demographically different areas (Bronx County, New York, Los Angeles County, California, Maricopa County, Arizona, and Washington, DC). I will also be analyzing the outcomes of the trials, rather than just the process of jury selection. This will allow me to connect the issue of racial biases in jury decision making to these different cities in order to highlight this significant fault within the justice system and the fact that it is present within all juries and not one particular area.

__Data__

```{r, echo=FALSE, results=FALSE}
library(foreign)
attorney <- read.dta("data/Attorney.dta")
case <- read.dta("data/Case.dta")
count.sheet.long <- read.dta("data/Countsheet.dta")
judge <- read.dta("data/Judge.dta")
jury <- read.dta("data/Juror.dta")
```

```{r, echo=FALSE, results=FALSE} 
#Reshaping Count Sheet Data

# The floor function drops any number after the decimal point
count.sheet.long$caseno1 <- floor(count.sheet.long$CASENO)
# Gets the number after the decimal point by subtracting caseno1
# Muliplies by 10 to make into an integer
count.sheet.long$caseno2 <- (count.sheet.long$CASENO - count.sheet.long$caseno1)*10
head(count.sheet.long)
# Rounds to make into integer
count.sheet.long$caseno2 <- round(count.sheet.long$caseno2)
head(count.sheet.long)
table(count.sheet.long$caseno2)
# Adds 1 if caseno2 == 0 
count.sheet.long$caseno2[count.sheet.long$caseno2 == 0] <- 1
table(count.sheet.long$caseno2)
```

```{r, echo=FALSE, results=FALSE} 
#Make data wide using reshape function

count.sheet.wide <- reshape(count.sheet.long, idvar = c("caseno1", "SITE"), timevar = "caseno2", direction = "wide")
head(count.sheet.wide)
```

```{r, echo=FALSE, results=FALSE}
#Subsetting the case data

case.1 <- subset(case, subset = NUMDEFTS == 1)

case.final <- subset(case.1, select = c(CASENO, SITE, DEFTGEND, DEFTRACE, DEFTREPR, CRIMHIST, VICTGEND, VICTGND2, VICTGND3, VICTGND4, VICTRACE, VICTRCE2, VICTRAC3, VICTRAC4)) 
```

```{r, echo=FALSE, results=FALSE}
#Subsetting the count sheet data

library(tidyverse)
count.sheet.final <- subset(count.sheet.wide, select = c(SITE, CASENO.1, CASETYPE.1, COUNT1.1, COUNT2.1, COUNT3.1, COUNT4.1, COUNT5.1, COUNT6.1, TOTCOUNT.1, TOTCONV.1, TOTACQUT.1, SENTENC.1))

count.sheet.final <- rename(count.sheet.final, c("CASENO" = "CASENO.1"))
```

```{r, echo=FALSE, results=FALSE}
#subsetting the judge survey data

judge.final <- subset(judge, select = c(CASENO, SITE, EFTTEST, ICTTEST, THELAW, ODEFEND, NDERSTD)) 
```

```{r, echo=FALSE, results=FALSE}
#subsetting the attorney survey data

attorney.1 <- subset(attorney, select = c(CASENO, SITE, ATTYTYPE, NOTAGREE, AGE, GENDER)) 
```

```{r, echo=FALSE, results=FALSE} 
#Reshaping the Attorney Data

attorney.final <- reshape(attorney.1, idvar = c("CASENO", "SITE"), timevar = "ATTYTYPE", direction = "wide")
```

```{r, echo=FALSE, results=FALSE}
#subsetting the jury survey data

jury.1 <- subset(jury, select = c(CASENO, SITE, JURORNO, DEFTEVID, DSYMPATH, VSYMPATH, DEFSTRNG, NVCNGMD, FAVORWHO, DIFFVERD, ONEPERSN, GENDER, AGE, SCHOOL, RACE, RELIGON, INCOME, JOBSTAT, OCCUPAT)) 
```

```{r, echo=FALSE, results=FALSE}
#Reshaping the Jury Data

jury.final <- reshape(jury.1, idvar = c("CASENO", "SITE"), timevar = "JURORNO", direction = "wide")
```

```{r, echo=FALSE, results=FALSE}
#Merging the data

law <- Reduce(function(x, y) merge(x, y), list(case.final, count.sheet.final, attorney.final, judge.final, jury.final))
```

```{r, echo=FALSE, results=FALSE}
#Creating race variables for juror 1

attributes(law$RACE.1)

law$race.1.white <- 0
law$race.1.white[law$RACE.1 == "White/Caucasian"] <- 1
law$race.1.white[law$RACE.1 == "White/Hispanic"] <- 1
law$race.1.white[law$RACE.1 == "Unknown"] <- 0
law$race.1.white[law$RACE.1 == "Nonwhite/Hispanic"] <- 0
law$race.1.white[law$RACE.1 == "Black/African American"] <- 0
law$race.1.white[law$RACE.1 == "Native American"] <- 0
law$race.1.white[law$RACE.1 == "Asian/Pacific Islander"] <- 0
law$race.1.white[law$RACE.1 == "Other - please specifiy:"] <- 0

law$race.1.notwhite <- 0
law$race.1.notwhite[law$RACE.1 == "White/Caucasian"] <- 0
law$race.1.notwhite[law$RACE.1 == "White/Hispanic"] <- 0
law$race.1.notwhite[law$RACE.1 == "Nonwhite/Hispanic"] <- 1
law$race.1.notwhite[law$RACE.1 == "Black/African American"] <- 1
law$race.1.notwhite[law$RACE.1 == "Native American"] <- 1
law$race.1.notwhite[law$RACE.1 == "Asian/Pacific Islander"] <- 1
law$race.1.notwhite[law$RACE.1 == "Other - please specifiy:"] <- 1
law$race.1.notwhite[law$RACE.1 == "Unknown"] <- 0

law$race.1.unknown <- 0
law$race.1.unknown[law$RACE.1 == "White/Caucasian"] <- 0
law$race.1.unknown[law$RACE.1 == "White/Hispanic"] <- 0
law$race.1.unknown[law$RACE.1 == "Nonwhite/Hispanic"] <- 0
law$race.1.unknown[law$RACE.1 == "Black/African American"] <- 0
law$race.1.unknown[law$RACE.1 == "Native American"] <- 0
law$race.1.unknown[law$RACE.1 == "Asian/Pacific Islander"] <- 0
law$race.1.unknown[law$RACE.1 == "Other - please specifiy:"] <- 0
law$race.1.unknown[law$RACE.1 == "Unknown"] <- 1
```

```{r, echo=FALSE, results=FALSE}
#Creating race variables for juror 2

law$race.2.white <- 0
law$race.2.white[law$RACE.2 == "White/Caucasian"] <- 1
law$race.2.white[law$RACE.2 == "White/Hispanic"] <- 1
law$race.2.white[law$RACE.2 == "Unknown"] <- 0
law$race.2.white[law$RACE.2 == "Nonwhite/Hispanic"] <- 0
law$race.2.white[law$RACE.2 == "Black/African American"] <- 0
law$race.2.white[law$RACE.2 == "Native American"] <- 0
law$race.2.white[law$RACE.2 == "Asian/Pacific Islander"] <- 0
law$race.2.white[law$RACE.2 == "Other - please specifiy:"] <- 0

law$race.2.notwhite <- 0
law$race.2.notwhite[law$RACE.2 == "White/Caucasian"] <- 0
law$race.2.notwhite[law$RACE.2 == "White/Hispanic"] <- 0
law$race.2.notwhite[law$RACE.2 == "Nonwhite/Hispanic"] <- 1
law$race.2.notwhite[law$RACE.2 == "Black/African American"] <- 1
law$race.2.notwhite[law$RACE.2 == "Native American"] <- 1
law$race.2.notwhite[law$RACE.2 == "Asian/Pacific Islander"] <- 1
law$race.2.notwhite[law$RACE.2 == "Other - please specifiy:"] <- 1
law$race.2.notwhite[law$RACE.2 == "Unknown"] <- 0

law$race.2.unknown <- 0
law$race.2.unknown[law$RACE.2 == "White/Caucasian"] <- 0
law$race.2.unknown[law$RACE.2 == "White/Hispanic"] <- 0
law$race.2.unknown[law$RACE.2 == "Nonwhite/Hispanic"] <- 0
law$race.2.unknown[law$RACE.2 == "Black/African American"] <- 0
law$race.2.unknown[law$RACE.2 == "Native American"] <- 0
law$race.2.unknown[law$RACE.2 == "Asian/Pacific Islander"] <- 0
law$race.2.unknown[law$RACE.2 == "Other - please specifiy:"] <- 0
law$race.2.unknown[law$RACE.2 == "Unknown"] <- 1
```

```{r, echo=FALSE, results=FALSE}
#Creating race variables for juror 3

law$race.3.white <- 0
law$race.3.white[law$RACE.3 == "White/Caucasian"] <- 1
law$race.3.white[law$RACE.3 == "White/Hispanic"] <- 1
law$race.3.white[law$RACE.3 == "Unknown"] <- 0
law$race.3.white[law$RACE.3 == "Nonwhite/Hispanic"] <- 0
law$race.3.white[law$RACE.3 == "Black/African American"] <- 0
law$race.3.white[law$RACE.3 == "Native American"] <- 0
law$race.3.white[law$RACE.3 == "Asian/Pacific Islander"] <- 0
law$race.3.white[law$RACE.3 == "Other - please specifiy:"] <- 0

law$race.3.notwhite <- 0
law$race.3.notwhite[law$RACE.3 == "White/Caucasian"] <- 0
law$race.3.notwhite[law$RACE.3 == "White/Hispanic"] <- 0
law$race.3.notwhite[law$RACE.3 == "Nonwhite/Hispanic"] <- 1
law$race.3.notwhite[law$RACE.3 == "Black/African American"] <- 1
law$race.3.notwhite[law$RACE.3 == "Native American"] <- 1
law$race.3.notwhite[law$RACE.3 == "Asian/Pacific Islander"] <- 1
law$race.3.notwhite[law$RACE.3 == "Other - please specifiy:"] <- 1
law$race.3.notwhite[law$RACE.3 == "Unknown"] <- 0

law$race.3.unknown <- 0
law$race.3.unknown[law$RACE.3 == "White/Caucasian"] <- 0
law$race.3.unknown[law$RACE.3 == "White/Hispanic"] <- 0
law$race.3.unknown[law$RACE.3 == "Nonwhite/Hispanic"] <- 0
law$race.3.unknown[law$RACE.3 == "Black/African American"] <- 0
law$race.3.unknown[law$RACE.3 == "Native American"] <- 0
law$race.3.unknown[law$RACE.3 == "Asian/Pacific Islander"] <- 0
law$race.3.unknown[law$RACE.3 == "Other - please specifiy:"] <- 0
law$race.3.unknown[law$RACE.3 == "Unknown"] <- 1
```

```{r, echo=FALSE, results=FALSE}
#Creating race variables for juror 4

law$race.4.white <- 0
law$race.4.white[law$RACE.4 == "White/Caucasian"] <- 1
law$race.4.white[law$RACE.4 == "White/Hispanic"] <- 1
law$race.4.white[law$RACE.4 == "Unknown"] <- 0
law$race.4.white[law$RACE.4 == "Nonwhite/Hispanic"] <- 0
law$race.4.white[law$RACE.4 == "Black/African American"] <- 0
law$race.4.white[law$RACE.4 == "Native American"] <- 0
law$race.4.white[law$RACE.4 == "Asian/Pacific Islander"] <- 0
law$race.4.white[law$RACE.4 == "Other - please specifiy:"] <- 0

law$race.4.notwhite <- 0
law$race.4.notwhite[law$RACE.4 == "White/Caucasian"] <- 0
law$race.4.notwhite[law$RACE.4 == "White/Hispanic"] <- 0
law$race.4.notwhite[law$RACE.4 == "Nonwhite/Hispanic"] <- 1
law$race.4.notwhite[law$RACE.4 == "Black/African American"] <- 1
law$race.4.notwhite[law$RACE.4 == "Native American"] <- 1
law$race.4.notwhite[law$RACE.4 == "Asian/Pacific Islander"] <- 1
law$race.4.notwhite[law$RACE.4 == "Other - please specifiy:"] <- 1
law$race.4.notwhite[law$RACE.4 == "Unknown"] <- 0

law$race.4.unknown <- 0
law$race.4.unknown[law$RACE.4 == "White/Caucasian"] <- 0
law$race.4.unknown[law$RACE.4 == "White/Hispanic"] <- 0
law$race.4.unknown[law$RACE.4 == "Nonwhite/Hispanic"] <- 0
law$race.4.unknown[law$RACE.4 == "Black/African American"] <- 0
law$race.4.unknown[law$RACE.4 == "Native American"] <- 0
law$race.4.unknown[law$RACE.4 == "Asian/Pacific Islander"] <- 0
law$race.4.unknown[law$RACE.4 == "Other - please specifiy:"] <- 0
law$race.4.unknown[law$RACE.4 == "Unknown"] <- 1
```

```{r, echo=FALSE, results=FALSE}
#Creating race variables for juror 5

law$race.5.white <- 0
law$race.5.white[law$RACE.5 == "White/Caucasian"] <- 1
law$race.5.white[law$RACE.5 == "White/Hispanic"] <- 1
law$race.5.white[law$RACE.5 == "Unknown"] <- 0
law$race.5.white[law$RACE.5 == "Nonwhite/Hispanic"] <- 0
law$race.5.white[law$RACE.5 == "Black/African American"] <- 0
law$race.5.white[law$RACE.5 == "Native American"] <- 0
law$race.5.white[law$RACE.5 == "Asian/Pacific Islander"] <- 0
law$race.5.white[law$RACE.5 == "Other - please specifiy:"] <- 0

law$race.5.notwhite <- 0
law$race.5.notwhite[law$RACE.5 == "White/Caucasian"] <- 0
law$race.5.notwhite[law$RACE.5 == "White/Hispanic"] <- 0
law$race.5.notwhite[law$RACE.5 == "Nonwhite/Hispanic"] <- 1
law$race.5.notwhite[law$RACE.5 == "Black/African American"] <- 1
law$race.5.notwhite[law$RACE.5 == "Native American"] <- 1
law$race.5.notwhite[law$RACE.5 == "Asian/Pacific Islander"] <- 1
law$race.5.notwhite[law$RACE.5 == "Other - please specifiy:"] <- 1
law$race.5.notwhite[law$RACE.5 == "Unknown"] <- 0

law$race.5.unknown <- 0
law$race.5.unknown[law$RACE.5 == "White/Caucasian"] <- 0
law$race.5.unknown[law$RACE.5 == "White/Hispanic"] <- 0
law$race.5.unknown[law$RACE.5 == "Nonwhite/Hispanic"] <- 0
law$race.5.unknown[law$RACE.5 == "Black/African American"] <- 0
law$race.5.unknown[law$RACE.5 == "Native American"] <- 0
law$race.5.unknown[law$RACE.5 == "Asian/Pacific Islander"] <- 0
law$race.5.unknown[law$RACE.5 == "Other - please specifiy:"] <- 0
law$race.5.unknown[law$RACE.5 == "Unknown"] <- 1
```

```{r, echo=FALSE, results=FALSE}
#Creating race variables for juror 6

law$race.6.white <- 0
law$race.6.white[law$RACE.6 == "White/Caucasian"] <- 1
law$race.6.white[law$RACE.6 == "White/Hispanic"] <- 1
law$race.6.white[law$RACE.6 == "Unknown"] <- 0
law$race.6.white[law$RACE.6 == "Nonwhite/Hispanic"] <- 0
law$race.6.white[law$RACE.6 == "Black/African American"] <- 0
law$race.6.white[law$RACE.6 == "Native American"] <- 0
law$race.6.white[law$RACE.6 == "Asian/Pacific Islander"] <- 0
law$race.6.white[law$RACE.6 == "Other - please specifiy:"] <- 0

law$race.6.notwhite <- 0
law$race.6.notwhite[law$RACE.6 == "White/Caucasian"] <- 0
law$race.6.notwhite[law$RACE.6 == "White/Hispanic"] <- 0
law$race.6.notwhite[law$RACE.6 == "Nonwhite/Hispanic"] <- 1
law$race.6.notwhite[law$RACE.6 == "Black/African American"] <- 1
law$race.6.notwhite[law$RACE.6 == "Native American"] <- 1
law$race.6.notwhite[law$RACE.6 == "Asian/Pacific Islander"] <- 1
law$race.6.notwhite[law$RACE.6 == "Other - please specifiy:"] <- 1
law$race.6.notwhite[law$RACE.6 == "Unknown"] <- 0

law$race.6.unknown <- 0
law$race.6.unknown[law$RACE.6 == "White/Caucasian"] <- 0
law$race.6.unknown[law$RACE.6 == "White/Hispanic"] <- 0
law$race.6.unknown[law$RACE.6 == "Nonwhite/Hispanic"] <- 0
law$race.6.unknown[law$RACE.6 == "Black/African American"] <- 0
law$race.6.unknown[law$RACE.6 == "Native American"] <- 0
law$race.6.unknown[law$RACE.6 == "Asian/Pacific Islander"] <- 0
law$race.6.unknown[law$RACE.6 == "Other - please specifiy:"] <- 0
law$race.6.unknown[law$RACE.6 == "Unknown"] <- 1
```

```{r, echo=FALSE, results=FALSE}
#Creating race variables for juror 7

law$race.7.white <- 0
law$race.7.white[law$RACE.7 == "White/Caucasian"] <- 1
law$race.7.white[law$RACE.7 == "White/Hispanic"] <- 1
law$race.7.white[law$RACE.7 == "Unknown"] <- 0
law$race.7.white[law$RACE.7 == "Nonwhite/Hispanic"] <- 0
law$race.7.white[law$RACE.7 == "Black/African American"] <- 0
law$race.7.white[law$RACE.7 == "Native American"] <- 0
law$race.7.white[law$RACE.7 == "Asian/Pacific Islander"] <- 0
law$race.7.white[law$RACE.7 == "Other - please specifiy:"] <- 0

law$race.7.notwhite <- 0
law$race.7.notwhite[law$RACE.7 == "White/Caucasian"] <- 0
law$race.7.notwhite[law$RACE.7 == "White/Hispanic"] <- 0
law$race.7.notwhite[law$RACE.7 == "Nonwhite/Hispanic"] <- 1
law$race.7.notwhite[law$RACE.7 == "Black/African American"] <- 1
law$race.7.notwhite[law$RACE.7 == "Native American"] <- 1
law$race.7.notwhite[law$RACE.7 == "Asian/Pacific Islander"] <- 1
law$race.7.notwhite[law$RACE.7 == "Other - please specifiy:"] <- 1
law$race.7.notwhite[law$RACE.7 == "Unknown"] <- 0

law$race.7.unknown <- 0
law$race.7.unknown[law$RACE.7 == "White/Caucasian"] <- 0
law$race.7.unknown[law$RACE.7 == "White/Hispanic"] <- 0
law$race.7.unknown[law$RACE.7 == "Nonwhite/Hispanic"] <- 0
law$race.7.unknown[law$RACE.7 == "Black/African American"] <- 0
law$race.7.unknown[law$RACE.7 == "Native American"] <- 0
law$race.7.unknown[law$RACE.7 == "Asian/Pacific Islander"] <- 0
law$race.7.unknown[law$RACE.7 == "Other - please specifiy:"] <- 0
law$race.7.unknown[law$RACE.7 == "Unknown"] <- 1
```

```{r, echo=FALSE, results=FALSE}
#Creating race variables for juror 8

law$race.8.white <- 0
law$race.8.white[law$RACE.8 == "White/Caucasian"] <- 1
law$race.8.white[law$RACE.8 == "White/Hispanic"] <- 1
law$race.8.white[law$RACE.8 == "Unknown"] <- 0
law$race.8.white[law$RACE.8 == "Nonwhite/Hispanic"] <- 0
law$race.8.white[law$RACE.8 == "Black/African American"] <- 0
law$race.8.white[law$RACE.8 == "Native American"] <- 0
law$race.8.white[law$RACE.8 == "Asian/Pacific Islander"] <- 0
law$race.8.white[law$RACE.8 == "Other - please specifiy:"] <- 0

law$race.8.notwhite <- 0
law$race.8.notwhite[law$RACE.8 == "White/Caucasian"] <- 0
law$race.8.notwhite[law$RACE.8 == "White/Hispanic"] <- 0
law$race.8.notwhite[law$RACE.8 == "Nonwhite/Hispanic"] <- 1
law$race.8.notwhite[law$RACE.8 == "Black/African American"] <- 1
law$race.8.notwhite[law$RACE.8 == "Native American"] <- 1
law$race.8.notwhite[law$RACE.8 == "Asian/Pacific Islander"] <- 1
law$race.8.notwhite[law$RACE.8 == "Other - please specifiy:"] <- 1
law$race.8.notwhite[law$RACE.8 == "Unknown"] <- 0

law$race.8.unknown <- 0
law$race.8.unknown[law$RACE.8 == "White/Caucasian"] <- 0
law$race.8.unknown[law$RACE.8 == "White/Hispanic"] <- 0
law$race.8.unknown[law$RACE.8 == "Nonwhite/Hispanic"] <- 0
law$race.8.unknown[law$RACE.8 == "Black/African American"] <- 0
law$race.8.unknown[law$RACE.8 == "Native American"] <- 0
law$race.8.unknown[law$RACE.8 == "Asian/Pacific Islander"] <- 0
law$race.8.unknown[law$RACE.8 == "Other - please specifiy:"] <- 0
law$race.8.unknown[law$RACE.8 == "Unknown"] <- 1
```

```{r, echo=FALSE, results=FALSE}
#Creating race variables for juror 9

law$race.9.white <- 0
law$race.9.white[law$RACE.9 == "White/Caucasian"] <- 1
law$race.9.white[law$RACE.9 == "White/Hispanic"] <- 1
law$race.9.white[law$RACE.9 == "Unknown"] <- 0
law$race.9.white[law$RACE.9 == "Nonwhite/Hispanic"] <- 0
law$race.9.white[law$RACE.9 == "Black/African American"] <- 0
law$race.9.white[law$RACE.9 == "Native American"] <- 0
law$race.9.white[law$RACE.9 == "Asian/Pacific Islander"] <- 0
law$race.9.white[law$RACE.9 == "Other - please specifiy:"] <- 0

law$race.9.notwhite <- 0
law$race.9.notwhite[law$RACE.9 == "White/Caucasian"] <- 0
law$race.9.notwhite[law$RACE.9 == "White/Hispanic"] <- 0
law$race.9.notwhite[law$RACE.9 == "Nonwhite/Hispanic"] <- 1
law$race.9.notwhite[law$RACE.9 == "Black/African American"] <- 1
law$race.9.notwhite[law$RACE.9 == "Native American"] <- 1
law$race.9.notwhite[law$RACE.9 == "Asian/Pacific Islander"] <- 1
law$race.9.notwhite[law$RACE.9 == "Other - please specifiy:"] <- 1
law$race.9.notwhite[law$RACE.9 == "Unknown"] <- 0

law$race.9.unknown <- 0
law$race.9.unknown[law$RACE.9 == "White/Caucasian"] <- 0
law$race.9.unknown[law$RACE.9 == "White/Hispanic"] <- 0
law$race.9.unknown[law$RACE.9 == "Nonwhite/Hispanic"] <- 0
law$race.9.unknown[law$RACE.9 == "Black/African American"] <- 0
law$race.9.unknown[law$RACE.9 == "Native American"] <- 0
law$race.9.unknown[law$RACE.9 == "Asian/Pacific Islander"] <- 0
law$race.9.unknown[law$RACE.9 == "Other - please specifiy:"] <- 0
law$race.9.unknown[law$RACE.9 == "Unknown"] <- 1
```

```{r, echo=FALSE, results=FALSE}
#Creating race variables for juror 10

law$race.10.white <- 0
law$race.10.white[law$RACE.10 == "White/Caucasian"] <- 1
law$race.10.white[law$RACE.10 == "White/Hispanic"] <- 1
law$race.10.white[law$RACE.10 == "Unknown"] <- 0
law$race.10.white[law$RACE.10 == "Nonwhite/Hispanic"] <- 0
law$race.10.white[law$RACE.10 == "Black/African American"] <- 0
law$race.10.white[law$RACE.10 == "Native American"] <- 0
law$race.10.white[law$RACE.10 == "Asian/Pacific Islander"] <- 0
law$race.10.white[law$RACE.10 == "Other - please specifiy:"] <- 0

law$race.10.notwhite <- 0
law$race.10.notwhite[law$RACE.10 == "White/Caucasian"] <- 0
law$race.10.notwhite[law$RACE.10 == "White/Hispanic"] <- 0
law$race.10.notwhite[law$RACE.10 == "Nonwhite/Hispanic"] <- 1
law$race.10.notwhite[law$RACE.10 == "Black/African American"] <- 1
law$race.10.notwhite[law$RACE.10 == "Native American"] <- 1
law$race.10.notwhite[law$RACE.10 == "Asian/Pacific Islander"] <- 1
law$race.10.notwhite[law$RACE.10 == "Other - please specifiy:"] <- 1
law$race.10.notwhite[law$RACE.10 == "Unknown"] <- 0

law$race.10.unknown <- 0
law$race.10.unknown[law$RACE.10 == "White/Caucasian"] <- 0
law$race.10.unknown[law$RACE.10 == "White/Hispanic"] <- 0
law$race.10.unknown[law$RACE.10 == "Nonwhite/Hispanic"] <- 0
law$race.10.unknown[law$RACE.10 == "Black/African American"] <- 0
law$race.10.unknown[law$RACE.10 == "Native American"] <- 0
law$race.10.unknown[law$RACE.10 == "Asian/Pacific Islander"] <- 0
law$race.10.unknown[law$RACE.10 == "Other - please specifiy:"] <- 0
law$race.10.unknown[law$RACE.10 == "Unknown"] <- 1
```

```{r, echo=FALSE, results=FALSE}
#Creating race variables for juror 11

law$race.11.white <- 0
law$race.11.white[law$RACE.11 == "White/Caucasian"] <- 1
law$race.11.white[law$RACE.11 == "White/Hispanic"] <- 1
law$race.11.white[law$RACE.11 == "Unknown"] <- 0
law$race.11.white[law$RACE.11 == "Nonwhite/Hispanic"] <- 0
law$race.11.white[law$RACE.11 == "Black/African American"] <- 0
law$race.11.white[law$RACE.11 == "Native American"] <- 0
law$race.11.white[law$RACE.11 == "Asian/Pacific Islander"] <- 0
law$race.11.white[law$RACE.11 == "Other - please specifiy:"] <- 0

law$race.11.notwhite <- 0
law$race.11.notwhite[law$RACE.11 == "White/Caucasian"] <- 0
law$race.11.notwhite[law$RACE.11 == "White/Hispanic"] <- 0
law$race.11.notwhite[law$RACE.11 == "Nonwhite/Hispanic"] <- 1
law$race.11.notwhite[law$RACE.11 == "Black/African American"] <- 1
law$race.11.notwhite[law$RACE.11 == "Native American"] <- 1
law$race.11.notwhite[law$RACE.11 == "Asian/Pacific Islander"] <- 1
law$race.11.notwhite[law$RACE.11 == "Other - please specifiy:"] <- 1
law$race.11.notwhite[law$RACE.11 == "Unknown"] <- 0

law$race.11.unknown <- 0
law$race.11.unknown[law$RACE.11 == "White/Caucasian"] <- 0
law$race.11.unknown[law$RACE.11 == "White/Hispanic"] <- 0
law$race.11.unknown[law$RACE.11 == "Nonwhite/Hispanic"] <- 0
law$race.11.unknown[law$RACE.11 == "Black/African American"] <- 0
law$race.11.unknown[law$RACE.11 == "Native American"] <- 0
law$race.11.unknown[law$RACE.11 == "Asian/Pacific Islander"] <- 0
law$race.11.unknown[law$RACE.11 == "Other - please specifiy:"] <- 0
law$race.11.unknown[law$RACE.11 == "Unknown"] <- 1
```

```{r, echo=FALSE, results=FALSE}
#Creating race variables for juror 12

law$race.12.white <- 0
law$race.12.white[law$RACE.12 == "White/Caucasian"] <- 1
law$race.12.white[law$RACE.12 == "White/Hispanic"] <- 1
law$race.12.white[law$RACE.12 == "Unknown"] <- 0
law$race.12.white[law$RACE.12 == "Nonwhite/Hispanic"] <- 0
law$race.12.white[law$RACE.12 == "Black/African American"] <- 0
law$race.12.white[law$RACE.12 == "Native American"] <- 0
law$race.12.white[law$RACE.12 == "Asian/Pacific Islander"] <- 0
law$race.12.white[law$RACE.12 == "Other - please specifiy:"] <- 0

law$race.12.notwhite <- 0
law$race.12.notwhite[law$RACE.12 == "White/Caucasian"] <- 0
law$race.12.notwhite[law$RACE.12 == "White/Hispanic"] <- 0
law$race.12.notwhite[law$RACE.12 == "Nonwhite/Hispanic"] <- 1
law$race.12.notwhite[law$RACE.12 == "Black/African American"] <- 1
law$race.12.notwhite[law$RACE.12 == "Native American"] <- 1
law$race.12.notwhite[law$RACE.12 == "Asian/Pacific Islander"] <- 1
law$race.12.notwhite[law$RACE.12 == "Other - please specifiy:"] <- 1
law$race.12.notwhite[law$RACE.12 == "Unknown"] <- 0

law$race.12.unknown <- 0
law$race.12.unknown[law$RACE.12 == "White/Caucasian"] <- 0
law$race.12.unknown[law$RACE.12 == "White/Hispanic"] <- 0
law$race.12.unknown[law$RACE.12 == "Nonwhite/Hispanic"] <- 0
law$race.12.unknown[law$RACE.12 == "Black/African American"] <- 0
law$race.12.unknown[law$RACE.12 == "Native American"] <- 0
law$race.12.unknown[law$RACE.12 == "Asian/Pacific Islander"] <- 0
law$race.12.unknown[law$RACE.12 == "Other - please specifiy:"] <- 0
law$race.12.unknown[law$RACE.12 == "Unknown"] <- 1
```

```{r, echo=FALSE, results=FALSE}
#adding up the race variables for the jury

law$jury.white <- NA
law$jury.white <- law$race.1.white + law$race.2.white + law$race.3.white + law$race.4.white + law$race.5.white + law$race.6.white + law$race.7.white + law$race.8.white + law$race.9.white + law$race.10.white + law$race.11.white + law$race.12.white 

law$jury.notwhite <- NA
law$jury.notwhite <- law$race.1.notwhite + law$race.2.notwhite + law$race.3.notwhite + law$race.4.notwhite + law$race.5.notwhite + law$race.6.notwhite + law$race.7.notwhite + law$race.8.notwhite + law$race.9.notwhite + law$race.10.notwhite + law$race.11.notwhite + law$race.12.notwhite 

law$jury.unknown <- NA
law$jury.unknown <- law$race.1.unknown + law$race.2.unknown + law$race.3.unknown + law$race.4.unknown + law$race.5.unknown + law$race.6.unknown + law$race.7.unknown + law$race.8.unknown + law$race.9.unknown + law$race.10.unknown + law$race.11.unknown + law$race.12.unknown 

table(law$jury.white)
table(law$jury.notwhite)
table(law$jury.unknown)
table(law$def.notwhite)
```

```{r, echo=FALSE, results=FALSE}
#Creating race variables for the defendant

attributes(law$DEFTRACE)
table(law$DEFTRACE)

law$def.white <- 0
law$def.white[law$DEFTRACE == "White - not Hispanic"] <- 1
law$def.white[law$DEFTRACE == "White - Hispanic"] <- 1
law$def.white[law$DEFTRACE == "Black - not Hispanic"] <- 0
law$def.white[law$DEFTRACE == "Black - Hispanic"] <- 0
law$def.white[law$DEFTRACE == "Native American"] <- 0
law$def.white[law$DEFTRACE == "Asian"] <- 0
law$def.white[law$DEFTRACE == "Other (please specify):"] <- 0
law$def.white[law$DEFTRACE == "Unknown"] <- 0

law$def.notwhite <- 0
law$def.notwhite[law$DEFTRACE == "White - not Hispanic"] <- 0
law$def.notwhite[law$DEFTRACE == "White - Hispanic"] <- 0
law$def.notwhite[law$DEFTRACE == "Black - not Hispanic"] <- 1
law$def.notwhite[law$DEFTRACE == "Black - Hispanic"] <- 1
law$def.notwhite[law$DEFTRACE == "Native American"] <- 1
law$def.notwhite[law$DEFTRACE == "Asian"] <- 1
law$def.notwhite[law$DEFTRACE == "Other (please specify):"] <- 1
law$def.notwhite[law$DEFTRACE == "Unknown"] <- 0

law$def.unknown <- 0
law$def.unknown[law$DEFTRACE == "White - not Hispanic"] <- 0
law$def.unknown[law$DEFTRACE == "White - Hispanic"] <- 0
law$def.unknown[law$DEFTRACE == "Black - not Hispanic"] <- 0
law$def.unknown[law$DEFTRACE == "Black - Hispanic"] <- 0
law$def.unknown[law$DEFTRACE == "Native American"] <- 0
law$def.unknown[law$DEFTRACE == "Asian"] <- 0
law$def.unknown[law$DEFTRACE == "Other (please specify):"] <- 0
law$def.unknown[law$DEFTRACE == "Unknown"] <- 1

print(subset(law, law$def.unknown == 1))
```

```{r, echo=FALSE, results=FALSE}
#Creating race variables for the victims

law$vict.white <- NA
law$vict.white[law$VICTRACE == "White - not Hispanic"] <- 1
law$vict.white[law$VICTRACE == "White - Hispanic"] <- 1
law$vict.white[law$VICTRACE == "Black - not Hispanic"] <- 0
law$vict.white[law$VICTRACE == "Black - Hispanic"] <- 0
law$vict.white[law$VICTRACE == "Native American"] <- 0
law$vict.white[law$VICTRACE == "Asian"] <- 0
law$vict.white[law$VICTRACE == "Other (please specify):"] <- 0
law$vict.white[law$VICTRACE == "Unknown"] <- 0
law$vict.white[law$VICTRCE2 == "White - not Hispanic"] <- 1
law$vict.white[law$VICTRCE2 == "White - Hispanic"] <- 1
law$vict.white[law$VICTRCE2 == "Black - not Hispanic"] <- 0
law$vict.white[law$VICTRCE2 == "Black - Hispanic"] <- 0
law$vict.white[law$VICTRCE2 == "Native American"] <- 0
law$vict.white[law$VICTRCE2 == "Asian"] <- 0
law$vict.white[law$VICTRCE2 == "Other (please specify):"] <- 0
law$vict.white[law$VICTRCE2 == "Unknown"] <- 0
law$vict.white[law$VICTRAC3 == "White - not Hispanic"] <- 1
law$vict.white[law$VICTRAC3 == "White - Hispanic"] <- 1
law$vict.white[law$VICTRAC3 == "Black - not Hispanic"] <- 0
law$vict.white[law$VICTRAC3 == "Black - Hispanic"] <- 0
law$vict.white[law$VICTRAC3 == "Native American"] <- 0
law$vict.white[law$VICTRAC3 == "Asian"] <- 0
law$vict.white[law$VICTRAC3 == "Other (please specify):"] <- 0
law$vict.white[law$VICTRAC3 == "Unknown"] <- 0
law$vict.white[law$VICTRAC4 == "White - not Hispanic"] <- 1
law$vict.white[law$VICTRAC4 == "White - Hispanic"] <- 1
law$vict.white[law$VICTRAC4 == "Black - not Hispanic"] <- 0
law$vict.white[law$VICTRAC4 == "Black - Hispanic"] <- 0
law$vict.white[law$VICTRAC4 == "Native American"] <- 0
law$vict.white[law$VICTRAC4 == "Asian"] <- 0
law$vict.white[law$VICTRAC4 == "Other (please specify):"] <- 0
law$vict.white[law$VICTRAC4 == "Unknown"] <- 0

law$vict.notwhite <- NA
law$vict.notwhite[law$VICTRACE == "White - not Hispanic"] <- 0
law$vict.notwhite[law$VICTRACE == "White - Hispanic"] <- 0
law$vict.notwhite[law$VICTRACE == "Black - not Hispanic"] <- 1
law$vict.notwhite[law$VICTRACE == "Black - Hispanic"] <- 1
law$vict.notwhite[law$VICTRACE == "Native American"] <- 1
law$vict.notwhite[law$VICTRACE == "Asian"] <- 1
law$vict.notwhite[law$VICTRACE == "Other (please specify):"] <- 1
law$vict.notwhite[law$VICTRACE == "Unknown"] <- 1
law$vict.notwhite[law$VICTRCE2 == "White - not Hispanic"] <- 0
law$vict.notwhite[law$VICTRCE2 == "White - Hispanic"] <- 0
law$vict.notwhite[law$VICTRCE2 == "Black - not Hispanic"] <- 1
law$vict.notwhite[law$VICTRCE2 == "Black - Hispanic"] <- 1
law$vict.notwhite[law$VICTRCE2 == "Native American"] <- 1
law$vict.notwhite[law$VICTRCE2 == "Asian"] <- 1
law$vict.notwhite[law$VICTRCE2 == "Other (please specify):"] <- 1
law$vict.notwhite[law$VICTRCE2 == "Unknown"] <- 1
law$vict.notwhite[law$VICTRAC3 == "White - not Hispanic"] <- 0
law$vict.notwhite[law$VICTRAC3 == "White - Hispanic"] <- 0
law$vict.notwhite[law$VICTRAC3 == "Black - not Hispanic"] <- 1
law$vict.notwhite[law$VICTRAC3 == "Black - Hispanic"] <- 1
law$vict.notwhite[law$VICTRAC3 == "Native American"] <- 1
law$vict.notwhite[law$VICTRAC3 == "Asian"] <- 1
law$vict.notwhite[law$VICTRAC3 == "Other (please specify):"] <- 1
law$vict.notwhite[law$VICTRAC3 == "Unknown"] <- 1
law$vict.notwhite[law$VICTRAC4 == "White - not Hispanic"] <- 0
law$vict.notwhite[law$VICTRAC4 == "White - Hispanic"] <- 0
law$vict.notwhite[law$VICTRAC4 == "Black - not Hispanic"] <- 1
law$vict.notwhite[law$VICTRAC4 == "Black - Hispanic"] <- 1
law$vict.notwhite[law$VICTRAC4 == "Native American"] <- 1
law$vict.notwhite[law$VICTRAC4 == "Asian"] <- 1
law$vict.notwhite[law$VICTRAC4 == "Other (please specify):"] <- 1
law$vict.notwhite[law$VICTRAC4 == "Unknown"] <- 1
```

```{r, echo=FALSE, results=FALSE}
#creating a variable for at least one conviction

law$yes.conv <- 0
law$yes.conv[law$COUNT1.1 == "Conviction" | law$COUNT2.1 == "Conviction" | law$COUNT3.1 == "Conviction" | law$COUNT4.1 == "Conviction" | law$COUNT5.1 == "Conviction" | law$COUNT6.1 == "Conviction"] <- 1
```

```{r, echo=FALSE, results=FALSE}
#creating a variable for at least one jury member to think the victim was very believable 

law$believe.vict <- 0
law$believe.vict[law$VSYMPATH.1 == "Very believable" | law$VSYMPATH.2 == "Very believable" | law$VSYMPATH.3 == "Very believable" | law$VSYMPATH.4 == "Very believable" | law$VSYMPATH.5 == "Very believable" | law$VSYMPATH.6 == "Very believable" | law$VSYMPATH.7 == "Very believable" | law$VSYMPATH.8 == "Very believable" | law$VSYMPATH.9 == "Very believable" | law$VSYMPATH.10 == "Very believable" | law$VSYMPATH.11 == "Very believable" | law$VSYMPATH.12 == "Very believable"] <- 1
table(law$believe.vict)
```

```{r, echo=FALSE, results=FALSE}
#creating a variable for at least one jury member to have sympathy for the defendant 

law$def.sympt <- 0
law$def.sympt[law$DSYMPATH.1 == "A great deal of sympathy" | law$DSYMPATH.2 == "A great deal of sympathy" | law$DSYMPATH.3 == "A great deal of sympathy" | law$DSYMPATH.4 == "A great deal of sympathy" | law$DSYMPATH.5 == "A great deal of sympathy" | law$DSYMPATH.6 == "A great deal of sympathy" | law$DSYMPATH.7 == "A great deal of sympathy" | law$DSYMPATH.8 == "A great deal of sympathy" | law$DSYMPATH.9 == "A great deal of sympathy" | law$DSYMPATH.10 == "A great deal of sympathy" | law$DSYMPATH.11 == "A great deal of sympathy" | law$DSYMPATH.12 == "A great deal of sympathy"] <- 1
table(law$def.sympt)
```

```{r, echo=FALSE, results=FALSE}
#creating variables for the severity of the charge

attributes(law$CASETYPE.1)
law$felony <- NA
law$felony[law$CASETYPE.1 == "Murder, first degree"] <- 1
law$felony[law$CASETYPE.1 == "Murder, second degree"] <- 1
law$felony[law$CASETYPE.1 == "Manslaughter"] <- 1
law$felony[law$CASETYPE.1 == "Rape/sexual battery/sex conduct w/minor"] <- 1
law$felony[law$CASETYPE.1 == "Robbery"] <- 1
law$felony[law$CASETYPE.1 == "Assault (not sexual)"] <- 0
law$felony[law$CASETYPE.1 == "Child abuse/neglect"] <- 0
law$felony[law$CASETYPE.1 == "Burglary"] <- 1
law$felony[law$CASETYPE.1 == "Larceny/theft"] <- 0
law$felony[law$CASETYPE.1 == "Arson"] <- 1
law$felony[law$CASETYPE.1 == "Illegal drug, possession"] <- 1
law$felony[law$CASETYPE.1 == "Illegal drug, sale"] <- 1
law$felony[law$CASETYPE.1 == "Illegal drug, manufacture"] <- 1
law$felony[law$CASETYPE.1 == "DUI/DWI"] <- 0
law$felony[law$CASETYPE.1 == "Attempted murder"] <- 1
law$felony[law$CASETYPE.1 == "Weapons"] <- 1
law$felony[law$CASETYPE.1 == "Forgery"] <- 0
law$felony[law$CASETYPE.1 == "Unlawful flight/leaving scene/failure to stop/resist arrest"] <- 0
law$felony[law$CASETYPE.1 == "Other"] <- 0
law$felony[law$CASETYPE.1 == "Unknown"] <- 0

law$misdemeanor <- NA
law$misdemeanor[law$CASETYPE.1 == "Murder, first degree"] <- 0
law$misdemeanor[law$CASETYPE.1 == "Murder, second degree"] <- 0
law$misdemeanor[law$CASETYPE.1 == "Manslaughter"] <- 0
law$misdemeanor[law$CASETYPE.1 == "Rape/sexual battery/sex conduct w/minor"] <- 0
law$misdemeanor[law$CASETYPE.1 == "Robbery"] <- 0
law$misdemeanor[law$CASETYPE.1 == "Assault (not sexual)"] <- 1
law$misdemeanor[law$CASETYPE.1 == "Child abuse/neglect"] <- 1
law$misdemeanor[law$CASETYPE.1 == "Burglary"] <- 0
law$misdemeanor[law$CASETYPE.1 == "Larceny/theft"] <- 1
law$misdemeanor[law$CASETYPE.1 == "Arson"] <- 0
law$misdemeanor[law$CASETYPE.1 == "Illegal drug, possession"] <- 0
law$misdemeanor[law$CASETYPE.1 == "Illegal drug, sale"] <- 0
law$misdemeanor[law$CASETYPE.1 == "Illegal drug, manufacture"] <- 0
law$misdemeanor[law$CASETYPE.1 == "DUI/DWI"] <- 1
law$misdemeanor[law$CASETYPE.1 == "Attempted murder"] <- 0
law$misdemeanor[law$CASETYPE.1 == "Weapons"] <- 0
law$misdemeanor[law$CASETYPE.1 == "Forgery"] <- 1
law$misdemeanor[law$CASETYPE.1 == "Unlawful flight/leaving scene/failure to stop/resist arrest"] <- 1
law$misdemeanor[law$CASETYPE.1 == "Other"] <- 0
law$misdemeanor[law$CASETYPE.1 == "Unknown"] <- 0
```

```{r, echo=FALSE, results=FALSE}
#creating a variable for the proportion of the jury that matches the race of the defendant 

law$prop.race <- NA
law$prop.race <- if(!is.na(law$def.notwhite == 1)) {
  print(law$jury.notwhite/(law$jury.white + law$jury.notwhite))
} else if(!is.na(law$def.white == 1)) {
  print(law$jury.white/(law$jury.white + law$jury.notwhite))
} else if(!is.na(law$def.unknown == 1)) {
  print(law$def.unknown <- NA)
}

```

```{r, echo=FALSE, results=FALSE}
#creating variables for whether the proportion of jurors whose race matches the defendant is more than / less than 0.50

law$prop.race.big50 <- NA
law$prop.race.big50[law$prop.race >= 0.50] <- 1
law$prop.race.big50[law$prop.race < 0.50] <- 0

law$prop.race.less50 <- NA
law$prop.race.less50[law$prop.race >= 0.50] <- 0
law$prop.race.less50[law$prop.race < 0.50] <- 1
```

I will use the data from the “Evaluation of Hung Juries in Bronx County, New York, Los Angeles County, California, Maricopa County, Arizona, and Washington, DC, 2000-2001 (ICPSR 3689)” by Paula Hannaford-Agor, Valerie Hans, Nicole Mott, and G. Thomas Munsterman. The data includes information on four courts (Bronx County Supreme Court in New York, Los Angeles County Superior Court in California, Maricopa County Superior Court in Arizona, and District of Columbia Superior Court in Washington, DC). Each court was sent a case data form and count sheet data form, as well as three questionnaires for the judges, attorneys, and jurors. The case data form includes the demographic information for the defendant and the victim(s) and the type of representation for the defendant. The count sheet data includes the case type, the jury’s decision for each count the defendant was charged with, the total number of convictions, and the sentence length. The judge questionnaire includes the evaluation of the evidence, case complexity, likelihood that the jury understood the case, importance of the victim’s testimony, and importance of the defendant’s testimony. The attorney questionnaire includes information assessing the case complexity, type of defense, whether or not the jury would become hung, and their own demographical information. The juror questionnaire includes responses regarding case complexity, whether or not the evidence was convincing, whether or not they had sympathy towards the defendant or victim(s), whether or not the defense had a strong case, which side they favored before, during, and after deliberations, and demographical information on themselves. 

In order to analyze this data as a whole, I reshaped the attorney and jury datasets so that each row corresponded to a singular court site and case number. Once the data was widened, I was able to merge all five datasets together to create one larger dataset, entitled “law.” To construct my key independent variable (the proportion of the jury whose members are less than 50% racially similar to the defendant), I first created three dummy variables for the race of each jury member (White, not White, and unknown). Once all 36 variables were created (since trials could have up to 12 jurors), I added them together so that I would have a total count of the jury members of each race per case number (becoming the variables jury.white, jury.notwhite, and jury.unknown). Next, I created the same three dummy variables for the defendant’s race (def.white, def.notwhite, and def.unknown). Once these six variables were created, I constructed the continuous proportion variable (becoming the variable prop.race) by matching the race of the defendant with the number of people who matched that race on the jury and dividing that number by the total number of jurors for that case. I constructed my actual independent variable (becoming prop.race.less50) as a dummy variable that equals 1 if the proportion of the jury whose race matches the defendant was less than half of the members and 0 if the proportion of the jury is equal to or more than half of the members. Because my hypothesis is that juries in which at least 50% of the jurors are the same race as the defendant are more likely to side in favor of the defendant, I made the group in which the proportion of the jury whose race is equal to or more than half the same as the defendant the excluded group. 

Afterwards, I constructed my dependent variable by combining the results for whether or not a defendant had a least one conviction for the six possible counts they could have been charged with in that particular case (becoming the variable yes.conv). The variable is coded as 1 if they had at least one conviction and 0 if they had no convictions. A measurement assumption of this variable, however, is that I am assuming that these juries had negative racial biases, when it could have been the opposite and positive, resulting in a lesser sentence or charge rather than a conviction for the defendant. 
Additionally, I chose to control for four different variables that all could influence both the proportion of jury members with a similar race to the defendant and whether or not the defendant was convicted on at least one count. First, I chose to control for whether or not the jury felt “a great deal of sympathy” for the defendant. It seems like having a large amount of sympathy for the defendant would cause the jury to rule in favor of the defendant, regardless of their race. I coded this variable (def.sympt) as a dummy variable that equals 1 if at least one of the jury members felt a great deal of sympathy for the defendant and 0 if none of the jury members felt a great deal of sympathy for the defendant. I would expect that someone who has no sympathy towards the defendant would rule more harshly, so I made that my excluded group. Similarly, I chose to control for whether or not the jury felt that the victim(s) was very believable. It seems like thinking that the victim(s) was very believable would cause the jury to rule against the defendant, regardless of race. I coded this variable (believe.vict) as a dummy variable that equals 1 if at least one of the jury members felt that the victim(s) was very believable and 0 if none of the jury members felt that the victims(s) was very believable. I would expect that someone who does not think that the victim was believable would rule less harshly against the defendant, so I made that my excluded group. My third control variable is the crime the defendant was charged with. I created two variables: the first (felony) equals 1 if the crime is classified as a felony and 0 if the crime is classified as a misdemeanor and the second (misdemeanor) equals 1 if the crime is classified as a misdemeanor and 0 if the crime is classified as a felony. I would expect that if someone was charged with a crime as serious as murder or rape, a juror would weigh that more heavily than whether or not they were the same race. Because of this, I made the felony variable my excluded group. Finally, my fourth control variable is the victim’s race. Because of the preconceived biases made by the jury in the research I previously discussed in my Literature Review, I decided to look at whether or not the victim was White, as most people in the study associated White with “Not Guilty” and “Pleasant.” I created two variables: the first (vict.white) equals 1 if the victim was White and 0 if victim was any other race and the second (vict.notwhite) equals 1 if the victim was any race other than White and 0 if the victim was White. Because I would expect the jury to favor White victims, I made that my excluded group.

```{r, echo=FALSE}
#cretaing a descriptive statistics table

sublaw <- subset(law, select = c(yes.conv, prop.race.less50, believe.vict, def.sympt, vict.notwhite, misdemeanor), na.rm = T)

stargazer(sublaw, type = "text", title="Table 1: Descriptive Statistics for Convictions and Proportion of Similar Race", summary.stat = c("n", "mean", "sd", "min", "max"),
          covariate.labels= c("At least one conviction",
                              "Proportion of the jury whose members are less than 50% racially similar to the defendant", "Victim Believability","Defendant Sympathy", "Not White Victim", "Misdemeanor"),
          out="/Users/briannafisher/Dropbox/PSCI338/Final/Law.txt") 
```

Table 1 presents descriptive statistics for my dependent variable, independent variable, and control variables. The table depicts the number of observations, mean, standard deviation, minimum, and maximum values for the following variables: the defendant having at least one conviction, the proportion of the jury whose members are less than 50%	 racially similar to the defendant, at least one jury member thinking the victim was very believable, at least one jury member having sympathy for the defendant, if the case had a victim that was not White, and if the crime was a misdemeanor.

__Hypothesis and Empirical Tests__

Like I previously mentioned, my hypothesis is that “juries in which at least 50% of the jurors are the same race as the defendant are more likely to side in favor of the defendant.” I plan on testing this hypothesis through a quantitative analysis by running a regression between whether or not the defendant had at least one conviction and the proportion of the jury whose members are less than 50% racially similar to the defendant. By doing this, I will be able to see how much more likely juries with a greater proportion of members who are the same race as the defendant are to rule in favor of the defendant than juries with a smaller proportion. 

In this case, my null hypothesis is that juries in which at least 50% of the jurors are the same race as the defendant would make the same decision on the outcome of a case as juries that were not mostly the same race as the defendant. In order to reject my null hypothesis, I would need to see the coefficient for the proportion of the jury whose members are less than 50% racially similar to the defendant be zero after running the regression, meaning that there was no difference in the likelihood of having at least one conviction between juries that were more or less racially similar to the defendant. I would also need to see the p-value for the proportion of the jury whose members are less than 50% racially similar to the defendant be 0.05 or less, meaning that there was such a small chance of committing a type I error, or rejecting the null hypothesis that juries in which at least 50% of the jurors are the same race as the defendant would make the same decision on the outcome of a case as juries that were not mostly the same race as the defendant, when it is true. 

__Results__
```{r, echo=FALSE}
#plotting Average Proportion of time that someone is convicted when they are not white / white

#percentage of the time that someone is convicted when they are not white 
mean1 <- mean(law$yes.conv[law$prop.race.big50 ==1 & law$def.notwhite ==1], na.rm = T) # 0.5211268
mean2 <- mean(law$yes.conv[law$prop.race.less50 ==1 & law$def.notwhite ==1], na.rm = T) # 0.65625

#percentage of the time that someone is convicted when they are white 
mean3 <- mean(law$yes.conv[law$prop.race.big50 ==1 & law$def.notwhite ==0], na.rm = T)  # 0.6086957
mean4 <- mean(law$yes.conv[law$prop.race.less50 ==1 & law$def.notwhite ==0], na.rm = T) # 0.6923077

conv <- c("Not White", "Not White", "White", "White")

law.graph <- data.frame(avg.prop=c(0.52, 0.66, 0.61, 0.69),
                 Legend=c("Jury's at least 50% same race as defendant", "Jury's less than 50% same race as defendant", "Jury's at least 50% same race as defendant", "Jury's less than 50% same race as defendant"), conv)

law.bar <- ggplot(law.graph, aes(x = Legend, y = avg.prop, fill = Legend)) + 
  geom_bar(stat="identity", position = "dodge") +
  geom_text(aes(label=avg.prop), vjust=-0.3, size=4) +
  ylab("Average Proportion of Times that Someone is Convicted") +
  scale_fill_manual(values = c("hotpink1", "lightskyblue", "hotpink1", "lightskyblue")) +
  facet_wrap(vars(conv),
             ncol = 2, 
             nrow = 1) +
  xlab("% Jury Same Race as Defendant") +
  ggtitle("Figure 1: Average Proportion of Times that Someone is Convicted with a 
          Jury Similar in Race to the Defendant") +  
  theme(plot.title = element_text(hjust = 0.5)) +
  theme_bw() +
  scale_y_continuous(limits = c(0, 0.70)) + 
  scale_x_discrete(labels=c("At least 50%", "Less than 50%", "At least 50%", "Less than 50%"))
law.bar

ggsave(filename = "law.bar.png", 
       plot = law.bar,
       width = 12, 
       height = 7)
```

Figure 1 displays the average proportion of times that someone is convicted with a jury similar in race to the defendant. The first panel displays the average proportions when the jury members were both at least 50% racially similar to the defendant and less than 50% racially similar to the defendant for when the defendant was convicted on at least one count and was not white. The second panel also displays the average proportions when the jury members were both at least 50% racially similar to the defendant and less than 50% racially similar to the defendant, but now for when the defendant was convicted on at least one count and was white.

Both panels highlight, as I hypothesized, the difference in jury decision making when the jury is made up of a different percent of members that match the race of the defendant. When the jury is made up of at least 50% of members of the same race as the defendant, they are more likely to not convict the defendant than juries made up of members that are less than 50% of the same race. If the defendant was not white and the majority of the jury was not white, the defendant was less likely to be convicted by a larger margin than if the defendant was white and the majority of the jury was also white.

To model this further, I ran two regressions between having at least one conviction and the proportion of the jury whose members were less than 50% racially similar to the defendant, controlling for victim believability, defendant sympathy, if the crime was a misdemeanor, and if the victim was not white in the second regression.

```{r, echo=FALSE, results=FALSE}
#running a baseline regression between whether or not the defendant had a least 1 conviction and the proportion of the jury that had the same race as the defendant

reg.baseline <- lm(yes.conv ~ prop.race.less50, data=law)
summary(reg.baseline)
```

```{r, echo=FALSE, results=FALSE}
#running the same regression but with controls

reg.controls <- lm(yes.conv ~ prop.race.less50 + believe.vict + def.sympt + vict.notwhite + misdemeanor, data=law)
summary(reg.controls)
```

```{r, echo=FALSE}
#creating a table of the regression results

stargazer(reg.baseline, reg.controls, omit.stat = c("f","adj.rsq","ser","ll","aic","bic"), 
          title="Table 2: Proportion of the Jury whose Race Matches the Defendant and Total Convictions",
          model.names = FALSE, 
          column.labels = c("Baseline","Controls"),
          covariate.labels = c("Prop of the jury less than 50% racially similar to defendant", "Victim Believability","Sympathy for the Defendant","Not White Victim", "Misdemeanor", "Constant"), type="text", out="/Users/briannafisher/Dropbox/PSCI338/Midterm/Table2.txt")
```

Table 2 presents both regression analyses, regressed on the dependent variable of having at least one conviction. The average chance of the defendant having at least one conviction in their case when the jury was at least 50% racially similar to the defendant was 54.3 percentage points. When the proportion of the jury whose members were less than 50% racially similar to the defendant, the defendant was more likely to be convicted by 12.4 percentage points. This baseline provides evidence for my hypothesis, as juries with more members who matched the race of the defendant were less likely to convict the defendant. Additionally, the p-value for the average chance of the defendant having at least one conviction in their case when the jury was at least 50% racially similar to the defendant is 2 X 10 ^ -16. Since this is an extremely small value, I can reject the null hypothesis that juries in which at least 50% of the jurors are the same race as the defendant would make the same decision on the outcome of a case as juries that were not mostly the same race as the defendant.

Furthermore, when no jury members thought that the victim was believable or had sympathy for the defendant, the crime was a felony, and the victim was white, the average chance of a defendant having at least one conviction in their case when the jury was at least 50% racially similar to the defendant was 80.1 percentage points. When the proportion of the jury whose members were less than 50% racially similar to the defendant, the defendant was more likely to be convicted by 16.5 percentage points than when the jury was at least 50% racially similar to the defendant, holding fixed victim believability, defendant sympathy, if the crime was a misdemeanor, and if the victim was not white. I expected there to be an increase in the coefficient, as juries without a majority of the same race should be more likely to convict when there is no overarching demographical connection. When at least one jury member thought that the victim was very believable, the defendant was more likely to be convicted than if none of the jury members thought that the victim was very believable by only 0.4 percentage points. I expected there to be an increase in the likelihood of a conviction since I assumed the jury would feel bad for the victim, but the small increase could be accounted for by the fact that maybe only one out of the 12 jurors believed the victim, or they believed the victim but not to a “very believable” extent. When the victim was not white, the defendant was less likely to be convicted than if the victim was white by 36.6 percentage points. This seemed strange at first, as I expected juries to be harsher on defendants when the victim was white. However, the majority of defendants were not white (136 out of 185) and 58% of the time, juries were made up of a majority of people who identified as not white. This indicates that juries had more sympathy towards defendants that were not white, rather than white defendants. This is also proven in Figure 1, as not white defendants with a jury that was mostly not white were less likely to be convicted than white defendants with a jury was mostly white.

Additionally, there were two results from the second regression that surprised me. When at least one jury member had a great deal of sympathy for the defendant, the defendant was more likely to be convicted than if none of the jury had sympathy for the defendant by 19.7 percentage points. I expected this coefficient to be negative, since feeling bad for the defendant would theoretically lead the jury to not convict them. Similarly to the victim believability variable, I was only measuring if a jury member had “a great deal of sympathy” for the defendant, and they could have felt some sympathy but did not reach the “great deal” threshold. Criminal cases also require a unanimous decision by the jury, so it could be possible that at least one juror felt a “great deal of sympathy” but was overpowered by the rest of the jury, leading to a conviction. Likewise, when the crime was a misdemeanor, the defendant was more likely to be convicted than if it was a felony by 14.5 percentage points. I expected this result to be negative as well, since I thought that people charged with felonies would be more likely to be convicted than someone charged with a less serious crime. A juror could possibly have more sympathy for a defendant if the defendant was going to jail versus if they were sentenced to a fine or probation (usually the outcome of misdemeanor cases), and maybe most of the cases in the data did not result in jail or prison sentences, accounting for both of these discrepancies.

__Discussion and Conclusion__

I was able to find evidence that juries in which at least 50% of the jurors are the same race as the defendant are more likely to side in favor of the defendant. For both regressions, the defendant was more likely to be convicted when the jury was less than 50% racially similar to the defendant than when the jury was at least 50% racially similar to the defendant, including when I held fixed victim believability, defendant sympathy, if the crime was a misdemeanor, and if the victim was not white. I also found that when at least one jury member thought that the victim was very believable, the defendant was more likely to be convicted than if none of the jury members thought that the victim was very believable and when the victim was not white, the defendant was less likely to be convicted than if the victim was white. Surprisingly, I found that when at least one jury member had a great deal of sympathy for the defendant, the defendant was more likely to be convicted than if none of the jury had sympathy for the defendant and when the crime was a misdemeanor, the defendant was more likely to be convicted than if it was a felony. More research needs to be conducted on these two variables (for example, splitting the cases up by type of crime rather than overall category) in order to account for these discrepancies. 

My results are consistent with previous research completed on the topic. Racially similar juries are more likely to side the same way as each other, as well as in favor of the defendant if they matched the race. In a 2003 study completed by law professor Phoebe C. Ellsworth for the University of Michigan Law School Scholarship Repository researching jury decision making in a race salient and non-race salient mock trial, Ellsworth found that “White mock jurors were more likely to vote to convict the Black defendant (90% of jurors voted to convict) than the White defendant (70% conviction rate).” This is consistent with my results, as juries that were mostly White with a non-White defendant and juries that were mostly not-White with a White defendant were more likely to convict than if the races matched. My results also matched the studies discussed in the Literature Review, as the first paper written by Joy (actually analyzing another study completed by Ellsworth) found that that all-White juries were more likely to convict African American defendants than White defendants. The second paper, written by Levinson, Cai, and Young, also found that people are more likely to perceive black people as guilty and therefore convict them. While I did not look at race in depth and rather as White or not-White, my results are consistent with all three studies and the idea that implicit racial bias impacts jury decision making.

Some potential confounds for interpreting my results and stopping me from finding a causal effect between my variables are other demographical information that I did not have available in the data. Controlling for a juror’s religion could have been useful since different religions value different punishments and sentences. For example, Catholics are less likely to support the death penalty than Protestants and would be more lenient towards a defendant in a death penalty case (Miller 2007). Similarly, controlling for whether or not a juror was married or had kids would be helpful to better explain the relationship between my independent and dependent variables. Picking parents and grandparents for a trial of a teenager, for example, would make the jury more sympathetic towards the defendant when the defendant could have been their own kid. Additionally, a potential confound for interpreting my results is whether or not a juror has any experience or strong opinions on the criminal justice system. If a juror was a lawyer or police officer, or had a family member arrested or in jail, they would have a different opinion and perspective on the case than if they had no or very limited knowledge on the topic. Ideally, I would have been able to control for all of these demographical characteristics, as well as harder to measure variables (empathy, feelings on the legal system, feelings the day of the trial), in order to be more confident that the proportion of the jury being a certain race impacts how the jury decides in the case.

Based on my results, it is clear that jury selection needs to be better regulated so that juries do not have preconceived biases before making life changing decisions. A case should not be decided before evidence is even presented, and attorneys should have a responsibly to create a diverse, fair jury rather than one crafted just to win. Further research needs to be completed on other demographical information in order to create a more comprehensive way to reshape the voir dire process and ensure that the legal system works more efficiently. 

__Works Cited__
Hannaford-Agor, Paula L., Hans, Valerie P., Mott, Nicole L., and Munsterman, G. Thomas. 	Evaluation of Hung Juries in Bronx County, New York, Los Angeles County, California, 	Maricopa County, Arizona, and Washington, DC, 2000-2001. [distributor], 2006-03-30. 
Illegal Racial Discrimination in Jury Selection: A Continuing Legacy. (2020, August 21). Retrieved December 17, 2020, from https://eji.org/reports/illegal-racial-discrimination-in-jury-selection/
Joy, P. (109). RACE MATTERS IN JURY SELECTION. Northwestern University Law Review.
Levinson, J., Cai, H., & Young, D. (2010). Guilty By Implicit Racial Bias: The Guilty/Not Guilty Implicit Association Test. OHIO STATE JOURNAL OF CRIMINAL LAW, 8, 187-208.
Miller, M.K., Hayward, R.D. Religious Characteristics and the Death Penalty. Law Hum 	Behav 32, 113–123 (2008). 
Sommers, S., & Ellsworth, P. (2003). How Much Do We Really Know about Race and Juries? A 	Review of Social Science Theory and Research. University of Michigan Law School 	Scholarship Repository, 3, 997-1031.


## Statistics for the Social Sciences

<h2>Statistics for the Social Sciences</h2>

### Assignment 1

__Problem 1__

Install the datasets package on the console below using `install.packages("datasets")`. Now load the library.
```{r}
#Install the dataset package  
#install.packages("datasets")

#load in the library 
library(datasets)
```

Load the USArrests dataset and rename it `dat`. Note that this dataset comes with R, in the package datasets, so there's no need to load data from your computer. Why is it useful to rename the dataset?
```{r}
#Load in the dataset
USArrests

#rename the USArrests dataset
dat <- USArrests
```
__It is useful to rename the dataset because it is easier to work with. If the data set had a longer or more complicated name, it would be difficult and time consuming to type out the dataset name every time when you want to perform a function on the data. It also lets you keep track of your work if you make different versions of it so that it is not contaminated by changes that were meant to be on one version and not the other. This will let you replicate the work if changes were made to different versions.__

__Problem 2__
Use this command to make the state names into a new variable called State. 
```{r, eval=TRUE}
dat$state <- tolower(rownames(USArrests))
```

This dataset has the state names as row names, so we just want to make them into a new variable. We also make them all lower case, because that will help us draw a map later - the map function requires the states to be lower case.

List the variables contained in the dataset `USArrests`.

```{r, eval=TRUE}
#find the variables in the dataset
names(dat)
```
 
__The variables in the USArrests dataset are Murder, Assault, UrbanPop, Rape, and State.__ 
 
__Problem 3__

What type of variable (from the DVB chapter) is `Murder`? 

__Murder is a quantitative variable from the DVB chapter since it is a count of numbers.__

What R Type of variable is it?

__Murder is a numeric variable from the R type since it is also a count of numbers and functions such as mean or median can be applied.__

__Problem 4__

What information is contained in this dataset, in general? What do the numbers mean? 

__The dataset contains arrest numbers for 4 types of crimes within all 50 states. Each state has a corresponding arrest rate for murder, assault, and rape, as well as the percent of urban population within the state. The numbers mean the number of arrests per 100,000 people in that state.__

__Problem 5__

Draw a histogram of `Murder` with proper labels and title.
```{r}
hist(dat$Murder, main = "Histogram of Murder Arrests", xlab = "Number of Murder Arrests", ylab = "Frequency")
```

__Problem 6__

Please summarize `Murder` quantitatively. What are its mean and median? What is the difference between mean and median? What is a quartile, and why do you think R gives you the 1st Qu. and 3rd Qu.?

```{r}
#finding the summary statistics of the murder variable
summary(dat$Murder)
```
__The mean of the murder variable is 7.788 murders, while the median is 7.250 murders. The mean is the sum of all data values divided by the number of values, or the average of the values within the dataset. The median, however, is the middle value after all of the values are put in numerical order. When distributions are skewed or there are outliers in the data, the median is better to use than the mean because the mean changes with skew or outliers and the median is more robust. A quartile is each of three values in which the data can be distributed into even fourths. I think that R gives us the 1st quartile and 3rd quartile because they can be used to calculate the interquartile range, which tells us the interval where half of the values within the data set lie. The median is also the 2nd quartile, so the three groups are given that split the data in even fourths.__
 
__Problem 7__

Repeat the same steps you followed for `Murder`, for the variables `Assault` and `Rape`. Now plot all three histograms together. You can do this by using the command `par(mfrow=c(3,1))` and then plotting each of the three. 

```{r, echo = TRUE, fig.width = 5, fig.height = 8}
#make a histogram of assault
hist(dat$Assault, main = "Histogram of Assault Arrests", xlab = "Number of Assault Arrests", ylab = "Frequency")

#make a histogram of rape
hist(dat$Rape, main = "Histogram of Rape Arrests", xlab = "Number of Rape Arrests", ylab = "Frequency")

#plot all three histograms together
par(mfrow=c(3,1))
hist(dat$Murder, main = "Histogram of Murder Arrests", xlab = "Number of Murder Arrests", ylab = "Frequency")
hist(dat$Assault, main = "Histogram of Assault Arrests", xlab = "Number of Assault Arrests", ylab = "Frequency")
hist(dat$Rape, main = "Histogram of Rape Arrests", xlab = "Number of Rape Arrests", ylab = "Frequency")
```

What does the command par do, in your own words (you can look this up by asking R `?par`)?

__Par can be used to set the parameters on a graph, making it easier to combine multiple graphs into one.__

What can you learn from plotting the histograms together?

__By plotting these histograms together, you can compare the arrest rates for each crime. Murders happen the least frequently and assaults happen the most frequently. You can also see that the histogram for murder is unimodal and skewed, the histogram for assaults is bimodal, and the histogram for rapes is also unimodal and skewed.__ 

__Problem 8__

In the console below (not in text), type `install.packages("maps")` and press Enter, and then type `install.packages("ggplot2")` and press Enter. This will install the packages so you can load the libraries.

```{r, fig.width = 7.5, fig.height = 4}
#install and load in the maps and ggplot2 packages
install.packages('maps')
library('maps') 
library('ggplot2') 
```

Run this code:
```{r, fig.width = 7.5, fig.height = 4}
ggplot(dat, aes(map_id=state, fill=Murder)) + 
  geom_map(map=map_data("state")) + 
  expand_limits(x=map_data("state")$long, y=map_data("state")$lat)
```
What does this code do? Explain what each line is doing.

__The first line above the map code loads the library for both packages. The first line of the map code is creating a plot of murder. The ggplot function is telling R to create a plot, the "dat" is telling R which dataset to use in the plot, and the "aes(map_id=state, fill=Murder))" is telling R to plot each state and fill it with the corresponding murder arrest rate. The geom_map function creates shapes for a reference map, and the map=map_data("state") function is telling R to map the data that corresponds with the state variable that we created earlier. The expand_limits function makes sure that the entire map fits within the plot of the graph and the (x=map_data("state")$long, y=map_data("state")$lat) tells R which data to base the plot limits off of, which in this case is the state data.__

### Assignment 2

__Problem 1__

Load in the data.
```{r}
dat <- read.csv(file = "data/Assignment2datacopy.csv")
```

What are the dimensions of the dataset? 
```{r}
dim(dat)
```
__There are 171 columns and 7 rows (or 171 respondents and 7 questions)__

__Problem 2__

Describe the variables in the dataset.
```{r}
names(dat)
```
__There are 7 variables in the dataset:__
__1. "mjage" (How old were you the first time you used marijuana or hashish?)__
__2. "cigage" (How old were you when you first started smoking cigarettes everyday?)__
__3. "iralcage" (How old were you when you first tried alcohol?)__
__4. "age2" (Recoded final edited age (since respondents had multiple chances to change their age throughout the survey))__
__5. "sexatract" (Sexual attraction)__
__6. "speakengl" (How well do you speak English)__
__7. "irsex" (Imputation revised gender)__

__Mjage, cigage, and iralcage are numeric variables (or quantitative) because the respondent gave an exact number for their answers for each variable and functions like mean can be applied to find the average age the respondents tried marijuana, cigarettes, and alcohol. Age2, sexatract, speakengl, and irsex are categorical variables because the respondents' answers were split into categories when coded. Because respondents had the opportunity to change their age throughout the interview, the age variable was calculated from the raw birth date and the final edited interview date, the age entered in the questionnaire roster (if it exists), and the pre-interview screener age because interviewees had the opportunity to change their age throughout the interview.__

What is this dataset about? Who collected the data, what kind of sample is it, and what was the purpose of generating the data?
__The dataset is a small sample from the National Survey of Drug Use and Health, which was conducted by the Center for Behavioral Health Statistics and Quality (CBHSQ, formerly the Office of Applied Studies) within the Substance Abuse and Mental Health Services Administration (SAMHSA) and is conducted by RTI International, Research Triangle Park, North Carolina. The survey was conducted through a computer assisted administration, and was changed from a strictly national design to a state-based sampling plan in 1999. The primary purpose of generating the data was to measure the prevalence and correlation of substance use and mental health issues in the United States, according to the NSDUH 2019 Codebook.__

__Problem 3: Age and gender__

What is the age distribution of the sample like? Make sure you read the codebook to know what the variable values mean.
```{r}
hist(dat$age2, main = "Histogram of Recoded Final Edited Age Categories", xlab = "Recoded Final Edited Age Categories")
```
__The age variable is skewed to the left, with the majority of the values in the 14-16 bin (which means that the majority of the people in the dataset are 30 to 64 years old, according to the codebook). There are fewer people who were very young when filling out the survey, with only a few in the 4-6 and 6-8 bins (meaning that the respondents in these bins were 15-17 and 18-19, respectively).__

Do you think this age distribution representative of the US population? Why or why  not?
```{r}
min(dat$age2) #the youngest respondent was 15 (category 4)
max(dat$age2) #the oldest respondent was 65 years old or older (category 17)
```
__Yes, I think that this age distribution is representative of the US population. The survey was conducted in order to evaluate drug use, and I would think that people would not try drugs before turning 15 (the youngest respondent) and very few people would continue using drugs when they are 65 years old or older (the oldest respondent). Also, according to the codebook, the participants were randomly selected to complete the survey, which fulfills one requirement of a representative sample. It makes sense that the number of respondents increased when the respondents were 19 to 23 (8 to 12 categories) as those are the ages when most people would be exposed to marijuana, drugs, and alcohol for the first time, and that the number of respondents increased again when the respondents were 24 to 64 (categories 12 to 16), as those are the ages that people would continue to use marijuana, drugs, and alcohol as adults (especially after potentially being exposed in college). I also think that it makes sense that the majority of respondents were 34 to 64 years old, because older generations are more likely to have smoked cigarettes everyday before perception and knowledge changed.__

Is the sample balanced in terms of gender? If not, are there more females or males?
```{r}
table(dat$irsex, dat$age2)
```
__The sample is not balanced in terms of gender. There were 91 males included in the dataset and 80 females included.__

Use this code to draw a stacked bar plot to view the relationship between sex and age. What can you conclude from this plot?
```{r}
tab.agesex <- table(dat$irsex, dat$age2)
barplot(tab.agesex,
        main = "Stacked barchart",
        xlab = "Age category", ylab = "Frequency",
        legend.text = rownames(tab.agesex),
        beside = FALSE) # Stacked bars (default)
```
__From this plot, I can conclude that more males answered the survey than females, as most age categories have a higher frequency of males than females (especially in categories 6 and 7). I can also conclude than more older males answered the survey than older females. As indicated in both the plot and the table of sex and age categories, the highest five categories (13, 14, 15, 16, and 17) had more male responses than females (1 more, 4 more, 4 more, 4 more, and 5 more, respectively).__

__Problem 4: Substance use__

For which of the three substances included in the dataset (marijuana, alcohol, and cigarettes) do individuals tend to use the substance earlier?
```{r}
boxplot(dat$mjage, dat$cigage, dat$iralcage, main = "Substance Usage and Age",
        ylab="Age", xlab="Types of Substances", 
        names=c("Marijuana or Hashish","Cigarettes","Alcohol"))
```
__Based on the boxplot of substance usage and age, it looks like individuals tend to use alcohol earlier than marijuana / hashish or earlier than they started smoking cigarettes every day.__

```{r}
min(dat$mjage) 
min(dat$cigage) 
min(dat$iralcage) 
```
__Looking at the minimum values for each type of substance, the minimum recorded age for when an individual first tried marijuana / hashish was 7, the minimum recorded age for when an individual first started smoking cigarettes everyday was 10, and the minimum recorded age for when an individual first tried alcohol was 5. This also confirms that like individuals tend to use alcohol earlier than marijuana / hashish or earlier than they started smoking cigarettes every day.__

__Problem 5: Sexual attraction__

What does the distribution of sexual attraction look like? Is this what you expected?
```{r}
dat.sexat <- subset(dat$sexatract, subset = dat$sexatract<7)

hist(dat.sexat, main = "Distribution of Sexual Attraction", xlab = "Sexual Attraction")
```
__The distribution of sexual attraction is skewed to the right, with the majority of respondents answering that they are only attracted to the opposite sex (category one). The next greatest frequency of response is that the respondent is mostly attracted to the opposite sex (category 2), and then followed by the respondent is equally attracted to males and females (category 3). This is exactly what I expected because I would think that an overwhelming majority of people would be straight as that is most common in the United States.__

What is the distribution of sexual attraction by gender?
```{r}
table(dat$irsex, dat$sexatract)

library(dplyr) 

dat$sexatract <- dat$sexatract %>% na_if(., "85")
dat$sexatract <- dat$sexatract %>% na_if(., "94")
dat$sexatract <- dat$sexatract %>% na_if(., "97")
dat$sexatract <- dat$sexatract %>% na_if(., "98")
dat$sexatract <- dat$sexatract %>% na_if(., "99")

dat.five <- data.frame(dat$sexatract, dat$irsex)

barplot <- barplot(table(dat.five$dat.irsex, dat.five$dat.sexatract),
        main = "Sexual Attraction and Gender",
        xlab = "Sexaul Attraction Category",
        ylab = "Count",
        border = "black",
        col = c("hotpink1", "blue"),
        ylim = c(0,171), legend.text = c("Males","Females"),
        )
barplot
```
__Looking at the stacked bar plot of sexual attraction and gender, it confirms what was seen in the table that more males than females responded that they are only attracted to the opposite sex (category one). It also confirms that more females than males answered that they are mostly attracted to the opposite sex (category 2) and are equally attracted to males and females (category 3).__

__Problem 6: English speaking__

What does the distribution of English speaking look like in the sample? 
```{r}
hist(dat$speakengl, main = "Histogram of English Speakers", xlab = "How Well You Speak English (1 - lowest, 4 - highest)")
```
__The distribution of English speaking looks extremely skewed to the right, with the majority of respondents answering that they speak English very well (category one).__

```{r}
table(dat$speakengl)
```
__Looking at the table of respondents who answered the “Speak English” question,161 people answered that the speak English very well, eight answered that they speak English well, and only two answered that they speak English not well. This confirms the skew seen in the histogram.__

Is this what you might expect for a random sample of the US population?
__This is what I would expect a random sample of the US population to look like, as the majority of people in the US speak English and speak it very well. Even if there were people included in the random sample from places that do not speak as much English, like Texas or Miami, for example, the large amount of people who do speak English well would account for what is seen in the histogram.__

Are there more English speaker females or males?
```{r}
table(dat$irsex, dat$speakengl)

barplot(table(dat$irsex, dat$speakengl),
        main="English Speaking Level and Gender",
        xlab="English Speaking Level Category",
        ylab="Count",
        col=c("hotpink1", "blue"),
        ylim = c(0,200),  legend.text = c("Males","Females")
)
```
__Looking at the stacked bar plot of English speaking level and gender, it looks like the number of males and females that answered that they spoke English very well was pretty close, will a few more males (exactly 11, according to the table). The plot also confirms that more men responded that they spoke English well than women, and that no men responded that they spoke English not well.__

### Exam 1

Load the data into an R data frame.
```{r}
dat <- read.csv(file = "data/fatal-police-shootings-datacopy.csv")
```

__Problem 1 (10 points)__

a. Describe the dataset. This is the source: https://github.com/washingtonpost/data-police-shootings . Write two sentences (max.) about this.

__The dataset is made up of every fatal police shooting in the US since January 1, 2015, as collected by the Washington Post. The dataset includes 6594 people and 17 variables, which contain important information about each shooting, such as the name of the person shot, their mental health status, and their race.__

b. How many observations are there in the data frame?
```{r}
dim(dat)
```

__There are 6594 observations in the data frame.__

c. Look at the names of the variables in the data frame. Describe what "body_camera", "flee", and "armed" represent, according to the codebook. Again, only write one sentence (max) per variable.
```{r}
names(dat)
```

__The "body_camera" variable indicates whether or not news reports stated that a police officer that was at the scene of the incident was wearing a body camera and may have recorded parts of the incident. The "flee" variable indicates whether or not news reports have started that the victim was moving away from the officer during the incident. The "armed" variable indicates whether or not the victim was armed with any type of weapon that could have been thought to as possible to cause harm by an officer.__

d. What are three weapons that you are surprised to find in the "armed" variable? Make a table of the values in "armed" to see the options.
```{r}
head(table(dat$armed))
```

__Three weapons that I was surprised to find in the dataset were an air conditioner, microphone, and pen.I feel like an air conditioner and microphone are definitely unusual weapons, and the pen does not seem like it would do anything against an officer's gun.__

__Problem 2 (10 points)__

a. Describe the age distribution of the sample. Is this what you would expect to see?
```{r}
hist(dat$age, main = "Age Distribution of the Sample", xlab = "Age", xlim = c(0, 100))
```

__The age distribution of the sample is skewed to the right, with a large number of values between ages 20 and 40. This indicates that most people killed by the police in fatal shootings are young, and that older people between ages 60 and 100 are being killed in fatal police shootings at a much lower rate. This is exactly what I expected to see in the age distribution because younger people, especially in the 20 to 40 year old range, are more likely to have encounters with the police, as well as be healthy and be able to try to talk to or provoke the police and try to run away.__

b. To understand the center of the age distribution, would you use a mean or a median, and why? Find the one you picked.
```{r}
median(dat$age, na.rm = TRUE)
```

__To understand the center of the age distribution, I would use the median because the data is skewed to the right and the median is a more robust measure of skewed data as the mean changes with skew or outliers. The median of the age distribution for this dataset is 35 years old, and I removed the missing values since there are only 308 of them out of 6594 observations and they indicate that the person's age was unknown or missing.__

c. Describe the gender distribution of the sample. Do you find this surprising?
```{r}
table(dat$gender)
counts <- table(dat$gender, useNA = "ifany")
barplot(counts, main = "Gender Distrubution", xlab = "Gender", ylab = "Counts", names=c("None", "Females", "Males"))
```

__The gender distribution is definitely skewed, with 6005 more males being fatally shot by police officers than females. This can also be seen in the barplot, with the majority of respondents being males. There were also 3 unknown values in the data, indicating no gender according to the codebook. I do not find this surprising, however, because the majority of police shootings that we hear about in the news are of males, with the rare occurrence of a female. While females are definitely still being killed by the police, it is happening disproportionately to males which is indicated by both the news and the data.__


__Problem 3 (10 points)__

a. How many police officers had a body camera, according to news reports? What proportion is this of all the incidents in the data? Are you surprised that it is so high or low?

```{r}
table(dat$body_camera)
910/6594
```

__According to the news reports, 910 police officers had a body camera, which is about 13.80% of all incidents in the data. I am surprised that this is so low because I would think that after the 2014 killing of Michael Brown and subsequent police shootings, police offices and the public would call for an increased use of body cameras.__

b. In  how many of the incidents was the victim fleeing? What proportion is this of the total number of incidents in the data? Is this what you would expect?
```{r}
table(dat$flee)
1058+845+248 #fleeing
2151/6594
```

__There are 2151 incidents of the victim fleeing, which is about 32.62% of all incidents in the data. This was calculated by including the 491 unknown observations in the "not fleeing" group, as what this category of observations represents was not included in the codebook and cannot be assumed to be fleeing, especially since there is already an "other" group. This is pretty much what I would expect because I would think that the majority of people when interacting with the police would not flee, since it is known that the consequences would probably be worse because of it.__

__Problem 4 (10 points)__ 

a. Describe the relationship between the variables "body camera" and "flee" using a stacked barplot. What can you conclude from this relationship? 

*Hint 1: The categories along the x-axis are the options for "flee", each bar contains information about whether the police officer had a body camera (vertically), and the height along the y-axis shows the frequency of that category).*

*Hint 2: Also, if you are unsure about the syntax for barplot, run ?barplot in R and see some examples at the bottom of the documentation. This is usually a good way to look up the syntax of R code. You can also Google it.*


```{r}
library(ggplot2) 
ggplot(dat, aes(fill=body_camera, y=frequency(body_camera), x=flee)) + 
  geom_bar(position="stack", stat="identity") +
  ggtitle("Stacked Barplot of Body Camera Usage and Victim Fleeing") +
  labs(y="Frequency of Body Camera Usage", x = "How the Victim Fled") +
  labs(fill = "Body Camera Usage")
```

__From the plot, it can be seen that everybody that fled from the police did so more often when the police were not wearing a body camera. It looks like not fleeing and the police wearing a body camera are related, as when more police wore a body camera less people fled (since the not fleeing bar had the most police wearing a body camera). You can also see that the most people fled by using a car, which during those indicidents police were less likely to wear a body camera than to actually have it on. While it is unknown what the first bar represents as it is left out of the codebook, it follows the same pattern of the other bars that the police did not wear body cameras more often than they did.__

b. Describe the relationship between age and race by using a boxplot. What can you conclude from this relationship? 

*Hint 1: The categories along the x-axis are the race categories and the height along the y-axis is age.* 

*Hint 2: Also, if you are unsure about the syntax for boxplot, run ?boxplot in R and see some examples at the bottom of the documentation. This is usually a good way to look up the syntax of R code. You can also Google it.*


```{r}
boxplot <- ggplot(dat, aes(x=race, y=age)) + 
  geom_boxplot() +
  ggtitle("Boxplot of Race and Age")
boxplot
```

__The relationship between race and age looks pretty even, with the median values of age for each race category between 25 and 37. The range for all ages except White is between 12 and 62, while the White range extends from about 5 to 80. There are a significant number of outliers, however, for the Black, Hispanic, and White categories. The NAs for age were removed, and the unknown race category was plotted first on the graph but cannot be interpreted as it is not in the codebook. From this relationship, I can conclude that on average, all races of a similar age between 25 and 37 are killed at similar rates. While there are some outliers to this, especially for the Black and Hispanic categories, all of the medians of age for each race is almost identical.__

__Extra credit (10 points)__

a. What does this code tell us? 

```{r, eval=FALSE}
mydates <- as.Date(dat$date)
head(mydates)
(mydates[length(mydates)] - mydates[1])
```

__The as.Date function in R converts the string of date values into actual dates that functions can be applied to. The head function makes sure that this conversion was done correctly by showing us the first 6 values of the data. The "(mydates[length(mydates)] - mydates[1])" function tells us the time difference between the last observation (which is the entire length of mydates) and the first obeservation (which is "mydates[1]), which ends up being 2458 days.__

b. On Friday, a new report was published that was described as follows by The Guardian: "More than half of US police killings are mislabelled or not reported, study finds." Without reading this article now (due to limited time), why do you think police killings might be mislabelled or underreported?

__I think that police killings may be mislabeled or underreported because police offices do not want to admit to have killing anyone or engaging in illegal or overly forceful activities. I think that there may be disparities between the police reporting shooting and witnesses observing shootings, as police offices may be less likely to do so. I also think that police offices may mislabel the shooting as something that was not their fault so that they do not get attacked by the public for the incident.__

c. Regarding missing values in problem 4, do you see any? If so, do you think that's all that's missing from the data?

__Yes, I saw missing values in problem 4 in the age category. The race and fleeing variable also had unknown values, as it was not indicated by the codebook. I do not think that this is all that is missing from the data, as other variables, such as gender, also had missing or unknown values. I think that going along with part b, some of the data reported was mislabeled or incorrect, and this may be represented by the missing or unknown values in the data.__

### Assignment 3

Load the data.
```{r}
install.packages("readr")
library(readr)
library(knitr)
dat.crime <- read_delim("/Users/briannafisher/Dropbox/CRIM250/Data/crime_simple.txt", delim = "\t")
```

This is a dataset from a textbook by Brian S. Everitt about crime in the US in 1960. The data originate from the Uniform Crime Report of the FBI and other government sources. The data for 47 states of the USA are given. 

Here is the codebook:

R: Crime rate: # of offenses reported to police per million population

Age: The number of males of age 14-24 per 1000 population

S: Indicator variable for Southern states (0 = No, 1 = Yes)

Ed: Mean of years of schooling x 10 for persons of age 25 or older

Ex0: 1960 per capita expenditure on police by state and local government

Ex1: 1959 per capita expenditure on police by state and local government

LF: Labor force participation rate per 1000 civilian urban males age 14-24

M: The number of males per 1000 females

N: State population size in hundred thousands

NW: The number of non-whites per 1000 population

U1: Unemployment rate of urban males per 1000 of age 14-24

U2: Unemployment rate of urban males per 1000 of age 35-39

W: Median value of transferable goods and assets or family income in tens of $

X: The number of families per 1000 earning below 1/2 the median income


We are interested in checking whether the reported crime rate (# of offenses reported to police per million population) and the average education (mean number of years of schooling for persons of age 25 or older) are related. 


__Problem 1__

How many observations are there in the dataset? To what does each observation correspond?
```{r}
dim(dat.crime)
```

__There are 47 observations in the dataset, with 14 different variables. Each observation corresponds to a particular state.__

__Problem 2__

Draw a scatterplot of the two variables. Calculate the correlation between the two variables. Can you come up with an explanation for this relationship?
```{r, fig.width=6, fig.height=4}
plot(dat.crime$Ed, dat.crime$R, main = "Scatterplot of Average Education and Reported Crime Rate", xlab = "mean number of years of schooling for persons of age 25 or older times 10", ylab = "# of offenses reported to police per million population")
```

```{r}
cor(dat.crime$R, dat.crime$Ed)
```

__The correlation of the reported crime rate (measured in the number of offenses reported to police per million population) and average education (measured in the mean number of years of schooling for persons of age 25 or older times 10) is 0.32, which is pretty weak. The scatterplot of these variables proves this, as it is positive but fairly spread out. One explanation for this relationship may be that states with bigger cities are populated by people with more years of education than states with rural areas, and states with bigger cities have higher reported crime rates. While these two variables specificaly are not highly correlated (since the value was 0.32), high average education and high reported crime rates are both characteristic of states with big cities.__

__Problem 3__

Regress reported crime rate (y) on average education (x) and call this linear model `crime.lm` and write the summary of the regression by using this code, which makes it look a little nicer `{r, eval=FALSE} kable(summary(crime.lm)$coef, digits = 2)`.
```{r} 
crime.lm <- lm(formula = R ~ Ed, data = dat.crime)

summary(crime.lm)
```

__Problem 4__
4. Are the four assumptions of linear regression satisfied? To answer this, draw the relevant plots. (Write a maximum of one sentence per assumption.)

```{r} 
#linearity and independence assumptions - residuals vs. x plot
plot(dat.crime$Ed, crime.lm$residuals, ylim=c(-15,15), main="Residuals vs. Average Education", xlab="mean number of years of schooling for persons of age 25 or older times 10", ylab="Residuals")
abline(h = 0, lty="dashed")
```

```{r} 
#linearity assumption - residuals vs. fitted
plot(crime.lm, which=1)
```

__Both the residuals vs. x plot and residuals vs. fitted plot show no clear linear patterns and the residuals appear evenly spread out above and below both lines, so it satisfies the linearity assumption (because there are also only 47 observations, with the number that are given we can assume this is good enough for linear regression).__

__Looking again at the residuals vs. x plot, we see that there are no patterns in the plot, so the independence assumption is fulfilled.__

```{r} 
#equal variance / homoscedasticity assumption - resuiduals vs. predicted values
plot(crime.lm, which=3)
```

__Looking at the residuals plotted against the predicted values, the red line looks pretty flat and there are no significant trends in the red line, so the equal variance / homoscedasticity assumption looks satisfied, but the scatterplot we made earlier shows no strong linear association.__

```{r} 
#Normal population assumption - residuals vs. leverage plot
plot(crime.lm, which=5)
```

```{r} 
#Normal population assumption - Normal qq plot
plot(crime.lm, which=2)
```

__The residuals vs. leverage plot fulfills the normal population assumption as the values are within Cook's distance, but the normal qq plot looks like there is an issue with some of the values curving, especially since we know these are not outliers.__

__Problem 5__

Is the relationship between reported crime and average education statistically significant? Report the estimated coefficient of the slope, the standard error, and the p-value. What does it mean for the relationship to be statistically significant?

__The relationship between reported crime rates and average education is statistically significant. The coefficient of the slope is 1.1161, which means that on average, for every additional year of average education, the reported crime rate increases by 1.1161 offenses reported to police per million population. The standard error is 0.4878, which means that the number of offenses reported to the police per million population can vary by 0.4878 offenses. The p-value is 0.02688, which means that we can reject the null hypothesis and conclude that there is a relationship between reported crime rates and average education. For the relationship to be statistically significant, it would mean that the p-value is less than 0.05, telling us that it is unlikely that the relationship between reported crime rates and average education is due to chance.__

__Problem 6__

How are reported crime and average education related? In other words, for every unit increase in average education, how does reported crime rate change (per million) per state?

__On average, for every additional year of average education, the reported crime rate increases by 1.1161 offenses reported to police per million population per state. __

__Problem 7__

Can you conclude that if individuals were to receive more education, then crime will be reported more often? Why or why not?

__You cannot conclude that if individuals were to receive more education, then crime will be reported more often. While the p-value indicates that there is some relationship between the two variables, the correlation between them is only 0.32 and the r-squared value is 0.1042. Neither of these values indicate a strong relationship between average education and reported crime rate. This statement also implies causation, that if people received more education then crime will decrease. Causation cannot be assumed, as there may be other causes or hidden variables that influence the decrease in crime rate with increased education. Similarly, this dataset is in relation to states, not individuals, so this statement could not be proven by this linear model.__


### Exam 2

__Instructions__

a. Create a folder in your computer (a good place would be under Crim 250, Exams). 

b. Download the dataset from the Canvas website (sim.data.csv) onto that folder, and save your Exam 2.Rmd file in the same folder.

c. Data description: This dataset provides (simulated) data about 200 police departments in one year. It contains information about the funding received by the department as well as incidents of police brutality. Suppose this dataset (sim.data.csv) was collected by researchers to answer this question: **"Does having more funding in a police department lead to fewer incidents of police brutality?"**
d. Codebook:
- funds: How much funding the police department received in that year in millions of dollars.
- po.brut: How many incidents of police brutality were reported by the department that year.
- po.dept.code: Police department code

__Problem 1: EDA (10 points)__ 

Describe the dataset and variables. Perform exploratory data analysis for the two variables of interest: funds and po.brut.

```{r}
dat <- read.csv(file = '/Users/briannafisher/Dropbox/Github/BriannaFisher/data/sim.data.2.csv')

dim(dat)
names(dat)
```

__The dataset has 200 observations and 3 variables, with each observation corresponding to a particular police department. The variables are "po.dept.code", which is the police department code, "funds", which is the amount of funding the department received that year in millions of dollars, and "po.brut", which is the number of incidents of police brutality reported by the department that year.__

```{r}
plot(dat$funds, dat$po.brut, main = "Scatterplot of Department Funding and Police Brutality", xlab = "Department Funding in Millions of Dollars that Year", ylab = "Number of Incidents of Police Brutality that Year", xlim = c(0,100))
```
```{r}
cor(dat$funds, dat$po.brut)
```

__Looking at the scatterplot of department funding and police brutality, it looks like the two have a strong, negative association. As department funding increases, it looks like reported police brutality incidents decreases. The two variables also have a correlation of -0.985, indicating that the two are strongly, negatively correlated.__

__Problem 2: Linear regression (30 points)__

a. Perform a simple linear regression to answer the question of interest. To do this, name your linear model "reg.output" and write the summary of the regression by using "summary(reg.output)". 

```{r}
reg.output <- lm(formula = po.brut ~ funds, data = dat)
summary(reg.output)
```

b. Report the estimated coefficient, standard error, and p-value of the slope. Is the relationship between funds and incidents statistically significant? Explain.

__The relationship between reported incidents of police brutality and department funding is statistically significant. The estimated coefficient is -0.367, which means that one unit higher of funding is associated with 0.367 less reported incidents of police brutality. The standard error is 0.0045, which means that the number of reported incidents of police brutality can vary by 0.0045 incidents. The p-value is less than 2.2e-16, which means that we can reject the null hypothesis and conclude that there is a relationship between reported incidents of police brutality and department funding. For the relationship to be statistically significant, it would mean that the p-value is less than 0.05 (which 2.2e-16 is), telling us that it is unlikely that the relationship between reported incidents of police brutality and department funding is due to chance.__

c. Draw a scatterplot of po.brut (y-axis) and funds (x-axis). Right below your plot command, use abline to draw the fitted regression line, like this:
```{r, fig.width=6, fig.height=4}
plot(dat$funds, dat$po.brut, main = "Scatterplot of Department Funding and Police Brutality", xlab = "Department Funding in Millions of Dollars that Year", ylab = "Number of Incidents of Police Brutality that Year", xlim = c(0,100))
abline(reg.output, col = "red", lwd=2)
```
Does the line look like a good fit? Why or why not?

__Looking at the scatterplot, the line does not look like a good fit. The points on the scatterplot look curved, with the values on both ends of the line curving away from the line. If the line was a good fit, it would have no pattern and the data would also form a straight line. However, looking at the regression output, the R squared is 0.9712, indicating that the model fits the data incredibly well. Because my eyes can be deceiving and I changed the x-axis of the plot to include 0 squishing the data more towards the end of the plot, I would go with the R squared value and say that the line is a good fit.__

d. Are the four assumptions of linear regression satisfied? To answer this, draw the relevant plots. (Write a maximum of one sentence per assumption.) If not, what might you try to do to improve this (if you had more time)?

Assumption 1
```{r} 
#linearity and independence assumptions - residuals vs. x plot
plot(dat$funds, reg.output$residuals, ylim=c(-15,15), main="Residuals vs. Department Funding", xlab="Department Funding in Millions of Dollars that Year", ylab="Residuals")
abline(h = 0, lty="dashed")
```
```{r} 
#linearity assumption - residuals vs. fitted
plot(reg.output, which=1)
```
__Because both the residuals vs. x plot and residuals vs. fitted plot show clear curved patterns in the plots instead of no pattern at all, I would say that the linearity assumption is not satisfied.__

Assumption 2
__Looking again at the residuals vs. x plot, we see that there is a curved pattern in the plot, so the independence assumption is not satisfied.__

Assumption 3
```{r} 
#equal variance / homoscedasticity assumption - resuiduals vs. predicted values
plot(reg.output, which=3)
```
__Looking at both the scatterplot from question 1 and the scale-location plot, there is a clear pattern in the plot, so the equal variance / homoscedasticity assumption is not satisfied.__

Assumption 4
```{r} 
#Normal population assumption - residuals vs. leverage plot
plot(reg.output, which=5)
```
```{r} 
#Normal population assumption - Normal qq plot
plot(reg.output, which=2)
```
__Looking at the residuals vs. leverage plot (it looks like many values are clustered at the top of the line) and the normal qq plot (the values on the ends of the line are curving away from the line), the normal population assumption is not satisfied.__ 

__Because none of the assumptions are satisfied, if I had more time I would perform some sort of transformation to the data. I would probably start with logging funds, because I know that wages are usually logged when performing linear regression and funds are a pretty similar type of variable.__

e. Answer the question of interest based on your analysis: "Does having more funding in a police department lead to fewer incidents of police brutality?"

__Based on my analysis, it cannot be concluded that having more funding in a police department leads to fewer incidents of police brutality, as this implies causation and there could be hidden variables influencing the relationship. However,it does seem like having more funding in a police department is associated with fewer incidents of police brutality. The scatterplot and correlation show a strong negative relationship between the variables, and the p-value is statistically significant indicating that this relationship is not due to chance. Also, I do not think that the linear model is the best way to represent the data without performing any transformations. All of the assumptions were not satisfied, and even the scatterplot indicates a slight curving pattern. Transforming the data may give more insight into the association between department funding and incidents of police brutality.__

__Problem 3: Data ethics (10 points)__

Describe the dataset. Considering our lecture on data ethics, what concerns do you have about the dataset? Once you perform your analysis to answer the question of interest using this dataset, what concerns might you have about the results?

__Considering our lecture on data ethics, I am concerned that the dataset is biased because the police brutality variable is based off of the reported incidents of police brutality by the departments themselves. There is no way to know if departments are under reporting brutality, so the numbers in the dataset may not be correct or may not actually be reporting the ground truth of police brutality. Once I performed my analysis, I am concerned that the results may interpreted that more funding leads to less brutality (as even stated in the question of interest). This, however, implies causation, and while there is a relationship between the two variables there may be another hidden variable that is truly causing the association. It may be that having more funding leads to better service programs being provided by the police which leads to decreased police brutality, but that is something that cannot be proven with this dataset and analysis. In terms of implications, a policy maker may look at this analysis and think that increasing funding is the best solution to decreasing police brutality, which other research has proven that may not be the case. This analysis could, essentially, cause more harm if all police departments had an increase in funding but the funding was misused or put towards other things than decreasing police brutality.__


### Final Project

__Marijuana Possession Charges__
__An exploratory look at the relationship between race and sentencing outcomes__
__By Brianna Fisher, Sophie Faircloth, Anna Sophia Lotman, Hannah Wassermann__

__INTRODUCTION__
Following Nixon’s call for the War on Drugs in June 1971, there was a push for mandatory sentencing in drug-related crimes, effectively expanding the role of the federal government in drug-related arrests and sentencing (Drug Policy Alliance, 2021). Recently, there has been an uptick of discussion in the political world and in pop culture of the United States on the War on Drugs, namely regarding the adjustment of the severity of sentencing and its disproportionate effect on minority communities. These racial disparities are particularly discussed in regards to marijuana-related charges, as Black Americans have been found to be four times more likely to be arrested for marijuana charges than White Americans and six times more likely to be incarcerated for drug-related charges (Rahamatulla, 2017). Many agree that a solution to the disproportionate effects of drug-related charges needs to be created, and through the work discussed in this paper, we hope to focus our attention on sentencing outcomes and race for marijuana charges to further understand where disparities lie. Due to the increasing prevalence and history of drug-related sentencing, we wanted to examine the relationships in drug-related sentencing between race and sentencing likelihood, especially focusing on marijuana. We expect, from past studies examined in and outside of this course, that the rate of prison sentencing for Black people would be higher than the rate of prison sentencing of white people. These motivations lead to the research question: Are Black people sentenced federally to prison for marijuana at a higher rate than white people?

__DESCRIPTION OF THE DATA USED__
The data set we utilized for this review is a record of federal criminal sentences as provided by the US Sentencing Committee (United States Sentencing Commission, 2007). This data set includes information on federal cases sentenced under the guidelines of the Sentencing Reform Act of 1984. Because of the research question prompting this paper, we chose to look at only cases where the defendant was charged with possession of marijuana. We used the “Drug Type 1” variable in the dataset to create a subset with these cases, as this variable indicated that marijuana was the highest penalty incurring drug the defendant was found with. Because we wanted to look at the relationship between race and being sentenced to prison, our independent variable was the defendant’s race (either Black or white cases) and our dependent variable was the type of sentence (either prison or no prison). We extrapolated specifically Black and white instantiations in the race variable so as to control for the number of independent variables being observed. We also decided to control for the defendant’s age, the defendant’s gender, and whether or not the defendant has a criminal record. We thought that these three variables would be the most influential in determining sentence type, both as legal (criminal record) and extralegal (age and gender) variables.

```{r, echo=FALSE}
#Reading in our dataset from the federal sentencing 
library(readr)
library(knitr)
originaldata <- read.table("/Users/briannafisher/Dropbox/Github/BriannaFisher/data/sentencing.tsv", sep = '\t', header = TRUE)
```

```{r, echo=FALSE}
#Creating a subset of the dataset so that it is easier to work with

dat <- subset(originaldata, select = c(USSCIDN, AGE, MONRACE, MONSEX, CRIMHIST, DRUGTYP1, SENTIMP))

dat1 <-  dat[ which(dat$DRUGTYP1==4) , ]

#The variables we are working with are
#1. USSCIDN = Unique Case ID Number
#2. AGE = Defendant Age
#3. MONRACE = Defendant Race
#4. MONSEX = Defendant Gender
#5. CRIMHIST = If the Defendant has a Criminal History
#6. DRUGTYP1 = Drug Type (Looking specifically at marijuana)
#7. SENTIMP = Type of Sentence 
```

```{r, echo=FALSE}
#We created white, black, prison, and non prison variables to complete the analyses. 

dat2 <-  dat1[ which( dat1$MONRACE==1 | dat1$MONRACE==2 ) , ] # only keep white and black cases
dat2$race <- dat2$MONRACE

dat2$white <- NA
dat2$white[dat2$race == "1"] <- 1
dat2$white[dat2$race == "2"] <- 0

dat2$black <- NA
dat2$black[dat2$race == "1"] <- 0
dat2$black[dat2$race == "2"] <- 1

dat2$prison <- ifelse(dat2$SENTIMP==1 | dat2$SENTIMP==2, 1, 0) # 0: not prison, 1: prison
```

__EXPLORATORY DATA ANALYSIS__
```{r, echo=FALSE, results=FALSE}
#We made a bar plot of being sentenced and race

library(ggplot2)

sum(dat2$black) #763
sum(dat2$white) #5365

table(dat2$black,dat2$prison)

#white and no prison: 299
#white and prison : 5061
#black and no prison: 80
#black and prison: 683

#percentage of the time that someone is sentenced to prison when they are black
683/763 # 0.89515

#percentage of the time that someone is not sentenced to prison when they are black
80/763 # 0.10485

#percentage of the time that someone is sentenced to prison when they are white
5061/5365 # 0.94334

#percentage of the time that someone is not sentenced to prison when they are black
299/5365 #0.05573

labs <- c("Black", "Black", "White", "White")

prison.graph <- data.frame(avg.prop=c(0.90, 0.10, 0.94, 0.06),
                 Legend=c("Prison", "No Prison"), labs)

prison.bar <- ggplot(prison.graph, aes(x = Legend, y = avg.prop, fill = Legend)) + 
  geom_bar(stat="identity", position = "dodge") +
  geom_text(aes(label=avg.prop), vjust=-0.3, size=4) +
  ylab("Average Proportion of Being Sentenced to Prison") +
  scale_fill_manual(values = c("indianred1", "darkturquoise")) +
  facet_wrap(vars(labs),
             ncol = 2, 
             nrow = 1) +
  xlab("Sentence Outcome") +
  ggtitle("Average Proportion of Being Sentenced to Prison Depending on Race") +  
  theme(plot.title = element_text(hjust = 0.3)) +
  theme_bw() +
  scale_y_continuous(limits = c(0, 1)) + 
  scale_x_discrete(labels=c("No Prison", "Prison", "No Prison", "Prison"))
prison.bar

ggsave(filename = "prison.bar.png", 
       plot = prison.bar,
       width = 12, 
       height = 7)
```
To most successfully represent the variables being examined in this paper, we chose to create a bar plot representing the proportion of people sentenced and not sentenced to prison for both races included in the dataset. 

__REPRESENTATIVE MODEL AND DIAGNOSTIC INFORMATION__
For the sake of our data set, we used a logistic regression. A logistic regression model is very similar to a linear regression; however, it is used to evaluate relationships between binary variables. Because our variables - race and sentencing outcome - both have only two options for the purpose of our study, we can examine this relationship between the binaries. Rather than a standard line, the graph of fit is a logit. The application of this model is to categorical variables, and the dependent variable matches the variable type of the independent.


```{r, echo=FALSE, results=FALSE}
#We first ran a baseline logistic regression to look at the relationship between race and type of sentence 

reg.baseline <- glm(prison ~ black, family=binomial(link='logit'), data=dat2)
summary(reg.baseline)
```

__LOGISTIC REGRESSION ASSUMPTIONS__
```{r, echo=FALSE}
#We next checked the assumptions of logist regression:

diag.fun.glm = function(glm.out){
  n <- dim(glm.out$model)[1]
  par(mfrow=c(2,3))
  
  # qq plot
  #plot(glm.out, 2)
  qqnorm(rstandard(glm.out, type="deviance"), main="QQ plot of stand. dev. residuals")
  qqline(rstandard(glm.out, type="deviance"))
  
  # std. deviance vs. fitted values with horizontal lines at -2, 2
  plot(predict.glm(glm.out, type="response"), rstandard(glm.out, type="deviance"), ylab="Stand. deviance resid.", xlab="Fitted values", main="Stand. dev. resid. vs. fitted values"); abline(h=c(0,-2,2), lty=c(1,2,2))
  
  # studentized residuals
  alpha <- 0.05
  hi <- -qnorm(alpha/(2*n),0,1)
  lo <- qnorm(alpha/(2*n),0,1)
  plot(predict.glm(glm.out), rstudent(glm.out, type="deviance"), ylab="Stud. deviance resid.", xlab="Fitted values", main="Stud. dev. resid. vs. fitted values", ylim=c(lo-2,hi+2)); abline(h=c(0, hi, lo), lty=c(1,2,2))  
  
  # cook's distance plot
  cooks <- cooks.distance(glm.out)
  plot(cooks, type="h", main="Cook's distance", ylab="Cook's distance", xlab="Index")
  
  # leverage plot
  leverage <- hatvalues(glm.out) 
  plot(leverage, type="h", main="Leverage", ylab="Leverage", xlab="Index")
  
  # cook's distance vs. leverage plot
  plot(glm.out, 5)
}

#calling all of the plots
diag.fun.glm(reg.baseline)
```

For the sake of our data set, we used a logistic regression. A logistic regression model is very similar to a linear regression; however, it is used to evaluate relationships between binary variables. Because our variables - race and sentencing outcome - both have only two options for the purpose of our study, we can examine this relationship between the binaries. Rather than a standard line, the graph of fit is a logit. The application of this model is to categorical variables, and the dependent variable matches the variable type of the independent.

The Residual vs. Fitted Plots in this figure look to see if there are any curvilinear trends in the plots that were originally missed. Because logistic regression is already curvilinear - as demonstrated by the logit that was previously displayed - these plots do not tell us any definitive information on the validity of this regression. 

The QQ plot in the figure determines if the residuals are normally distributed. This plot is not indicative of anything definitive either because residuals do not have to be normally distributed in a logistic regression. 

The Residuals vs. Leverage plots help identify outliers, but this plot too is not particularly useful because the results are not definitive either. 
From the models demonstrated in the assumptions, we do not gain information that definitively determines the strength of the logistic regression model for our data set, but the assumption display is crucial to data analysis so as to examine any particularly significant data that strays from the norm. 

__Regression Model__
```{r, echo=FALSE}
#We created binary control variables

#creating age group variables
dat2$age1629 <- 0
dat2$age1629[dat2$AGE >= 16 & dat2$AGE <= 29] <- 1

dat2$age3049 <- 0
dat2$age3049[dat2$AGE >= 30 & dat2$AGE <= 49] <- 1

dat2$age5069 <- 0
dat2$age5069[dat2$AGE >= 50 & dat2$AGE <= 69] <- 1

dat2$age7097 <- 0
dat2$age7097[dat2$AGE >= 70 & dat2$AGE <= 97] <- 1

#creating gender variables
dat2$male <- NA
dat2$male[dat2$MONSEX == "0"] <- 1
dat2$male[dat2$MONSEX == "1"] <- 0

dat2$female <- NA
dat2$female[dat2$MONSEX == "0"] <- 0
dat2$female[dat2$MONSEX == "1"] <- 1

#creating criminal history variables
dat2$crimyes <- NA
dat2$crimyes[dat2$CRIMHIST == "0"] <- 0
dat2$crimyes[dat2$CRIMHIST == "1"] <- 1

dat2$crimno <- NA
dat2$crimno[dat2$CRIMHIST == "0"] <- 1
dat2$crimno[dat2$CRIMHIST == "1"] <- 0
```

```{r, echo=FALSE, results=FALSE}
#We then ran the same regression with our control variables

reg.controls <- glm(prison ~ black + age7097 + age5069  + age3049 + female + crimno, family=binomial(link='logit'), data=dat2)
summary(reg.controls)
```

```{r, echo=FALSE}
#Creating a table of the regression results
install.packages("stargazer")
library(stargazer)
stargazer(reg.baseline, reg.controls, omit.stat = c("f","adj.rsq","ser","ll","aic","bic"), 
          title="Logistic Regression Outputs", 
          model.names = FALSE, 
          column.labels = c("Baseline","Controls"),
          covariate.labels = c("Black", "Ages 70-97","Ages 50-69","Ages 30-49", "Female", "No Criminal History" , "Constant"), type="text", out="/Users/briannafisher/Dropbox/CRIM250/Final/RegOutputs.txt")
```

Looking at the baseline regression, we can see that Black people in the dataset were less likely to be sentenced to prison at a significant rate. Similarly, looking at the controlled regression, we can see that Black people were more likely to not be sentenced when compared to white people in the dataset. We split the age variable into three groups (of 16-29, 30-49, 50-69, and 70-97), leaving the 16-29 group out of the regression as our control because we thought that this group would be most likely to be in possession of marijuana. To our surprise, all three age groups were more likely to be sentenced to prison for marijuana charges than people that were 16-29. This may be due to the fact that there could have been more people in these other groups, or there could have been a large number of minors in the 16-29 group that were not sentenced to prison. We split the gender variable into male or female, leaving out the male group since we thought that this group would be more likely to be sentenced to prison. Looking at the model, we can see that this is true, and females were significantly less likely to be sentenced to prison than males. Finally, we split the criminal history variable into yes or no groups, leaving out the yes group since we thought that this group would be more likely to be sentenced to prison. To our surprise, having no criminal history made the defendant more likely to be sentenced to prison, but by an insignificant amount.

__CAUSAL ANALYSIS__
Because we used the “Drug Type 1” variable, we assumed that the defendant was either only found with marijuana or the other drug(s) did not incur any penalty. This did not take into account whether or not the defendant was charged with something incurring a felony charge, such as possession of drug paraphernalia or intent to sell. In an ideal world, our data would have been clear about what the defendant was actually charged with on all fronts, rather than just what drugs they were in possession of at the time of their arrest. We also only looked at about 6,000 observations, since we dropped everyone who was not Black or white. However, there were more white people in the dataset and more white people in prison in the dataset, so the groups may not have been proportional. 

__DAG:__
    
    BEING ARRESTED 
    ^           |
    |           v
    RACE -------> BEING SENTENCED TO PRISON

Additionally, the DAG portrays the situation where the defendant’s race determines whether or not they will be arrested, and therefore the arrest determines whether they will be sentenced. Not everyone who is caught with marijuana is arrested, and not everyone who is arrested for marijuana charges is convicted. Similarly, the biases of the police and prosecutors could be at play, influencing both the arrest and sentence outcome. Because of these confounders, we would not be able to conclude that there was a causal analysis.

__LIMITATIONS AND FUTURE DIRECTIONS__

While setting out to examine sentencing outcomes and their relationship to race for marijuana-related charges, we observed a series of confounds: 

1. Sentencing charges are not equated to arrests. It is worth looking in the future into the relationship between arrests and race for marijuana-related charges.
2. Our analysis did not include sentencing duration. Sentencing severity is a large component of the discussion for racial disparities in sentencing, not just the binary of whether someone was sentenced or not.
3. Though we controlled for different factors such as past arrests because they are crucial in determining sentencing outcomes they should be analyzed further in conjunction with the information we observed for future studies. 

This dataset is also a really interesting example of how a failure through data analysis can lead to false projections and misleading statistics. This is also a useful showcase of how easily data can also be manipulated depending on the neglect of specific outliers or parameters for the research.  As previously stated, this data set is very limited. We don’t feel it can answer our research question in an accurate way, but it still provides a good lesson on the sensitivity of datasets with outlying variables and unobserved confounders.  

For future research, it could be extremely valuable to look at the current different sentencing rates across states with different laws regarding the legality and decriminalization of marijuana. All marijuana usage (whether medical or recreational) is a federal crime, so theoretically everyone in the dataset should have been arrested regardless of race. However, this is not the case, and it is important to look at how there are disparities between federal and state sentences. Additionally, state police and prosecutors have much more discretion in deciding who to arrest, and what crimes to charge. We also were only able to look at sentencing as a binary factor without the important information of arrests records in general or whether or not the defendant has been arrested for marijuana in the past. In the future, we want to do a more well-rounded in-depth data analysis including everyone who was arrested (regardless of their conviction status), as well as the state’s current laws regarding marijuana.  

__References__
Commission, U. S. S. (2014, June 25). Monitoring of federal criminal sentences, [united states], 2007.               Monitoring of Federal Criminal Sentences, [United States], 2007. Retrieved December 12, 2021, from https://www.icpsr.umich.edu/web/NACJD/studies/22623. 
Cusick Director, J., Cusick, J., Director, Director, C. M. A., Montecinos, C., Director, A., Director, S. H.  A., Hananel, S., Oduyeru Manager, L., Oduyeru, L., Manager, Gordon	Director, P., Gordon, P., Director, J. P. D., Parshall, J., Director, D., Pearl, B., Perez, M., Chung, E., … Simpson,    E. (2021, October 28). Ending the war on drugs: By the numbers. Center for American Progress. Retrieved December 12, 2021, from https://www.americanprogress.org/article/ending-war-drugs-numbers/. 
Rahamatulla, A. (2017, March 23). The War on Drugs has failed. what's next? Ford Foundation. Retrieved December 12, 2021, from https://www.fordfoundation.org/just-matters/just-matters/posts/the-war-on-drugs-has-failed-what-s-next/. 
We Are The Drug Policy Alliance. (n.d.). A history of the Drug War. Drug Policy Alliance. Retrieved December 12, 2021, from https://drugpolicy.org/issues/brief-history-drug-war. 


## Applied Data Science

<h2>Applied Data Science</h2>

### Problem Set 1

__Question 1a__
```{r}
#read in data
covid <- read.csv(file = "//Users/briannafisher/Dropbox/Github/BriannaFisher/data/covid-20220118.csv")
```

```{r}
#keeping only data from the US
us.covid <- covid[which(covid$Country_Region == "US"),]
```

```{r}
#removing places that are not states
us.covid <- us.covid[which(us.covid$Province_State %in% state.name),]
```

```{r}
#removing any rows where the county is unassigned or out of state
us.covid <- us.covid[which(us.covid$Admin2 != "Unassigned"),]
us.covid <- us.covid[which(us.covid$Admin2 != "Out of AL"),]
us.covid <- us.covid[which(us.covid$Admin2 != "Out of AZ"),]
us.covid <- us.covid[which(us.covid$Admin2 != "Out of CA"),]
us.covid <- us.covid[which(us.covid$Admin2 != "Out of CO"),]
us.covid <- us.covid[which(us.covid$Admin2 != "Out of GA"),]
us.covid <- us.covid[which(us.covid$Admin2 != "Out of HI"),]
us.covid <- us.covid[which(us.covid$Admin2 != "Out of IL"),]
us.covid <- us.covid[which(us.covid$Admin2 != "Out of KS"),]
us.covid <- us.covid[which(us.covid$Admin2 != "Out of LA"),]
us.covid <- us.covid[which(us.covid$Admin2 != "Out of ME"),]
us.covid <- us.covid[which(us.covid$Admin2 != "Out of MI"),]
us.covid <- us.covid[which(us.covid$Admin2 != "Out of NY"),]
us.covid <- us.covid[which(us.covid$Admin2 != "Out of OK"),]
us.covid <- us.covid[which(us.covid$Admin2 != "Out of TN"),]
```

```{r}
#counting the # of rows left 
nrow(us.covid)
```
There are now 3127 rows left in the dataset after I am done with this filtering.

__Question 1b__
```{r}
#subsetting to keep only columns that we are interested in
us.covid <- subset(us.covid, select = c(FIPS, Admin2, Province_State, Confirmed, Deaths))
```

```{r}
#renaming variables
library(dplyr)
us.covid <- rename(us.covid, c("fipscode" = "FIPS", "County" = "Admin2", "State" = "Province_State", "Cases" = "Confirmed"))
```

__Question 1c__
```{r}
#finding how many confirmed cases there have been in Philadelphia County, PA
sum(us.covid$Cases[us.covid$County == "Philadelphia"]) #280648
```
```{r}
#finding how many deaths there have been in Philadelphia County, PA
sum(us.covid$Deaths[us.covid$County == "Philadelphia"]) #4426
```
```{r}
#finding how many counties had at least 280648 cases
us.covid.more <- subset(us.covid, subset = us.covid$Cases >= 280648)

nrow(us.covid.more) #25

#removing philadelphia from the count
25-1 #24
```

```{r}
#finding how many counties had at least 4426 deaths
us.covid.less <- subset(us.covid, subset = us.covid$Deaths >= 4426)

nrow(us.covid.less) #20

#removing philadelphia from the count
20-1 #19
```
There were 280648 confirmed COVID cases and 4426 deaths in Philadelphia County, PA. 24 counties had at least as many cases as Philadelphia, and 19 counties had at least as many deaths as Philadelphia.

__Question 1d__
```{r}
#finding how many counties had at least 10,000 cases
us.covid.10000 <- subset(us.covid, subset = us.covid$Cases >= 10000)

nrow(us.covid.10000) #992
```

```{r}
#finding which county had the highest rate of deaths to confirmed cases
us.covid.10000$death.rate <- us.covid.10000$Deaths / us.covid.10000$Cases

max(us.covid.10000$death.rate) #0.03524969
us.covid.10000[us.covid.10000$death.rate == max(us.covid.10000$death.rate), c("County", "State")] %>% na.omit()
```
992 counties have had at least 10,000 confirmed COVID cases. Among these counties, Citrus, Florida has had the highest rate of deaths to confirmed cases at a rate of 0.03524969 deaths per cases.

__Question 1e__
```{r}
#load in demographic data
dem <- readRDS("acs-2019-demographics.RDS")
```

```{r}
#merge the two datasets by fipscode

merged <- merge(us.covid, 
               dem, 
               by = c("fipscode"),
               all = T)

merged[is.na(merged$fipscode),]
```
Utah seems to have the biggest issue with this merge. Six different counties within Utah have NA values for the fipscode, making it difficult to match the two datasets.

__Question 1f__
```{r}
#creating a variable for confirmed cases rate
merged$case.rate <- merged$Cases / merged$pop
```

```{r}
#creating a variable for death rate
merged$death.rate <- merged$Deaths / merged$pop
```

```{r}
#creating a variable for % of people over 65
merged$prop.over.65 <- merged$over.65 / merged$pop
```

```{r}
#creating a variable for % of people that are white, non hispanic
merged$prop.white.non.hispanic <- merged$white.non.hispanic / merged$pop
```

```{r}
#library(ggplot2)

regression <- lm(formula = death.rate ~ prop.over.65, data = merged)
regression

plot(merged$prop.over.65, merged$death.rate, main = "Elderly Percentage and Death Rate", xlab = "Percent of People over 65 Years Old", ylab = "Death Rate")
abline(regression, col = "blue")
```
```{r}
max(merged$prop.over.65, na.rm = T)
merged[merged$prop.over.65 == max(merged$prop.over.65, na.rm = T), c("County", "State")] %>% na.omit()
```
I wanted to look at the death rates for the percent of people over 65 in the dataset. I decided to plot the two, and plot the corresponding regression line. First, I was shocked to see how low the death rate was. It makes sense when you think about how many people live in the country (and how many people may have covid but not have died), but I was definitely expecting numbers above 0.10. I also saw one county that looked like an outlier in the percentage of people over 65 that live there. This point looked like it was pulling down the regression line. I decided to look into which county has over 50% of their citizens as people that are over 65 years old, and it was Sumter County, Florida. I feel like this also makes sense, as Florida is known to have more elderly people than the rest of the country.


__Question 2a__
```{r}
#read in data
install.packages("rio")
library(rio)
marist <- rio::import("marist-jan21.DTA")
```

```{r}
#calculating the number of rows and columns in the dataset
nrow(marist) #1173
ncol(marist) #179
```
There are 1173 rows and 179 columns in the dataset.

__Question 2b__
```{r}
#finding the proportion of people that were male and female
table(marist$gender)

611+562 #1173

#male
611/1173 #0.5208866

#female
562/1173 #0.4791134
```
52% of people in the survey said that they were male, and 48% of people in the survey said they were female.

__Question 2c__
```{r}
#using attributes to check which #'s to code as missing, I see that it is 8 and 9
attributes(marist$TRUD016)

#coding the unsure / refused answers as missing
marist$TRUD016[marist$TRUD016 == "8"] <- NA
marist$TRUD016[marist$TRUD016 == "9"] <- NA
```

```{r}
#calculating the % of survey respondents who said that Trump would go down as one of the best presidents

#attributes tells me that this answer is coded as 1
attributes(marist$TRUD016)

table(marist$TRUD016) #there are 198 ones
sum(table(marist$TRUD016)) #1147 people

198/1147 #0.1726242

#can also do this with the mean function
mean(marist$TRUD016 == 1, na.rm = T)
```

```{r}
#calculating the % of survey respondents who said that Trump would go down as one of the worst presidents

#attributes tells me that this answer is coded as 5
attributes(marist$TRUD016)

table(marist$TRUD016) #there are 553 fives
sum(table(marist$TRUD016)) #1147 people

553/1147 #0.4821273

#can also do this with the mean function
mean(marist$TRUD016 == 5, na.rm = T)
```
17.26% of survey respondents said that Trump would fo down as one of the best presidents in US history. 48.21% of survey respondents said that he will go down as one of the worst presidents in history.

__Question 2d__
```{r}
#using attributes to check which #'s to code as missing, I see that it is 8 and 9
attributes(marist$PZ20VT)

#coding the unsure / refused answers as missing
marist$PZ20VT[marist$PZ20VT == "8"] <- NA
marist$PZ20VT[marist$PZ20VT == "9"] <- NA
```

```{r}
#creating a table of the two variables 
table(marist$TRUD016, marist$PZ20VT)

#columns: 1 (Biden), 2 (Trump)
#rows: 1 (best), 5 (worst)

#finding the proportion of people who voted for Biden out of the people who said Trump was one of the best
sum(marist$PZ20VT == 1 & marist$TRUD016 == 1, na.rm = T) / sum(marist$TRUD016 == 1, na.rm = T) #0.005050505

#finding the proportion of people who voted for Trump out of the people who said Trump was one of the worst
sum(marist$PZ20VT == 2 & marist$TRUD016 == 5, na.rm = T) / sum(marist$TRUD016 == 5, na.rm = T) #0.06148282
```
One person in the survey said that they thought Trump would be one of the best presidents in US history, but also voted for Biden. Of the people who said Trump was one of the best presidents in US history, the proportion of people who still voted for Biden was 0.005050505. 34 people in the survey said that Trump would go down as one of the worst presidents in US history, but still voted for Trump. Of the people who said Trump was one of the worst presidents in US history, the proportion of people who still voted for Trump was 0.06148282.

__Question 2e__
```{r}
#creating a new dataframe that only includes people who said that they voted for Trump in 2020
trump <- subset(marist, subset = PZ20VT == 2)
```

```{r}
#creating a dummy variable that indicates whether or not they said they thought Trump would go down as one of the worst presidents
trump$yes.worst <- FALSE
trump$yes.worst[trump$TRUD016 == "5"] <- TRUE

#looking at what proportion of Trump voters said they thought he would go down as one of the worst presidents
mean(trump$yes.worst == TRUE)
```
The proportion of Trump voters that said they thought Trump would go down as one of the worst presidents is 0.07834101.

__Question 2f__
```{r}
#looking at who said they were democrats
table(trump$TRUD016, trump$PRTD3)

# 1 (democrats), 3 (independents), 5 (republicans), 97 (other), 99 (refused)

#coding the unsure / refused answers as missing
trump$PRTD3[trump$PRTD3 == "97"] <- NA
trump$PRTD3[trump$PRTD3 == "99"] <- NA

#proportion who were democrats who said he was worst out of Trump voters
sum(trump$PRTD3 == 1 & trump$yes.worst == TRUE, na.rm = T) / sum(trump$yes.worst == TRUE, na.rm = T) #0.1764706

#proportion who were democrats who did not say he was worst out of Trump voters
sum(trump$PRTD3 == 1 & trump$yes.worst == FALSE, na.rm = T) / sum(trump$yes.worst == FALSE, na.rm = T)
```
The proportion of Trump voters who said that Trump was one of the worst presidents and were also Democrats is 0.1764706. The proportion of Trump voters who did not say that Trump was one of the worst presidents and were Democrats is 0.0675. 

```{r}
#looking at who said they were democrats
table(trump$TRUD016, trump$BIDJ020)

# 1 (favorable), 2 (unfavorable), 3 (heard but unsure), 4 (never heard of him), 8 (unsure), 9 (refused)

#coding the unsure / refused answers as missing
trump$BIDJ020[trump$BIDJ020 == "8"] <- NA
trump$BIDJ020[trump$BIDJ020 == "9"] <- NA

#proportion who had a favorable opinion of Biden and also said Trump was the worst out of Trump voters
sum(trump$BIDJ020 == 1 & trump$yes.worst == TRUE, na.rm = T) / sum(trump$yes.worst == TRUE, na.rm = T) #0.2058824

#proportion who had a favorable opinion of Biden and also did not say Trump was worst out of Trump voters
sum(trump$BIDJ020 == 1 & trump$yes.worst == FALSE, na.rm = T) / sum(trump$yes.worst == FALSE, na.rm = T) #0.04
```
The proportion of Trump voters who had a favorable opinion of Biden and also said Trump was the worst President is 0.2058824. The proportion of Trump voters who had a favorable opinion of Biden and also did not say that Trump was one of the worst presidents is 0.04. These numbers might tell us that there is a very small number of Trump voters that did not say he would go down as one of the worst presidents and also were democrats (6.75%) or found Biden favorable (4%). This means that while these responses are unlikely, they are pretty rare. They also tell us that slightly more people who voted for Trump but think that he is the worst president were democrats (17.65%) or found Biden favorable (20.59%). While these are also unusual, it makes sense that people who think that Trump would go down as one of the worst presidents would also be democrats or find Biden favorable.

__Question 2g__
```{r}
#looking at who said they were democrats
table(trump$TRUD016, trump$educrec)

# 1 (less than HS), 2 (high school), 3 (some college), 4 (college), 5 (grad/professional), 9 (refused)

#coding the refused answers as missing
trump$educrec[trump$educrec == "9"] <- NA

#relooking at the table
table(trump$TRUD016, trump$educrec)

#proportion who had a grad/professional degree and also did not say Trump was worst out of Trump voters
sum(trump$educrec == 5 & trump$yes.worst == FALSE, na.rm = T) / sum(trump$yes.worst == FALSE, na.rm = T) #0.145

#proportion who had a grad/professional degree and also said Trump was the worst out of Trump voters
sum(trump$educrec == 5 & trump$yes.worst == TRUE, na.rm = T) / sum(trump$yes.worst == TRUE, na.rm = T) #0.08823529
```
I wanted to look at education levels between the two groups to see if there were any differences. I looked at the proportion of each group who had a graduate/professional degree, and found that 8.82% of Trump voters who said Trump was the worst president had a graduate/professional degree and 14.5% of Trump voters who did not say Trump was one of the worst presidents had a graduate/professional degree. I was surprised by these results, as I assumed that more people who thought Trump was one of the worst presidents would have a graduate/professional degree (since we already saw that these people where more likely to be democrats, and democrats are known to pursue higher education). These findings do make sense, though, when you consider the fact that the group who voted for Trump and did not say Trump was one of the worst presidents was much larger than the other group, so it was more likely for more people to have a graduate/professional degree just because of the disproportionality of the sizes of the groups.

__Question 3a__
```{r}
#read in data
gov <- import("Government Shutdown Poll Dataset.sav")

#looking at the attributes of the q15 
attributes(gov$q15)

#looking at the attributes of the q43
attributes(gov$q43)
```
The main difference between these two questions is that q43 asks about "derogatory" remarks made by Trump, while q15 does not include any loaded language. I would expect this difference to impact the way in which people answer the questions because question q43 implies that Trump's remarks were negative and may influence respondents to answer in the "right" way as according to society. This may not be their true feelings, which would create errors in the data. The respondents may also answer differently to the two questions (especially since the non-loaded question is asked first), causing more errors.

__Question 3b__
```{r}
#calculating the # of people that said yes to q15
mean(gov$q15 == 1, na.rm = T) #0.5163551

#calculating the # of people that said yes to q43
mean(gov$q43 == 1, na.rm = T) #0.523015
```
51.64% of people answered yes to question q15, and 52.30% answered yes to question q43. Based on these results, I would say that more people answered yes (saying that Trump's derogatory remarks have impacted negotiations over a federal government shutdown) to the loaded question than did to the non-loaded question (which did not describe Trump's remarks as derogatory). However, this was only a slight difference, and the wording had very little impact on responses, in actuality.  


__Question 4a__
When first looking at these variables, one of the most interesting questions to me is the relationship between 2020 presidential vote and Biden job approval. I think this is interesting because the 2020 election was different from any election in the past, since many moderates / even Republicans voted for Biden because they did not support Trump (rather than because of their party). I would first transform these variables into dummy variables (Biden/Trump and approve/disapprove) so that I can calculate the correlation between the two. I would then calculate the proportions of Biden voters who approve and then disapprove of Biden and Trump voters who approve and then disapprove of Biden (so 4 in total). Finally, I would create a bar plot of these proportions with one panel having the proportions of Biden voters who approve and then next to it disapprove of Biden, and then the second panel having the proportions of Trump voters who approve and then next to it disapprove of Biden. Another question that I find interesting is the relationship between Biden job approval and age. I think this is interesting because Democrats (who I would assume think Biden is doing a better job than Republicans do) are mostly made up of younger, more diverse, more education, and female voters. However, Baby Boomers and older generations are (as sad as this sounds) dying off, and are leaving behind more open, accepting generations. Because of this, I think it would be interesting to look at age groups and their support for Biden. I would run a linear regression on the two, with Biden job approval as my y variable and age as my x. I would split age into generational groups, leaving out the youngest group (probably 18-29) to compare the others to, since I think this group would support Biden the most. I would then run a second regression for Biden job approval and age, controlling for the factors listed before that characterize democrats (female, diverse, more educated). I think these results may not be exactly what I am expected (high support) because many people felt as though Biden was the last resort during the election but do not necessarily support his policies. I would replicate this process but with 2020 presidential vote and age, and compare it to the regressions for Biden job approval and age to see if my hypothesis of a difference in support is true. 

__Question 4b__

1. What would you describe your ideology as?
a. Left
b. Leaning left
c. Center
d. Leaning right
e. Right

Because of the support from moderates / some Republicans for Biden during the 2020 election, I think it would be interesting to break up ideology even further to see where people lie specifically on the scale and analyze the relationship between ideology and 2020 presidential vote. I would even go further and look at the relationship between ideology and how they approve of Biden, since winning the election is no longer a motivation for support. 


2. How often would you say you watch the evening news (from ABC, CBS, or NBC)?
a. Every night
b. 4-6 nights a week
c. 1-3 nights a week
d. Never

I think it would be interesting to look at the relationship between how often people watch unbiased news and Biden job approval / approval of Biden's handling of the pandemic, since people may answer the approval questions based on one-sided news outlets or party opinions rather than their own opinions of what is happening.


### Problem Set 2

__1. For this question, we will be looking at data about live expectancy and GDP in countries across the world. The data are available in the 'gapminder' package in R.__

__a) To begin, install and load the 'gapminder' package in R. Once you have the package loaded, use the data() function to load the 'gapminder' dataset into your workspace. How many rows and columns does the dataset have? What is the unit of analysis?__
```{r}
# install and load in the gapminder package and other necessary packages
#install.packages("gapminder")
install.packages("gapminder")
library(gapminder)
require(tidyverse)

# use data() to load the dataset
data("gapminder")
```

```{r}
# check the number of rows and columns in the dataset
nrow(gapminder) #1704
ncol(gapminder) #6

# double check this with the dim function
dim(gapminder)

# use the head function to determine a unit of analysis
head(gapminder)
```
The gapminder dataset has 1704 rows and 6 columns. The unit of analysis is a particular country in a particular year (for example, Afghanistan in 1952 is one observation while Afghanistan in 1957 is another).
  
__b) Use bracket notation and conditional logic to determine the population of Norway in 1967.__
```{r}
# using bracketing to indicate that I want only the population when the country is equal to Norway and the year is equal to 1967 

norway <- gapminder[gapminder$country == "Norway" & gapminder$year == "1967", c("pop")]
norway
```
The population of Norway in 1967 was 3786019 people.
	
__c) What is the correlation between life expectancy and GDP per capita. The cor() function should be helpful. Give a basic interpretation of what this tells us.__
```{r}
# using the correlation function 
cor(gapminder$lifeExp, gapminder$gdpPercap)
```
The correlation between life expectancy and GDP per capita is 0.5837062. This is a relatively strong positive correlation, meaning that as life expectancy increases, so does GDP per capita.
	
__d) Which countries, if any, had a life expectancy under 40 at any point after the year 2000?__
```{r}
# create a subset for observations after the year 2000
over.2000 <- subset(gapminder, subset = gapminder$year >= 2000)

# checking if any countries had a life expectancy under 40 after the year 2000
over.2000$country[over.2000$lifeExp < 40]
```
Swaziland, Zambia, and Zimbabwe all had a life expectancy under 40 at any point after the year 2000.

__e) What percentage of countries experienced a decrease in life expectancy between 1977 and 2007? Which countries were these?__
```{r}
# subset the dataset so that it only has the years 1977 and 2007

gapminder.sub <- filter(gapminder, year == 1977 | year == 2007)
gapminder.sub <- subset(gapminder.sub, select=c(country, year, lifeExp))

# use the gather function to split the year column into two separate columns for 1977 and 2007
gapminder.sub <- spread(gapminder.sub, 
                    key = year,
                    value = lifeExp)

# use the rename function to rename the variables
gapminder.sub <- rename(gapminder.sub, c("year.1977" = "1977", "year.2007" = "2007"))

# calculate the percent of countries that experienced a decrease in life expectancy 
change.life <- (gapminder.sub$year.2007)-(gapminder.sub$year.1977)

gapminder.sub <- data.frame(gapminder.sub, change.life)

# using this function to print which numbers are negative (and therefore had a decrease in life expectancy)
Negative_number <- function(i) i[i <0]
Negative_number(change.life) #14 numbers 

# divide 14 by total number of countries
14/142 #0.09859155

# creating a subset to determine the countries with the decrease in life expectancey 
low.life <- subset(gapminder.sub, subset = gapminder.sub$change.life < 0)
print(low.life$country)
```
9.86% of countries experienced a decrease in life expectancy between 1977 and 2007. These countries were Botswana, Central African Republic, Dem. Rep. of Congo, Rep. of Congo, Cote D'Ivoire, Iraq, Kenya, Lesotho, Mozambique, Namibia, South Africa, Lesotho, Zambia, and Zimbabwe.


__2. Use the GenForward survey data (`genforward sept 2017.sav`) to answer the following questions. The data are from a 2017 survey that focused on the political attitudes of Millennials and GenZ'ers. If you need to do any data cleaning before performing these calculations, please include that code in your R script.^[You do not need to consider survey weights for any of the answers in this question. Also, be sure that you are careful about how you handle people who did not answer particular questions.]__

```{r}
# load in the genforward data

setwd("/Users/briannafisher/Dropbox/Github/BriannaFisher/data/")
library(rio)
require(tidyr)
install.packages("lubridate")
require(lubridate)
require(stringr)
require(dplyr)
genfor <- import("genforward sept 2017.sav")
genfor.untouched <- genfor
```

```{r}
# look to see if anything needs to be cleaned 

# I realized that the Q13 question was spread out, so I used the gather function to make it easier to analyze

genfor <- gather(genfor,
                 key = "top.issue",
                 value = "val",
                 starts_with("Q13_"))

# Now lets drop the rows where the value equals 0
genfor <- genfor[genfor$val != 0,]

# Lets check if the gathering and removing values worked in terms of observations
table(genfor$top.issue)

# We don't need the value column anymore so it can be dropped
genfor$val <- NULL
```

```{r}
# Lets rename the values within the top issue column so that they make sense by using a for loop
label <- data.frame(issue.id = str_subset(names(genfor.untouched), "Q13_"),
                           issue.description = NA)

for(ii in 1:nrow(label)){
  
  current.id <- label$issue.id[ii]
  
  label$issue.description[ii] <- attr(genfor.untouched[,current.id], "label")
  
}

# cleaning up the top issue column

label$issue.description <- gsub("\\[", "", label$issue.description)
label$issue.description <- gsub("]", "", label$issue.description)
label$issue.description <- gsub("What", "", label$issue.description)
label$issue.description <- gsub("do you think", "", label$issue.description)
label$issue.description <- gsub("is the most important", "", label$issue.description)
label$issue.description <- gsub("problem facing this country today", "", label$issue.description)
label$issue.description <- gsub("\\?", "", label$issue.description)

# Now lets merge these descriptions back into the dataset

#check class, names, overlap between variables 

# check class of variables
class(genfor$top.issue) #character
class(label$issue.id) #character

unique(genfor$top.issue)
unique(label$issue.id)

genfor2 <- merge(genfor, 
                label,
                by.x = "top.issue",
                by.y = "issue.id",
                all = T)

head(genfor)

## Let's get rid of the old version of top.issue, and rename issue.description

genfor2$top.issue <- NULL
genfor2 <- rename(genfor2, top.issue = issue.description)

```

```{r}
# I now changed all the variable names to lowercase so that they are easier to work with
attr(genfor2, "names") <- tolower(attr(genfor2,"names"))

# I then changed the names of the variables that I will be analyzing (Q1 and PartyID7 since Q13 has already been renamed)

attributes(genfor.untouched$Q1) #Trump approval
attributes(genfor.untouched$PartyID7) #Party ID

# using the rename function to make the labels meaningful
genfor2 <- rename(genfor2, c("trump.approval" = "q1", "party.id" = "partyid7", "vote.2016" = "q0"))
```


__a) What percent of the sample strongly approved or somewhat approved of the way that President Trump was handling his job as president (using question Q1)?__
```{r}
# looking at the attributes for question Q1 
attributes(genfor.untouched$Q1) # 1 = strongly approved, 2 = somewhat approve

#looking at a table to look at the weird values (77, 98, 99)
table(genfor2$trump.approval)

#coding the don't know / skipped on web / refused answers as missing so they don't mess with the values
genfor2$trump.approval[genfor2$trump.approval == "77"] <- NA
genfor2$trump.approval[genfor2$trump.approval == "98"] <- NA
genfor2$trump.approval[genfor2$trump.approval == "99"] <- NA

# using the sum function to find the percent of the sample strongly approved or somewhat approved of the way that President Trump was handling his job as president 
sum(genfor2$trump.approval == 1 | genfor2$trump.approval == 2, na.rm = T) / sum(table(genfor2$trump.approval)) 

# could also do this
mean(genfor2$trump.approval %in% c(1,2))
```
14.72% of the sample strongly approved or somewhat approved of the way that President Trump was handling his job as president.
	
__b) What percentage of Republican men "strongly approve" or "somewhat approve" of the way Trump is handling his job as president? What is this percentage for Republican women? What percentage of Republican men and Republican women (separately) "somewhat disapprove" or "strongly disapprove" of Trump?^[For this question, you should use the `PartyID7` variable and consider anybody who is in the "Lean Republican", "Moderate Republican", or "Strong Republican" categories to be a Republican.]__
```{r}
# looking up the attributes for the party ID variable
attributes(genfor.untouched$PartyID7) # 5 = lean republican, 6 = moderate republican, 7 = strong republican

# looking at a table of these two variables
table(genfor2$trump.approval, genfor2$party.id) # found a weird -1, looking again at attributes and see that -1 means unknown

# recoding the -1s as NAs
genfor2$party.id[genfor2$party.id == "-1"] <- NA
```

```{r}
# first make a subset of  men
attributes(genfor.untouched$gender) # looking at the gender varibale, 1 = male, 2 = female
men <- subset(genfor2, subset = genfor2$gender == 1)

# look at the percentage of republican men who strongly or somewhat approve of how Trump is handling the presidency
sum((men$trump.approval == 1 | men$trump.approval == 2) & (men$party.id == 5 | men$party.id == 6 | men$party.id == 7), na.rm = T) / sum(men$party.id == 5 | men$party.id == 6 | men$party.id == 7, na.rm = T)

# this gets 0.5244444

# now look at the percentage of republican men who strongly or somewhat disapprove of how Trump is handling the presidency
sum((men$trump.approval == 4 | men$trump.approval ==5) & (men$party.id == 5 | men$party.id == 6 | men$party.id == 7), na.rm = T) / sum(men$party.id == 5 | men$party.id == 6 | men$party.id == 7, na.rm = T)

# this gets 0.3111111
```

```{r}
# next make a subset of women
attributes(genfor.untouched$gender) # looking at the gender variable, 1 = male, 2 = female
women <- subset(genfor2, subset = genfor2$gender == 2)

# looking at the percentage of republican men strongly or somewhat approve of how Trump is handling the presidency
sum((women$trump.approval == 1 | women$trump.approval == 2) & (women$party.id == 5 | women$party.id == 6 | women$party.id == 7), na.rm = T) / sum(women$party.id == 5 | women$party.id == 6 | women$party.id == 7, na.rm = T)

# this gets 0.4545455

# now look at the percentage of republican women who strongly or somewhat disapprove of how Trump is handling the presidency
sum((women$trump.approval == 4 | women$trump.approval ==5) & (women$party.id == 5 | women$party.id == 6 | women$party.id == 7), na.rm = T) / sum(women$party.id == 5 | women$party.id == 6 | women$party.id == 7, na.rm = T)

# this gets 0.3801653
```
52.44% of Republican men "strongly approve" or "somewhat approve" of the way Trump is handling his job as president, while 45.45% of Republican women"strongly approve" or "somewhat approve" of the way Trump is handling his job as president. However, 31.11% of Republican men "somewhat disapprove" or "strongly disapprove" of Trump, while 38.02% of Republican women feel the same way.

__c) Which two issues did 2016 Trump voters indicate were the most important problems facing the country? What percentage of Trump voters listed each of these two issues as the top issue?__
```{r}
# first I need to make a subset of Trump voters

# I started by looking at the attributes of the 2016 vote variable
attributes(genfor.untouched$Q0) # 1 = Clinton, 2 = Trump 

# I decided to recode the don't know (77), skipped on web (98), and refused responses (99) so that they did not mess with the percentages (I thought did not vote was important to keep while the others could mess up the responses)
genfor2$vote.2016[genfor2$vote.2016 == "77"] <- NA
genfor2$vote.2016[genfor2$vote.2016 == "98"] <- NA
genfor2$vote.2016[genfor2$vote.2016 == "99"] <- NA

# finally I am ready to subset Trump voters
trump <- subset(genfor2, subset = genfor2$vote.2016 == 2)
```

```{r}
# lets make a table of Trump voters and top issues to answer this question
table(trump$top.issue)

# finding the top two issues
sort(prop.table(table(genfor2$top.issue[genfor2$vote.2016 == 2])), decreasing = T)[1:2]

# adding the percentages together to find the percent of voters who listed these as their top two issues
sum(sort(prop.table(table(genfor2$top.issue[genfor2$vote.2016 == 2])), decreasing = T)[1:2])
```
2016 Trump voters indicated that terrorism / homeland security and health care were the most important problems facing the country. 28.81% of Trump voters listed each of these two issues as the top issue, with 18% listing terrorism / homeland security and 10% listing heath care.
	
__What percentage of 2016 Clinton voters listed these two issues are the most important problem facing the country?__
```{r}
# first I need to make a subset of Clinton voters
clinton <- subset(genfor2, subset = genfor2$vote.2016 == 1)
```

```{r}
# lets make a proportion table of Clinton voters and top issues to answer this question
prop.table(table(clinton$top.issue))

# adding up the terrorism / homeland security and health care issues to get the proportion of Clinton voters who said these were their top two issues
0.044548652+0.135990621 #0.1805393
```
18.05% of Clinton voters listed terrorism / homeland security or health care as the most important problem facing the country, with 4.5% listing terrorism / homeland security and 13.6% listing health care. This makes sense since Trump promoted fears of terrorism and homeland security while campaigning, so Trump supporters would be more likely to have this as one of their most important issues.

__e) What are the top three issues that women over 30 years old care about?  Are these top issues the same for women aged 30 and under?__
```{r}
#  lets look at the top three issues that women over 30 care about
sort(prop.table(table(genfor2$top.issue[genfor2$age > 30])), decreasing = T)

# the top three issues are health care, racism, and the environment / climate change

# now lets look for women aged 30 and under
sort(prop.table(table(genfor2$top.issue[genfor2$age <= 30])), decreasing = T)

# the top three issues are health care, racism, and the environment / climate change
```
The top three issues for both women over 30 years old and women aged 30 and under are racism, health care, and the environment / climate change. Women over 30 were more likely to care about heath care, then racism, then the environment / climate change, while women aged 30 and under were more likely to rank the issues as racism, the environment / climate change, and then health care.


__3. Consider the following survey question:__

__Who is to blame for the dysfunction and gridlock in Washington? (select one)__

__- Joe Biden__
__- Donald Trump__
__- Congress__
__- Nancy Pelosi__
__- Joe Manchin and Kyrsten Sinema__
__- Mitch McConnell__
__- The media__
	

__Discuss the problems with the way this survey question has been written.__
One problem with the way this survey question has been written is that the response choices are just a list of names with no context. People who are uninterested in the survey may just pick the one at the top without reading the rest of them. This would mess with the survey results if the responses do not accurately portray the views of the respondents. Another problem with the way this survey question has been written is that the question is loaded. The use of term "dysfunction" makes it seem incredibly negative, and may prompt someone who is super pro-Trump, for example, to respond with Biden just because he beat Trump and not because they really answered the question. A third problem with the question is that the answer choices do not fall into one category. For example one person might think that the media and Biden were to blame, or that Manchin and not Sinema was to blame and be forced to pick an answer that they do not totally agree with. There needs to be a better unit for the survey responses (like either certain people, or certain branches, or certain policies, or certain news outlets).__

__Rewrite the survey question and response options. Explain how your survey wording addresses the issues you identified.__
How responsible do you think Republicans in Congress are for gridlock in Washington?
a. All of it
b. Most of it
c. Some of it
d. None of it

How responsible do you think Biden and Democrats in Congress are for gridlock in Washington?
a. All of it
b. Most of it
c. Some of it
d. None of it

In order to make this survey question better, I would split it into two questions. While I still think people that are so pro-Trump may say "all of it" to the democrats and "none of it" to republicans (and vice versa), I think that this helps group the responses better (taking care of the categories issue). I also think that providing a range of options will provide a more accurate response since people do not only have a single person to blame, but are instead evaluating two groups. Finally, taking the word dysfunction out of the question and asking about gridlock for both of the republican and democratic groups would neutralize the wording and remove any priming or framing effects associated with the term "gridlock" since both questions would be answered. 


__4. As part of your final project for this course, you will write a report that analyzes survey on political attitudes.  Before you could write this report, however, the survey must first be drafted and fielded. For this question, you will write two survey questions (with question and response options) that could potentially be included in such a survey. One of your questions should be focused on either:__

__a. Election integrity. You could include something about:__
  
__- changes to federal election law by Congress__
__- proposed or adopted legislation at the state level that changes election law__
__- the January 6th insurrection/the Big Lie__
    
__b. The state of the economy or economic development. You could include something about:__
  
__- Biden's Build Back Better plan__
__- inflation__
    
__Your second question can either focus on another issue mentioned above, or on any other topic that is relevant to politics today.__
    
__Along with each question, please provide a brief paragraph that highlights why your proposed survey question would help you to write a thoughtful article about American politics.  In the paragraph, you should also highlight the strengths, or potential weaknesses, of your proposed question wording.__ 

__You may choose a question that has been used in a previous survey. If you do you should write a little bit more about why you think this is a good question. If you do not write your own original question, please provide a citation for where you found the question you’re proposing.__

a. ERIC (Electronic Registration Information Center) is a non-profit organization that improves the accuracy of America’s voter rolls and increase access to voter registration for all eligible citizens. The program cross-references voter registration lists with other government lists (like from the DMV) to determine if people have moved, died, need to be registered, and more. Would you support your state enrolling in ERIC?
    a. Yes
    b. No
    c. Maybe - I need more information

I think this would be a really interesting question to ask because of the misinformation surrounding ERIC and how the program works, especially with Louisiana recently withdrawing from the organization. Along with this question I would ask about where people get most of their news (social media, the nightly news, etc) and see if there is a relationship between getting the majority of their news on social media (where most fake news is posted) and saying no to supporting a state enrolling in ERIC. I think that this would help me write a thoughtful article about American politics because I would be able to gain insight into how people feel about voting policy and particularly measure support before the midterm elections. I would also be able to make really interesting connections between supporting policy and political party, news (and fake news) consumption, and education. I would also probably follow this question up with other questions on particular election policy to see if these follow the same relationship trends. One con of asking this question is that it is really specific and the normal person probably doesn't know what ERIC is. This could be solved by asking something like "Would you support your state enrolling in a program that improves the accuracy of voter rolls?" to achieve the same sort of answer. This would also make the question easier for respondents to understand. Another weakness of asking this question is that respondents may answer yes because it seems desirable to improve the accuracy of voter rolls. However, I think that with all of the election / voter fraud stuff in the news people may have strong opinions against enrolling in this program (probably those that are far-right), and the responses would be accurate in regard to those beliefs.

b. How would you compare the state of the economy to how it was a year ago today?__
  a. Better
  b. About the same
  c. Worse
  
I think that this would help me write a thoughtful article about American politics because it is important to know how people's beliefs have changed over time. With COVID still going on, I think that there is a high chance that people's opinions on the state of the economy have changed which would be interesting to note. I would also want to look at the relationship between this change and people's attitudes on COVID (if they are less worried and are shopping / traveling more it may change their opinion of how the economy is doing), and the relationship between this change and their approval of Biden (since the President is normally evaluated in terms of how the economy is doing). I think that there are plenty of other questions that could be associated with the opinion of the state of the economy a year ago, which would provide a lot of content and opportunity for interesting analysis. One weakness of this question is that some people may not really have the best idea of the economy or not know how the economy as a whole was doing a year ago today, but I think that most people would have a general sense.


### Problem Set 3

__1. The US Census Bureau has released a dataset of demographic information about peoples' last names/surnames. The data contain information about every last name shared by at least 100 people in the 2010 Census.^[Unfortunately, the 2020 data hasn't been released yet.] For each last name, the data reports the total number of people sharing the name, as well as the racial and ethnic distribution of those people. If you're interested, you can read more about the data [here](https://www.census.gov/topics/population/genealogy/data/2010_surnames.html).^[Blank/missing values in the dataset indicate that there were a very small number of people in that cell. Those data were suppressed by the Census Bureau to protect those individuals' privacy.]__

__These data are an _aggregation_ of the 2010 individual-level Census results. When they did this aggregation, which variable was used to group the individual-level responses? What is the unit of analysis of the surname dataset? What does this tell you about the relationship between grouping variables and the unit of analysis after aggregating?__
```{r}
# lets first load in the data and take a look at the unit of analysis and how it is coded
census <- read.csv("Names_2010Census.csv")

# using the head function to look at the first couple of rows of the dataset
head(census)
```
The variable used to group the individual-level responses when the Census Bureau did this aggregation was last name, which is also the unit of analysis of the surname dataset. This tells us that the grouping variable and the unit of analysis after aggregating are the same, and that "last names" is the variable being measured in the dataset.

__Let's begin by writing a function that will help us to explore the data. Write a function that takes a last name, and returns the name, the number of people with that last name (the 'count' variable), and the racial demographics of the last name (the variables beginning with 'pct'). If the name does not appear in the dataset, have the function output a row of data that contains NAs for the count and racial demographics variables.__ 

__Test your function on your own last name. Write a sentence or two about what these results tell you. If your function returns NAs, explain why that is the case.__

__i. Bonus: Allow your function to take, as input, multiple last names and return those variables for each last name. Even better if you're able to do this without using a for-loop.__
```{r}
#I am going to first create a subset for the first name to see if this gives me what I want
smith <- subset(census, name == "SMITH", select = c(name, count, pctwhite, pctblack, pctapi, pctaian, pct2prace, pcthispanic))

#I am now going to try a word that I know is not a name to see what happens
code <- subset(census, name == "code", select = c(name, count, pctwhite, pctblack, pctapi, pctaian, pct2prace, pcthispanic))

#I can put these two subsets into the function using an if else statement
last.name <- function(surname, data){
  if(surname %in% data$name){
    df <- subset(data, name == surname, select = c(name, count, pctwhite, pctblack, pctapi, pctaian, pct2prace, pcthispanic))
  } else{
    df <- data.frame(name = surname, count = NA, pctwhite = NA, pctblack = NA, pctapi = NA, pctaian = NA, pct2prace = NA, pcthispanic = NA)
  } 
   return(df)
}

#I can test my function on my last name to see what I get
last.name("FISHER", census)
```
Using my function on Fisher, I see that 214,703 people in the country have the same last name as me. The majority of people are white (82.58% of people with the last name Fisher are white), and 11.79% are Black. The other racial demographic categories are small, telling me that the majority of people in the country with the name Fisher are either white or Black.

__c. Use the function you write in 1B to create a cleanly-formatted table (i.e. something you might put in a paper or a report) that displays these statistics for your last name, as well as the last names of the 207 teaching staff (Lapinski, Flemke, Sangenito, Pettigrew). Write a couple sentences describing what this table tells you.__
```{r}
install.packages("kableExtra")
library(kableExtra)
library(dplyr)

#using my function on all of the names I want to look at
fisher <- last.name("FISHER", census)
lapinski <- last.name("LAPINSKI", census)
flemke <- last.name("FLEMKE", census)
sangenito <- last.name("SANGENITO", census)
pettigrew <- last.name("PETTIGREW", census)

#creating a data frame with all of the information I want
teach <- bind_rows(fisher, lapinski, flemke, sangenito, pettigrew)

#creating a nice looking table for these statistics
kbl(teach, caption = "Statistics on my last name and the teaching staff's last names",col.names = c("Last Name", "Count", "% White", "% Black", "% Asian / Pacific Islander", "% American Indian / Alaska Native", "% Two or more Races", "% Hispanic")) %>%
kable_classic_2()
```
This table tells us that Fisher is the most common last name out of this grouping, with Pettigrew being the second most common and Lapinski being the third. The table also returns "NA" values for Flemke and Sangenito, meaning that less than 100 people in the country share those last names. The majority of people with the last names Fisher, Pettigrew, and Lapinski are white, with Pettigrew being the most diverse of the three.
    
__d. Which last name is the most common among white Americans? Black Americans? Create a table that reports (for each of the 6 race/ethnicity categories) the most popular last name and total number of people in that racial category with that name. Create a similar table that shows the 5th most common name for each category. For this question, you should omit the "ALL OTHER NAMES" row in the data.__
```{r}
#omitting the all other names row by using tail to check which row number it is
tail(census)
census <- census[-c(162254),]

#lets check if that worked
tail(census)

#creating variables for the number of Americans with each surname for each race variable
census$white.count <- census$count*census$pctwhite/100
census$black.count <- census$count*census$pctblack/100
census$api.count <- census$count*census$pctapi/100
census$aian.count <- census$count*census$pctaian/100
census$tworace.count <- census$count*census$pct2prace/100
census$hispanic.count <- census$count*census$pcthispanic/100

#finding the most common surname among white Americans
census[census$white.count == max(census$white.count, na.rm = T), c("name")] %>% na.omit() #Smith

#finding the most common surname among Black Americans
census[census$black.count == max(census$black.count, na.rm = T), c("name")] %>% na.omit() #Williams

#finding the most common surname among Asian / Pacific Islander Americans
census[census$api.count == max(census$api.count, na.rm = T), c("name")] %>% na.omit() #Nguyen

#finding the most common surname among American Indian / Alaska Native Americans
census[census$aian.count == max(census$aian.count, na.rm = T), c("name")] %>% na.omit() #Smith

#finding the most common surname among Americans with two or more races
census[census$tworace.count == max(census$tworace.count, na.rm = T), c("name")] %>% na.omit() #Smith

#finding the most common surname among Hispanic Americans
census[census$hispanic.count == max(census$hispanic.count, na.rm = T), c("name")] %>% na.omit() #Garcia

#creating a dataframe of the results
pop.race <- c("White", "Black", "Asian / Pacific Islander", "American Indian / Alaska Native", "Two or more Races", "Hispanic")
pop.names <- c("Smith", "Williams", "Nguyen", "Smith", "Smith", "Garcia")
pop.count <- c("1732071", "774920", "422109", "21742", "53501", "1073180")
pop <- cbind(pop.race, pop.names, pop.count)

#creating a nice looking table for these statistics
kbl(pop, caption = "Most popular last name and total number of people with that name per race group", col.names = c("Race", "Last Name", "Count")) %>%
kable_classic_2()
```
The last name Smith is the most common among white Americans. The last name Williams is the most common among Black Americans. The last name Nguyen is the most common among Asian / Pacific Islander Americans. The last name Smith is the most common among American Indian / Alaska Native Americans. The last name Smith is the most common among Americans with two or more races. The last name Garcia is the most common among Hispanic Americans.

```{r}
#finding the fifth most common surname among white Americans
census[census$white.count == sort(census$white.count, decreasing=T)[5], c("name")] %>% na.omit() #Jones

#finding the fifth most common surname among Black Americans
census[census$black.count == sort(census$black.count, decreasing=T)[5], c("name")] %>% na.omit() #Brown

#finding the fifth most common surname among Asian / Pacific Islander Americans
census[census$api.count == sort(census$api.count, decreasing=T)[5], c("name")] %>% na.omit() #Tran

#finding the fifth most common surname among American Indian / Alaska Native Americans
census[census$aian.count == sort(census$aian.count, decreasing=T)[5], c("name")] %>% na.omit() #Jones

#finding the fifth most common surname among Americans with two or more races
census[census$tworace.count == sort(census$tworace.count, decreasing=T)[5], c("name")] %>% na.omit() #Brown

#finding the fifth most common surname among Hispanic Americans
census[census$hispanic.count == sort(census$hispanic.count, decreasing=T)[5], c("name")] %>% na.omit() #Lopez

#creating a dataframe of the results
fifth.race <- c("White", "Black", "Asian / Pacific Islander", "American Indian / Alaska Native", "Two or more Races", "Hispanic")
fifth.names <- c("Jones", "Brown", "Tran", "Jones", "Brown", "Lopez")
fifth.count <- c("786717", "511581", "180958", "14255", "36644", "812607")
fifth <- cbind(fifth.race, fifth.names, fifth.count)

#creating a nice looking table for these statistics
kbl(fifth, caption = "Fifth most popular last name and total number of people with that name per race group", col.names = c("Race", "Last Name", "Count")) %>%
kable_classic_2()
```
The fifth most common last name for White Americans is Jones. The fifth most common last name for Black Americans is Brown. The fifth most common last name for Asian / Pacific Islander Americans is Tran. The fifth most common last name for American Indian / Alaska Native Americans is Jones. The fifth most common last name for Americans with two or more races is Brown. The fifth most common last name for Hispanic Americans is Lopez.
    
__e. A [Herfindahl Index](https://en.wikipedia.org/wiki/Herfindahl%E2%80%93Hirschman_Index) is a metric used in the business/economics to measure how competitive/monopolistic a market is. An industry/market that is a complete monopoly (i.e. 100% of the market is controlled by one company/firm) would have a Herfindahl Index of 1. A industry/market that is made up of a huge number of small firms would have a Herfindahl Index near 0. Herfindahl Indexes can be used in non-business contexts to measure diversity or competition.__ 
    __For this question, calculate the Herfindahl Index value that measures the racial diversity of each surname in the dataset. Then produce a table that shows the five most diverse last names (i.e. least monopolized by a single racial/ethnic group). Limit this analysis to only last names shared by at least 1,000 people.__  
    __To calculate a Herfindahl Index value for the racial/ethnic diversity of specific last name, first set any blank or missing values in the data to be zero. Then, convert the race variables to range from 0 to 1. Then square each variable. Finally take the sum of those squared values. This sum is the Herfindahl value for the surname:__ 
    __$$Herf_{surname} = \sum_{races}{pct_{surname, race}^2}$$__
```{r}
#calculating the Herfindahl value for each surname

#load the scales package
library(scales)

census.index <- census %>% filter(count >= 1000) %>%
  mutate(indexwhite = (pctwhite/100)^2,
         indexblack = (pctblack/100)^2,
         indexaian = (pctaian/100)^2,
         indexapi = (pctapi/100)^2,
         index2prace = (pct2prace/100)^2,
         indexhispanic = (pcthispanic/100)^2)

#replacing all NAs with 0s in the dataset
census.index[is.na(census.index)] <- 0

#adding up all races into one variable
census.index$index <- census.index$indexwhite+census.index$indexblack+census.index$indexaian+
  census.index$indexapi+census.index$index2prace+census.index$indexhispanic

#creating a table of these
herf.num <- c("0.2259582", "0.2290171", "0.2382656", "0.2417969", "0.2462893")
herf.name <- c("Ben", "Ismael", "Sam", "Fortes", "Joe")
herf.table <- cbind(herf.name, herf.num)

kbl(herf.table, caption = "Five most diverse last names (shared by at least 1,000 people)", col.names = c("Last Name", "Herfindahl value")) %>%
kable_classic_2()
```
The five most diverse last names are Ben, Ismael, Sam, Fortes, and Joe.

__2. For this question we will use a wealth of data about Olympic athletes between 1896 and 2016.__  

__a. To begin, we'll need to read in all the data. First, unzip the "olympic-athletes.zip" file. You don't need to use R code to do this; you can just do the unzipping in your file browser. Make sure that there are several dozen "athletes-....csv" files are inside your working directory.__
	__You'll see that the data are split across several different CSVs, one for each Summer or Winter Olympic Games. To analyze the data, we'll need to combine everything together into a single dataframe.__ 
	__To do this, we'll need to create a vector of the files that we need to read in using the `dir()` function. If the unzipped CSVs are inside your working directory, then you should be able to create a vector of the filenames using `filenames <- dir(pattern = "athletes-")`.__
	__Now we'll use the `map()` function in the `purrr` package to create a list of dataframes with the data we want to read in. The two arguments you'll need to give `map()` are the vector of filenames, and the name of the function we want to apply to each of those filenames. In this case, we want to read in the filenames, so `read.csv()` is the function we'll want to use: `map(filenames, read.csv)`.__
	__Now use the `bind_rows()` function (in the `dplyr` package) to append the dataframes together into a single dataframe. How many rows and columns does this dataframe have? How many different athletes appear in the data?__
```{r}
#download the purrr package
#install.packages("purrr")
library(purrr)

#I can use dir to create the filenames vector
filenames <- dir(pattern = "athletes-", path = "olympic-athletes", full.names = TRUE)

#I can use map to read in all of the files
olympics <- map(filenames, read.csv)

#I can use bind rows to put in into a dataset
olympics <- bind_rows(olympics)

#Use nrow and ncol to find the number of rows and columns in the dataframe
nrow(olympics)
ncol(olympics)
dim(olympics)
```
The dataframe has 187,303 rows and 12 columns. Because each row is a unique athlete, there are 187,303 athletes in the data.
	
__b. Aggregate the data to figure out how many gold, silver, bronze, and total medals each country has won.^[Note: the medal counts you calculate here won't match up with what you might find online. This is because when you aggregate the data, team events will be counted as many times as there are athletes on the team. In typical Olympic medal counts, this usually only counts as one medal. You can ignore this nuance for these questions.]__
	
__i. Which country has the biggest difference in the number of gold medals they've won, compared to silver ones? What is this difference?__
```{r}
#using aggregate to find out how many gold medals each country has won
gold <- aggregate(gold ~ country,
            olympics,
             sum)

#using aggregate to find out how many silver medals each country has won
silver <- aggregate(silver ~ country,
            olympics,
             sum)

#using aggregate to find out how many silver medals each country has won
bronze <- aggregate(bronze ~ country,
            olympics,
             sum)

#merge the gold and silver numbers together 
medal <- merge(gold, silver, by = c("country"), all = T)

#merge those with the bronze medals
medal <- merge(medal, bronze, by = c("country"), all = T)

#finding the total number of medals won by each country
medal$total <- rowSums(medal[, c(2,3,4)])

#finding the country with the biggest difference in gold medals compared to silver medals
medal$diff <- abs(medal$silver - medal$gold)

max(medal$diff) #997
medal[medal$diff == max(medal$diff, na.rm = T), c("country")] %>% na.omit() #"United States"
```
The country with the biggest difference in the number of gold medals they've won, compared to silver ones, is the United States. The United States has 997 more gold medals than silver medals.

__ii. Among countries with at least 30 total medals, which country had the highest percentage of its medals being gold? What is this percentage?__
```{r}
#subsetting to create a dataframe with only countries with at least 30 total medals
more <- subset(medal, total >= 30)

#finding the percentage for each medal type
more$per.gold <- more$gold / more$total
more$per.silver <- more$silver / more$total
more$per.bronze <- more$bronze / more$total

#finding the country with the highest percentage of its medals being gold
more[more$per.gold == max(more$per.gold, na.rm = T), c("country")] %>% na.omit() #"India"
max(more$per.gold, na.rm = T) #0.7005076
```
Among countries with at least 30 total medals, India had the highest percentage of its medals being gold at 70.05%.
	
__c. Let's use aggregation to learn about which countries participated in which years. We'll count a Winter Games and a Summer Games in the same year as different events.__
	
__i. How many years has the Summer Olympic Games been held? How many years were the Winter Games held? How many total (summer plus winter) Games have been held? You can ignore the Olympics that have happened since 2016 (and thus aren't in the data).__
```{r}
#using a table to see how many years the Summer Olympic Games have been held
aggregate(year ~ season == "summer", olympics, unique) #29

#using a table to see how many years the Winter Olympic Games have been held
aggregate(year ~ season == "winter", olympics, unique)  #22

#calculating the total number of years the games have been held
29+22 #51
```
The Summer Olympic Games have been held for 29 years, while the Winter Olympic Games have been held for 22 years. There have been 51 total games held.

__ii. Which countries participated in every Olympic Games between 1896 and 2016?__
```{r}
#create a variable for every season / year combination
olympics$game.id <- paste(olympics$season, olympics$year,
                          sep = "-")

#use aggregate to find the length of each unique year 
every <- aggregate(game.id ~ country, olympics, function(x)length(unique(x))) 

#use sort to find the names of the countries that participated in every Olympic Games
every[every$game.id == sort(every$game.id[every$game.id == 51], decreasing=F), c("country")] %>% na.omit()
```
France, Great Britain, and Italy have participated in every Olympic Games between 1896 and 2016.
		
__iii. Which Olympic Games did Greece not participate in? The %in% or setdiff() functions might be helpful here.__
```{r}
#creating a vector with all of the unique games
all.games <- unique(olympics$game.id)

#creating a vector with all the games Greece played in
greece.games <- unique(olympics$game.id[olympics$country == "Greece"])

#using set diff to find the games Greece did not play in
setdiff(all.games, greece.games)
```
Greece did not participate in the 1924 winter games, the 1928 winter games, the 1932 winter games, and the 1960 winter games.

__d. Aggregate the data by individual athlete. You should use the "id" variable to do this, since there might be multiple different people who share the same name.__
	
__i. Which athlete has won the most Olympic medals? How many did this person win?__
```{r}
#Aggregating the data by individual athlete
athlete <- aggregate(total ~ id,
                 olympics,
                 sum)

#looking at which athlete won the most medals and by how many
athlete[athlete$total == max(athlete$total, na.rm = T), c("id")] %>% na.omit() # "michael-phelps-1"
max(athlete$total, na.rm = T) #28
```
Michael Phelps has won the most Olympic medals. He won 28 medals.
		
__ii. Which athletes have medaled in the most Olympic Games? How many did they win?__
```{r}
athletes <- olympics %>% group_by(id) %>%
  summarize(medal.count = sum(total),
            number.games.medal = sum(total>0),
            sum.summer = sum(season == "summer"),
            sum.winter = sum(season == "winter"),
            summer.medal = sum(total[season == "summer"]),
            winter.medal = sum(total[season == "winter"]),
            latest.year = max(year))

athletes %>% filter(number.games.medal == max(number.games.medal)) %>% select(id, medal.count, number.games.medal)
```
Aladar Gerevich, Anky Van Grunsven, Armin Zoggeler, Brigit Fischer Schmidt, Elisabeta Oleniuc Lipa, and Kim Rhode all medaled in the most Olympic Games, winning 6 medals.
		
__iii. How many athletes have participated in both a Summer and a Winter Games? (the any() function might be helpful here)__
```{r}
nrow(athletes %>% filter(sum.summer > 0 & sum.winter > 0))
```
164 athletes have participated in both a Summer and a Winter Games.

__iv. How many athletes have received a medal in both a Summer and Winter Games? Who was the most recent person to accomplish this feat?__
```{r}
med.both.seasons <- athletes %>% filter(summer.medal > 0 & winter.medal > 0)
nrow(med.both.seasons)

med.both.seasons$id[which.max(med.both.seasons$latest.year)]
```
10 athletes have recieved a medal in both a Summer and Winter Games. The most recent person to accomplish this feat was Lauryn Williams.
		
__3. In this question, we're going to use data merging to investigate survey data in a new way. The GenForward Survey Project interviews a panel of 1,750 millennials between the ages of 18 and 34 every two months. Because the the same respondents are being interviewed multiple times, we can use the data to understand how their attitudes may change over time. __ 	
	__We have provided two snapshots of the GenForward data. The object called `oct` contains survey responses from October 2017. The object called `dec` contains responses from December of the same year.__

__a. Our first step in doing the data analysis is merging together the datasets. When we merge data, we must first determine whether we want to perform an inner, outer, left, or right merge/join. In this case, what type of merge would give us the most flexibility for analyzing our data? We must also determine how we will pair together data from the same respondent in the two datasets. Which variable in our data could be used to perform this merge?__
```{r}
#lets first load in the two datasets
genfor <- load("gen-forward.RData")

#now lets use the head function to take a look at the datasets
head(oct)
head(dec)
```
Doing an outer merge would give us the most flexibility in analyzing our data because some people may have been interviewed in October and not December, for example, so doing a merge that only keeps the overlapping cases or all of October only or all of December only would get rid of these additional observations. Doing an outer merge would ensure that these cases are in the dataset and can be analyzed, and can later be removed if necessary (but still starting with everything). The variable in our data that could be used to perform this merge is the GenF_ID variable, which is the unique identifier of each person in the data.
		
__b. How many respondents took the survey in both months? How many respondents took the survey in October, but not December? How many took it in December, but not October? Based on these answers, what is your best guess at the number of rows our data would have if we did a outer merge?__		
```{r}
#finding how many respondents took the survey in both months
table(oct$GenF_ID %in% dec$GenF_ID) #1387

#using the set diff function to see how many respondents took the survey in October, but not December
setdiff(oct$GenF_ID, dec$GenF_ID) #489

#using the set diff function to see how many respondents took the survey in December, but not October
setdiff(dec$GenF_ID, oct$GenF_ID) #457

#adding up the rows
1387+489+457
```
1387 respondents took the survey in both months. 489 respondents took the survey in October, but not December. 457 respondents took the survey is December, but not October. Based on these answers and the sums of each result, I would guess that there would be 2333 rows in the data if we did an outer merge.

__c. Use the `merge()` function to merge the two datasets together. Use your answers from question A to properly specify the arguments inside the function. Also, use the 'suffixes' argument to make it easier to distinguish between the columns of data from the October data and those from the unmerged December data. How many rows and columns does the merged dataset have?__
```{r}
#merge the two datasets together
month <- merge(oct, 
                dec,
                by = c("GenF_ID"),
                all = T,
                suffixes  = c(".oct",".dec"))

#finding the number of rows and columns in the merged dataset
nrow(month)
ncol(month)
dim(month)
```
There are 2333 rows and 37 columns in the merged dataset.

__d. A big concern with panel surveys like this one is the level of attrition, i.e. the rate at which people drop out of the study by not taking later versions of the survey. If attrition is random (not correlated with anything), then it's not a big concern. But if a person's likelihood of dropping out of the study can be predicted by measured (like demographics) or unmeasured factors (like their underlying interest in politics), then attrition becomes a problem that has to be dealt with. We'll use our merged data to do a simple exploration of attrition to answer the question of whether gender/sex was predictive of attrition.__
		__First, create a new variable in the merged dataset which tells us whether or not each respondent took the December wave of the survey. Conveniently, there are no NAs in the unmerged December data for variable Q0. Use this fact to create this new variable in the merged data. Then create another variable (using missingness in the October Q0 variable) which tells us whether or not each respondent took the October wave of the survey. Create a third variable (using the first two) to create a variable that tells us whether or not each person took both the October and December wave of the survey.__		
		
__Now use these variables to compare the percent of the respondents who are female between the group of people who took the October and December survey to those who took only the October survey. Is there a difference in the gender composition of the group who dropped out of the study and those who stayed in it?__
```{r}
#creating a new variable that tells us if the respondent took the December survey (1 is yes, 0 is no)
month$yes.dec[month$Q0.dec == "1"] <- 1
month$yes.dec[month$Q0.dec == "2"] <- 1
month$yes.dec[month$Q0.dec == "3"] <- 1
month$yes.dec[month$Q0.dec == "4"] <- 1
month$yes.dec[month$Q0.dec == "77"] <- 0
month$yes.dec[month$Q0.dec == "98"] <- 0
month$yes.dec[month$Q0.dec == "99"] <- 0
month$yes.dec[month$Q0.dec == "NA"] <- 0 

#changing the NAs to zeros
month$yes.dec[is.na(month$yes.dec)] <- 0

#creating a new variable that tells us if the respondent took the October survey (1 is yes, 0 is no)
month$yes.oct[month$Q0.oct == "1"] <- 1
month$yes.oct[month$Q0.oct == "2"] <- 1
month$yes.oct[month$Q0.oct == "3"] <- 1
month$yes.oct[month$Q0.oct == "4"] <- 1
month$yes.oct[month$Q0.oct == "77"] <- 0
month$yes.oct[month$Q0.oct == "98"] <- 0
month$yes.oct[month$Q0.oct == "99"] <- 0
month$yes.oct[month$Q0.oct == "NA"] <- 0 

#changing the NAs to zeros
month$yes.oct[is.na(month$yes.oct)] <- 0

#finally, creating a new variable for all of the people who took both surveys (1 is yes, 0 is no)
month$both <- 0
month$both[month$yes.oct == 1 & month$yes.dec == 1] <- 1
```

```{r}
#comparing the % of respondents who are female in the oct/dec group and only oct group

#for those who took the survey in both october and december
mean(month$gender.dec[month$both == 1] == 2) #0.5039826

mean(month$gender.dec[month$both == 1] == 2)

#for those who just took it in october
mean(month$gender.oct[month$yes.dec == 0 & month$yes.oct == 1] == 2) #0.6057495
```
Yes, there is a difference in the gender composition of the group who dropped out of the study and those who stayed in it. The proportion of the group who stayed in the survey (50%) is about 10 percent lower than the group who took the survey in just October (61%).

__e. Let's look at how people are evaluating the strength of the economy by taking advantage of the panel structure of our data. Question 7 asks how respondents would describe the nation's economy. What percentage of respondents gave the same rating to the economy in both October and December? What percentage of respondents believe the economy was stronger in December than it was in October? What percentage believe the economy was weaker in December than in October? You can treat the responses 'not sure', 'skipped', and 'refused' as missing data.__
```{r}
#setting the responses not sure, skipped, and refused to be missing
month$Q7.oct[month$Q7.oct == "Not sure"] <- NA
month$Q7.oct[month$Q7.oct == "SKIPPED ON WEB"] <- NA
month$Q7.oct[month$Q7.oct == "refused"] <- NA
month$Q7.dec[month$Q7.dec == "Not sure"] <- NA
month$Q7.dec[month$Q7.dec == "SKIPPED ON WEB"] <- NA
month$Q7.dec[month$Q7.dec == "refused"] <- NA

#finding how many people answered the same in october and december to question 7
month[month$Q7.oct == month$Q7.dec, c("GenF_ID")] %>% na.omit() #713

#finding how many people took both surveys
month[month$both == 1, c("GenF_ID")] %>% na.omit() #1387

#calculating the proportion
713/1387 #0.5140591

#finding how many people answered that the economy was stronger in december
month[month$Q7.oct < month$Q7.dec, c("GenF_ID")] %>% na.omit()  #274

#calculating the proportion
274/1387 #0.1975487

#finding how many people answered that the economy was weaker in december
month[month$Q7.oct > month$Q7.dec, c("GenF_ID")] %>% na.omit()  #400

#calculating the proportion
400/1387 #0.2883922

#double checking that the percents add up to 100
0.2883922+0.1975487+0.5140591

#double checking this with the mean function
mean(month$Q7.oct == month$Q7.dec, na.rm = T)
mean(month$Q7.oct < month$Q7.dec, na.rm = T)
mean(month$Q7.oct > month$Q7.dec, na.rm = T)
```
51.4% of respondents gave the same rating to the economy in both October and December. 19.8% of respondents said that the economy was stronger in December than October. 28.8% of respondents said that the economy was weaker in December than October.
	
### Problem Set 4
__1. In this question, we'll look at data about population density and the results from the 2016 presidential election.__

__a. To begin, we'll need to read in all the data. First, unzip the "pop-density.zip" file. You don't need to use R code to do this; you can just do the unzipping in your file browser. Make sure that the 50 "pop-density-[state].csv" files are inside your working directory.__ 
	__You'll see that the population density data are split across 50 different CSVs. The presidential vote results, however, all all contained within one file. To combine everything together, we'll first need to append together all 50 files of population density data.__ 
	__To do this, we'll need to get a list of the files that we need to read in. Use the `dir()` function (and the "pattern" argument) to create a vector of the 50 filenames of population density data.__
	__Now use those filenames in the `map()` function (in the `purrr` package) to create a list of 50 dataframes with the data we want to read.__  
	__Once you have the list of dataframes, use the `bind_rows()` function (in the `dplyr` package) to append them together into a single dataframe. How many rows and columns does this dataframe have?__
```{r}
#load the purrr and dplyr packages
library(purrr)
library(dplyr)

#I can use dir to create the filenames vector
filenames <- dir(pattern = "pop-density-", path = "population-density", full.names = TRUE)

#I can use map to read in all of the files
pop <- map(filenames, read.csv)

#I can use bind rows to put in into a dataset
pop <- bind_rows(pop)

#Use nrow and ncol to find the number of rows and columns in the appended dataframe
nrow(pop)
ncol(pop)
dim(pop)
```
The appended dataframe has 3140 rows and 5 columns.
	
__b. Now read in the presidential vote results. How many rows and columns does this dataframe have? Explore the data a bit. Why does the population density data have a different number of rows than the votes data?__
```{r} 
#reading in the presidential vote results
vote.unchanged <- read.csv("2016-president-results.csv")

#Use nrow and ncol to find the number of rows and columns in this dataframe
nrow(vote.unchanged)
ncol(vote.unchanged)
dim(vote.unchanged)

#exploring the data
table(vote.unchanged$state)
table(pop$State)

#which state is not in the population density data
head(pop$State[!unique(pop$State) %in% pop$Geographic.area])

#this shows many repeated fips codes

#finding those fips codes
ind <- pop$Fipscode %in% unique(vote.unchanged$fipscode[!vote.unchanged$jurisdiction %in% pop$Geographic.area])

#which areas in the pop density data have the same fips codes of the repeated fips in the votes data
pop$Geographic.area[ind]

#find the states where this is this case
unique(pop$State[ind])
```
The presidential vote results dataframe has 4639 rows and 9 columns. The population density data has less rows than the votes data because the counties listed are represented as the individual jurisdictions within the counties rather than as the county as a whole, like they are in the population density data. This occured in Connecticut, Maine, Massachusetts, New Hampshire, Rhode Island, and Vermont. The population density data is also missing the entire state of Alaska.
	
__c. Because of the different numbers of rows, we'll need to aggregate the votes data so that there is only one row per county and all the vote counts are in terms of county totals (not towns/cities). The `summarize()` and `group_by()` functions will be helpful here, as will the "fipscode" variable. How many rows does the aggregated data have?__
```{r}
#aggregating the data
vote <- vote.unchanged %>%
          group_by(fipscode) %>%
          summarize(vote.count = sum(totalvotes), clinton = sum(clinton), trump = sum(trump))

#Use nrow to find the number of rows in this dataframe
nrow(vote)
dim(vote)
```
The aggregated data has 3111 rows.

__d. Let's merge the population density and aggregated vote count data together. What variable should we use to perform the merge? What type of merge should we do if we're interested in comparing population density to Trump's vote share in 2016? How many rows does the final dataset have?__
```{r}
#renaming the fipscode so its lowercase
pop <- rename(pop, "fipscode" = "Fipscode")

#merge the population density and aggregated vote count together
merged <- merge(pop, 
              vote,
              by = c("fipscode"),
              all = T)

#finding the number of rows the final dataset has 
nrow(merged)
```
In order to perform this merge, we should use the fipscode variable. Since we are interested in comparing population density to Trump's vote share in 2016, we should do an outer merge so that all of the counties from both datasets are included. The final dataset had 3140 rows.

__e. We can finally analyze what we've got. Let's create three new variables. The first will be the population density, which we'll calculate by dividing the population by the land area in each county. The second is Trump's overall vote percentage, which we'll get my dividing his vote total by the vote total in the county. The third will be the Republican two-party vote percentage, which we'll calculate in each county by dividing Trump's vote count by the sum of Clinton and Trump's vote counts. What are the mean values of each of these three new variables?__
```{r}
#creating the population density variable
merged$pop.density <- merged$Population / merged$Land.Area.in.square.miles

#finding the mean
mean(merged$pop.density)

#creating the Trump overall vote percentage variable
merged$trump.overall <- merged$trump / merged$vote.count

#finding the mean
mean(merged$trump.overall, na.rm = T)

#creating the Republican two party vote percentage
merged$rep.2 <- merged$trump / (merged$trump + merged$clinton)

#finding the mean
mean(merged$rep.2, na.rm = T)
```
The mean value of the population density variable is 256. The mean value of the Trump overall vote percentage variable is 0.63. The mean value of the Republican two party vote percentage variable is 0.67.
	
__f. Now recalculate the mean of Trump's overall vote percentage, but this time use the total number of votes in each county as a weight. How does this average differ from the average you calculated in part E? Why do you think they are different?__
```{r}
#load in the weights package
install.packages("weights")
library(weights)

#calculating the weighted mean of Trump's overall vote percentage
weighted.mean(merged$trump.overall, w = merged$vote.count, na.rm = T) 
```
The weighted mean of Trump's overall vote percentage is 0.46. This is 0.17 points lower than the unweighted average that I calculated in part E, which was 0.63. One reason I think they are different is that people who voted for Trump are over represented in the unweighted data. When the data is weighted Trump's overall vote percentage dropped, which means that people who voted for Trump had smaller weights than people who were did not vote for him.
	
__g. Using either the `plot()` or `ggplot()` function, make a simple scatterplot of the relationship between the log of the population density (use the `log()` function) in each county (on the x-axis) and Trump's vote percentage (on the y-axis). What does this tell us about the 2016 election?__
```{r}
#make a scatterplot
plot(x = log(merged$pop.density), y = merged$trump.overall, main = "Log of Population Density and Trump's Vote Percentage", xlab = "Log of Population Density", ylab = "Trump's Vote Percentage")
```
This graph tells us that there is a strong negative relationship between the log of population density and Trump's vote percentage in the 2016 election. This means that for jurisdictions with smaller population densities, Trump's vote percentage was higher. For jurisdictions with larger population densities, Trump's vote percentage was smaller This makes sense since people who live in cities with larger population densities were less likely to vote for Trump, while people who live in rural areas with smaller population densities were more likely to vote for Trump.
	
__h. Aggregate the data to the state level, and recalculate the Republican 2-party vote percentage (i.e. Rep / (Rep+Dem)) and population density variables. What is the correlation between the log of each state's population density and the Republican 2-party vote percentage? How does this number compare to the same correlation, calculated at the county level? What might this tell us about the importance of the unit of analysis we choose when we're analyzing data?__

```{r}
#aggregating to the state level
state <- merged %>%
          group_by(State) %>%
          summarise(trump.state = sum(trump), clinton.state = sum(clinton), pop.state = sum(Population), area.state = sum(Land.Area.in.square.miles))

#recalculating the rep 2 party vote percentage variable
state$rep.2.state <- state$trump.state / (state$trump.state + state$clinton.state)

#recalculating the  population density variable
state$pop.density.state <- state$pop.state / state$area.state

#calculating the correlation between the log of each state's population density and the Republican 2 party vote %
cor(log(state$pop.density.state), state$rep.2.state, use = "complete.obs")

#calculating the correlation for the county level
cor(log(merged$pop.density), merged$rep.2, use = "complete.obs")
```
The correlation between the log of each state's population density and the Republican 2 party vote percentage when aggregated by state is -0.61, while it is -0.49 when aggregated by county. This means that when the data is aggregated by state, the relationship is stronger, meaning that when the log of each state's population density increases, the Republican 2 party vote percentage decreases (and vice versa) more than it would at the county level. This tells us that the unit of analysis is incredibly important because we could have different results if we do not pick the most specific unit for what we are studying. If we just looked at states, it could have been too generalized and breaking it up by counties would give more accurate results.
	

__2. If you've ever taken a probability class you may have heard of the 'birthday problem'.^[You can read more about the birthday problem here: [https://en.wikipedia.org/wiki/Birthday_problem](https://en.wikipedia.org/wiki/Birthday_problem). There's also a recent episode of This American Life that discusses what the birthday problem can teach us about voter fraud (in the section called `Fraud Complex'):[https://www.thisamericanlife.org/630/things-i-mean-to-know](https://www.thisamericanlife.org/630/things-i-mean-to-know)] The problem demonstrates (perhaps counter-intuitively) that in a group of only 23 people the probability of at least two people sharing a birthday exceeds 50__

__In this question, we're going to explore a variation of the birthday problem. Ultimately we want you to answer the following question: in a large group of people, what is the probability that you pick a random day of the year and nobody in the group has that birthday? For these questions you can assume that all years have 365 days. Throughout this question, we'll only worry about birth month and day (i.e. you can ignore birth year)__
	
__a)  We'll begin with the basics. Write a line or two of code that randomly draws birthdays for 300 people and checks whether nobody has a birthday on the first day of the year (i.e. January 1). The `sample()` function should be helpful here. Hint: use the numbers 1 through 365 to represent birthdays, and sample from those numbers.__
```{r}
#randomly drawing birthdays for 300 people
!(1 %in% sample(1:365, 300, replace = TRUE))
```
Out of this random sample, somebody has a birthday on the first day of the year.
	
__b) The previous question allowed us to calculate whether or not somebody had a January 1 birthday in the sample we drew. That's not especially interesting, since our answer could change if we drew a new sample. It would be more interesting to know (before we draw the sample) what the *probability* is that nobody in our group had a birthday on January 1.__
	
__We can use for-loops to estimate these types of probabilities. The idea is that if we repeat the simulation we did in part A a large number of times (each time drawing a new random sample of birthdays), the proportion of the samples/simulations in which nobody had a January 1 birthday equals the probability that nobody has a January 1 birthday (for a group this size).__
		
__Write a for-loop that repeats the calculation you did in part A 250 times. Each time, you should store the result (i.e. whether or not there was anybody with a January 1 birthday) in a vector so that you can see all 250 results after the loop is complete.__
```{r}
#creating an empty vector
bday <- c()

#setting the seed so I get the same results
set.seed(1)

#create the for loop with my code from above
for(i in 1:250){
  bday[i] <- !(1 %in% sample(1:365, 300, replace = TRUE))
}

#show results
bday
```

__c) Find the mean of the vector of results you created in part B. What is the probability that, in a group of 300 people, nobody in the group has a birthday on January 1? Hint: Your answer should be somewhere between 0 and 1 (i.e. 0\% and 100\%). If your answer equals exactly 0 or 1, you've done something wrong.__
```{r}
#find the mean of the vector of the results
mean(bday)
```
The mean of the vector of the results is 0.46. This means that the probability that, in a group of 300 people, nobody in the group has a birthday on January 1 is 46%.
	
__d) Now let's use what we learned about writing our own functions to make our code a little bit more general. Write a function where you can alter the number of people in (rather than fixing it at 300), and the function tells you the probability that nobody in a group that size has a January 1 birthday. Use the function to estimate that probability for a group of 750 people. What is that probability?__
```{r}
#setting the seed to get the same number
set.seed(1)

#creating a function
prop.bday <- function(num = 300, runs = 250){
  bday <- c()
  for(i in 1:runs){
  bday[i] <- !(1 %in% sample(1:365, num, replace = TRUE))
  }
  return(mean(bday))
}

#finding the probability for a group of 750 people
prop.bday(num = 750)
```
The probability that in a group of 750 people nobody in the group has a January 1 birthday is 14%.
		
__e) Use your function and another for-loop to calculate the probability for every group size between 300 and 1300. Make a simple scatter plot of your results. What do you notice about the relationship between the size of a group of people and the chances that nobody has a January 1st birthday?__
	
__Note: this calculation might take as much as a minute to run on your computer, so every time you re-knit your Markdown code, it will take a while. To avoid waiting as you're working on the pset, change the number of simulations from 250 to something small (like 25), get all your code working, and then when you're done with the whole problem set, change it back to 250 and wait for everything to compute.__
```{r}
#creating a new data frame to store everything
large <- as.data.frame(matrix(nrow = 1001, ncol = 2))
large[,1] <- 300:1300

#creating the for loop[]
for(i in 1:1001){
  large[i,2] <- prop.bday(num = large[i,1])
}

#renaming the columns
names(large) <- c("Size", "Probability")

#creating a scatter plot
plot(x = large$Size, y = large$Probability, main = "The Probability That No One in a Group Sized Between\n 300 and 1300 has a Birthday on January 1st", xlab = "Size of the Group", ylab = "Probability")
```
There is a strong negative relationship between the size of the group and the probability that no one in a group sized 300 to 1300 has a birthday on January 1st. This means that the larger the group size, the smaller the chances the nobody has a birthday on January 1st.

__3. (Midterm evaluation question) Typically when we're working with survey data, our goal is to use the responses of the survey to understand the larger group of people that the survey respondents represent (usually called the *sample frame*). If we're interested in understanding the political attitudes of everybody who lives in the United States, then we could use a survey of Americans to further our understanding. It's almost impossible, however, that a sample of a few thousand (or even a hundred thousand) people would have demographic attributes that are exactly identical to the US population as a whole. Because of this fact, we use survey weights to slightly adjust the composition of our sample to match the sampling frame.__

__In an ideal world, every respondents' survey weight would equal exactly 1. In practice, this is never really possible in any real-world scenario. The best we can do is to draw a survey that's as representative of the sampling frame as possible, and then use weights to make small adjustments to account for the imperfection and randomness in the sampling process.__
	
__In this question, we're going to use survey data from a July 2019 survey about American politics ("july-2019-sm-poll.sav). To keep things a bit simpler, the data we've provided for this problem set doesn't include every question on the survey.__
	
__a. We'll begin by looking at the `weight` variable in the dataset. What is the average weight given to people in the dataset? Why is it generally a good idea for survey weights to have this average?__
```{r}
#load in rio
library(rio)

#load in data 
poll <- import("july-2019-sm-poll.sav")

#finding the average weight
mean(poll$weight)
```
The average weight given to people in the dataset is 1. It is generally a good idea for survey weights to have the average of 1 because a weight of 1 means that each person would count once in the dataset and it would be representative of the population.
		
__b. Sometimes we trim survey weights so that no single respondent has a huge amount of influence on the conclusions we draw from the data. Does it appear that the survey weights in the anger data have been trimmed? If so, what value were they trimmed to?__
```{r}
#calculate the range 
range(poll$weight)
```
Yes, it appears that the survey weights in the data have been trimmed at 7.0. This means that this was the highest weight value assigned to someone in the dataset.

__c. Identify the person in the data that has the highest survey weight. What is the race and gender of this person? Why might this person have such a high survey weight?__
```{r}
#finding the highest survey weight
poll[poll$weight == max(poll$weight), c("respondentId", "gender", "race", "weight")] %>% na.omit()

#determining what race and gender are coded for
attributes(poll$gender) # 1 male 2 female
attributes(poll$race) # 1 White 2 Black 3 Hispanic 4 Asian 5 Other
```
The person in the data that has the highest survey weight is weighted to 7, and is a Hispanic female. This person may have such a high weight because there may be very few or only one Hispanic females in the survey, so they are upweighted so that that demographic is represented.
	
__d. What is the unweighted average age of people in the dataset? Using the survey weights, what is the weighted average age of people in the data? The `weighted.mean()` function might be helpful here. You can ignore the people who did not provide their age in the survey, and leave them out of the denominators. What does the difference between these two numbers indicate to you?__
```{r}
#calculating the unweighted average age of people in the dataset
mean(poll$age, na.rm = T) #52.12744

#calculating the weighted average age
weighted.mean(poll$age, w = poll$weight, na.rm = T) #45.02371
```
The unweighted average age of people in the dataset is 52. The weighted average age of people in the dataset is 45.This difference between these two numbers indicates that more people who were older took the survey. Once the average age was weighted, the average age of respondents drops, which means that people who were older had smaller weights than people who were younger.
		
__e. Compare the unweighted versus weighted percentages of people in the survey who are white, black, Hispanic, and Asian. When you apply the weights, which groups increase in size and which decrease? By how much do each of the group sizes change (in terms of percentage points)? You might find the `wpct()` function in the 'weights' package to be useful.__
```{r}
#unweighted percentage of people who are white
prop.table(table(poll$race == "1")) #0.7372014

#weighted percentage of people who are white
wpct(poll$race == "1", weight = poll$weight) #0.6170958

#unweighted percentage of people who are Black
prop.table(table(poll$race == "2")) #0.08996072

#weighted percentage of people who are Black
wpct(poll$race == "2", weight = poll$weight) #0.1289135

#unweighted percentage of people who are Hispanic
prop.table(table(poll$race == "3")) #0.06497521

#weighted percentage of people who are Hispanic
wpct(poll$race == "3", weight = poll$weight) #0.1600116

#unweighted percentage of people who are Asian
prop.table(table(poll$race == "4")) #0.03412969

#weighted percentage of people who are Asian
wpct(poll$race == "4", weight = poll$weight) #0.03031985
```
When the weights are applied, the groups of white and Asian survey respondents increases while the groups of Black and Hispanic survey respondents decreases. The group of white survey respondents decreases by 12 percentage points, the group of Black survey respondents increases by 3.9 percentage points, the group of Hispanic survey respondents increases by 9.5 percentage points, and the group of Asian survey respondents decreases by 0.004 percentage points.

__f. What percentage of people said that they would be somewhat or very willing to pay higher taxes to pay for infrastructure improvements? What is this percentage when you only look at Republicans? What about when you only look at Democrats? You should use the survey weights and omit people who did not answer the question from your calculations.__
```{r}
#looking at the attributes for the tax variable
attributes(poll$taxes_improve_infrastructure) # 1 very willing, 2 somewhat willing, 3 not too willing, 4 not at all willing, 5 no answer

#looking at the attributes for the republicans variable
attributes(poll$party) # 1 republican, 2 independent, 3 democrat

#calculating the percentage of people that would be somewhat or very willing to pay higher taxes to pay for infrastructure improvements
wpct(poll$taxes_improve_infrastructure == "1" | poll$taxes_improve_infrastructure == "2", weight = poll$weight) #0.5709911

#calculating the percentage of people that would be somewhat or very willing to pay higher taxes to pay for infrastructure improvements for republicans
weighted.mean(poll$taxes_improve_infrastructure[poll$party == 1] == 1 
              | poll$taxes_improve_infrastructure[poll$party ==1] == 2, 
              w = poll$weight[poll$party == 1], na.rm = T)

#calculating the percentage of people that would be somewhat or very willing to pay higher taxes to pay for infrastructure improvements for democrats
weighted.mean(poll$taxes_improve_infrastructure[poll$party == 3] == 1 
              | poll$taxes_improve_infrastructure[poll$party ==3] == 2, 
              w = poll$weight[poll$party == 3], na.rm = T)
```
57% of people said that they would be somewhat or very willing to pay higher taxes to pay for infrastructure improvements. When only looking at Republicans, 49% of people said that they would be somewhat or very willing to pay higher taxes to pay for infrastructure improvements. When only looking at Democrats, 70% of people said that they would be somewhat or very willing to pay higher taxes to pay for infrastructure improvements.
		
__g. Analyze the questions about trust in the state and federal governments. Use those variables, and others in the dataset, to find some interesting pattern or result in the data. What did you find?__
```{r}
#loading ggplot packages
install.packages("ggthemes")
library(ggplot2)
library(ggthemes)

#exploring the data
attributes(poll$trust_fed_gov) # 1 always, 2 most, 3 half, 4 some, 5 never 
attributes(poll$trust_state_gov) # 1 always, 2 most, 3 half, 4 some, 5 never 

#removing no answers
poll$trust_fed_gov[poll$trust_fed_gov == "6"] <- NA
poll$trust_state_gov[poll$trust_state_gov == "6"] <- NA
poll$taxes_improve_infrastructure[poll$taxes_improve_infrastructure == "5"] <- NA

#correlation between trusting the federal gov always / most of the time and being very / somewhat willing to pay higher taxes for infrastructure improvements
cor(poll$trust_fed_gov == "1" | poll$trust_fed_gov == "2", poll$taxes_improve_infrastructure == "1" | poll$taxes_improve_infrastructure == "2", use = "complete.obs") #0.06639313

#correlation between trusting the federal gov never / some of the time and being very / somewhat willing to pay higher taxes for infrastructure improvements
cor(poll$trust_fed_gov == "4" | poll$trust_fed_gov == "5", poll$taxes_improve_infrastructure == "1" | poll$taxes_improve_infrastructure == "2", use = "complete.obs") #-0.06220522

#correlation between trusting the state gov always / most of the time and being very / somewhat willing to pay higher taxes for infrastructure improvements
cor(poll$trust_state_gov == "1" | poll$trust_state_gov == "2", poll$taxes_improve_infrastructure == "1" | poll$taxes_improve_infrastructure == "2", use = "complete.obs") #0.146496

#correlation between trusting the state gov never / some of the time and being very / somewhat willing to pay higher taxes for infrastructure improvements
cor(poll$trust_state_gov == "4" | poll$trust_state_gov == "5", poll$taxes_improve_infrastructure == "1" | poll$taxes_improve_infrastructure == "2", use = "complete.obs") #-0.1734566
```

```{r}
#finding percentages for federal 

#number of people who always / most of the time trust the federal government and are very / somewhat willing to pay higher taxes for infrastructure improvements
table(poll$trust_fed_gov, poll$taxes_improve_infrastructure)
# 95+74+364+761 = 1294
sum(table(poll$trust_fed_gov, poll$taxes_improve_infrastructure)) #14988
1294/14988 #0.08633574

#number of people who never / some of the time trust the federal government and are very / somewhat willing to pay higher taxes for infrastructure improvements
table(poll$trust_fed_gov, poll$taxes_improve_infrastructure)
# 1057+798+2247+1599 = 5701
sum(table(poll$trust_fed_gov)) #15112
5701/15112 #0.3772499

#number of people who always / most of the time trust the state government and are very / somewhat willing to pay higher taxes for infrastructure improvements
table(poll$trust_state_gov, poll$taxes_improve_infrastructure)
# 150+136+827+1581 = 2694
sum(table(poll$trust_state_gov, poll$taxes_improve_infrastructure)) #14991
2694/14991 #0.1797078

#number of people who never / some of the time trust the state government and are very / somewhat willing to pay higher taxes for infrastructure improvements
table(poll$trust_state_gov, poll$taxes_improve_infrastructure)
# 729+1684+473+897 = 3783
sum(table(poll$trust_state_gov, poll$taxes_improve_infrastructure)) #14991
3783/14991 #0.2523514
```

```{r}
#creating the data frame
labs <- c("Federal Government", "Federal Government", "State Government", "State Government")

graph <- data.frame(avg.prop=c(0.09, 0.38, 0.18, 0.25),
                Legend=c("Always / Mostly Trust Govt", "Never / Sometimes Trust Govt"), labs)

#plotting this
ggplot(graph, aes(x = Legend, y = avg.prop, fill = Legend)) + 
  geom_bar(stat="identity", position = "dodge") +
  geom_text(aes(label=avg.prop), vjust=-0.3, size=4) +
  ylab("Percentage") +
  scale_fill_manual(values = c("deeppink", "darkturquoise")) +
  facet_wrap(vars(labs),
             ncol = 2, 
             nrow = 1) +
  xlab("Trust in Government") +
  ggtitle("Percent of People Who are Very or Somewhat Willing\n to Pay Higher Taxes for Infrastructure Improvements") +  
  theme(plot.title = element_text(hjust = 0.5)) +
  theme_bw() +
  scale_y_continuous(limits = c(0, 1), labels = scales::percent_format(accuracy = 1)) + 
  scale_x_discrete(labels=c("Always / Mostly", "Never / Sometimes", "Always / Mostly", "Never / Sometimes")) +
  theme(legend.position = "none")
```
I wanted to look at the relationship between the percent of people who are very or somewhat willing to pay higher taxes for infrastructure improvements and the amount of trust people have in the state and federal governments. I first looked at the correlations to get a sense of the relationships. The correlation of people who trust the federal government always or most of the time and are very or somewhat willing to pay higher taxes for infrastructure improvements is 0.066, while the correlation of people who trust the federal government never or some of the time and are very or somewhat willing to pay higher taxes for infrastructure improvements is -0.062. This makes sense, because I would expect that when people have more distrust for the federal government, they would be less supportive of paying higher taxes for infrastructure. Similarly, the correlation of people who trust the state government always or most of the time and are very or somewhat willing to pay higher taxes for infrastructure improvements is 0.146, while the correlation of people who trust the state government never or some of the time and are very or somewhat willing to pay higher taxes for infrastructure improvements is -0.173. This also makes sense that there would be a negative relationship between people with more distrust in the government and willingness to pay for improvements. Additionally, I wanted to graph this relationship. I found that 9% of people who are very or somewhat willing to pay higher taxes for infrastructure improvements always or most of the time trust the federal government, while 38% of people who are very or somewhat willing to pay higher taxes for infrastructure improvements never or some of the time trust the federal government. This was surprising, because I would think that people who always or most of the time trust the federal government would have higher support for higher taxes for infrastructure improvements because they may trust where the money is going. I found a similar, but weaker, difference for trust in the state government. I found that 18% of people who are very or somewhat willing to pay higher taxes for infrastructure improvements always or most of the time trust the state government, while 25% of people who are very or somewhat willing to pay higher taxes for infrastructure improvements never or some of the time trust the state government. While this is less pronounced, this still seems weird that people with less trust in the government are more likley to support higher taxes for infrastructure improvements. 


### Problem Set 5

__1. For this exercise, we'll be working with daily weather data from a weather station in New York City's Central Park. The station has been running continuously since January of 1869, so we'll be able to analyze 150+ years of weather patterns. The data come from a dataset extraction tool provided by the National Oceanic and Atmospheric Administration.^[You can download data for other cities or locations here: https://www.ncdc.noaa.gov/cdo-web/search?datasetid=GHCND.]__

__a. Begin by loading the temperature data.^[All temperatures are in terms of Fahreinheit.] Use the `separate()` function to turn the `DATE` variable into three separate variables for year, month, and date. Which years are missing at least one day of temperature data, and how many days are missing?__
```{r}
require(tidyr)
require(tidyverse)

#loading in the data
temp <- read.csv("nyc-central-park-temps.csv")

#separating the date variable
temp <- separate(temp,
                  col = "DATE",
                  into = c("year","month","day"),
                  sep = "-")

#looking at which years are missing data
table(temp$year)

#1869 has 358
365-358
```
1869 is missing 7 days of temperature data.

__b. Create a variable that tells us the difference between the highest and lowest temperature for each day. Across the full dataset, what the average of this difference? Which day during this 150 year window had the biggest difference between the highest and lowest temperature? Averaging across years, which month tends to have the highest average difference in daily high and low temperatures?__
```{r}
#creating a variable to tell the difference between max and min temps
temp$diff <- temp$TMAX - temp$TMIN

#finding the average across the entire dataset
mean(temp$diff) #14.71454

#finding the day with the biggest difference
temp[temp$diff == max(temp$diff), c("day", "month", "year", "diff")] %>% na.omit()

#aggregating by month and year
month.year <- aggregate(temp$diff, by=list(Category=temp$month, temp$year), FUN=sum)

#seeing which month appears most
month.year %>% 
 arrange(desc(x)) %>%
 select(Category)
```
The average of the difference between the highest and lowest temperature for each day across the entire dataset is 14.71 degrees Fahrenheit. March 28, 1921 had the biggest difference between the highest and lowest temperature, which was 48 degrees Fahrenheit. Averaging across years, May tends to have the highest average difference in daily high and low temperatures.

__c. Load and merge in the precipitation data. What type of merge does it mark sense to perform? Which variable(s) will you merge on? Perform the merge, then use the results to figure out how many days had a high temperature of at least 50 degrees and received at least 1 inch of snowfall.__
```{r}
#loading in the precipitation data
prec <- read.csv("nyc-central-park-precipitation.csv")

#separating the date column
prec <- separate(prec,
                  col = "DATE",
                  into = c("year","month","day"),
                  sep = "-")

#merging the two datasets
weather <- merge(temp, 
                prec,
                by = c("STATION", "year", "month", "day"),
                all = T)

#finding out how many days had a high temp of at least 50 and received at least 1 inch of snowfall
weather[weather$TMAX >= 50 & weather$SNOW >= 1, c("day")] %>% na.omit()
```
It makes sense to perform an outer merge so that all of the variables are included. I will merge on the variables station, year, month, and day, so that all of the information is correct and accurate. 25 days had a high temperature of at least 50 and received at least 1 inch of snowfall.
	
__d. Aggregate the data by month to figure out what percentage of days have had preciptation since 1869. Your resulting dataset should have 12 rows (one per month). You should use the PRCP variable (and ignore the SNOW variable). Which month tends to have the most rainy days in New York City? What percentage of days does it usually rain in this month? And which month tends to be the dryest (i.e. fewest days with precipitation)? What percentage?__
```{r}
#aggregating the data by month
prec.1869 <- weather %>%
          group_by(month) %>%
          summarise(PRCPCOUNT = sum(PRCP > 0)/n()*100)

#finding the month with the most rain
prec.1869[prec.1869$PRCPCOUNT == max(prec.1869$PRCPCOUNT), c("month", "PRCPCOUNT")] %>% na.omit()

#finding the month with the least rain
prec.1869[prec.1869$PRCPCOUNT == min(prec.1869$PRCPCOUNT), c("month", "PRCPCOUNT")] %>% na.omit()

```   
March tends to have the most rainy days in New York City, with 36.33% of days being rainy. October tends to be the driest month, with 27.45% of days being dry.
	
__e. Use aggregation to figure out how many days in each year since 1869 had a low temperature of 32 degree or below. Create a graph that shows the relationship between the year and the number of cold days in Central Park. What pattern do you notice in this graph?__
```{r}
library(ggplot2)

cold <- weather %>%
          group_by(year) %>%
          summarise(temp = sum(as.numeric(TMIN <= 32)))

graph <- ggplot(data = cold, aes(x = as.numeric(year), y = temp)) +
  ggtitle("Number of Cold Days per Year") +
  geom_bar(stat = "identity", width = 0.8) +
  scale_x_continuous(name = "Year", breaks = seq(1870, 2021, by = 10)) +
  scale_y_continuous(name = "Number of Cold Days") +
  theme_minimal() +
  theme(legend.position = "none",
        plot.title = element_text(size = 12))
graph
```
The pattern in the graph shows that the number of decreases slowly decrease over time.

__2.  The graph below shows what effect a particular treatment had on the probability that a voter supported Diane Feinstein, Kevin de Leon, or another candidate in a recent California primary election.__

![](experiment-graph-bad.pdf)

__Imagine you have been given that data that created this graph (`election-data-for-graph.RData`), and have been asked to improve the graph. Begin by replicating the graph exactly as it appears here. Then improve the graph in any way you see fit. One specific thing your client has asked is that you to make each of the three sets of points and line segments into three separate colors. You may also want to improve the labeling or text that appears on the graph. In your submission, explain why you corrected for these features in your replication.__
```{r}
#load in the packages and data
require(tidyverse)
library(dplyr)
library(ggplot2)
library(ggthemes)
load("election-data-for-graph.RData")

#changing the levels of the candidates variable
experiment$candidates <- as.character(experiment$candidates)
experiment$candidates <- factor(experiment$candidates, levels = unique(experiment$candidates))

#creating labels for the graph
experiment$label <- paste(round(experiment$ATE * 100, digits = 1), "%", sep = "")
experiment$label[1] <- paste("+", experiment$label[1], sep = "")

#making the plot
old <- ggplot(data = experiment, mapping = aes(x = candidates, y = ATE)) + 
  geom_point(shape = "diamond", size = 2, col = "red") +            #red diamond points
  ggtitle("Average Treatment Effect on Candidate Support") +        #title
  xlab("Candidate Support") +                                       #x axis
  scale_y_continuous(name = "a.t.e.", limits = c(-0.4,0.6),         #y axis and limits
                     breaks = seq(from = -0.4, to = 0.4, by = 0.2),
                     expand = c(0.02,0)) +
  geom_errorbar(aes(ymin = ci_lower,                                #error bars
                    ymax = ci_upper,
                    width = 0), size = 0.2) +
  geom_text(aes(size = 3, label = label, hjust = -0.2),             #text
            show.legend = FALSE) +
  theme(text = element_text(family = "Helvetica"),                  #text of title
        plot.title = element_text(size = 9, hjust = 0.5, face = "bold"),    #title size and boldness
        axis.title = element_text(size = 12),                       #axis size
        axis.title.x = element_text(vjust = -3),                    #axis position
        axis.line = element_line(color = "black", size = 0.3),      #get rid of grid and border lines
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.border = element_blank(),
        panel.background = element_blank(),
        panel.grid.major.y = element_line(colour = "grey", size = 0.1),  #add grey lines
        axis.text.x = element_text(color = "black", size = 12, vjust = 0.7),  #make axis labels black and right size
        axis.text.y = element_text(color = "black", size = 12),
        axis.ticks.length = unit(0.25, "cm"),                               #make ticks longer
        axis.ticks = element_line(size = 0.2, color = "black"),
        plot.margin = margin(1,1,10,1))                             #change margins
old
```
```{r}
#adding a color designater to the data
experiment$color <- NA
experiment$color[experiment$candidates == "Vote Feinstein"] <- 1
experiment$color[experiment$candidates == "Vote de León"] <- 2
experiment$color[experiment$candidates == "Vote Other Candidate"] <- 3

#making the new graph
new <- ggplot(data = experiment, mapping = aes(x = candidates, y = ATE, color = as.factor(color))) + 
  geom_point(shape = "diamond", size = 4) +            #red diamond points
  ggtitle("Average Treatment Effect on Candidate Support") +        #title
  xlab("Candidate Support") +                                       #x axis
  scale_y_continuous(name = "Average Treatment Effect", limits = c(-0.4,0.6),         #y axis and limits
                     breaks = seq(from = -0.4, to = 0.4, by = 0.2),
                     expand = c(0.02,0), labels = scales::percent) +
  geom_errorbar(aes(ymin = ci_lower,                                #error bars
                    ymax = ci_upper,
                    width = 0), size = 0.8) +
  geom_text(aes(size = 3, label = label, hjust = -0.2),             #text
            show.legend = FALSE) +
  scale_color_manual(values = c("deeppink", "midnightblue", "darkviolet")) +
  theme(legend.position = "none") +
  theme(text = element_text(family = "Helvetica"),                  #text of title
        plot.title = element_text(size = 15, hjust = 0.5, face = "bold"),    #title size and boldness
        axis.title = element_text(size = 12),                       #axis size
        axis.title.x = element_text(vjust = -3),                    #axis position
        axis.line = element_line(color = "black", size = 0.3),      #get rid of grid and border lines
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.border = element_blank(),
        panel.background = element_blank(),
        panel.grid.major.y = element_line(colour = "grey", size = 0.1),  #add grey lines
        axis.text.x = element_text(color = "black", size = 12, vjust = 0.7),  #make axis labels black and right size
        axis.text.y = element_text(color = "black", size = 12),
        axis.ticks.length = unit(0.25, "cm"),                               #make ticks longer
        axis.ticks = element_line(size = 0.2, color = "black"),
        plot.margin = margin(1,1,10,1))                             #change margins
new
```
In the new graph, I made the diamond size bigger so that it was easier to read and made the error bars thicker so they were easier to see. I changed the the y-axis label from a.t.e. to average treatment effect so that it was more meaningful. I made the title size bigger so that it was easier to read, and I made each candidate point and error bar a different color so that they could be easily differentiated. Finally, I changed the y-axis labels into percentages instead of decimals so that it was easier to understand and matched the text on the graph.


__3. In many states, convicted felons are banned from voting while they serve their prison, parole, or probation sentence. In some of those states, they are able to have their voting rights restored. Even after voting rights are restored, former felons continue to register to vote and vote at extremely low rates. In this question, we will look at an experiment (co-authored by UPenn's Dr. Marc Meredith) that sought to understand what caused these low rates. The researchers were specifically interested in how much of this low rate could be explained by felons' not knowing that their voting rights had been or could be restored after serving their sentence.__

__For these exercises, you will use the dataset 'felons.RData' to replicate some of the findings in the article "Can Incarcerated Felons be (Re)integrated into the Political System? Results from a Field Experiment."^[[https://onlinelibrary.wiley.com/doi/abs/10.1111/ajps.12166](https://onlinelibrary.wiley.com/doi/abs/10.1111/ajps.12166)]__

__a. Imagine you wanted to understand the effect that felony convictions and incarceration have on voter registration and turnout (after the sentence has been served). Somebody suggests that you compare the voter registration rates and turnout rates of former felons to people who never have served time for a felony. Discuss why this research design could or could not help you to get a good estimate of the causal effect that you are interested in.__
I do not think that this research design could help us get a good estimate of the causal effect that we are interested in because the two groups are too different. People who have never served time for a felony are more likely to be more educated and politically active, and thus more likely to vote in general. In terms of former felons, they may not know if they are eligible to vote, may have barriers (like paying restitution) that stop them from voting, or may not even know about the candidates at all and have never voted before their sentence. This would also not be able to prove whether or not felons voted before incarceration. Because of these differences that are too difficult to control for, the research design would not help get us the causal effect that we are interested in.
	
__b. Read the `Experimental Design` section of the "Can Incarcerated Felons be (Re)integrated into the Political System?" (pages 915 through 917 in \emph{gerber, et al 2015.pdf}).__
		__i. What are the causal effect(s) that the authors are interested in studying?__
		    The causal effect that the authors are interested in studying is the effect that political outreach to former felons has on their likelihood of registering to vote and actually voting.
		__ii. Describe the treatment and control conditions in the experiment.__
		    There were two treatment groups, with both receiving a mailing in an envelope from the Secretary of State's office that provided them with general information related to the election and that they were not registered to vote. The letters mentioned appeals to civic duties and had a statement that said that they were "eligible to register to vote." This was all that the first treatment group received. The second treatment group, however, got an assurance explained mailing that contained an additional paragraph to address any concerns about being turned away or questioned about being an ex felon. The control group received neither of these treatments.
		__iii. Describe the randomization strategy that the authors used.__
		    The authors randomly assigned individuals to either the control or one of two treatment groups. The control group consisted of about 50% of the sample, and each treatment group had 25%. The assignment was within blocks for different crimes, so that all three groups were balanced. For leftover cases that could not be blocked, they were independently and randomly assigned to a group.

__c. Now we're going to analyze the results from the experiment. Begin by removing the 161 people in the dataset who returned to prison before the experiment was conducted. Then create a new variable called `treatment_collapsed' which tells us whether each observation in the data was in the control group (FALSE) or a treatment group (TRUE).__
```{r}
#load in the data
load("felons.RData")

#removing the people who returned to prison
felons <- felons %>% filter(returntoprison != 1)

#creating the treatment_collapsed variable
attributes(felons$treatment)

felons$treatment_collapsed <- FALSE
felons$treatment_collapsed[felons$treatment == "2"] <- TRUE
felons$treatment_collapsed[felons$treatment == "3"] <- TRUE
```

__d. The first thing you should always do before analyzing the results of an experiment is assess whether you have balance in your treatment and control groups. In a well-balanced experiment, no pre-treatment covariates (i.e. the variables that existed before you ran the experiment) would predict whether or not somebody ended up in the treatment or control group. For the following questions, use the 	`treatment_collapsed` variable.__
	
		__i. Use 4 t-tests to assess whether the felons' age, number of days served in prison, time since their release from prison, or 2008 vote turnout is a statistically significant predictor of treatment. To do the t-tests, you'll want to write code that looks like this: `t.test(felons$age ~ felons$treatment_collapsed)`. Create a well-formatted table the present the average values for each of these variables in the treatment and control groups, as well as the the p-value associated with the difference between those averages. You can pull out these values from the output of the `t.test()` object using the $ operator.  Is there significant imbalance for any of those four variables?__
```{r}
library(kableExtra)
library(dplyr)

#testing age
t.test(felons$age ~ felons$treatment_collapsed) #control = 35.34835, treatments = 35.23333, p-value = 0.6604

#testing number of days served in prison
t.test(felons$days_served ~ felons$treatment_collapsed) #control = 370.1308, treatments = 369.4835, p-value = 0.9194

#testing time since release from prison
t.test(felons$yrs_since_release ~ felons$treatment_collapsed) #control = 1.809551, treatments = 1.808286, p-value = 0.9553

#testing 2008 vote turnout
t.test(felons$vote08 ~ felons$treatment_collapsed) #control = 0.04952830, treatments = 0.05223172, p-value = 0.6894

#creating a table of these results
control <- c("35.34835", "370.1308", "1.809551", "0.04952830")
treatment <- c("35.23333", "369.4835", "1.808286", "0.05223172")
p.value <- c("0.6604", "0.9194", "0.9553", "0.6894")
variable <- c("Age", "Days Served", "Time Since Release", "2008 Vote Turnout")
table <- cbind(variable, control, treatment, p.value)

kbl(table, caption = "T-Test Results", col.names = c("Variable", "Control Mean", "Treatment Mean", "P-Value")) %>%
kable_classic_2()
```
There is no significant imbalances for any of the variables. All of the p-values are above the 0.05 threshold, so none of the values are statistically significant.

__ii. Use linear regression to assess whether the type of crime predicts whether somebody ended up in the treatment or control group. Were any crimes strong predictors of the treatment?__
```{r}
#running a linear regression for crime type
reg.crime <- lm(treatment_collapsed ~ felony_type, data=felons)
summary(reg.crime)
```
None of the crimes were strong predictors of ending up in the treatment group.

__iii. Use linear regression to assess balance for all the variables (age, days in prison, time since release, 2008 turnout, crime type) simultaneously. When you do this, do you find imbalance for any of the pre-treatment covariates?__
```{r}
#running a linear regression for all of the variables
reg.all <- lm(treatment_collapsed ~ felony_type + age + days_served + yrs_since_release + vote08, data=felons)
summary(reg.all)
```
When I run a linear regression to assess balance for all of the variables, I do not find an imbalance for any of the pre-treatment covariates. All of the coefficients are really small, and none of them are significant. This means that the groups are all well balanced.

__e. Did the experiment have an effect on whether or not ex-felons registered to vote? Did it impact their turnout in 2012? If so, how much did the treatment increase or decrease the probability that they registered or turned out? You can use linear regression and the 'treatment_collapsed' variable to answer this question.__
```{r}
#running a linear regression for registering to vote 
reg.registered <- lm(treatment_collapsed ~ registered, data=felons)
summary(reg.registered)

#running a linear regression for turnout
reg.vote12 <- lm(treatment_collapsed ~ vote12, data=felons)
summary(reg.vote12)
```
The experiment had an effect on both whether or not ex-felons registered to vote and on their turnout in 2012. If the ex-felons were treated, they had a 0.709 increase in likelihood of registering to vote than if they were not treated. The treated ex-felons also had a 0.068 increase in the likelihood of turning out to vote in 2012. Both of these values are significant.
	
__f. Use linear regression to estimate these two treatment effects again. This time, control for the five pre-treatment covariates (the ones you checked for balance in part C in your regression. What effect did the treatment have on registration and voting?__
```{r}
#running a linear regression for registering to vote 
reg.registered.control <- lm(treatment_collapsed ~ registered + age + days_served + yrs_since_release + vote08, data=felons)
summary(reg.registered.control)

#running a linear regression for turnout
reg.vote12.control <- lm(treatment_collapsed ~ vote12 + age + days_served + yrs_since_release + vote08, data=felons)
summary(reg.vote12.control)
```
The experiment had an effect on whether or not ex-felons registered to vote, but not on their turnout in 2012. Controlling for the age, years since release, days served, and vote in 2008 variables, if the ex-felons were treated, they had a 0.08468 increase in likelihood of registering to vote than if they were not treated. The p-value is 0.0488, and both are significant. However, the treated ex-felons  had a 0.0717 increase in the likelihood of turning out to vote in 2012. The p-value is 0.2792, and neither of these values are significant. 


### Problem Set 6

__1. Given any three randomly chosen integers between 1 and infinity, what are the chances that their product is divisible by 100?__

	__a. We'll begin by finding the exact solution to the problem, using integers between 1 and 99 (instead of infinity). We'll figure out every possible triplet of the numbers 1 through 99, and see how many of them have a product that's divisible by 100. To do this, first create a matrix that contains all 970,299 (99^3) possible triplets of the numbers between 1 and 99. The `expand.grid()` function should make this easy. Now use multiplication to get the product of the three numbers in each triplet. How many of those products are divisible by 100? The modulus operator (%%) will help here. To understand how it works, type `300 %% 100` into R. Then type `301 %% 100`. What percentage of the triplets have a product divisible by 100? In other words, what is the probability of choosing 3 numbers between 1 and 99 and having their product be divisible by 100?__
```{r}
#using expand grid to create the matrix
df <- expand.grid(first = seq(1, 99, 1),
                  second = seq(1, 99, 1),
                  third = seq(1, 99, 1))

#finding the product of the triplets
df$product <- df$first * df$second * df$third

#finding which products are divisible by 100
df$divisible <- ifelse(df$product %% 100 == 0, 1, 0)

#finding the probability 
mean(df$divisible)
```
The probability of choosing 3 numbers between 1 and 99 and having their product be divisible by 100 is 9.75%.
	
__b. Now let's imagine we weren't able to create all 970,299 triplets. We could try to estimate the solution to the problem by using simulation. To do this, write some code that randomly samples 3 numbers from between 1 and 99 and checks whether their product is divisible by 100. Use a for loop to repeat this process 5000 times, and use those 5000 results to estimate the probability of choosing 3 numbers between 1 and 99 that have a product that's divisible by 100. How close was this estimated probably to the true probability we calculated in part A?__
```{r}
#setting the seed
set.seed(1)

#creating the vector
products <- c()

#creating the for loop
 for(i in 1:5000){
    vec <- sample(1:99, 3, replace = T)
    products[i] <- prod(vec)
  }

#finding the probability
(mean(products %% 100 == 0) * 100)

#finding the difference
9.75-9.16
```
Using the simulation, the probability of choosing 3 numbers between 1 and 99 that have a product that's divisible by 100 is 9.16%. This is close to the true probability calculated in part A (which was 9.75%), but was 0.59% off.

__c. Let's imagine we wanted to we wanted to solve the same problem, except our triplets came from any number between 1 and 999 (instead of just 99). If we wanted to check every possible triplet (like in part A), we'd have to look at almost a billion combinations of numbers! Turn your code from part B into a function that takes, as an argument, the upper number (i.e. 99 or 999), and returns the probability of the product of 3 randomly chosen numbers between 1 and that number being divisible by 100. What is this probability if the upper bound in 999?__
```{r}
#setting the seed
set.seed(1)

#creating the function with the code from part B
divisible.by.100 <- function(x){
  products <- c()
  
  for(i in 1:5000){
    vec <- sample(1:x,3, replace = T)
    products[i] <- prod(vec)
  }
  
  return(mean(products %% 100 == 0) * 100)
  
}

#testing the function on 999
divisible.by.100(999)
```
The probability of choosing 3 numbers between 1 and 99 that have a product that's divisible by 100 when the upper bound is 999 is 12.32%.
	
__d. Now use your function inside another for loop to estimate the probabilities when the upper bound is 1, 2, 3, ... 997, 998, 999. Store all these probabilities in a vector called `all.probabilities`, and then use `plot(all.probabilities)` to examine the pattern of your results. What do you notice about the results?__
```{r}
#setting my seed
set.seed(1)

#creating a vector
all.probabilities <- c()

#creating the for loop
for(i in 1:999){
  all.probabilities[i] <- divisible.by.100(i)
}

#plotting the results
plot(all.probabilities)
```
The plot shows that the probability of choosing 3 numbers between 1 and 99 that have a product that's divisible by 100 does not ever get higher than about 13%.

__2. Download the Philadelphia Youth Risk dataset. You will use these data to explore how location relates to risk for children in the city.__

__Description of the variables:__

__- CODE: Zip code__

__- Risk: Each zip code was assigned an overall "Risk score" based on factor analysis__

__- Poverty: Percent of families with children below the poverty line__

__- Education: Percent of individuals with less than a high school diploma__

__- Unemployment: Percent of unemployed individuals within the zip code__

__- Crime: Shooting victims per 10,000__

__- ACEs: Percent with at least one Adverse Childhood Experience__

__- RiskF: a variable that bins the Risk scores into 4 sections__

__a. Explore the Risk, Poverty, Education, Unemployment, Crime, and ACEs variables by looking at the mean, median, and any other descriptive statistics that you think are important to know. Write up your findings in a couple of sentences for each variable.__
```{r}
#load in the data and packages
risk <- read.csv("philly-youth-risk.csv")
require(tidyr)
require(tidyverse)

#calculating descriptive statistics for the risk variable
summary(risk$Risk)
risk[risk$Risk == min(risk$Risk), c("CODE", "Risk")] %>% na.omit()
risk[risk$Risk == max(risk$Risk), c("CODE", "Risk")] %>% na.omit()

#calculating descriptive statistics for the poverty variable
summary(risk$Poverty)
risk[risk$Poverty == min(risk$Poverty), c("CODE", "Poverty")] %>% na.omit()
risk[risk$Poverty == max(risk$Poverty), c("CODE", "Poverty")] %>% na.omit()

#calculating descriptive statistics for the education variable
summary(risk$Education)
risk[risk$Education == min(risk$Education), c("CODE", "Education")] %>% na.omit()
risk[risk$Education == max(risk$Education), c("CODE", "Education")] %>% na.omit()

#calculating descriptive statistics for the unemployment variable
summary(risk$Unemployment)
risk[risk$Unemployment == min(risk$Unemployment), c("CODE", "Unemployment")] %>% na.omit()
risk[risk$Unemployment == max(risk$Unemployment), c("CODE", "Unemployment")] %>% na.omit()

#calculating descriptive statistics for the crime variable
summary(risk$Crime)
risk[risk$Crime == min(risk$Crime), c("CODE", "Crime")] %>% na.omit()
risk[risk$Crime == max(risk$Crime), c("CODE", "Crime")] %>% na.omit()

#calculating descriptive statistics for the ACEs variable
summary(risk$ACEs)
which(risk$ACEs == 60.70)
which(risk$ACEs == 98.20)
```
The mean risk score assigned to a zip code is 49.68, with the median being 49.95. The zip code with the lowest risk score (2.1) is 19102, while the zip code with the highest risk score (97.8) is 19133. The mean percent of families with children below the poverty line is 25.40%, while the median is 23.73%. The zip code with the smallest percent of families with children below the poverty line (1.49%) is 19118, while the zip code with the largest percent of families with children below the poverty line (61.81%) is 19133. The mean percent of individuals with less than a high school diploma is 5.851, while the median is 4.770. The zip code with the smallest percent of individuals with less than a high school diploma (0.59%) is 19103, while the zip code with the largest percent of individuals with less than a high school diploma (19.21%) is 19133. The mean percent of unemployed individuals is 14.04, while the median is 13.81. The zip code with the smallest percent of unemployed individuals (3.5%) is 19106, while the zip code with the largest percent of unemployed individuals (25.89%) is 19133. The mean number of shooting victims per 10,000 people is 7.435, while the median is 4.725. The zip codes with the smallest number of shooting victims per 10,000 people (0) are 19137, 19115, 19128, 19118, 19102, while the zip code with the largest number of shooting victims per 10,000 people (27.610) is 19133. The mean percent of people with at least one Adverse Childhood Experience is 82.44%, while the median is 82.10%. The zip code with the smallest percent of people with at least one Adverse Childhood Experience (60.70%) is 19147, while the zip code with the largest percent of people with at least one Adverse Childhood Experience (98.20%) is 19140. For almost all of the variables (risk score, poverty, education, unemployment, and crime), the zip code of 19133 (located in North Philadelphia) had the maximum values. This means that 19133 had the highest risk score, highest percent of families with children below the poverty line, highest percent of individuals with less than a high school diploma, highest percent of unemployed individuals, and highest number of shooting victims per 10,000 people.

__b. Create a Place Matters choropleth map (like in class) that highlights the difference in risk scores between Philadelphia zip codes. You'll need to unzip the "Zipcodes_Poly.zip" file. Remember that the shapefile *folder* should appear in your working directory (i.e. don't put the individual files within that folder into your working directory. Keep them inside their own folder called "Zipcodes_Poly" and put that folder into your working directory.)__
```{r}
#load in necessary packages
install.packages("leaflet")
library(leaflet)
library(dplyr)
install.packages("sf")
library(sf)

#reading in the shape file
zips <- read_sf("/Users/briannafisher/Dropbox/Github/BriannaFisher/data/Zipcodes_Poly")
  
#making the code variable a character so the two match
risk$CODE <- as.character(risk$CODE)

# use a left_join to merge them
info <- left_join(zips, risk, by = c("CODE" = "CODE"))
  
# writing the pop up values
 info_popup <- paste0(
    "<strong>Zip Code: </strong>",
    info$CODE,
    "<br>Risk Score: ",
    info$Risk
  )
  
# coloring by factor level, from risk variable
factpal <- colorFactor(c("#FFCCE5",
                           "#FF66B2",
                            "#FF3399",
                              "#CC0066"), info$RiskF)

#creating the map
  map <- leaflet(info) %>%
    fitBounds(-124, 34,-62, 40) %>%
    addProviderTiles("CartoDB.Positron") %>%
    addPolygons(
      stroke = TRUE,
      smoothFactor = 0.2,
      fillOpacity = .8,
      color = ~ factpal(RiskF),
      weight = 1,
      popup = info_popup
    ) %>%
    addLegend(
      "topright",
      colors = c("#FFCCE5","#FF66B2","#FF3399", "#CC0066"),
      labels = c(
        "Significantly Lowest Risk Score",
        "Lower Risk Score",
        "Higher Risk Score",
        "Significantly Higher Risk Score"
      ),
      title = "Difference in the Risk Scores of Different Zip Codes in Philadelphia",
      opacity = 1
    )
map
```


__c. Place your choropleth into a Shiny app.__


__[Midterm assessment question]__

__3. Using the data for the final project (either what we provided, or different survey data that you're planning to use), create a graph that visualizes a response (or set of responses) that you find interesting. For instance, you may want to think about displaying how responses to one of the substantive questions vary by demographic group. Your visual should include enough information to clearly communicate the numbers behind the visual. At a minimum, your graph should include:__

	__- A title__
	__- Appropriate axes__
	__- Appropriate labels__
	__- Appropriate sizing of the text and numbers__

__You should export your graph to a .png file and include it in your submission. It should also include a brief caption that accompanies the figure.__

```{r}
#load in library
require(rio)
library(ggplot2)
library(ggthemes)
library(dplyr)

#load in the data
data <- rio::import("pa-survey-data.SAV")

#looking at data attributes
attributes(data$Q7)

#graphing Q7 (important issue) and Q24 (political party)
plot <- ggplot(data, aes(factor(data$Q24), fill = as.factor(data$Q7))) +
geom_bar(stat="count", position = "dodge") +
  ggtitle("Current Most Important Issue and Political Party") +
  scale_x_discrete(name = "Political Party", labels = c("Republican", "Democrat", "Independent")) +
  scale_y_continuous(name = "Count") +
   theme(plot.title = element_text(size = 15, hjust = 0.5, face = "bold"),   
        axis.title = element_text(size = 12),                 
        axis.title.x = element_text(vjust = 0),                  
        axis.line = element_line(color = "black", size = 0.3),     
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.border = element_blank(),
        panel.background = element_blank(),
        panel.grid.major.y = element_line(colour = "grey", size = 0.1),
          plot.caption = element_text(hjust = 0))  +
  scale_fill_discrete(name = "Important Issue", labels = c("COVID-19", "Inflation", "Economy", "Taxes",
                                                           "Crime", "Education", "Health Care", "Immigration", "Russia/Ukraine")) +
  labs(caption = "This graph shows the respondent's current most important issues and their political party. Inflation was more commonly cited as the most important \nissue for Republicans than Democrats, while the situation in Russia and Ukraine was more commonly cited by Democrats \nthan Republicans. These two issues were also most common among Independents, but there were less respondents than \nDemocrats or Republicans.")
plot

ggsave(filename = "issue.png", 
       plot = plot,
       width = 12, 
       height = 7)
```


### Final Project

__Lean of Independents Signifies their Approval of Biden__

A new survey of Pennsylvanians has found that support for the way that Joe Biden is handling his job as President differs most for Independents, rather than Democrats or Republicans.

```{r, echo=FALSE, results=FALSE}
#loading in some libraries
require(rio)
library(dplyr)
library(ggplot2)
library(ggthemes)
require(weights)

#loading in the data
survey <- rio::import("pa-survey-data.SAV")
```

Looking first at Biden approval by party
```{r, echo=FALSE, results=FALSE}
#subsetting biden approval and party
biden.party <- survey %>%
          group_by(Q24) %>%
          summarise(perc.strong.approve = weighted.mean(Q15 == "1", weight = WT, na.rm = T),
                    perc.some.approve = weighted.mean(Q15 == "2", weight = WT, na.rm = T),
                    perc.approve = (perc.strong.approve+perc.some.approve)*100,
                    perc.strong.disapprove = weighted.mean(Q15 == "3", weight = WT, na.rm = T),
                    perc.some.disapprove = weighted.mean(Q15 == "4", weight = WT, na.rm = T),
                    perc.disapprove = (perc.strong.disapprove+perc.some.disapprove)*100)

#cleaning up the data frame a little so that it is easier to graph
party <- c("Republican", "Republican", "Democrat", "Democrat", "Independent", "Independent")

approval <- c(10.12146, -89.87854, 81.91882, -18.08118, 35.57895, -64.42105)

color <- c(1, 2, 3, 4, 5, 6)

biden.party.full <- data.frame(party, approval, color)

#fixing the levels of the party variable
biden.party.full$party <- factor(party, levels = c("Republican", "Democrat", "Independent"))

biden.party.full$party <- factor(biden.party.full$party, levels = rev(levels(biden.party.full$party)))
```


```{r, echo=FALSE}
ggplot(data = biden.party.full,
       aes(x = party, y = approval, fill=as.factor(color)))+
  geom_bar(stat = "identity", width = .8)+
  coord_flip()+
  geom_hline(yintercept = 0)+
  scale_y_continuous(labels = abs, limits = c(-100,100), 
                     name = "Disapprove                                                                          Approve")+
    scale_x_discrete(labels=c("1" = " ", 
                            "2" = " ", 
                            "3" = " "),
                   name= NULL)+ 
  scale_fill_manual(values=c("#FF0000","#FFD7D7", "#0000FF", "#CCE5FF", "#808080", "#C0C0C0")) +
  ggtitle("Percent of Support for the way Joe Biden is Handling his Job as President by Political Party") +
  annotate("text", x = 1, y = 10, size = 12, label = "36%", color = "#C0C0C0") +
  annotate("text", x = 1, y = -10, size = 12, label = "64%", color = "#606060") +
  annotate("text", x = 2, y = 10, size = 12, label = "82%", color = "#CCE5FF") +
  annotate("text", x = 2, y = -9, size = 12, label = "18%", color = "#0000FF") +
  annotate("text", x = 3, y = 17, size = 12, label = "10%", color = "#FF0000") +
  annotate("text", x = 3, y = -10, size = 12, label = "90%", color = "#FF0000") +
   theme(plot.title = element_text(size = 23),
         axis.text.x = element_text(size = 20),
         axis.text.y = element_text(size = 20),
         axis.title = element_text(size = 20)) +
  theme(legend.position = "none") 
```

Overall, there is low support for the way that Joe Biden is handling his job as President across Republicans and Independents in Pennsylvania, whereas Democrats in Pennsylvania still approve of Biden at high rates. Unsurprisingly, 90% of Republicans disapprove of Biden, while 82% of Democrats approve of him. This aligns with what would be expected of people who support the President strongly based on their party, rather than other factors. 

More interestingly, 64% of Independents disapprove of how Biden is handling his job, while 36% approve. While this is not an even, fifty-fifty split, the 64% disapproval rating is a weak majority leaning more towards the right, and is certainty not as drastic as Republican’s 90% disapproval rating. One reason for this weak disapproval rating may be that only 28% of the Independents in the survey lean Republican (which is greater than the 22% that lean Democrat). This small percentage (as well as the 50% that lean neither Republican nor Democrat) may account for the slight lean to the right in the survey responses. This article will take a deeper look into the differences in demographics of Independents, and whether or not these demographics help to highlight a trend for either approval or disapproval for how Biden is handling his job as President. 

__Region of Pennsylvania__

Looking first at the region of Pennsylvania that the survey respondent is from, there is an overall trend towards higher disapproval than approval for Biden across all six regions for Independents (Greater Philadelphia, Greater Pittsburgh, North Central, Northeast, Northwest, and South Central).

```{r, echo=FALSE, results=FALSE}
#load in the data
zips <- read.csv("zip-codes.csv")
county <- readRDS("PA-county-shapefile.RDS")

#subsetting independents
independents <- subset(survey, subset = Q24 == 3)

#calculating the weighted means for the zip code and biden variables
zip.means <- independents %>%
          group_by(Q34) %>%
          summarise(perc.strong.approve = weighted.mean(Q15 == "1", weight = WT, na.rm = T),
                    perc.some.approve = weighted.mean(Q15 == "2", weight = WT, na.rm = T),
                    perc.approve = (perc.strong.approve+perc.some.approve),
                    perc.strong.disapprove = weighted.mean(Q15 == "3", weight = WT, na.rm = T),
                    perc.some.disapprove = weighted.mean(Q15 == "4", weight = WT, na.rm = T),
                    perc.disapprove = (perc.strong.disapprove+perc.some.disapprove))

#making the variable type match
zips$zipcode <- as.character(zips$zipcode)
zip.means$Q34 <- as.character(zip.means$Q34)

#using a left_join to merge them
all <- left_join(zip.means, zips, by = c("Q34" = "zipcode"))

#making the variable type match
all$county_fips <- as.character(all$county_fips)
county$county_fips <- as.character(county$county_fips)

#removing the geometry column
county <- county[ -c(4) ]

#merging with county data to get long and lat info
with.county <- left_join(all, county, by = c("county_fips" = "county_fips"))

#aggregate from zips to county
zips.to.county <- with.county %>%
                    group_by(county_fips, region.x) %>%
                        summarise(perc.approve.county = mean(perc.approve),
                                  perc.disapprove.county = mean(perc.disapprove))

#aggregate from county to region
county.to.region <- zips.to.county %>% 
                      group_by(region.x) %>%
                        summarise(perc.approve.region = mean(perc.approve.county),
                                  perc.disapprove.region = mean(perc.disapprove.county))

#cleaning up the data frame a little so that it is easier to graph
region <- c("Greater Philadelphia", "Greater Philadelphia", "Greater Pittsburgh", "Greater Pittsburgh", "North Central", "North Central", "Northeast", "Northeast", "Northwest", "Northwest", "South Central", "South Central")

approval <- c(37.60090, -62.39910, 40.90050, -59.09950, 21.23016, -78.76984, 34.59077, -65.40923, 36.25000, -63.75000, 16.23623, -83.76377)

color <- c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12)

region.full <- data.frame(region, approval, color)
```

```{r, echo=FALSE}
ggplot(data = region.full,
       aes(x = region, y = approval, fill=as.factor(color)))+
  geom_bar(stat = "identity", width = .8)+
  coord_flip()+
  geom_hline(yintercept = 0)+
  scale_y_continuous(labels = abs, limits = c(-100,100), 
                     name = "Disapprove                                                                          Approve")+
    scale_x_discrete(labels=c("1" = " ", 
                            "2" = " ", 
                            "3" = " "),
                   name= NULL)+ 
  scale_fill_manual(values=c("#FF3399","#FF99CC", "#FF9933", "#FFCC99", "#F6DA21", "#FFE957", "#00CC66", "#CCFFCC", "#0000FF", "#1FDBFF", "#B266FF", "#E5CCFF")) +
  ggtitle("Percent of Support from Independents for the way Joe Biden is Handling his Job as President by Region of Pennsylvania") +
  annotate("text", x = 1, y = 8, size = 10, label = "38%", color = "white") +
  annotate("text", x = 1, y = -10, size = 10, label = "62%", color = "black") +
  annotate("text", x = 2, y = 8, size = 10, label = "41%", color = "white") +
  annotate("text", x = 2, y = -10, size = 10, label = "59%", color = "black") +
  annotate("text", x = 3, y = 8, size = 10, label = "21%", color = "white") +
  annotate("text", x = 3, y = -10, size = 10, label = "79%", color = "black") +
  annotate("text", x = 4, y = 8, size = 10, label = "35%", color = "white") +
  annotate("text", x = 4, y = -10, size = 10, label = "65%", color = "black") +
  annotate("text", x = 5, y = 8, size = 10, label = "36%", color = "white") +
  annotate("text", x = 5, y = -10, size = 10, label = "64%", color = "black") +
  annotate("text", x = 6, y = 8, size = 10, label = "16%", color = "white") +
  annotate("text", x = 6, y = -10, size = 10, label = "84%", color = "black") +
   theme(plot.title = element_text(size = 23),
         axis.text.x = element_text(size = 20),
         axis.text.y = element_text(size = 20),
         axis.title = element_text(size = 20)) +
  theme(legend.position = "none") 
```

The greatest percentages of approval from Independents for Biden came from the Greater Pittsburgh region (at 41% approval), followed by the Greater Philadelphia region (at 38% approval). The next two highest levels of approval came from the Northwest and Northeast regions, at 36% and 35%, respectfully. Finally, the lowest amount of support came from the North Central region (at 21%), and then the South Central region (at 16%). Historically, areas like Philadelphia and Pittsburgh are more Democratic than the Central regions of the state. In the same vein, larger cities are more likely to be Democratic than rural areas, which may explain why the Greater Philadelphia and Pittsburgh regions have the greatest approval ratings among Independents while the North and South Central regions have the lowest. 

Additionally, Biden’s approval rating depends on which party the Independents lean to. In Pittsburgh, for example, only 11% of the Independents lean Democrat. However, 63% lean neither Democratic nor Republican. This data points towards a large percentage of the people who lean to neither party approving of how Biden is handling his job, which would explain why this region has the highest approval rating. Similarly, 34% of Independents in the South Central region lean Republican, while only 12% lean Democrat. This relatively large number of Independents who lean Republican is likely bringing the approval rating for Biden down, indicating the only 16% approval rating from this region. 

__Most Important Policy Issue__

Another demographic that yielded a trend from Independents for the support of the way that Biden was handling his job as President is the most import policy issue picked by the survey respondents.

```{r, echo=FALSE, results=FALSE}
#calculating the weighted means for the issue and biden variables
biden.issue <- independents %>%
          group_by(Q7) %>%
          summarise(perc.strong.approve = weighted.mean(Q15 == "1", weight = WT, na.rm = T),
                    perc.some.approve = weighted.mean(Q15 == "2", weight = WT, na.rm = T),
                    perc.approve = (perc.strong.approve+perc.some.approve),
                    perc.strong.disapprove = weighted.mean(Q15 == "3", weight = WT, na.rm = T),
                    perc.some.disapprove = weighted.mean(Q15 == "4", weight = WT, na.rm = T),
                    perc.disapprove = (perc.strong.disapprove+perc.some.disapprove))

#removing some columns so it is easier to work with
biden.issue <- biden.issue[ -c(2,3,5,6) ]

#cleaning up the data frame a little so that it is easier to graph
issue <- c("COVID-19", "COVID-19", "Inflation", "Inflation", "Economy", "Economy", "Taxes", "Taxes", "Crime", "Crime", "Education", "Education", "Health Care", "Health Care", "Immigartion", "Immigartion", "Russia / Ukraine", "Russia / Ukraine")

approval <- c(54.54545, -45.45455, 27.50000, -72.50000, 22.22222, -77.77778, 16.00000, -84.00000, 37.14286, -62.85714, 35.71429, -64.28571, 53.22581, -46.77419, 15.78947, -84.21053, 51.38889, -48.61111)

color <- c(1, 2, 3, 4, 5, 6, 7, 8, 9 , 10, 11, 12, 13, 14, 15, 16, 17, 18)

issue.full <- data.frame(issue, approval, color)

#fixing the levels of the variable
issue.full$issue <- factor(issue, levels = c("COVID-19", "Inflation", "Economy", "Taxes", "Crime", "Education", "Health Care", "Immigartion", "Russia / Ukraine"))

issue.full$issue <- factor(issue.full$issue, levels = rev(levels(issue.full$issue)))
```

```{r, echo=FALSE, results=FALSE}
ggplot(data = issue.full,
       aes(x = issue, y = approval, fill=as.factor(color)))+
  geom_bar(stat = "identity", width = .8)+
  coord_flip()+
  geom_hline(yintercept = 0)+
  scale_y_continuous(labels = abs, limits = c(-100,100), 
                     name = "Disapprove                                                                          Approve")+
    scale_x_discrete(labels=c("1" = " ", 
                            "2" = " ", 
                            "3" = " "),
                   name= NULL)+ 
  scale_fill_manual(values=c("#FF0000", "#FFD7D7", "#FF9933", "#FFCC99", "#F6DA21", "#FDFFA1", "#00CC66", "#CCFFCC", "#6CE8E0", "#B6FFFB", "#0000FF", "#1FDBFF", "#B266FF", "#E5CCFF", "#FF66FF", "#FFCCFF", "#FF3399","#FF99CC")) +
  ggtitle("Percent of Support by Independents for the way Joe Biden is Handling his Job as President by Most Important Policy Issue") +
  annotate("text", x = 1, y = 8, size = 10, label = "51%", color = "white") +
  annotate("text", x = 1, y = -8, size = 10, label = "49%", color = "black") +
  annotate("text", x = 2, y = 8, size = 10, label = "16%", color = "white") +
  annotate("text", x = 2, y = -8, size = 10, label = "84%", color = "black") +
  annotate("text", x = 3, y = 8, size = 10, label = "53%", color = "white") +
  annotate("text", x = 3, y = -8, size = 10, label = "47%", color = "black") +
  annotate("text", x = 4, y = 8, size = 10, label = "36%", color = "white") +
  annotate("text", x = 4, y = -8, size = 10, label = "64%", color = "black") +
  annotate("text", x = 5, y = 8, size = 10, label = "37%", color = "white") +
  annotate("text", x = 5, y = -8, size = 10, label = "63%", color = "black") +
  annotate("text", x = 6, y = 8, size = 10, label = "16%", color = "white") +
  annotate("text", x = 6, y = -8, size = 10, label = "84%", color = "black") +
  annotate("text", x = 7, y = 8, size = 10, label = "22%", color = "white") +
  annotate("text", x = 7, y = -8, size = 10, label = "78%", color = "black") +
  annotate("text", x = 8, y = 8, size = 10, label = "28%", color = "white") +
  annotate("text", x = 8, y = -8, size = 10, label = "72%", color = "black") +
  annotate("text", x = 9, y = 8, size = 10, label = "55%", color = "white") +
  annotate("text", x = 9, y = -8, size = 10, label = "45%", color = "black") +
   theme(plot.title = element_text(size = 23),
         axis.text.x = element_text(size = 20),
         axis.text.y = element_text(size = 20),
         axis.title = element_text(size = 20)) +
  theme(legend.position = "none") 
```

Independents who picked COVID-19 as their current most important issue had the greatest approval for the way Biden is handling his job, at 55%. Closely afterwards, Independents who picked health care had the next highest approval (at 53%), followed by Independents who picked the situation in Russia and the Ukraine (at 51%). Interestingly, 24% of Independents who picked COVID-19 lean Democrat compared to 9% that lean Republican, 32% of Independents who picked health care lean Democrat compared to 10% that lean Republican, and 38% of Independents who picked the situation in Russia and the Ukraine lean Democrat compared to 17% that lean Republican. Because these three issues (COVID-19, health care, and the situation in Russia and the Ukraine) are important policy issues for Democrats, it makes sense that a relatively high number of Independents who lean Democrat picked these issues as well. 

On the other hand, Independents who picked immigration or taxes as their current most important issue had the greatest disapproval for Biden, both at 84%. Closely afterwards, Independents who picked the economy had the next greatest disapproval for Biden (at 78%), followed by Independents who picked inflation (at 72%). Additionally, 28% of Independents who picked taxes as their most important issue lean Republican compared to the 8% that lean Democrat, 58% of Independents who picked immigration lean Republican compared to the 16% that lean Democrat, 37% of Independents who picked inflation lean Republican compared to the 19% that lean Democrat, and finally 37% of Independents who picked the economy lean Republican compared to the 10% that lean Democrat. This follows a similar trend to the Independents who picked COVID-19, health care, and the situation in Russia and the Ukraine as their most important issues and leaned Democrat –– those Independents who picked issues that Republicans prioritize were also more likely to lean Republican.

 Overall, a survey respondent’s political party showed the greatest trend of whether or not they approved of the way Biden is handling his job as President. Survey respondents who identified as Republican highly disapproved of Biden, while those who identified as Democrat highly approved of Biden. None of this data is surprising – it is the Independents who leaned to a certain side based off of the region in Pennsylvania where they live in and their most important policy issue that drew the most fascinating data points. Based off of this data, Independent’s carry a great deal of weight on Biden’s approval rating.

__Methodology__

This survey was conducted from March 25 through April 3, 2022, by the Penn Program on Opinion Research and Election Studies (PORES) team. It was fielded in Pennsylvania, so all respondents are adult Pennsylvanians. The sample size is 1511 people, made up of 1011 respondents who replied online and 500 respondents who were polled after the phone. Responses were weighted to gender, age, and race and education, and all of the calculations in the article are weighted so that they could better represent the population.


## Criminal Justice Data Analytics

<h2>Criminal Justice Data Analytics</h2>

### Problem Set 1

__Question 1__
```{r}
#load in the LEOKA data
leoka <- read.csv("/Users/briannafisher/Dropbox/Github/BriannaFisher/data/leoka-feloniously killed.csv")
```

__Question 2__
```{r}
#Use square brackets to print the first 3 rows of the data set
leoka[1:3,]
```
The first three rows of data are from Connecticut, Maine, and Massachusetts.

__Question 3__
```{r}
#use a subset to get the number of officers killed in Ohio in 2007
subset(leoka, grepl("Ohio", Area) & (X2007)) 
```
Two officers were killed in Ohio in 2007.

__Question 4__
```{r}
#use a subset to get the states in the East North Central region
east.north <- subset(leoka, grepl("East North Central", Region2))

#use a table to see how many officers were killed in 2012
table(east.north$X2012)
```
Two officers were killed in the East North Central region in 2012.

__Question 5__
```{r}
#Create a dataframe with the columns I want to add up
cols <- c("X2004", "X2005", "X2006", "X2007", "X2008", "X2009","X2010", "X2011", "X2012", "X2013")

#use row sums to add the colums and create a new variable
leoka$total <- rowSums(leoka[,cols])
```

```{r}
#I could have also done this by adding the columns together
leoka$total <- leoka$X2004 + leoka$X2005 + leoka$X2006 + leoka$X2007 + 
  leoka$X2008 + leoka$X2009 + leoka$X2010 + leoka$X2011 + leoka$X2012 +
  leoka$X2013
```

__Question 6__
```{r}
#use max to find the largest number of officers killed
max(leoka$total, na.rm=TRUE)

#use which to find the Area that had 44 officers killed
leoka[which(leoka$total == 44),]
```
Texas and California both had the largest number of officers killed, which was 44 officers.

__Question 7__
```{r}
#use aggregate to find the number of officers killed per region
aggregate(total~Region1, data=leoka, sum) 
```
The region with the largest number of officers killed is the South.

__Question 8__
```{r}
#use which to find the Areas with 0 officers killed
leoka[which(leoka$total == "0"),]
```
The areas that had no officers killed between 2004 and 2013 are Maine, Vermont, Nebraska, Wyoming, American Samoa, Guam, and the Mariana Islands. 

__Question 9__
```{r}
#use which to look where and when 9 officers were killed
leoka[which(leoka$X2004 == "9"),]
leoka[which(leoka$X2005 == "9"),]
leoka[which(leoka$X2006 == "9"),]
leoka[which(leoka$X2007 == "9"),]
leoka[which(leoka$X2008 == "9"),]
leoka[which(leoka$X2009 == "9"),]
leoka[which(leoka$X2010 == "9"),]
leoka[which(leoka$X2011 == "9"),]
leoka[which(leoka$X2012 == "9"),]
leoka[which(leoka$X2013 == "9"),]
```
There were nine officers killed in Texas in 2007. 

__Question 10__
```{r}
#use aggregate to find the number of officers killed per region in 2013
region.2013 <- aggregate(X2013~Region1, data=leoka, sum) 

#use order to sort the data frame from smallest to largest
region.2013.sorted <- region.2013[order(region.2013$X2013),]
```
The Northeast had two officers killed in 2013, the Midwest had four officers killed in 2013, the West had six officers killed in 2013, and the South had 15 officers killed in 2013. 

__Question 11__
```{r}
#use aggregate to find the number of officers killed per region
region.full <- aggregate(total~Region1, data=leoka, sum)

#use the bar plot function to create a bar plot of the number of officers killed by region
barplot(region.full$total, main = "Number of Officers Killed Per Region", xlab = "Region", ylab = "Number of Officers Killed", names = c("Midwest", "Northeast", "Other", "South", "West"), ylim=c(0,250), col = c("red", "orange", "yellow", "green", "blue"))
```

__Question 12__
```{r}
#use the col sums function and the cols data frame created earlier
off.by.year <- colSums(leoka[,cols])

plot(off.by.year, main = "Total Number of Officers Killed By Year", xlab = "Year", ylab = "Number of Officers Killed", xaxt = "n")
axis(1, at = seq(1:10), labels = c("2004", "2005", "2006", "2007", "2008", "2009", "2010", "2011", "2012", "2013"))

barplot(off.by.year)
```

### Problem Set 2

__Question 1__
```{r}
#load in UCR data
load("/Users/briannafisher/Dropbox/CRIM 4002/UCR Assignment/UCRdata copy.rda")

#create a clean ucr data frame
ucr <- data.frame(ORI   =as.character(da35021.0001$V3),
                  AGENCY=as.character(da35021.0001$V29),
                  AREA  =as.character(da35021.0001$V26),
                  POP   =da35021.0001$V14+
                         da35021.0001$V17+
                         da35021.0001$V20,
                  MONTHS=as.character(da35021.0001$V12),
                  STATE=as.character(da35021.0001$V2))

# variable definitions stored in the dataset's attributes
var.lookup <- attributes(da35021.0001)$variable.labels

# tabulate all the murder numbers
var.names <- grep("ACT NUM MURDER",var.lookup,value=TRUE)
var.names <- names(var.names)
ucr$murder <- rowSums(da35021.0001[,var.names])

var.names <- grep("ACT NUM RAPE",var.lookup,value=TRUE)
var.names <- names(var.names)
ucr$rape <- rowSums(da35021.0001[,var.names])

# robbery - taking something by force/threat of force
var.names <- grep("ACT NUM ROBBRY",var.lookup,value=TRUE)
var.names <- names(var.names)
ucr$robbery <- rowSums(da35021.0001[,var.names])

# aggravated assault are #assaults - #simple assaults
#    aggravated assaults - purpose is severe injury, normally with
#       a weapon, 25% guns, 15% knives, 25% hands/feet, rest other
var.names <- grep("ACT NUM ASSLT",var.lookup,value=TRUE)
var.names <- names(var.names)
ucr$assault <- rowSums(da35021.0001[,var.names])
var.names <- grep("ACT # SIMPLE ASSLT",var.lookup,value=TRUE)
var.names <- names(var.names)
ucr$assault <- ucr$assault - rowSums(da35021.0001[,var.names])

# burglary - entering a home/business to steal something
var.names <- grep("ACT # BURGLARY",var.lookup,value=TRUE)
var.names <- names(var.names)
ucr$burglary <- rowSums(da35021.0001[,var.names])

# larceny - stealing something, generally serious
var.names <- grep("ACT # LARCENY",var.lookup,value=TRUE)
var.names <- names(var.names)
ucr$larceny <- rowSums(da35021.0001[,var.names])

# vehicle theft
var.names <- grep("ACT # VHC THEFT",var.lookup,value=TRUE)
var.names <- names(var.names)
ucr$gta <- rowSums(da35021.0001[,var.names])
```

```{r}
#now that the UCR data frame is set up, I can use if else to calculate the homicide rate per 100,000
ucr$hom.rate <- ifelse(ucr$POP == 0, 0, (ucr$murder/ucr$POP)*100000)

#use order to sort the homicide rate from greatest to smallest
i <- order(ucr$hom.rate, decreasing = TRUE)
ucr <- ucr[i,]

#use square brackets to pull the 10 cities with the highest homicide rate
ucr[1:10,]
```
The ten cities with the highest homicide rate per 100,000 residents are Vernon, Suget, Glen Echo Park, Pocahontas, Shorter, Kinloch, Cumberland City, Helper, Sand City, and Whitakers.

__Question 2__
```{r}
#subsetting for cities with more than 100,000 residents
large.city <- subset(ucr, subset = POP > 100000)

#use order to sort the homicide rate from greatest to smallest
hom.order <- order(large.city$hom.rate, decreasing = TRUE)
large.city <- large.city[hom.order,]

#use square brackets to pull the 10 cities with the highest homicide rate
large.city[1:10,]
```
The ten cities  with more than 100,000 residents that have the highest homicide rate per 100,000 residents are Flint, Detroit, New Orleans, Jackson, St. Louis, Baltimore, Newark, Oakland, Birmingham, and Baton Rouge. 

__Question 3__

__Which ten cities have the most costly crime burden?__
```{r}
#creating a cost of homicide variable
ucr$cost.hom <- ucr$murder*5000000

#creating a cost of rape variable
ucr$cost.rape <- ucr$rape*150000

#creating a cost of robbery variable
ucr$cost.robbery <- ucr$robbery*23000

#creating a cost of assault variable
ucr$cost.assault <- ucr$assault*55000

#creating a cost of burglary variable
ucr$cost.burglary <- ucr$burglary*5000

#creating a cost of rape variable
ucr$cost.larceny <- ucr$larceny*2800

#creating a cost of vehicle theft variable
ucr$cost.gta <- ucr$gta*9000

#adding up all the costs of the seven crimes
ucr$total.costs <- with(ucr, cost.hom + cost.rape + cost.robbery + cost.assault + cost.burglary + cost.larceny + cost.gta)

#use order to sort the total costs from greatest to smallest
large.costs <- order(ucr$total.costs, decreasing = TRUE)
ucrCost <- ucr[large.costs,]

#use square brackets to pull the 10 cities with the highest homicide rate
ucrCost[1:10,]

#calculate cost per capita
ucrCost$costpercapita <- with(ucrCost, total.costs/POP)
ucrCost <- subset(ucrCost, POP > 0)
```
Using the accounting method from study 1, the ten cities that have the most costly crime burdens are New York, Chicago, Detroit, Los Angeles, Philadelphia, Houston, Baltimore, Memphis, Dallas, and Phoenix. 

### Problem Set 3

```{r}
#scan in the file with the words
words <- scan(file="/Users/briannafisher/Dropbox/CRIM 4002/Scrabble Assignment/scrabble4letter.txt", what="")
```

__Question 1__
```{r}
grep("^[z]", words, value=TRUE)
```

__Question 2__
```{r}
grep("zz", words, value=TRUE)
```

__Question 3__
```{r}
grep("[^aeiou][^aeiou][^aeiou][^aeiou]", words, value=TRUE)
```

__Question 4__
```{r}
grep("[r]...", words, value=TRUE) #185
grep(".[r]..", words, value=TRUE) #200
grep("..[r].", words, value=TRUE) #354 
grep("...[r]", words, value=TRUE) #123
```
You are most likely to find an "r" in the third letter position. 

__Question 5__
```{r}
rhyme <- grep("(it$)|(itt$)", words, value=TRUE)
rhyme2 <- grep(".[^a]..", rhyme, value=TRUE)
rhyme3 <- grep(".[^o]..", rhyme2, value=TRUE)
rhyme4 <- grep(".[^u]..", rhyme3, value=TRUE)
```

### Problem Set 4
```{r}
#scan in the file with the words
words <- scan(file="/Users/briannafisher/Dropbox/CRIM 4002/Scrabble Assignment/scrabble4letter.txt", what="")
```

__GREP:__

__Question 1__
```{r}
grep("(.)\\1", words, value=TRUE)
#letter one stored in register one followed by letter one called from register one
```

__Question 2__
```{r}
grep("(.)(.)\\2\\1", words, value=TRUE)
#letter one stored in register one, letter two stored in register two, letter two called from register two, letter one called from register one
```


GSUB:

__Question 1__
```{r}
gsub("ll", "l", words)
```

__Question 2__
```{r}
gsub("^g", "G", words)
```

__Question 3__
```{r}
letter <- gsub("([A-Za-z])([A-Za-z])([A-Za-z])([A-Za-z])", "\\1", words)
```

__Question 4__
```{r}
table(letter)
sort(table(letter))
```
S is the most common starting letter

### Problem Set 5
```{r}
# load library for working with SQL databases
library(sqldf)
library(lubridate)

# packages for creating maps
library(leaflet)
library(ggmap)
library(hexbin)

#set up the database 
a <- read.table("incidents_part1_part2_2020.csv",
                sep=",",nrows=30000,header=TRUE)
tail(a)


sure.you.want.to.rebuild.database <- TRUE
if(sure.you.want.to.rebuild.database) # run once to set up the database
{
  # connect to or create a new SQlite database
  con <- dbConnect(SQLite(), dbname="phillycrime.db")
  
  # how is SQLite planning on storing the data?
  variabletypes <- dbDataType(con, a)
  
  # remove a crime table if it already exists
  if(dbExistsTable(con, "crime")) dbRemoveTable(con, "crime")
  # import the cleaned data file into RSQLite
  dbWriteTable(con, "crime",
               "incidents_part1_part2_2020.csv",
               row.names=FALSE,
               header=TRUE,
               field.types=variabletypes,
               sep=",") #" RSQLite doesn't handle commas in quotes
  dbListFields(con,"crime")
  dbDisconnect(con)
}

#connect to the database 
con <- dbConnect(SQLite(), dbname="phillycrime.db")
dbListFields(con,"crime")

```

```{r}
#create the map 
res <- dbSendQuery(con, "
                   SELECT lat,lng,text_general_code,ucr_general
                   FROM crime")
a <- dbFetch(res, n = -1)
dbClearResult(res)

a$lat <- as.numeric(a$lat)
a$lng <- as.numeric(a$lng)

#create baseline of map with lat and long
philly.map <- ggmap(get_map(c(-75.25, 39.93, -75.18, 39.98),
                             scale="auto",source="stamen"))
philly.map

#add points to the map
map.points <- philly.map +
                  geom_point(aes(x=lng,y=lat), data=a,
                    alpha=0.5, color="darkred", size = 1)
map.points

#look at crime type and ucr code
res <- dbSendQuery(con, "
                   SELECT DISTINCT text_general_code, ucr_general
                   FROM crime
                   GROUP BY text_general_code, ucr_general")
dbFetch(res, n = -1)
dbClearResult(res)
```

```{r}
#subset for violent crimes 
#400 - aggravated assault with a firearm, 400 - aggravated assault with no firearm, 
#100 - homicide (criminal), 200 - rape, 300 - robbery with a firearm, 300 - robbery without a firearm 

res <- dbSendQuery(con, "
                   SELECT lat,lng,ucr_general
                   FROM crime
                   WHERE ucr_general='400' OR ucr_general='100' OR ucr_general='200' OR 
                   ucr_general='300'")
b <- dbFetch(res, n = -1)
dbClearResult(res)

b$lat <- as.numeric(b$lat)
b$lng <- as.numeric(b$lng)

#add points to the map
violent.points <- philly.map +
                      geom_point(aes(x=lng,y=lat), data=b,
                         alpha=0.5, color="darkred", size = 1)
violent.points

#subset for each violent crime

#homicide
res <- dbSendQuery(con, "
                   SELECT lat,lng,ucr_general
                   FROM crime
                   WHERE ucr_general='100'")
homicide <- dbFetch(res, n = -1)
dbClearResult(res)

homicide$color <- "Homicide"

#rape
res <- dbSendQuery(con, "
                   SELECT lat,lng,ucr_general
                   FROM crime
                   WHERE ucr_general='200'")
rape <- dbFetch(res, n = -1)
dbClearResult(res)

rape$color <- "Rape"

#robbery
res <- dbSendQuery(con, "
                   SELECT lat,lng,ucr_general
                   FROM crime
                   WHERE ucr_general='300'")
robbery <- dbFetch(res, n = -1)
dbClearResult(res)

robbery$color <- "Robbery"

#aggravated assault
res <- dbSendQuery(con, "
                   SELECT lat,lng,ucr_general
                   FROM crime
                   WHERE ucr_general='400'")
agg.assault <- dbFetch(res, n = -1)
dbClearResult(res)

agg.assault$lat <- as.numeric(agg.assault$lat)
agg.assault$lng <- as.numeric(agg.assault$lng)

agg.assault$color <- "Aggravated Assault"

#add all violent crimes to the map
violent.points.color <- philly.map +
                           geom_point(aes(x=lng,y=lat, fill = color), data=homicide,
                                alpha=0.5, color="darkred", size = 1) +
                          geom_point(aes(x=lng,y=lat, fill = color), data=rape,
                                alpha=0.5, color="blue", size = 1) +
                          geom_point(aes(x=lng,y=lat, fill = color), data=robbery,
                                alpha=0.5, color="yellow", size = 1) +
                          geom_point(aes(x=lng,y=lat, fill = color), data=agg.assault,
                                alpha=0.5, color="hotpink", size = 1) +
                          ggtitle("Violent Crimes in West Philadelphia in 2020") +
                          xlab("Longitude") +
                          ylab("Latitude") 

#add a legend to the plot
cols <- c("Homicide"="darkred", 'Rape'='blue', 'Robbery'='yellow', 'Aggravated Assault'='hotpink')

violent.points.color +
  scale_colour_manual(name="Type of Crime",values=cols) +
  scale_fill_manual(name = "Type of Crime", values = cols,
                  labels = c('Homicide', 'Rape', 'Robbery', 'Aggravated Assault')) +
  guides(color = guide_legend(override.aes = list(color = cols))) 

```


### Problem Set 6
```{r }
#Brianna Fisher
#CRIM 4002
#Regular Expressions and Webscraping Assignment

library(lubridate)

## Trying for one day 07/04/2019

# try scraping the data from one page
a <- scan("https://www.boxofficemojo.com/date/2019-07-04/",
          what="",sep="")

# the HTML code breaks up the table rows across multiple lines
#   this makes it a little difficult to keep the data for the same movie together
# use paste() to collapse the whole page into a single character string
a <- paste(a, collapse=" ")
# it's one long string with thousands of characters
length(a)
nchar(a)

# </tr> is the HTML tag to end a table row
#   chop up the page by the end of row tag
a <- strsplit(a, "</tr>")[[1]]

# remove the first and last
#   everything before the first </tr> is the table header row and all the text above that
#   everything after the last </tr> is the page footer
a <- a[-c(1,length(a))]

# examine the first component
#   it's a mess, but look and you will see the movie name and movie gross in there
a[[1]]

# split each row into separate columns, </td> is the HTML tag to end a table cell
a <- strsplit(a, "</td>")

# again examine the first component
#   now the block of text is split into the separate columns
#   which one has the movie name?
a[[1]]

# movie name is the third component (just like it's the third column in the table)
a[[1]][3]

# remove the HTML tags to leave just the movie name
gsub("<[^>]*>", "", a[[1]][3])

# tell every component of 'a' to extract the 3rd element, stripping HTML tags
sapply(a, function(x) gsub("<[^>]*>","", x[3]) )

# create a data frame with the movie names
data0 <- data.frame(movie = sapply(a, function(x) gsub("<[^>]*>","", x[3]) ))


## trying for every day 01/01/2010 to 10/01/2019

dates.list <- seq(ymd("2010-01-01"), ymd("2019-10-01"), by="days")

results <- vector("list", length(dates.list))

for(i.date in 1:length(dates.list))
{
  # print out our progress
  print(dates.list[i.date])
  
  url.text <- paste0("https://www.boxofficemojo.com/date/",
                     dates.list[i.date], "/")
  
  repeat{
    a <- try(scan(url.text,what="",sep=""))
    if(class(a)=="try-error")
    {
      Sys.sleep(10)
    }else
    {
      break
    }
  }

  # use paste() to collapse the whole page into a single character string
  a <- paste(a, collapse=" ")
  
  #   chop up the page by the end of row tag
  a <- strsplit(a, "</tr>")[[1]]
  
  # remove the first and last
  #   everything before the first </tr> is the table header row and all the text above that
  #   everything after the last </tr> is the page footer
  a <- a[-c(1,length(a))]
  
  # split each row into separate columns, </td> is the HTML tag to end a table cell
  a <- strsplit(a, "</td>")
  
  # get data
  data0 <- data.frame(movie = sapply(a, function(x) gsub("<[^>]*>","", x[3])),
                      gross = sapply(a, function(x) gsub("<[^>]*>|[,$]","", x[4])),
                      date  = dates.list[i.date])

  results[[i.date]] <- data0
  
} 
#else 
  {
  cat("Skipping\n")
}
#}

boxoffice.data <- do.call(rbind,results)

# add day of week
boxoffice.data$day.of.week <- wday(boxoffice.data$date,label=TRUE)

# biggest single day take
boxoffice.data[which.max(boxoffice.data$gross),]
# biggest totals
boxoffice.data$gross <- as.numeric(boxoffice.data$gross)
a <- aggregate(gross~movie, data=boxoffice.data, sum)
a[order(a$gross,decreasing = TRUE)[1:10],]
# gross by day of the week
aggregate(gross~day.of.week, data=boxoffice.data, sum)

# inflation adjust
#   based on average movie ticket prices
a <- data.frame(year=2010:2021,
                adjustment=c(1.36,1.32,1.29,1.27,1.26,
                             1.25,1.24,1.21,1.16,1.15,
                             1.10,1.00))
i <- match(year(boxoffice.data$date), a$year)
boxoffice.data$grossAdj <- boxoffice.data$gross * a$adjustment[i]

boxoffice.data[which.max(boxoffice.data$grossAdj),]
a <- aggregate(grossAdj~movie,data=boxoffice.data, sum)
a[order(a$grossAdj,decreasing = TRUE)[1:10],]

#save the box office data
setwd("/Users/briannafisher/Dropbox/CRIM 4002/Regular Exp and Webscraping Assignment")
save(boxoffice.data,file="boxoffice.RData",compress=TRUE)

#load in movie and box office data
setwd("/Users/briannafisher/Dropbox/CRIM 4002/")
load("11.3/movie revenue.RData")
load("Regular Exp and Webscraping Assignment/boxoffice.RData")

library(kableExtra)
library(dplyr)
library(ggpubr)
library(ggplot2)

#subset for the first day
moviedataDay1 <- subset(movie.data, date == "2010-01-01")
boxofficeDay1 <- subset(boxoffice.data, date == "2010-01-01")

#compare tables for the numbers.com and box office data for one day
table1 <- moviedataDay1 %>% 
            kbl %>% 
            kable_classic()

table2 <- boxofficeDay1 %>% 
            kbl %>% 
            kable_classic()

#Looking at the names of the movies, in the numbers.com data names that are too long are 
#replaced with "&hellip;" instead of the rest of the title. In the box office data, this
#is not done and all of the movie names are complete.

#look at changes over a month

#numbers.com
moviedataMonth <- movie.data[movie.data$date >= "2010-01-01" & movie.data$date <= "2010-01-31", ]

numbers.line <- ggplot(data=moviedataMonth, aes(x=movie, y=gross, group=movie)) +
                    geom_line(aes(color=movie))+
                      geom_point(aes(color=movie))

#box office
boxofficedataMonth <- boxoffice.data[boxoffice.data$date >= "2010-01-01" & boxoffice.data$date <= "2010-01-31", ]

boxoffice.line <- ggplot(data=boxofficedataMonth, aes(x=movie, y=gross, group=movie)) +
                       geom_line(aes(color=movie))+
                          geom_point(aes(color=movie))

combined <- ggarrange(numbers.line, boxoffice.line,
                        labels = c("Number.com", "Box Office"),
                         ncol = 1, nrow = 2)

#it looks like the change in movie gross over the month of January 2010 for both
#the numbers.com and box office data are the same. However, you can see in the list of
#movies that they are not the same

#I want to compare the number of movies per month
movie.month <- aggregate(gross~movie, data = moviedataMonth, FUN = sum)
boxoffice.month <- aggregate(gross~movie, data = boxofficedataMonth, FUN = sum)

#plot numbers.com
movie.month.plot <- ggplot(data= movie.month, aes(x = reorder(movie, gross), 
                                                y = gross, fill = reorder(movie, gross))) +
  geom_bar(stat= "identity") +
  xlab("") +
  ylab("Movie Gross") +
  ggtitle("January 2010 on Numbers.Com") +
  scale_fill_discrete(name = "Movie Name") +
  theme(axis.text.x= element_blank(),
        axis.ticks.x=element_blank())

#plot box office
boxoffice.month.plot <- ggplot(data= boxoffice.month, aes(x = reorder(movie, gross), 
                                                  y = gross, fill = reorder(movie, gross))) +
  geom_bar(stat= "identity") +
  xlab("") +
  ylab("Movie Gross") +
  ggtitle("January 2010 on Box Office") +
  scale_fill_discrete(name = "Movie Name") +
  theme(axis.text.x= element_blank(),
        axis.ticks.x=element_blank())

combined.month <- ggarrange(movie.month.plot, boxoffice.month.plot,
                      ncol = 1, nrow = 2)

nrow(boxoffice.month)
nrow(movie.month)


#While the aggregations look about the same for both websites, there are 29 more movies
#included in the numbers.com data for the month of January 2010 than are included in the
#box office data. It looks like there are missing movies in the box office data, not just
#duplicates or mistakes in the numbers.com data. While the box office data has nicer 
#formatted movie names, I think that it is more important to have all of the data and that
#we should use the numbers.com data set for our comparison with crime. 
```


### Problem Set 7
```{r}
library(sqldf)
library(lubridate)
library(ggmap)
library(reshape2)

setwd("/Users/briannafisher/Dropbox/CRIM 4002/")
con <- dbConnect(SQLite(), dbname="10.11/chicagocrime.db")
load("11.3/movie revenue.RData")
```

```{r}
#look at the relationship between movie revenue and crime

#look at weekdays versus weekends
res <- dbSendQuery(con, "
                      SELECT COUNT(*) AS count,
                             DATE(date) AS date0
                      FROM crime
                      WHERE (CAST(STRFTIME('%w',date) AS INTEGER)>=1)  AND
                            (CAST(STRFTIME('%w',date) AS INTEGER)<=4)  AND
                            (CAST(STRFTIME('%H',date) AS INTEGER)>=18) AND
                            (CAST(STRFTIME('%Y',date) AS INTEGER)>=2010) AND
                            (CAST(STRFTIME('%Y',date) AS INTEGER)<=2019)
                      GROUP BY date0")
weekday <- dbFetch(res, n = -1)
dbClearResult(res)
weekday$date0 <- ymd(weekday$date0)

movie.tab <- aggregate(gross~date, data=movie.data, FUN=sum)

# link the two datasets by date
i <- match(weekday$date0, movie.tab$date)

# merge in the movie gross
weekday$movie.gross <- movie.tab$gross[i]

# transform to 10s of millions of dollars
weekday$movie.gross <- weekday$movie.gross/10000000

plot(count~movie.gross, data=weekday)

#weekends
res <- dbSendQuery(con, "
                      SELECT COUNT(*) AS count,
                             DATE(date) AS date0
                      FROM crime
                      WHERE (CAST(STRFTIME('%w',date) AS INTEGER)>=5)  AND
                            (CAST(STRFTIME('%H',date) AS INTEGER)>=18) AND
                            (CAST(STRFTIME('%Y',date) AS INTEGER)>=2010) AND
                            (CAST(STRFTIME('%Y',date) AS INTEGER)<=2019)
                      GROUP BY date0")
weekend <- dbFetch(res, n = -1)
dbClearResult(res)
weekend$date0 <- ymd(weekend$date0)

# link the two datasets by date
i <- match(weekend$date0, movie.tab$date)

# merge in the movie gross
weekend$movie.gross <- movie.tab$gross[i]

# transform to 10s of millions of dollars
weekend$movie.gross <- weekend$movie.gross/10000000 

plot(count~movie.gross, data=weekend)
```
For both the weekends and weekdays, it looks like there is a little bit of a positive relationship between movie gross and crime, but it is not clearly linear. There are  definitely some outliers on the higher end of movie gross that skew the data, but it looks to be concentrated in the lower end (around 2 million for weekdays and 5 million for weekends). 

```{r}
#look at which days had the most crime
res <- dbSendQuery(con, "
                      SELECT COUNT(*) AS count,
                             DATE(date) AS date0
                      FROM crime
                      WHERE (CAST(STRFTIME('%Y',date) AS INTEGER)>=2010) AND
                            (CAST(STRFTIME('%Y',date) AS INTEGER)<=2019)
                      GROUP BY date0
                      ORDER BY count DESC")
pre.covid <- dbFetch(res, n = -1)
dbClearResult(res)
pre.covid$date0 <- ymd(pre.covid$date0)
head(pre.covid)
```
The four days with the most crime were on January 1, 2011, January 1, 2012, January 1, 2010, and January 1, 2013. It is really interesting that they were all on the same day but different years, and new years day could have something to do with it.

```{r}
#compare these four days to the movies released 
res <- dbSendQuery(con, "
                      SELECT movie,
                             gross
                      FROM movies
                      WHERE (date = '2010-01-01')")
dbFetch(res, n = -1)
dbClearResult(res)

res <- dbSendQuery(con, "
                      SELECT movie,
                             gross
                      FROM movies
                      WHERE (date = '2011-01-01')")
dbFetch(res, n = -1)
dbClearResult(res)

res <- dbSendQuery(con, "
                      SELECT movie,
                             gross
                      FROM movies
                      WHERE (date = '2012-01-01')")
dbFetch(res, n = -1)
dbClearResult(res)

res <- dbSendQuery(con, "
                      SELECT movie,
                             gross
                      FROM movies
                      WHERE (date = '2013-01-01')")
dbFetch(res, n = -1)
dbClearResult(res)
```
It seems like the highest grossing movies on these days had a relatively high gross compared to the other movies playing, meaning that many people were at the movies on these days. This seems like it would counter the idea that there is an incapacitation effect of movies on crime, as these days still had the highest number of crimes committed.

```{r}
#Explore whether the relationship is different depending on crime type.

#looking at violent crime

#assault
#temporary table for assault
res <- dbSendQuery(con, "
                      CREATE TEMPORARY TABLE movie_tab AS
                      SELECT SUM(gross) AS gross,
                             date
                      FROM movies
                      GROUP BY date")
dbClearResult(res)
dbFetch(dbSendQuery(con, "SELECT * FROM movie_tab LIMIT 10"))


res <- dbSendQuery(con, "
                      CREATE TEMPORARY TABLE crime_table AS
                      SELECT COUNT(*) AS count,
                            iucr.PrimaryType,
                             DATE(date) AS date0
                      FROM crime
                           INNER JOIN iucr
                           ON crime.iucr=iucr.iucr
                      GROUP BY iucr.PrimaryType, date0")
dbClearResult(res)
dbFetch(dbSendQuery(con, "SELECT * FROM crime_table LIMIT 10"))


# merge crime and movie data
res <- dbSendQuery(con, "
                      SELECT movie_tab.gross/10000000 AS gross,
                             crime_table.count,
                             movie_tab.date,
                             crime_table.PrimaryType
                      FROM crime_table
                         INNER JOIN movie_tab
                         ON crime_table.date0=movie_tab.date
                      WHERE crime_table.PrimaryType='ASSAULT'")
assault.movie <- dbFetch(res, n = -1)
dbFetch(res, n = 10)
dbClearResult(res)

plot(count~gross,data=assault.movie)

#homicide
res <- dbSendQuery(con, "
                      SELECT movie_tab.gross/10000000 AS gross,
                             crime_table.count,
                             movie_tab.date,
                             crime_table.PrimaryType
                      FROM crime_table
                         INNER JOIN movie_tab
                         ON crime_table.date0=movie_tab.date
                      WHERE crime_table.PrimaryType='HOMICIDE'")
homicide.movie <- dbFetch(res, n = -1)
dbFetch(res, n = 10)
dbClearResult(res)

plot(count~gross,data=homicide.movie)

#robbery
res <- dbSendQuery(con, "
                      SELECT movie_tab.gross/10000000 AS gross,
                             crime_table.count,
                             movie_tab.date,
                             crime_table.PrimaryType
                      FROM crime_table
                         INNER JOIN movie_tab
                         ON crime_table.date0=movie_tab.date
                      WHERE crime_table.PrimaryType='ROBBERY'")
robbery.movie <- dbFetch(res, n = -1)
dbFetch(res, n = 10)
dbClearResult(res)

plot(count~gross,data=robbery.movie)

#rape
res <- dbSendQuery(con, "
                      SELECT movie_tab.gross/10000000 AS gross,
                             crime_table.count,
                             movie_tab.date,
                             crime_table.PrimaryType
                      FROM crime_table
                         INNER JOIN movie_tab
                         ON crime_table.date0=movie_tab.date
                      WHERE crime_table.PrimaryType='CRIMINAL SEXUAL ASSAULT'")
rape.movie <- dbFetch(res, n = -1)
dbFetch(res, n = 10)
dbClearResult(res)

plot(count~gross,data=rape.movie)
```
Looking just at violent crime, it looks like the relationship between robbery and movie revenue and assault and movie revenue are the most similar. This makes sense, since rape are homicide are much rarer than robbery and assault. The number of assaults was mostly concentrated to when movies grossed under 10 million dollars, with some outliers for  assaults when movies grossed more than 10 million, and one closer to 17 million. This is a similar pattern for robberies, with a slight positive correlation that when a movie's revenue is higher, robberies are higher. However, there are many more assaults reported than robberies. For both homicides and rapes, the pattern is relatively flat, as a movie makes more money, the homicide and rape counts stay low. There are some outliers, with some extremely high counts of rape when the movie makes between 5 and 10 million, and one case where there is a homicide count of about 17 when the movie gross is closer to 1 million. 

```{r}
#look at the relationship between weather and crime

#Explore whether crime varies with precipitation

#temporary tables
res <- dbSendQuery(con, "
                      CREATE TEMPORARY TABLE crime_tab AS
                      SELECT COUNT(*) AS count,
                             DATE(date) AS date0,
                      FROM crime
                      GROUP BY date0")
dbClearResult(res)
dbFetch(dbSendQuery(con, "SELECT * FROM crime_tab LIMIT 10"))

# merge crime and weather data
res <- dbSendQuery(con, "
                      SELECT weather.prcp,
                             crime_tab.count,
                             weather.date
                      FROM crime_tab
                         INNER JOIN weather
                         ON crime_tab.date0=weather.date
                      ORDER BY count DESC")
crime.weather <- dbFetch(res, n = -1)
dbClearResult(res)

plot(count~PRCP,data=crime.weather)
```
On the top 10 out of 11 days with the highest counts of crime, the precipitation was 0.00 (with one day being 0.04). However, when looking at the plot of crime count and precipitation, it looks like most crimes occurred when there was a precipitation between 0 and 1. As precipitation increases it looks like crime increases slightly, but there are outliers both at the precipitation and counts ends. 

```{r}
#Explore whether crime varies with temperature

res <- dbSendQuery(con, "
                      SELECT weather.tmax,
                             crime_tab.count,
                             weather.date
                      FROM crime_tab
                         INNER JOIN weather
                         ON crime_tab.date0=weather.date
                      ORDER BY count DESC")
crime.temp <- dbFetch(res, n = -1)
dbClearResult(res)

head(crime.temp, n =10)

plot(count~TMAX,data=crime.temp)
```
Looking at the 10 days with the highest crime counts, there is significant variation in the maximum temperature. The highest is 85 with the lowest being 16, with temperatures everywhere in between for the remaining 8 days. However, looking at the plot you can see a positive association between temperature and crime. As the maximum temperature increases, the count of crime also increases. It seems like the variation seen in the top 10 days is because most days have between 500 and 1300 crimes, and the highest crime day drops from 1899 to 1558 the next day. 

```{r}
#Which crimes seem to be most impacted by weather? Do the relationships suggested in 
#Cohn (1990) hold up in the Chicago data?

#temporary tables
res <- dbSendQuery(con, "
                      CREATE TEMPORARY TABLE crime_type2 AS
                      SELECT COUNT(*) AS count,
                             iucr.PrimaryType,
                             DATE(date) AS date0
                      FROM crime
                          INNER JOIN iucr
                          ON crime.iucr=iucr.iucr
                      GROUP BY iucr.PrimaryType, date0")
dbClearResult(res)
dbFetch(dbSendQuery(con, "SELECT * FROM crime_type2 LIMIT 10"))

# merge crime and weather data
res <- dbSendQuery(con, "
                      SELECT weather.prcp,
                             crime_type2.count,
                             weather.date,
                             crime_type2.PrimaryType
                      FROM crime_type2
                         INNER JOIN weather
                         ON crime_type2.date0=weather.date
                      ORDER BY count DESC")
crime.type<- dbFetch(res, n = -1)
dbClearResult(res)

head(crime.type, n=20)

#temporary tables - temp
res <- dbSendQuery(con, "
                      SELECT weather.tmax,
                             crime_type2.count,
                             weather.date,
                             crime_type2.PrimaryType
                      FROM crime_type2
                         INNER JOIN weather
                         ON crime_type2.date0=weather.date
                      ORDER BY count DESC")
crime.type.tmax<- dbFetch(res, n = -1)
dbClearResult(res)

head(crime.type.tmax, n=20)

#look at assaults
res <- dbSendQuery(con, "
                      SELECT weather.tmax,
                             crime_type2.count,
                             weather.date,
                             crime_type2.PrimaryType
                      FROM crime_type2
                         INNER JOIN weather
                         ON crime_type2.date0=weather.date
                      WHERE crime_type2.PrimaryType='ASSAULT'
                      ORDER BY weather.tmax DESC")
assault.tmax <- dbFetch(res, n = -1)
dbClearResult(res)

head(assault.tmax, n=20)
tail(assault.tmax, n=20)

#look at burglary
res <- dbSendQuery(con, "
                      SELECT weather.tmax,
                             crime_type2.count,
                             weather.date,
                             crime_type2.PrimaryType
                      FROM crime_type2
                         INNER JOIN weather
                         ON crime_type2.date0=weather.date
                      WHERE crime_type2.PrimaryType='BURGLARY'
                      ORDER BY weather.tmax DESC")
burglary.tmax <- dbFetch(res, n = -1)
dbClearResult(res)

head(burglary.tmax, n=20)
tail(burglary.tmax, n=20)

#look at motor vehicle theft
res <- dbSendQuery(con, "
                      SELECT weather.tmax,
                             crime_type2.count,
                             weather.date,
                             crime_type2.PrimaryType
                      FROM crime_type2
                         INNER JOIN weather
                         ON crime_type2.date0=weather.date
                      WHERE crime_type2.PrimaryType='MOTOR VEHICLE THEFT'
                      ORDER BY weather.tmax DESC")
car.tmax <- dbFetch(res, n = -1)
dbClearResult(res)

head(car.tmax, n=20)
tail(car.tmax, n=20)
```
For the top 20 days when there were the highest crime counts, there was 0.00 precipitation  on 15 of those days and thefts on 13 of those days. However, on days with a high amount of rain, theft is a lot less common, with more mixed types of crimes occurring. Looking at the maximum temperature, it seems like there is a mixture of crime types for both the days with the highest and lowest temperatures. This indicates that precipitation may be a larger factor for criminals to consider than temperature. 

It seems like the relationships suggested by Cohn do hold up in the Chicago data. He suggests that assaults increase as temperature increases, which is seen in the data as there are generally more assaults on days when it is hot outside. Similar results are found when looking at burglary, as burglaries increase, so does the temperature. Looking at motor  vehicle theft, there seems to be no association between crime and temperature. Cohn comes to this same conclusion, and says that the two do not appear to be correlated. 

### Problem Set 8

```{r}
# to restart working with the data without having to rerun everything
library(lubridate)
library(sf)
library(leaflet)
library(jsonlite)
library(crayon)
setwd("/Users/briannafisher/Dropbox/CRIM 4002/11.8")
load("PPD OIS before.RData")
PPDmap <- st_read("Boundaries_PSA-shp 2")
```

```{r}
# Use leaflet to check for weird geocode errors
#    color in red those that have low scores or not geocoded to specific point
#    and need a closer review
ois$scoreCol <- "blue"
ois$scoreCol[ois$score<96] <- "red"
ois$scoreCol[ois$loctype %in% c("StreetName")] <- "red"
leaflet(ois) |>
  addTiles() |>
  addCircleMarkers(radius=3,
                   stroke=FALSE,
                   col=~scoreCol,
                   fillOpacity = 1,
                   popup = ~paste0("<b>",location,"</b><br>",
                                   addrmatch,"<br>",
                                   score))

#check the two cases 
#1. Lansdowne Drive - in front of the school where we moved it in class
#2. Loudon Street 
ois[ois$id == "16-03",]

ois$location[ois$id=="16-03"] <- "4300 N. Front Street, Philadelphia, PA"

i <- which(ois$id=="16-03")
ois[i,c("lat","lon")] <- c(40.01537, -75.12589)

#   convert gc.ois to an sf object
a <- st_as_sf(ois,
              coords=c("lon","lat"),
              crs=4326)

plot(st_geometry(PPDmap))
#add means to not replace the original outline but to add points to the top
plot(st_geometry(a), add=TRUE, col="red", pch=16)
ois <- a
is(ois)

# save the final versions
save(ois, file="PPD OIS final.RData")
```

```{r}
#reload in data and redo the map to check that the point is fixed
load("PPD OIS final.RData")

ois$scoreCol <- "blue"
ois$scoreCol[ois$score<96] <- "red"
ois$scoreCol[ois$loctype %in% c("StreetName")] <- "red"
leaflet(ois) |>
  addTiles() |>
  addCircleMarkers(radius=3,
                   stroke=FALSE,
                   col=~scoreCol,
                   fillOpacity = 1,
                   popup = ~paste0("<b>",location,"</b><br>",
                                   addrmatch,"<br>",
                                   score))

# Search for hospitals
ois$hospital <- "fill in"

#look for Presby
i <- grep("Presb",ois$text)
cat(gsub("Presb", bgYellow$black$bold("Presb"), ois$text[i]),
    sep="\n\n")
cat(paste(ois$id[i], collapse='","'))
ois$hospital[ois$id %in% c("22-07","22-03","20-29","19-04","18-02","17-13",
                           "17-30","17-36","16-12","16-13","16-29","16-32",
                           "16-35")] <- "Presby"

#look for Hospital of the University of Pennsylvania
i <- grep("Hospital of the University of Pennsylvania",ois$text)
cat(gsub("Hospital of the University of Pennsylvania", 
         bgYellow$black$bold("Hospital of the University of Pennsylvania"), 
         ois$text[i]),
    sep="\n\n")
cat(paste(ois$id[i], collapse='","'))
ois$hospital[ois$id %in% c("16-01")] <- "HUP"

#look for Temple Hospital
i <- grep("Temple Hospital",ois$text)
cat(gsub("Temple Hospital", 
         bgYellow$black$bold("Temple Hospital"), 
         ois$text[i]),
    sep="\n\n")
cat(paste(ois$id[i], collapse='","'))
ois[ois$id == "22-14",] 
ois[ois$id == "22-10",]
ois[ois$id == "22-06",]
ois$hospital[ois$id %in% c("16-19", "18-28", "19-23", "20-33", "20-34",
                           "22-14", "22-05", "21-10", "16-40", "16-43",
                           "15-09", "20-30", "19-13", "19-14", "19-20",
                           "18-01", "18-28", "17-19", "17-22", "17-23",
                           "17-25", "17-17", "16-07", "16-28", "16-37")] <- "Temple Hospital"


#look for Jefferson Hospital
i <- grep("Jefferson Hospital",ois$text)
cat(gsub("Jefferson Hospital", 
         bgYellow$black$bold("Jefferson Hospital"), 
         ois$text[i]),
    sep="\n\n")
cat(paste(ois$id[i], collapse='","'))
ois[ois$date == "2020-05-09",] 
ois[ois$location == "1300 Chancellor Street, Philadelphia, PA",] 
ois$hospital[ois$id %in% c("20-15", "22-24")] <- "Jefferson Hospital"

#look for Jefferson-Frankford Hospital
i <- grep("Jefferson-Frankford",ois$text)
cat(gsub("Jefferson-Frankford", 
         bgYellow$black$bold("Jefferson-Frankford"), 
         ois$text[i]),
    sep="\n\n")
cat(paste(ois$id[i], collapse='","'))
ois$hospital[ois$id %in% c("20-32")] <- "Jefferson-Frankford"

#look for Jefferson-Torresdale Hospital
i <- grep("Jefferson-Torresdale",ois$text)
cat(gsub("Jefferson-Torresdale", 
         bgYellow$black$bold("Jefferson-Torresdale"), 
         ois$text[i]),
    sep="\n\n")
cat(paste(ois$id[i], collapse='","'))
ois$hospital[ois$id %in% c("20-08", "16-34")] <- "Jefferson-Torresdale"

#look for Einstein Hospital
i <- grep("Einstein Hospital",ois$text)
cat(gsub("Einstein Hospital", 
         bgYellow$black$bold("Einstein Hospital"), 
         ois$text[i]),
    sep="\n\n")
cat(paste(ois$id[i], collapse='","'))
ois$hospital[ois$id %in% c("22-22", "21-06", "21-04", "16-42", "20-26",
                           "17-03", "17-37", "16-10", "16-33")] <- "Einstein Hospital"

#look for Lankenau Hospital
i <- grep("Lankenau Hospital",ois$text)
cat(gsub("Lankenau Hospital", 
         bgYellow$black$bold("Lankenau Hospital"), 
         ois$text[i]),
    sep="\n\n")
cat(paste(ois$id[i], collapse='","'))
ois$hospital[ois$id %in% c("21-15")] <- "Lankenau Hospital"

#look for Episcopal Hospital
i <- grep("Episcopal Hospital",ois$text)
cat(gsub("Episcopal Hospital", 
         bgYellow$black$bold("Episcopal Hospital"), 
         ois$text[i]),
    sep="\n\n")
cat(paste(ois$id[i], collapse='","'))
ois$hospital[ois$id %in% c("16-03")] <- "Episcopal Hospital"


#people who died at the scene / were not injured / did not specify the hospital
ois$hospital[ois$id %in% c("22-10", "22-06", "22-15", "21-14", "20-23",
                           "22-09", "22-08", "22-04", "22-01", "21-12",
                           "21-09", "15-02", "15-06", "15-10", "15-12",
                           "20-31", "20-07", "20-20", "20-24", "19-06",
                           "19-09", "19-11", "19-21", "18-08", "18-12",
                           "18-19", "18-25", "18-27", "17-20", "17-28",
                           "20-09", "20-12", "18-16", "18-17", "18-22",
                           "18-26", "16-02", "16-11", "16-16", "16-18",
                           "16-30", "16-38")] <- "NA"

#make sure all of the hospitals are there
sum(table(ois$hospital)) #+42 NA's


#get the coordinates for each hospital
hospitals <- textConnection(
  "hospital;address;lon;lat
Presby;51 N 39th St, Philadelphia, PA 19104;-75.19880;39.95887
HUP;3400 Spruce St, Philadelphia, PA 19104;-75.19361;39.94999
Temple;3401 N Broad St, Philadelphia, PA 19140;-75.150819;40.005273
Jefferson;111 S 11th St, Philadelphia, PA 19107;-75.158308;39.949733
Jefferson-Frankford;4900 Frankford Ave, Philadelphia, PA 19124;-75.081505;40.019822
Jefferson-Torresdale;10800 Knights Rd, Philadelphia, PA 19114;-74.982773;40.071286
Einstein;5501 Old York Rd, Philadelphia, PA  19141;-75.142147;40.036707
Lankenau;100 E Lancaster Ave, Wynnewood, PA  19096;-75.261515;39.987894
Episcopal;100 E Lehigh Ave, Philadelphia, PA  19125;-75.128937;39.990027")
hospitals <- read.table(hospitals, sep=";", header=TRUE)

#if you use the geocode function instead of adding coordinates
# a <- lapply(hospitals$address, geocodeARCGIS)
# hospitals$lon <- sapply(a, function(x) x$candidates$location$x[1])
# hospitals$lat <- sapply(a, function(x) x$candidates$location$y[1])

#create colors for each hospital
#hospitals$col <- hcl.colors(nrow(hospitals), "Blue-Red 3)
```

```{r}
# convert to sf object
hospitals <- st_as_sf(hospitals,    
                      coords=c("lon","lat"),
                      crs=4326)

#plot the locations of each hospital
plot(st_geometry(PPDmap))
plot(st_geometry(hospitals), add=TRUE, pch=19, col="blue")

#add a label
#text(st_coordinates(hospitals), labels = substring(hospitals$hospital,1,2))

#plot the officer involved shootings that resulted in a hospital visit
ois.hospital <- subset(ois, ois$hospital!="NA")
plot(st_geometry(ois.hospital), add=TRUE, pch=19, col="hotpink")
```

```{r}
#calculate the distance from each shooting to the hospitals
dist <- st_distance(ois.hospital, hospitals)

#add column to find which hospital is closest
ois.hospital$closest <- NA
for(i in 1:nrow(ois.hospital))
{
  
  results <- which.min(dist[i,])
  
  if (results == 1) {
    ois.hospital$closest[i] <- "Presby"
  } else if (results == 2) {
    ois.hospital$closest[i] <- "HUP"
  } else if (results == 3) {
    ois.hospital$closest[i] <- "Temple Hospital"
  } else if (results == 4) {
    ois.hospital$closest[i] <- "Jefferson Hospital"
  } else if (results == 5) {
    ois.hospital$closest[i] <- "Jefferson-Frankford Hospital"
  } else if (results == 6) {
    ois.hospital$closest[i] <- "Jefferson-Torresdale Hospital"
  } else if (results == 7) {
    ois.hospital$closest[i] <- "Einstein Hospital"  
  } else if (results == 8) {
    ois.hospital$closest[i] <- "Lankenau Hospital"
  } else if (results == 9) {
    ois.hospital$closest[i] <- "Episcopal Hospital"  
  } else {
    cat("Skipping\n")
  }
}

#another way to do this
# iclosest <- apply(dist, 1, which.min)
# table(actual=hospitals$hospital[i],
#  closest=hospitals$hospital[iclosest])
# 100*mean(i==iclosest)


#add column to see whether they were taken to the closest hospital
ois.hospital$yes.closest <- NA
for(i in 1:nrow(ois.hospital))
{
  if (ois.hospital$hospital[i] == ois.hospital$closest[i]) {
    ois.hospital$yes.closest[i] <- 1
  } else {
    ois.hospital$yes.closest[i] <- 0
  }
}

```


```{r}
#calculate in what percentage of PPD shootings do PPD officers transport the individuals 
#they shoot to the nearest hospital?

(sum(ois.hospital$yes.closest == 1))/54
```
In 44% of PPD shootings PPD officers transport the individuals they shoot to the 
#nearest hospitals.

### Final Exam

__1. Setup the data, load the libraries, and inspect the data__

__a. Load `finaldata2022.RData` file and the `lubridate` and `sf` packages. `finaldata2022.RData` contains two R objects:  `stops` is a data frame with all traffic stops made in Nashville in 2017 and 2018.  `precincts` is a geographic object describing the Nashville Police Precincts. (2 points)__
```{r}
load("finaldata2022.RData")

library(lubridate)
library(sf)
```

__b. Show the first 2 lines of the `stops` dataset. (2 points)__
```{r}
stops[1:2,]
```

__c. Write code that outputs the column names of the `stops` dataset. For the stop recorded in row 150, report the `violation` for which the driver was stopped and the `outcome` of the stop. (3 points)__
```{r}
names(stops)
stops[150, c("violation", "outcome")]
```
For row 150, the violation was a safety violation and the outcome was a warning.

__d. How many rows and columns are there in the `stops` dataset? (2 points)__
```{r}
nrow(stops)
ncol(stops)
dim(stops)
```
There are 449782 rows and 18 columns in the dataset. 

__e. There is a single individual who was arrested (`arrest_made`) after a stop for "child restraint" (`violation`). Write code that displays the sex, age, and race of this individual.  (2 points)__
```{r}
with(stops, subject_sex[arrest_made == TRUE & violation == "child restraint"])
with(stops, subject_age[arrest_made == TRUE & violation == "child restraint"])
with(stops, subject_race[arrest_made == TRUE & violation == "child restraint"])
```
The individual who was arrested for a child restraint violation is a 61 year old Black female.

__2. Fix Data Errors, Work with Time Variables and Create a New Dataset__

__a. Use the appropriate `lubridate` functions to transform `date` into a properly formatted and stored date object. Also, create a new variable in the `stops` data frame called `year` for the year in which a stop was made. (2 points)__
```{r}
stops$date <- ymd(stops$date)
is(stops$date) #check that it worked

stops$year <- year(stops$date)
is(stops$year)
table(stops$year)
```

__b. Create a new data frame called `stops_underage` that only contains stops from 2018 of underage drivers (younger than 16). (2 points)__
```{r}
stops_underage <- subset(stops, year == 2018 & subject_age < 16)
table(stops_underage$subject_age)
table(stops_underage$year)
```

__c. In your `stops_underage` dataset, how old was the youngest stopped driver in 2018? How many drivers stopped were (strictly) younger than 14? (2 points)__
```{r}
table(stops_underage$subject_age)
```
The youngest driver that was stopped in 2018 was 10 years old.

```{r}
sum(stops_underage$subject_age == 10)+sum(stops_underage$subject_age == 11)+
  sum(stops_underage$subject_age == 12)+sum(stops_underage$subject_age == 13)
1+1+2+3 #or add up the table responses
```
7 drivers were stopped that were younger than 14.

__d. What percent of all stop locations in the full `stop` dataset include the words `MURFEESBORO PIKE`? (Hint: You might want to use `grepl()`.) (4 points)__
```{r}
sum(grepl("MURFREESBORO PIKE", stops$location))

(28555/449782)*100
```
6.35% of the stop locations include the words Murfreesboro Pike

__e. Drop all stops for which no time was recorded in the dataset. (2 points)__
```{r}
sum(is.na(stops$time))
stops <- subset(stops, stops$time != is.na(stops$time))
```

__f. Count the number of stops that were recorded to occur *exactly* on the hour or at half past the hour. (e.g. ..., 09:30:00, 10:00:00, 10:30:00, ...). (Hint: consider using `grep()`) (4 points)__
```{r}
sum(table(grep("[0-9]\\:(0)(0)\\:(0)(0)|[0-9]\\:(3)(0)\\:(0)(0)", stops$time, value=TRUE)))
```
There were 19159 stops recorded to occur exactly on the hour or at half past the hour.

__g. Create a new column called `hour_of_stop` that lists the hour in which a stop was made. In what hour of the day do officers make the least stops? (4 points)__
```{r}
stops$time <- hms(stops$time)
stops$hour_of_stop <- hour(stops$time)

sort(table(stops$hour_of_stop))
```
Officers make the least amount of stops at 6 am.

__h. Create a new variable called `drugs_or_weapons` that equals 1 if `contraband_weapons` or `contraband_drugs` is `TRUE` and equals 0 otherwise. For each stop `outcome`, calculate the percentage of stops in which either drugs or weapons were found. For which value of `outcome` do the police most frequently find contraband (weapons or drugs)? (Hint: Use `aggregate()`) (5 points)__
```{r}
stops$drugs_or_weapons <- 0
stops$drugs_or_weapons[stops$contraband_drugs == "TRUE" | stops$contraband_weapons == "TRUE"] <- 1

aggregate(drugs_or_weapons~outcome, stops, mean)
```
Police most frequently find contraband when the outcome of the stop is an arrest.

__i. For each `stop_precinct`, how many unique zones are there? (Hint: `function(x) length(unique(x))` will give you the number of unique values... consider combining with `aggregate()`) (3 points)__
```{r}
length(unique(stops$stop_precinct))

table(stops$zone)
aggregate(zone~stop_precinct, stops, unique)
```
For precinct 1, there are 7 unique zones. For precinct 2, there are 8 unique zones. For precinct 3, there are 10 unique zones. For precinct 4, there are 6 unique zones. For precinct 5, there are 11 unique zones. For precinct 6, there are 8 unique zones. For precinct 7, there are 7 unique zones. For precinct 8, there are 9 unique zones.

__j. Calculate the number of stops in 2018 by month of stop and type of `violation`. (4 points)__
```{r}
stops$month <- month(stops$date)
aggregate(raw_row_number~violation+month, subset(stops, year == 2018), length)
```

__3. Examine the behavior of Officer ffd40c04a1__

__a. Create a new dataframe called `officer1` that contains all stops made by officer with `officer_id` ffd40c04a1. (2 points).__
```{r}
officer1 <- subset(stops, officer_id == "ffd40c04a1")
```

__b. How many days passed between the first day on which this officer made a stop, and the last day on which this officer made a stop? (Hint: Use `difftime()` to calculate the number of days.) (5 points)__
```{r}
difftime(max(officer1$date),
          min(officer1$date),
          units = "days")

range(officer1$date)

difftime("2018-12-07",
         "2017-01-03",
         units = "days")
```
703 days passed between the first day on which this officer made a stop and the last day.

__c. On what day did Officer ffd40c04a1 make the most stops? What do you notice about the location of the stops that this officer made on this day? (4 points)__
```{r}
sort(table(officer1$date))
officer1[officer1$date == "2018-06-10",]
```
Officer ffd40c04a1 made the most stops of 06/10/2018. The location for all of these stops on this day is the same place.

__d. Create `arrestDates` to be the collection of dates on which Officer ffd40c04a1 made an arrest. For each of the dates in `arrestDates`, count how many stops the officer made. (4 points)__
```{r}
arrestDates <- subset(officer1, arrest_made == "TRUE")

officer1[officer1$date == "2017-01-11",] #3
officer1[officer1$date == "2017-04-05",] #3
officer1[officer1$date == "2017-06-22",] #1
officer1[officer1$date == "2018-01-04",] #2
officer1[officer1$date == "2018-01-19",] #1
officer1[officer1$date == "2018-02-01",] #2
officer1[officer1$date == "2018-03-05",] #1
officer1[officer1$date == "2018-03-26",] #1
officer1[officer1$date == "2018-04-10",] #1
officer1[officer1$date == "2018-06-20",] #1
```

__e. Create a function called `last_stop_arrest()` that takes in a date and returns `TRUE` if the officer made an arrest during their last stop on the given day, and `FALSE` otherwise. Use your function `last_stop_arrest()` to check if the last stop on `"2017-01-11"` involved an arrest. `last_stop_arrest("2017-01-11")` should give you a value of `TRUE` or `FALSE`. (6 points)__
```{r}
last_stop_arrest <- function(x)
{
  if (isTRUE(max(officer1$time[x])) ==
      isTRUE(officer1$arrest_made[x] == "TRUE")) {
    return( TRUE )
  } else {
    return( FALSE )
  }
}

last_stop_arrest("2017-01-11")
```
2017-01-11 did involve an arrest.

__f. Make a barplot counting the number of Officer ffd40c04a1's stops by `outcome`. Label both the x and y axis and name the graph. (5 points)__
```{r}
data <- aggregate(raw_row_number~outcome, officer1, length)

barplot(data$raw_row_number, names.arg = data$outcome, ylab = "Number of Stops",
        xlab = "Outcome", main = "Officer ffd40c04a1's Stops by Outcome")
```

__4. Work with geographic data__

__a. Plot the Nashville Police Precincts (2 points)__
```{r}
plot(st_geometry(precincts))
```

__b. Plot `precincts` and add the precinct names as labels. Use `st_centroid()` and `st_coordinates()` to retrieve the coordinates of the centers of precincts and `text()` to add the labels. Make sure the names are small enough that they do not overlap each other. (Ignore warnings of "st_centroid assumes attributes are constant over geometries of x") (6 points)__
```{r}
plot(st_geometry(precincts))
labs <- with(precincts, paste0(precincts$precinct))
text(st_coordinates(st_centroid(precincts)),
     labels=labs, col="hotpink", cex = 0.5)
```

__c. Make a data frame called `arrests` containing only stops resulting in arrests, eliminating all observations with missing latitude or longitude. (3 points)__
```{r}
arrests <- subset(stops, arrest_made == "TRUE" & lat != is.na(lat) & lng != is.na(lng))
```

__d. Convert `arrests` into an `sf` spatial object called `arrests_sf`. You need to specify the correct values for `coords` and `crs`. Then make sure your new `arrests_sf` has the same CRS as `precincts`, transforming if necessary. (5 points)__
```{r}
arrests_sf <- st_as_sf(arrests,
                     coords=c("lng","lat"),
                     crs=4326)

st_crs(precincts)
arrests_sf <- st_transform(arrests_sf, st_crs(precincts))
```

__e. Plot the police precincts and plot all arrest locations. Color the districts in grey and arrests in red. Additionally, for arrests set arguments `pch=20` and `cex=0.3`. By looking at the map, are there any arrests outside the city boundaries? (5 points)__
```{r}
plot(st_geometry(precincts), col = "grey")
plot(st_geometry(arrests_sf), add = TRUE, col = "red", pch = 20, cex = 0.3)
```
By looking at the map, there looks like there is one arrest outside of city boundaries in the top right hand corner.

__f. Use `st_join()` to determine in which precinct each arrest occurred. To do so, note the `precincts` map object has a column called `precinct`. Use `st_join()` to merge `arrests_sf` with `precincts[,"precinct"]` making a new object called `arrests_precincts`. (3 points)__
```{r}
arrests_precincts <- st_join(arrests_sf, precincts[,"precinct"])
```

__g. `stop_precinct` reports the precinct in which the officer reported the stop occurred. Of the arrests the officer reported occurred in precinct 4 (which is the CENTRAL precinct), how many of the arrests had coordinates that were not in the CENTRAL precinct? (2 points)__
```{r}
precinct4 <- subset(arrests_precincts, stop_precinct == 4)
central <- subset(precincts, precinct == "CENTRAL")

i <- st_intersects(precinct4, central)
precinct4$incentral <- lengths(i) > 0

table(precinct4$incentral)
```
There are 10 arrests that had coordinates that were not in the central precinct

__h. Plot just the CENTRAL precinct. Color the precinct in grey and arrests in red. Plot a blue triangle (`pch=17`) for the one individual whose race is "unknown". Make the blue triangle bigger than the red dots so that it is easier to see. (6 points)__
```{r}
plot(st_geometry(subset(precincts, precinct == "CENTRAL")), col = "grey")
plot(st_geometry(subset(arrests_precincts, precinct == "CENTRAL")), 
     col = "red", add = TRUE, pch = 20, cex = 0.3)
plot(st_geometry(subset(arrests_precincts, precinct == "CENTRAL" & subject_race == "unknown")), 
     col = "blue", add = TRUE, pch = 17, cex = 1)
```

__i. For each precinct, compute the percentage of arrests for which contraband drugs are found. Color precincts with drug recovery rates between 0-15% `white`, 15%-20% `orange`, and over 20% `red`. (8 points)__
```{r}
drug.data <- aggregate(drugs_or_weapons~precinct, arrests_precincts, mean)

i <- match(precincts$precinct, drug.data$precinct)
precincts$drugs_or_weapons <- drug.data$drugs_or_weapons[i]

plot(st_geometry(precincts), col = "grey")
plot(st_geometry(subset(precincts, precinct == "CENTRAL")), col = "orange", add = TRUE)
plot(st_geometry(subset(precincts, precinct == "EAST")), col = "white", add = TRUE)
plot(st_geometry(subset(precincts, precinct == "HERMITAGE")), col = "white", add = TRUE)
plot(st_geometry(subset(precincts, precinct == "MADISON")), col = "orange", add = TRUE)
plot(st_geometry(subset(precincts, precinct == "MIDTOWN-HILLS")), col = "red", add = TRUE)
plot(st_geometry(subset(precincts, precinct == "NORTH")), col = "red", add = TRUE)
plot(st_geometry(subset(precincts, precinct == "SOUTH")), col = "orange", add = TRUE)
plot(st_geometry(subset(precincts, precinct == "WEST")), col = "orange", add = TRUE)
```























